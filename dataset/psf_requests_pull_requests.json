[
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-18T02:19:46Z",
        "closed_at": "2023-10-18T06:08:52Z",
        "merged_at": "2023-10-18T06:08:52Z",
        "body": "added assert statements tests/test_requests/test_header_validation in regards to the issue #6551",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-10-06T20:10:28Z",
        "closed_at": "2023-10-06T22:34:24Z",
        "merged_at": "2023-10-06T22:34:24Z",
        "body": "This should resolve #6544.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2023-09-25T16:28:36Z",
        "closed_at": "2023-09-25T18:30:06Z",
        "merged_at": "2023-09-25T18:30:06Z",
        "body": "Bumps [actions/checkout](https://github.com/actions/checkout) from 4.0.0 to 4.1.0.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/actions/checkout/releases\">actions/checkout's releases</a>.</em></p>\n<blockquote>\n<h2>v4.1.0</h2>\n<h2>What's Changed</h2>\n<ul>\n<li>Update README.md for V4 by <a href=\"https://github.com/sivapalan\"><code>@\u200bsivapalan</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1452\">actions/checkout#1452</a></li>\n<li>Add support for partial checkout filters by <a href=\"https://github.com/finleygn\"><code>@\u200bfinleygn</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1396\">actions/checkout#1396</a></li>\n<li>Prepare 4.1.0 release by <a href=\"https://github.com/cory-miller\"><code>@\u200bcory-miller</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1496\">actions/checkout#1496</a></li>\n</ul>\n<h2>New Contributors</h2>\n<ul>\n<li><a href=\"https://github.com/sivapalan\"><code>@\u200bsivapalan</code></a> made their first contribution in <a href=\"https://redirect.github.com/actions/checkout/pull/1452\">actions/checkout#1452</a></li>\n<li><a href=\"https://github.com/finleygn\"><code>@\u200bfinleygn</code></a> made their first contribution in <a href=\"https://redirect.github.com/actions/checkout/pull/1396\">actions/checkout#1396</a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/actions/checkout/compare/v4.0.0...v4.1.0\">https://github.com/actions/checkout/compare/v4.0.0...v4.1.0</a></p>\n</blockquote>\n</details>\n<details>\n<summary>Changelog</summary>\n<p><em>Sourced from <a href=\"https://github.com/actions/checkout/blob/main/CHANGELOG.md\">actions/checkout's changelog</a>.</em></p>\n<blockquote>\n<h1>Changelog</h1>\n<h2>v4.1.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1396\">Add support for partial checkout filters</a></li>\n</ul>\n<h2>v4.0.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1067\">Support fetching without the --progress option</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1436\">Update to node20</a></li>\n</ul>\n<h2>v3.6.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1377\">Fix: Mark test scripts with Bash'isms to be run via Bash</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/579\">Add option to fetch tags even if fetch-depth &gt; 0</a></li>\n</ul>\n<h2>v3.5.3</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1196\">Fix: Checkout fail in self-hosted runners when faulty submodule are checked-in</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1287\">Fix typos found by codespell</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1369\">Add support for sparse checkouts</a></li>\n</ul>\n<h2>v3.5.2</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1289\">Fix api endpoint for GHES</a></li>\n</ul>\n<h2>v3.5.1</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1246\">Fix slow checkout on Windows</a></li>\n</ul>\n<h2>v3.5.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1237\">Add new public key for known_hosts</a></li>\n</ul>\n<h2>v3.4.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1209\">Upgrade codeql actions to v2</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1210\">Upgrade dependencies</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1225\">Upgrade <code>@\u200bactions/io</code></a></li>\n</ul>\n<h2>v3.3.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1045\">Implement branch list using callbacks from exec function</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1050\">Add in explicit reference to private checkout options</a></li>\n<li>[Fix comment typos (that got added in <a href=\"https://redirect.github.com/actions/checkout/issues/770\">#770</a>)](<a href=\"https://redirect.github.com/actions/checkout/pull/1057\">actions/checkout#1057</a>)</li>\n</ul>\n<h2>v3.2.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/942\">Add GitHub Action to perform release</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/967\">Fix status badge</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1002\">Replace datadog/squid with ubuntu/squid Docker image</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/964\">Wrap pipeline commands for submoduleForeach in quotes</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1029\">Update <code>@\u200bactions/io</code> to 1.1.2</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1039\">Upgrading version to 3.2.0</a></li>\n</ul>\n<h2>v3.1.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/939\">Use <code>@\u200bactions/core</code> <code>saveState</code> and <code>getState</code></a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/922\">Add <code>github-server-url</code> input</a></li>\n</ul>\n<h2>v3.0.2</h2>\n<!-- raw HTML omitted -->\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/actions/checkout/commit/8ade135a41bc03ea155e62e844d188df1ea18608\"><code>8ade135</code></a> Prepare 4.1.0 release (<a href=\"https://redirect.github.com/actions/checkout/issues/1496\">#1496</a>)</li>\n<li><a href=\"https://github.com/actions/checkout/commit/c533a0a4cfc4962971818edcfac47a2899e69799\"><code>c533a0a</code></a> Add support for partial checkout filters (<a href=\"https://redirect.github.com/actions/checkout/issues/1396\">#1396</a>)</li>\n<li><a href=\"https://github.com/actions/checkout/commit/72f2cec99f417b1a1c5e2e88945068983b7965f9\"><code>72f2cec</code></a> Update README.md for V4 (<a href=\"https://redirect.github.com/actions/checkout/issues/1452\">#1452</a>)</li>\n<li>See full diff in <a href=\"https://github.com/actions/checkout/compare/3df4ab11eba7bda6032a0b82a6bb43b11571feac...8ade135a41bc03ea155e62e844d188df1ea18608\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=actions/checkout&package-manager=github_actions&previous-version=4.0.0&new-version=4.1.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n\n\n</details>",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 39,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2023-09-13T14:36:49Z",
        "closed_at": "2023-10-11T16:29:20Z",
        "merged_at": "2023-10-11T16:29:20Z",
        "body": "We spend a fair amount of time closing issues because people don't read the template closely or understand what they're being told. Let's take advantage of being able to auto-label an issue based on the template and then trigger a workflow to auto-magically close the issue with a message and lock the issue.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 40,
        "deletions": 30,
        "changed_files": 1,
        "created_at": "2023-09-07T21:41:42Z",
        "closed_at": "2023-09-07T23:05:53Z",
        "merged_at": null,
        "body": "Any thoughts here? \r\n\r\nI felt like the exception driven logic of `ok()` wasn't ideal, so I went in an added a new method: `is_raisable_status()`, which basically checks if the response code is 400 or more (could be improved?). \r\n\r\nAlso put `reason = self.decode_reason()` reason decoding into its own method.\r\n\r\nIf theres interest in getting this change pushed thru, I'll put in the effort to get unit tests updated and written, and update some of the method documentation \ud83d\ude02  ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2023-09-04T16:21:28Z",
        "closed_at": "2023-09-05T00:17:08Z",
        "merged_at": "2023-09-05T00:17:08Z",
        "body": "Bumps [actions/checkout](https://github.com/actions/checkout) from 3.6.0 to 4.0.0.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/actions/checkout/releases\">actions/checkout's releases</a>.</em></p>\n<blockquote>\n<h2>v4.0.0</h2>\n<h2>What's Changed</h2>\n<ul>\n<li>Update default runtime to node20 by <a href=\"https://github.com/takost\"><code>@\u200btakost</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1436\">actions/checkout#1436</a></li>\n<li>Support fetching without the --progress option by <a href=\"https://github.com/simonbaird\"><code>@\u200bsimonbaird</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1067\">actions/checkout#1067</a></li>\n<li>Release 4.0.0 by <a href=\"https://github.com/takost\"><code>@\u200btakost</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1447\">actions/checkout#1447</a></li>\n</ul>\n<h2>New Contributors</h2>\n<ul>\n<li><a href=\"https://github.com/takost\"><code>@\u200btakost</code></a> made their first contribution in <a href=\"https://redirect.github.com/actions/checkout/pull/1436\">actions/checkout#1436</a></li>\n<li><a href=\"https://github.com/simonbaird\"><code>@\u200bsimonbaird</code></a> made their first contribution in <a href=\"https://redirect.github.com/actions/checkout/pull/1067\">actions/checkout#1067</a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/actions/checkout/compare/v3...v4.0.0\">https://github.com/actions/checkout/compare/v3...v4.0.0</a></p>\n</blockquote>\n</details>\n<details>\n<summary>Changelog</summary>\n<p><em>Sourced from <a href=\"https://github.com/actions/checkout/blob/main/CHANGELOG.md\">actions/checkout's changelog</a>.</em></p>\n<blockquote>\n<h1>Changelog</h1>\n<h2>v4.0.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1067\">Support fetching without the --progress option</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1436\">Update to node20</a></li>\n</ul>\n<h2>v3.6.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1377\">Fix: Mark test scripts with Bash'isms to be run via Bash</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/579\">Add option to fetch tags even if fetch-depth &gt; 0</a></li>\n</ul>\n<h2>v3.5.3</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1196\">Fix: Checkout fail in self-hosted runners when faulty submodule are checked-in</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1287\">Fix typos found by codespell</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1369\">Add support for sparse checkouts</a></li>\n</ul>\n<h2>v3.5.2</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1289\">Fix api endpoint for GHES</a></li>\n</ul>\n<h2>v3.5.1</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1246\">Fix slow checkout on Windows</a></li>\n</ul>\n<h2>v3.5.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1237\">Add new public key for known_hosts</a></li>\n</ul>\n<h2>v3.4.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1209\">Upgrade codeql actions to v2</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1210\">Upgrade dependencies</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1225\">Upgrade <code>@\u200bactions/io</code></a></li>\n</ul>\n<h2>v3.3.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1045\">Implement branch list using callbacks from exec function</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1050\">Add in explicit reference to private checkout options</a></li>\n<li>[Fix comment typos (that got added in <a href=\"https://redirect.github.com/actions/checkout/issues/770\">#770</a>)](<a href=\"https://redirect.github.com/actions/checkout/pull/1057\">actions/checkout#1057</a>)</li>\n</ul>\n<h2>v3.2.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/942\">Add GitHub Action to perform release</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/967\">Fix status badge</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1002\">Replace datadog/squid with ubuntu/squid Docker image</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/964\">Wrap pipeline commands for submoduleForeach in quotes</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1029\">Update <code>@\u200bactions/io</code> to 1.1.2</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1039\">Upgrading version to 3.2.0</a></li>\n</ul>\n<h2>v3.1.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/939\">Use <code>@\u200bactions/core</code> <code>saveState</code> and <code>getState</code></a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/922\">Add <code>github-server-url</code> input</a></li>\n</ul>\n<h2>v3.0.2</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/770\">Add input <code>set-safe-directory</code></a></li>\n</ul>\n<h2>v3.0.1</h2>\n<!-- raw HTML omitted -->\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/actions/checkout/commit/3df4ab11eba7bda6032a0b82a6bb43b11571feac\"><code>3df4ab1</code></a> Release 4.0.0 (<a href=\"https://redirect.github.com/actions/checkout/issues/1447\">#1447</a>)</li>\n<li><a href=\"https://github.com/actions/checkout/commit/8b5e8b768746b50394015010d25e690bfab9dfbc\"><code>8b5e8b7</code></a> Support fetching without the --progress option (<a href=\"https://redirect.github.com/actions/checkout/issues/1067\">#1067</a>)</li>\n<li><a href=\"https://github.com/actions/checkout/commit/97a652b80035363df47baee5031ec8670b8878ac\"><code>97a652b</code></a> Update default runtime to node20 (<a href=\"https://redirect.github.com/actions/checkout/issues/1436\">#1436</a>)</li>\n<li>See full diff in <a href=\"https://github.com/actions/checkout/compare/f43a0e5ff2bd294095638e18286ca9a3d1956744...3df4ab11eba7bda6032a0b82a6bb43b11571feac\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=actions/checkout&package-manager=github_actions&previous-version=3.6.0&new-version=4.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n\n\n</details>",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-08-29T05:43:16Z",
        "closed_at": "2023-08-29T14:27:11Z",
        "merged_at": "2023-08-29T14:27:11Z",
        "body": "Remove `pytest.ini` in `MANIFEST.in`",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2023-08-28T16:12:38Z",
        "closed_at": "2023-08-28T19:05:57Z",
        "merged_at": "2023-08-28T19:05:57Z",
        "body": "Bumps [actions/checkout](https://github.com/actions/checkout) from 3.5.3 to 3.6.0.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/actions/checkout/releases\">actions/checkout's releases</a>.</em></p>\n<blockquote>\n<h2>v3.6.0</h2>\n<h2>What's Changed</h2>\n<ul>\n<li>Mark test scripts with Bash'isms to be run via Bash by <a href=\"https://github.com/dscho\"><code>@\u200bdscho</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1377\">actions/checkout#1377</a></li>\n<li>Add option to fetch tags even if fetch-depth &gt; 0 by <a href=\"https://github.com/RobertWieczoreck\"><code>@\u200bRobertWieczoreck</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/579\">actions/checkout#579</a></li>\n<li>Release 3.6.0 by <a href=\"https://github.com/luketomlinson\"><code>@\u200bluketomlinson</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1437\">actions/checkout#1437</a></li>\n</ul>\n<h2>New Contributors</h2>\n<ul>\n<li><a href=\"https://github.com/RobertWieczoreck\"><code>@\u200bRobertWieczoreck</code></a> made their first contribution in <a href=\"https://redirect.github.com/actions/checkout/pull/579\">actions/checkout#579</a></li>\n<li><a href=\"https://github.com/luketomlinson\"><code>@\u200bluketomlinson</code></a> made their first contribution in <a href=\"https://redirect.github.com/actions/checkout/pull/1437\">actions/checkout#1437</a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/actions/checkout/compare/v3.5.3...v3.6.0\">https://github.com/actions/checkout/compare/v3.5.3...v3.6.0</a></p>\n</blockquote>\n</details>\n<details>\n<summary>Changelog</summary>\n<p><em>Sourced from <a href=\"https://github.com/actions/checkout/blob/main/CHANGELOG.md\">actions/checkout's changelog</a>.</em></p>\n<blockquote>\n<h1>Changelog</h1>\n<h2>v3.6.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1377\">Fix: Mark test scripts with Bash'isms to be run via Bash</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/579\">Add option to fetch tags even if fetch-depth &gt; 0</a></li>\n</ul>\n<h2>v3.5.3</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1196\">Fix: Checkout fail in self-hosted runners when faulty submodule are checked-in</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1287\">Fix typos found by codespell</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1369\">Add support for sparse checkouts</a></li>\n</ul>\n<h2>v3.5.2</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1289\">Fix api endpoint for GHES</a></li>\n</ul>\n<h2>v3.5.1</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1246\">Fix slow checkout on Windows</a></li>\n</ul>\n<h2>v3.5.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1237\">Add new public key for known_hosts</a></li>\n</ul>\n<h2>v3.4.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1209\">Upgrade codeql actions to v2</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1210\">Upgrade dependencies</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1225\">Upgrade <code>@\u200bactions/io</code></a></li>\n</ul>\n<h2>v3.3.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1045\">Implement branch list using callbacks from exec function</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1050\">Add in explicit reference to private checkout options</a></li>\n<li>[Fix comment typos (that got added in <a href=\"https://redirect.github.com/actions/checkout/issues/770\">#770</a>)](<a href=\"https://redirect.github.com/actions/checkout/pull/1057\">actions/checkout#1057</a>)</li>\n</ul>\n<h2>v3.2.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/942\">Add GitHub Action to perform release</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/967\">Fix status badge</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1002\">Replace datadog/squid with ubuntu/squid Docker image</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/964\">Wrap pipeline commands for submoduleForeach in quotes</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1029\">Update <code>@\u200bactions/io</code> to 1.1.2</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1039\">Upgrading version to 3.2.0</a></li>\n</ul>\n<h2>v3.1.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/939\">Use <code>@\u200bactions/core</code> <code>saveState</code> and <code>getState</code></a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/922\">Add <code>github-server-url</code> input</a></li>\n</ul>\n<h2>v3.0.2</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/770\">Add input <code>set-safe-directory</code></a></li>\n</ul>\n<h2>v3.0.1</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/762\">Fixed an issue where checkout failed to run in container jobs due to the new git setting <code>safe.directory</code></a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/744\">Bumped various npm package versions</a></li>\n</ul>\n<h2>v3.0.0</h2>\n<!-- raw HTML omitted -->\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/actions/checkout/commit/f43a0e5ff2bd294095638e18286ca9a3d1956744\"><code>f43a0e5</code></a> Release 3.6.0 (<a href=\"https://redirect.github.com/actions/checkout/issues/1437\">#1437</a>)</li>\n<li><a href=\"https://github.com/actions/checkout/commit/7739b9ba2efcda9dde65ad1e3c2dbe65b41dfba7\"><code>7739b9b</code></a> Add option to fetch tags even if fetch-depth &gt; 0 (<a href=\"https://redirect.github.com/actions/checkout/issues/579\">#579</a>)</li>\n<li><a href=\"https://github.com/actions/checkout/commit/96f53100ba2a5449eb71d2e6604bbcd94b9449b5\"><code>96f5310</code></a> Mark test scripts with Bash'isms to be run via Bash (<a href=\"https://redirect.github.com/actions/checkout/issues/1377\">#1377</a>)</li>\n<li>See full diff in <a href=\"https://github.com/actions/checkout/compare/c85c95e3d7251135ab7dc9ce3241c5835cc595a9...f43a0e5ff2bd294095638e18286ca9a3d1956744\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=actions/checkout&package-manager=github_actions&previous-version=3.5.3&new-version=3.6.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n\n\n</details>",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-08-18T15:35:16Z",
        "closed_at": "2023-08-18T17:01:27Z",
        "merged_at": "2023-08-18T17:01:27Z",
        "body": "This was missed from #6507",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-08-16T11:44:09Z",
        "closed_at": "2023-08-16T15:16:54Z",
        "merged_at": "2023-08-16T15:16:54Z",
        "body": "This PR fixes the monthly download badge in the README.\r\n\r\n**At the moment:**\r\n<img width=\"791\" alt=\"image\" src=\"https://github.com/psf/requests/assets/11357413/189384fd-d24b-4e36-8e6d-a763581d207e\">\r\n\r\n\r\n**With this PR:**\r\n<img width=\"765\" alt=\"image\" src=\"https://github.com/psf/requests/assets/11357413/0174ed1a-82f1-475f-8245-dad2c57c11fc\">\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 14,
        "changed_files": 22,
        "created_at": "2023-08-13T19:55:45Z",
        "closed_at": "2023-08-13T21:46:13Z",
        "merged_at": "2023-08-13T21:46:13Z",
        "body": "This is more of a pulse check/RFC from the other maintainers. Using a `src` directory has been the standard advice for package structure [1][2] for quite a while for proper test encapsulation. This PR proposes we move Requests to follow suit.\r\n\r\nI don't think we have anything requiring this move beyond providing a better example since Requests is still cited as an example for projects (despite being relatively out of date from community standards).\r\n\r\n1. https://packaging.python.org/en/latest/tutorials/packaging-projects/\r\n2. https://docs.pytest.org/en/latest/goodpractices.html",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 28,
        "deletions": 27,
        "changed_files": 4,
        "created_at": "2023-08-13T19:40:51Z",
        "closed_at": "2023-08-13T23:08:21Z",
        "merged_at": "2023-08-13T23:08:21Z",
        "body": "We missed removing `pytest-mock` in the Python 2.7 deprecation. Since we're not using any specialized functionality in `pytest-mock` and `mock` is available in the standard library through `unittest`, let's prefer that.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2023-08-13T18:35:47Z",
        "closed_at": "2023-08-13T19:56:19Z",
        "merged_at": "2023-08-13T19:56:19Z",
        "body": "Tests have been running smoothly for the last few months and now that we're in RC phase for Python 3.12, we should be able to formalize support.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2023-08-12T19:03:26Z",
        "closed_at": "2023-08-12T20:15:39Z",
        "merged_at": "2023-08-12T20:15:39Z",
        "body": "Bumps [actions/checkout](https://github.com/actions/checkout) from 2.7.0 to 3.5.3.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/actions/checkout/releases\">actions/checkout's releases</a>.</em></p>\n<blockquote>\n<h2>v3.5.3</h2>\n<h2>What's Changed</h2>\n<ul>\n<li>Fix: Checkout Issue in self hosted runner due to faulty submodule check-ins by <a href=\"https://github.com/megamanics\"><code>@\u200bmegamanics</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1196\">actions/checkout#1196</a></li>\n<li>Fix typos found by codespell by <a href=\"https://github.com/DimitriPapadopoulos\"><code>@\u200bDimitriPapadopoulos</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1287\">actions/checkout#1287</a></li>\n<li>Add support for sparse checkouts by <a href=\"https://github.com/dscho\"><code>@\u200bdscho</code></a> and <a href=\"https://github.com/dfdez\"><code>@\u200bdfdez</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1369\">actions/checkout#1369</a></li>\n<li>Release v3.5.3 by <a href=\"https://github.com/TingluoHuang\"><code>@\u200bTingluoHuang</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1376\">actions/checkout#1376</a></li>\n</ul>\n<h2>New Contributors</h2>\n<ul>\n<li><a href=\"https://github.com/megamanics\"><code>@\u200bmegamanics</code></a> made their first contribution in <a href=\"https://redirect.github.com/actions/checkout/pull/1196\">actions/checkout#1196</a></li>\n<li><a href=\"https://github.com/DimitriPapadopoulos\"><code>@\u200bDimitriPapadopoulos</code></a> made their first contribution in <a href=\"https://redirect.github.com/actions/checkout/pull/1287\">actions/checkout#1287</a></li>\n<li><a href=\"https://github.com/dfdez\"><code>@\u200bdfdez</code></a> made their first contribution in <a href=\"https://redirect.github.com/actions/checkout/pull/1369\">actions/checkout#1369</a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/actions/checkout/compare/v3...v3.5.3\">https://github.com/actions/checkout/compare/v3...v3.5.3</a></p>\n<h2>v3.5.2</h2>\n<h2>What's Changed</h2>\n<ul>\n<li>Fix: Use correct API url / endpoint in GHES by <a href=\"https://github.com/fhammerl\"><code>@\u200bfhammerl</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1289\">actions/checkout#1289</a> based on <a href=\"https://redirect.github.com/actions/checkout/issues/1286\">#1286</a> by <a href=\"https://github.com/1newsr\"><code>@\u200b1newsr</code></a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/actions/checkout/compare/v3.5.1...v3.5.2\">https://github.com/actions/checkout/compare/v3.5.1...v3.5.2</a></p>\n<h2>v3.5.1</h2>\n<h2>What's Changed</h2>\n<ul>\n<li>Improve checkout performance on Windows runners by upgrading <code>@\u200bactions/github</code> dependency by <a href=\"https://github.com/BrettDong\"><code>@\u200bBrettDong</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1246\">actions/checkout#1246</a></li>\n</ul>\n<h2>New Contributors</h2>\n<ul>\n<li><a href=\"https://github.com/BrettDong\"><code>@\u200bBrettDong</code></a> made their first contribution in <a href=\"https://redirect.github.com/actions/checkout/pull/1246\">actions/checkout#1246</a></li>\n<li><a href=\"https://github.com/fhammerl\"><code>@\u200bfhammerl</code></a> made their first contribution in <a href=\"https://redirect.github.com/actions/checkout/pull/1284\">actions/checkout#1284</a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/actions/checkout/compare/v3.5.0...v3.5.1\">https://github.com/actions/checkout/compare/v3.5.0...v3.5.1</a></p>\n<h2>v3.5.0</h2>\n<h2>What's Changed</h2>\n<ul>\n<li>Add new public key for known_hosts by <a href=\"https://github.com/cdb\"><code>@\u200bcdb</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1237\">actions/checkout#1237</a></li>\n</ul>\n<h2>New Contributors</h2>\n<ul>\n<li><a href=\"https://github.com/cdb\"><code>@\u200bcdb</code></a> made their first contribution in <a href=\"https://redirect.github.com/actions/checkout/pull/1237\">actions/checkout#1237</a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/actions/checkout/compare/v3.4.0...v3.5.0\">https://github.com/actions/checkout/compare/v3.4.0...v3.5.0</a></p>\n<h2>v3.4.0</h2>\n<h2>What's Changed</h2>\n<ul>\n<li>Upgrade codeql actions to v2 by <a href=\"https://github.com/Link\"><code>@\u200bLink</code></a>- in <a href=\"https://redirect.github.com/actions/checkout/pull/1209\">actions/checkout#1209</a></li>\n<li>Upgrade dependencies by <a href=\"https://github.com/Link\"><code>@\u200bLink</code></a>- in <a href=\"https://redirect.github.com/actions/checkout/pull/1210\">actions/checkout#1210</a></li>\n<li>Backfill changelog and bump actions/io by <a href=\"https://github.com/cory-miller\"><code>@\u200bcory-miller</code></a> in <a href=\"https://redirect.github.com/actions/checkout/pull/1225\">actions/checkout#1225</a></li>\n</ul>\n<h2>New Contributors</h2>\n<ul>\n<li><a href=\"https://github.com/Link\"><code>@\u200bLink</code></a>- made their first contribution in <a href=\"https://redirect.github.com/actions/checkout/pull/1209\">actions/checkout#1209</a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a href=\"https://github.com/actions/checkout/compare/v3.3.0...v3.4.0\">https://github.com/actions/checkout/compare/v3.3.0...v3.4.0</a></p>\n<!-- raw HTML omitted -->\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Changelog</summary>\n<p><em>Sourced from <a href=\"https://github.com/actions/checkout/blob/main/CHANGELOG.md\">actions/checkout's changelog</a>.</em></p>\n<blockquote>\n<h1>Changelog</h1>\n<h2>v3.5.3</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1196\">Fix: Checkout fail in self-hosted runners when faulty submodule are checked-in</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1287\">Fix typos found by codespell</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1369\">Add support for sparse checkouts</a></li>\n</ul>\n<h2>v3.5.2</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1289\">Fix api endpoint for GHES</a></li>\n</ul>\n<h2>v3.5.1</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1246\">Fix slow checkout on Windows</a></li>\n</ul>\n<h2>v3.5.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1237\">Add new public key for known_hosts</a></li>\n</ul>\n<h2>v3.4.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1209\">Upgrade codeql actions to v2</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1210\">Upgrade dependencies</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1225\">Upgrade <code>@\u200bactions/io</code></a></li>\n</ul>\n<h2>v3.3.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1045\">Implement branch list using callbacks from exec function</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1050\">Add in explicit reference to private checkout options</a></li>\n<li>[Fix comment typos (that got added in <a href=\"https://redirect.github.com/actions/checkout/issues/770\">#770</a>)](<a href=\"https://redirect.github.com/actions/checkout/pull/1057\">actions/checkout#1057</a>)</li>\n</ul>\n<h2>v3.2.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/942\">Add GitHub Action to perform release</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/967\">Fix status badge</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1002\">Replace datadog/squid with ubuntu/squid Docker image</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/964\">Wrap pipeline commands for submoduleForeach in quotes</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1029\">Update <code>@\u200bactions/io</code> to 1.1.2</a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/1039\">Upgrading version to 3.2.0</a></li>\n</ul>\n<h2>v3.1.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/939\">Use <code>@\u200bactions/core</code> <code>saveState</code> and <code>getState</code></a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/922\">Add <code>github-server-url</code> input</a></li>\n</ul>\n<h2>v3.0.2</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/770\">Add input <code>set-safe-directory</code></a></li>\n</ul>\n<h2>v3.0.1</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/762\">Fixed an issue where checkout failed to run in container jobs due to the new git setting <code>safe.directory</code></a></li>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/744\">Bumped various npm package versions</a></li>\n</ul>\n<h2>v3.0.0</h2>\n<ul>\n<li><a href=\"https://redirect.github.com/actions/checkout/pull/689\">Update to node 16</a></li>\n</ul>\n<h2>v2.3.1</h2>\n<!-- raw HTML omitted -->\n</blockquote>\n<p>... (truncated)</p>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/actions/checkout/commit/c85c95e3d7251135ab7dc9ce3241c5835cc595a9\"><code>c85c95e</code></a> Release v3.5.3 (<a href=\"https://redirect.github.com/actions/checkout/issues/1376\">#1376</a>)</li>\n<li><a href=\"https://github.com/actions/checkout/commit/d106d4669b3bfcb17f11f83f98e1cab478e9f635\"><code>d106d46</code></a> Add support for sparse checkouts (<a href=\"https://redirect.github.com/actions/checkout/issues/1369\">#1369</a>)</li>\n<li><a href=\"https://github.com/actions/checkout/commit/f095bcc56b7c2baf48f3ac70d6d6782f4f553222\"><code>f095bcc</code></a> Fix typos found by codespell (<a href=\"https://redirect.github.com/actions/checkout/issues/1287\">#1287</a>)</li>\n<li><a href=\"https://github.com/actions/checkout/commit/47fbe2df0ad0e27efb67a70beac3555f192b062f\"><code>47fbe2d</code></a> Fix: Checkout fail in self-hosted runners when faulty submodule are checked-i...</li>\n<li><a href=\"https://github.com/actions/checkout/commit/8e5e7e5ab8b370d6c329ec480221332ada57f0ab\"><code>8e5e7e5</code></a> Release v3.5.2 (<a href=\"https://redirect.github.com/actions/checkout/issues/1291\">#1291</a>)</li>\n<li><a href=\"https://github.com/actions/checkout/commit/eb35239ec22e9029a5be28f8c41e67452f615f0f\"><code>eb35239</code></a> Fix: convert baseUrl to serverApiUrl 'formatted' (<a href=\"https://redirect.github.com/actions/checkout/issues/1289\">#1289</a>)</li>\n<li><a href=\"https://github.com/actions/checkout/commit/83b7061638ee4956cf7545a6f7efe594e5ad0247\"><code>83b7061</code></a> Release v3.5.1 (<a href=\"https://redirect.github.com/actions/checkout/issues/1284\">#1284</a>)</li>\n<li><a href=\"https://github.com/actions/checkout/commit/40a16ebeed7da831425b665e600750cb36b38d06\"><code>40a16eb</code></a> Improve checkout performance on Windows runners by upgrading <code>@\u200bactions/github</code> ...</li>\n<li><a href=\"https://github.com/actions/checkout/commit/8f4b7f84864484a7bf31766abe9204da3cbe65b3\"><code>8f4b7f8</code></a> Add new public key for known_hosts (<a href=\"https://redirect.github.com/actions/checkout/issues/1237\">#1237</a>)</li>\n<li><a href=\"https://github.com/actions/checkout/commit/cd6a9fd49371476d813e892956e2e920fcc3fb7e\"><code>cd6a9fd</code></a> Update update-main-version.yml</li>\n<li>Additional commits viewable in <a href=\"https://github.com/actions/checkout/compare/v2.7.0...c85c95e3d7251135ab7dc9ce3241c5835cc595a9\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=actions/checkout&package-manager=github_actions&previous-version=2.7.0&new-version=3.5.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n\n\n</details>",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 29,
        "changed_files": 7,
        "created_at": "2023-08-12T17:09:38Z",
        "closed_at": "2023-08-12T19:03:11Z",
        "merged_at": "2023-08-12T19:03:11Z",
        "body": "Same vein as #6497, make sure we have pre-commit relatively up to date. The update to black made some minor formatting changes but they're all reasonable.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 21,
        "deletions": 10,
        "changed_files": 5,
        "created_at": "2023-08-12T17:05:11Z",
        "closed_at": "2023-08-12T19:02:58Z",
        "merged_at": "2023-08-12T19:02:58Z",
        "body": "Running tests for #6496 I noticed we have a bunch of warnings for out of date actions. I've moved us to pins and added a dependabot config to run weekly to make sure we stay relatively up to date. I took a note from the urllib3 team and disabled PRs for patch updates to minimize noise.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2023-08-12T16:55:36Z",
        "closed_at": "2023-08-13T16:56:53Z",
        "merged_at": "2023-08-13T16:56:53Z",
        "body": "This PR will upgrade the Requests test suite to use the recently released httpbin 0.10.0 that now supports the latest major version of Flask. This will let us remove our pins on pallets projects and hopefully allow distro maintainers to no longer need to support these older versions.\r\n\r\nThanks @mgorny and @kevin1024 for helping get this unblocked and closing out #6070!",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 31,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2023-07-04T11:29:18Z",
        "closed_at": "2023-07-04T18:38:51Z",
        "merged_at": null,
        "body": "In some cases, when using a proxy, it is necessary to specify specific header content. Therefore, I have implemented this functionality in a simple way.\r\n\r\nusage\uff1a\r\nhttps://github.com/anysoft/requests/blob/e6b05c5edba85b6b383b39fdde4b3ab9b514f6db/tests/test_proxy.py\r\n``` python\r\nimport requests\r\n\r\n\r\ndef uc_unicom(ip):\r\n    try:\r\n        headers = {\r\n            'user-agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Mobile Safari/537.36 Edg/111.0.1661.41'\r\n        }\r\n        proxies = {\r\n            'http': f'http://{ip}',\r\n            'https': f'http://{ip}',\r\n            'headers': {\r\n                'Proxy-Authorization': 'Basic dXNlcjpwd2Q=',\r\n                'Q-GUID': 'XXXX',\r\n            }\r\n        }\r\n        response = requests.get('https://api.ip.sb/ip', headers=headers, proxies=proxies)\r\n        print(response.text)\r\n    except Exception as e:\r\n        print(e)\r\n\r\n\r\n\r\nif __name__ == '__main__':\r\n    uc_unicom('127.0.0.1:8080')\r\n\r\n```",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-06-26T18:38:58Z",
        "closed_at": "2023-08-12T17:53:36Z",
        "merged_at": "2023-08-12T17:53:36Z",
        "body": "### Description.\r\n\r\nSmall improvement to the docs: `Session.headers` (and not `Session`) should be set to an `OrderedDict` to preserve header order.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 34,
        "deletions": 6,
        "changed_files": 4,
        "created_at": "2023-06-07T14:04:16Z",
        "closed_at": "2023-06-07T15:21:49Z",
        "merged_at": null,
        "body": "`raise_for_status()` will now raises \r\n- ClientError for status code 4xx\r\n- ServerError for status code 5xx\r\n\r\nBoth ClientError and ServerError are subclass of HTTPError, which should make them backward compatible for users that are catching `HTTPError`\r\n\r\nAlso kept the error message the same for backward compatibility too in case users are matching the message value.\r\n\r\nIdeally the \"Client Error\" and \"Server Error\" in the message could be removed given the class name provide the same context.\r\ni.e\r\n`f\"{self.status_code}: {reason} for url: {self.url}\"`",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-06-07T00:43:36Z",
        "closed_at": "2023-06-26T17:09:24Z",
        "merged_at": "2023-06-26T17:09:24Z",
        "body": null,
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-06-04T13:13:50Z",
        "closed_at": "2023-07-30T04:05:45Z",
        "merged_at": "2023-07-30T04:05:45Z",
        "body": "This PR adds a note to the documentation highlighting the behaviour of the adapter prefix matching to help users avoid potential mistakes.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 10,
        "deletions": 10,
        "changed_files": 1,
        "created_at": "2023-05-31T09:45:47Z",
        "closed_at": "2023-05-31T12:37:44Z",
        "merged_at": null,
        "body": "This just fix the grammar in this document when I was reading it and I think it's okay to have a contributed on this project.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 3340,
        "deletions": 2708,
        "changed_files": 56,
        "created_at": "2023-05-26T17:06:58Z",
        "closed_at": "2023-05-27T00:59:56Z",
        "merged_at": null,
        "body": "My humble contribution to keep requests so typos free as it is proudly is now.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-05-17T12:28:43Z",
        "closed_at": "2023-07-30T01:01:43Z",
        "merged_at": "2023-07-30T01:01:43Z",
        "body": "When I read the source code, I found that the  `request` method misses parameter hooks in docstring",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-05-09T15:08:51Z",
        "closed_at": "2023-05-09T16:55:34Z",
        "merged_at": "2023-05-09T16:55:34Z",
        "body": "I was going through the release history docs to ensure compatibility safety in case of upgrading the package to the latest version. While doing so found this minuscule typo in the docs, where the word `entries` was written as `entires`.\r\n\r\nForgive me for the petty nitpicking but just thought of proposing a fix \ud83d\ude05 ",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 8,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-05-08T18:52:34Z",
        "closed_at": "2023-05-11T13:26:32Z",
        "merged_at": null,
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2023-05-08T17:39:41Z",
        "closed_at": "2023-05-13T14:10:56Z",
        "merged_at": "2023-05-13T14:10:56Z",
        "body": null,
        "comments": 9
    },
    {
        "merged": false,
        "additions": 7,
        "deletions": 7,
        "changed_files": 3,
        "created_at": "2023-05-04T08:27:17Z",
        "closed_at": "2023-08-13T17:04:04Z",
        "merged_at": null,
        "body": "## Changes\r\n\r\n- Bump `actions/checkout` from `v2` (Node 12) to `v3` (Node 16). [This will fix the node 12 deprecation warnings in action runs]\r\n- Bump `actions/setup-python` to `v4`.\r\n- Bump `dessant/lock-threads` to `v4`.\r\n- Bump codeql actions to `v2`.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2023-04-25T23:23:31Z",
        "closed_at": "2023-04-26T15:19:11Z",
        "merged_at": "2023-04-26T15:19:11Z",
        "body": "2.29.0 (2023-04-26)\r\n-------------------\r\n\r\n**Improvements**\r\n\r\n- Requests now defers chunked requests to the urllib3 implementation to improve\r\n  standardization. (#6226)\r\n- Requests relaxes header component requirements to support bytes/str subclasses. (#6356)",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2023-04-23T11:21:15Z",
        "closed_at": "2023-05-15T15:04:22Z",
        "merged_at": "2023-05-15T15:04:22Z",
        "body": null,
        "comments": 0
    },
    {
        "merged": false,
        "additions": 20,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-04-22T14:22:33Z",
        "closed_at": "2023-04-22T23:13:29Z",
        "merged_at": null,
        "body": "Resolution of issue https://github.com/psf/requests/issues/6102",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-04-22T11:44:51Z",
        "closed_at": "2023-04-22T23:41:27Z",
        "merged_at": "2023-04-22T23:41:27Z",
        "body": "Fixes https://github.com/psf/requests/issues/6419",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2023-04-21T16:47:52Z",
        "closed_at": "2023-04-22T10:27:16Z",
        "merged_at": null,
        "body": "https://github.com/psf/requests/issues/6419",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-04-21T15:54:43Z",
        "closed_at": "2023-04-22T23:53:09Z",
        "merged_at": "2023-04-22T23:53:09Z",
        "body": "refs: https://github.com/psf/requests/issues/6417\r\n\r\nI tried running tox locally on ubuntu 22.04 and it passed",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-04-21T13:50:36Z",
        "closed_at": "2023-04-23T00:00:22Z",
        "merged_at": "2023-04-23T00:00:22Z",
        "body": "The warnings plugin was disabled in https://github.com/psf/requests/pull/4056 but that issue is now fixed by\r\nhttps://github.com/pytest-dev/pytest/pull/2445",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-04-21T09:41:02Z",
        "closed_at": "2023-04-21T15:34:29Z",
        "merged_at": null,
        "body": "Just a small enhancement that listing of all valid HTTP in `request()` method",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2023-04-19T08:35:45Z",
        "closed_at": "2023-04-19T13:55:45Z",
        "merged_at": null,
        "body": "This PR removes a beautification comment (i.e. a comment that includes an array of special characters for beautification).",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-04-19T08:35:23Z",
        "closed_at": "2023-04-19T13:55:31Z",
        "merged_at": null,
        "body": "This PR removed an irrelevant comment (i.e. comment that is not related to code or does not add much information to explain it)",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-04-19T08:35:07Z",
        "closed_at": "2023-04-19T13:55:26Z",
        "merged_at": null,
        "body": "This PR fixes a misleading comment (i.e. a comment that incorrectly describes what the code does).",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-04-19T08:34:34Z",
        "closed_at": "2023-04-19T13:55:20Z",
        "merged_at": null,
        "body": "This PR removes an obvious comment (i.e. comment that restates what the code does in an obvious manner). The code itself is understandable that the request is being created.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-04-17T20:34:58Z",
        "closed_at": "2023-04-19T13:54:58Z",
        "merged_at": null,
        "body": "This PR removes a task comment (i.e. a comment referring to a work that could/should be done in the future or was already done).",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-04-13T01:23:31Z",
        "closed_at": "2023-04-13T03:14:49Z",
        "merged_at": null,
        "body": "The newer `charset_normalizer` is installed as a dependency in a lot of cases, so there isn't much point in going to `chardet` as a first stop.  It might even be possible to switch to an unconditional import.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2023-04-10T11:20:55Z",
        "closed_at": "2023-04-10T12:46:59Z",
        "merged_at": null,
        "body": "I have updated the RequestCookieJar class to be compatible with python3.10^ on Linux machines using python3.10^ as the default versions and also compatibility with pymongo.\r\n\r\n\r\n**The error**\r\n```\r\nmodule 'collections' has no attribute 'MutableMapping'\r\n```\r\n\r\n\r\n\r\n<details>\r\n\r\n<summary>Pymongo full error</summary>\r\n\r\n>You can add text within a collapsed section. \r\n\r\nYou can add an image or a code block, too.\r\n\r\n```python\r\nFile \"<root-folder>/<app/folder>\", line 4, in <module>\r\n    from pymongo import MongoClient\r\n  File \"<root-folder>/.local/lib/python3.10/site-packages/pymongo/__init__.py\", line 92, in <module>\r\n    from pymongo.mongo_client import MongoClient\r\n  File \"<root-folder>/.local/lib/python3.10/site-packages/pymongo/mongo_client.py\", line 59, in <module>\r\n    from pymongo import (\r\n  File \"<root-folder>/.local/lib/python3.10/site-packages/pymongo/uri_parser.py\", line 32, in <module>\r\n    from pymongo.srv_resolver import _HAVE_DNSPYTHON, _SrvResolver\r\n  File \"<root-folder>/.local/lib/python3.10/site-packages/pymongo/srv_resolver.py\", line 21, in <module>\r\n    from dns import resolver\r\n  File \"<root-folder>/.local/lib/python3.10/site-packages/dns/resolver.py\", line 39, in <module>\r\n    import dns.query\r\n  File \"<root-folder>/.local/lib/python3.10/site-packages/dns/query.py\", line 47, in <module>\r\n    import requests\r\n  File \"<root-folder>/.local/lib/python3.10/site-packages/requests/__init__.py\", line 63, in <module>\r\n    from . import utils\r\n  File \"<root-folder>/.local/lib/python3.10/site-packages/requests/utils.py\", line 27, in <module>\r\n    from .cookies import RequestsCookieJar, cookiejar_from_dict\r\n  File \"<root-folder>/.local/lib/python3.10/site-packages/requests/cookies.py\", line 172, in <module>\r\n    class RequestsCookieJar(cookielib.CookieJar, collections.MutableMapping):\r\nAttributeError: module 'collections' has no attribute 'MutableMapping'\r\n```\r\n\r\n</details>",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2023-03-30T15:37:31Z",
        "closed_at": "2023-03-30T19:26:49Z",
        "merged_at": null,
        "body": "This PR aims to minimize the number of configuration files for the project. Instead of a separate `.coveragerc` for configuring coverage, we now would have the required configuration within the `pyproject.toml` file leading to a overall minimal code structure.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-03-27T18:47:13Z",
        "closed_at": "2023-03-28T05:59:02Z",
        "merged_at": null,
        "body": "According to the API reference of `max_retries` of `requests.adapters.HTTPAdapter`\r\n\r\n> The maximum number of retries each connection should attempt. Note, this applies only to failed DNS lookups, socket connections and connection timeouts, never to requests where data has made it to the server. By default, Requests does not retry failed connections. If you need granular control over the conditions under which we retry a request, **import urllib3\u2019s Retry class and pass that instead.**\r\n\r\nA widely used example can be found in this [StackOverflow answer](https://stackoverflow.com/a/35504626/10325430) and is also under review in #6258.\r\n\r\nHowever, the current source code does not really accept the passed-in `Retry` instance. Instead, it will silently discard and replace it with the default `Retry` instance.\r\n\r\nThis 2-line fix intends to fix the bug and restore its behavior to expect.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-03-23T22:22:33Z",
        "closed_at": "2023-05-22T01:09:36Z",
        "merged_at": null,
        "body": "I'm quite convinced the current one (`MMXVIX`) is invalid, or at the very least, ambiguous (online converters say it's either 2014, 2024, or invalid).\r\n\r\nI made this change assuming it was supposed to mean 2014.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-03-22T12:47:54Z",
        "closed_at": "2023-03-22T17:06:00Z",
        "merged_at": null,
        "body": "I'm sorry for my OCD \ud83d\ude05\r\nThere is some extra spacing. This doesn't match the spacing of the badge `downloads/month`\r\n\r\n![image](https://user-images.githubusercontent.com/72306953/226908616-73cdf003-4d45-4199-a8c4-0731b9e0a551.png)\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-03-15T13:59:46Z",
        "closed_at": "2023-07-30T01:11:38Z",
        "merged_at": null,
        "body": "This section applies not only to POST request, but all REST methods with data. Furthermore, a POST request with json body ist not complicated, but standard.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2023-03-14T18:41:18Z",
        "closed_at": "2023-03-14T21:30:30Z",
        "merged_at": null,
        "body": "fix #6377 \r\nThe reason why the file is not overwritten is that the test file in the TMP directory is not cleared after the test is run for the first time, and the directory and filename of the temporary file are the same after each test run.\r\n\r\nThis code skips overwriting when it finds that the file already exists:\r\n\r\n`if not os.path.exists(extracted_path):` in utils.extract_zipped_paths()\r\n\r\n**This means that calling this function twice in a row will not be able to detect changes in compressed files\uff1f**\r\n\r\nSo i thought that judgment might be redundant, so I removed it.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-03-09T08:36:54Z",
        "closed_at": "2023-07-30T01:15:22Z",
        "merged_at": null,
        "body": "requests.put() does not respect timeout when data is chunked",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-03-09T08:29:08Z",
        "closed_at": "2023-03-09T11:13:21Z",
        "merged_at": null,
        "body": "My reasoning is thus: emojis are cool",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2023-03-02T23:36:36Z",
        "closed_at": "2023-03-03T05:32:49Z",
        "merged_at": "2023-03-03T05:32:49Z",
        "body": "The comment for `json` parameter was really confusing and I changed it to make it consistent and clear.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-02-27T10:33:32Z",
        "closed_at": "2023-02-27T15:31:17Z",
        "merged_at": "2023-02-27T15:31:17Z",
        "body": null,
        "comments": 0
    },
    {
        "merged": false,
        "additions": 71,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2023-02-25T22:27:42Z",
        "closed_at": "2023-07-30T01:46:54Z",
        "merged_at": null,
        "body": "I'm using requests to automate a custom Django app.\r\nThe Django app sets cookies that are not parsed by requests.\r\n\r\nThis addresses two issues that keep requests from parsing the cookies:\r\n\r\n1. A Set-Cookie header with multiple cookies will fail to parse\r\n2. A Set-Cookie with a Max-Age attribute that is a floating point number will fail to parse\r\n\r\nDjango does both of these things.\r\n\r\nThis PR handles multiple cookies by replacing a single Set-Cookie header with multiple cookies with multiple Set-Cookie headers with one cookie each.\r\n\r\nThis PR rounds down Max-Age to an int.\r\n\r\n4 new tests are added.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 48,
        "deletions": 13,
        "changed_files": 3,
        "created_at": "2023-02-17T16:19:43Z",
        "closed_at": "2023-03-03T20:39:03Z",
        "merged_at": "2023-03-03T20:39:03Z",
        "body": "Closes https://github.com/psf/requests/issues/6159 Adapted from https://github.com/nateprewitt/requests/commit/66fcc9c88cf5a53e85322305f41006032744cbe3 but also supports mixed type tuples.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 42,
        "deletions": 35,
        "changed_files": 9,
        "created_at": "2023-02-08T03:44:16Z",
        "closed_at": "2023-02-08T12:39:46Z",
        "merged_at": null,
        "body": "Fix some f-strings\r\nRemove u-prefix from strings",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2023-01-20T18:26:35Z",
        "closed_at": "2023-01-21T08:44:33Z",
        "merged_at": "2023-01-21T08:44:33Z",
        "body": "urllib3 2.0 only supports OpenSSL 1.1.1+ which means SNI is mandatory, and removed the warning altogether.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-01-18T21:37:47Z",
        "closed_at": "2023-01-19T05:37:25Z",
        "merged_at": "2023-01-19T05:37:25Z",
        "body": "Resolves #6332\r\n\r\nThe \r\n\r\nhttps://github.com/psf/requests/blob/61c324da43dd8b775d3930d76265538b3ca27bc1/setup.py#L97\r\n\r\ncap was added in PR #6091.\r\n\r\nAs discussed in https://discuss.python.org/t/use-of-less-than-next-major-version-e-g-4-in-python-requires-setup-py/1066 and [other places](https://iscinumpy.dev/post/bound-version-constraints/) by the PyPA, use of upper bounds with `python_requires` for _future_ versions of Python is unintended use of `python_requires` and actively discouraged.\r\n\r\nc.f. https://github.com/pypa/packaging.python.org/pull/850 for further detail.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 27,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2023-01-13T02:41:11Z",
        "closed_at": "2023-08-12T18:34:42Z",
        "merged_at": null,
        "body": "I added a brief example of exception handling for `RequestException` and documented the `request` and `response` attributes. PR does not overlap with #6237",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2023-01-11T22:39:35Z",
        "closed_at": "2023-01-12T16:16:12Z",
        "merged_at": "2023-01-12T16:16:12Z",
        "body": "2.28.2 (2023-01-12)\r\n-------------------\r\n\r\n**Dependencies**\r\n\r\n- Requests now supports charset\\_normalizer 3.x. (#6261)\r\n\r\n**Bugfixes**\r\n\r\n- Updated MissingSchema exception to suggest https scheme rather than http. (#6188)",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2023-01-06T16:53:02Z",
        "closed_at": "2023-01-06T18:32:31Z",
        "merged_at": "2023-01-06T18:32:31Z",
        "body": null,
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2022-12-25T23:39:31Z",
        "closed_at": "2022-12-26T04:24:16Z",
        "merged_at": "2022-12-26T04:24:16Z",
        "body": "Closes #6316",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 12,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2022-11-30T16:28:24Z",
        "closed_at": "2022-11-30T19:46:02Z",
        "merged_at": null,
        "body": "The list of phony targets was incomplete. Add a list of the phony targets explicitly at the end of the file.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2022-11-21T20:09:10Z",
        "closed_at": "2022-11-21T22:06:02Z",
        "merged_at": "2022-11-21T22:06:02Z",
        "body": "As of March 2022, [GitHub has removed support for cloning repositories using the `git://` protocol](https://github.blog/2021-09-01-improving-git-protocol-security-github/). This project's installation docs still use a URL starting with `git://` when telling users how to clone the source repo. Let's replace that with the HTTPS URL for this repository.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2022-11-11T22:50:18Z",
        "closed_at": "2022-11-12T00:42:39Z",
        "merged_at": null,
        "body": "Since there is a `REQUIRED_PYTHON` tuple, use it to fill the `python_requires` argument of `setup()` to avoid hard-coding current \"3.7\" in multiple places.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2022-11-07T10:53:10Z",
        "closed_at": "2022-11-07T12:51:06Z",
        "merged_at": null,
        "body": "Hi!\r\n\r\nWhile doing some debugging I have encountered with unused stuff. Here is a microscopic tiny PR for this. Btw, this is my first contribution to the project \ud83c\udf89 ",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 36,
        "deletions": 28,
        "changed_files": 8,
        "created_at": "2022-11-03T03:18:49Z",
        "closed_at": "2022-11-03T04:47:30Z",
        "merged_at": null,
        "body": "some small tweaks to appease pylint and python 3 changes",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2022-10-23T18:37:01Z",
        "closed_at": "2023-08-12T18:51:42Z",
        "merged_at": "2023-08-12T18:51:42Z",
        "body": "I suggest to change the license string in the package information to an [SPDX parsable license expression](https://spdx.org/licenses/).\r\nThis makes it easier for downstream users to get the license information directly from the package metadata.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2022-10-21T07:45:17Z",
        "closed_at": "2022-10-21T16:37:48Z",
        "merged_at": "2022-10-21T16:37:48Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 3,
        "created_at": "2022-10-20T10:09:22Z",
        "closed_at": "2022-10-20T18:26:19Z",
        "merged_at": "2022-10-20T18:26:19Z",
        "body": "charset-normalizer 3.0.0 has been released.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 22,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2022-10-15T00:19:49Z",
        "closed_at": "2023-07-03T20:38:22Z",
        "merged_at": "2023-07-03T20:38:22Z",
        "body": "While Requests doesn't automatically retry failures, this is an extremely common advanced use case in real world applications.\r\n\r\nAlthough there's a mention of this capability in the [`HTTPAdapter` API docs](https://requests.readthedocs.io/en/latest/api/#requests.adapters.HTTPAdapter), it's a bit buried and not very specific.\r\n\r\nThe ubiquity of the use case fits perfectly in the [Transport Adapters section of the Advanced Usage docs](https://requests.readthedocs.io/en/latest/user/advanced/#transport-adapters), so I thought it would be useful to have a simple Example of this capability.\r\n\r\nI took a stab at such an addition, and tried to follow the style of the rest of the docs pretty closely.\r\n\r\nLinking over to the [`urllib3.util.Retry` docs](https://urllib3.readthedocs.io/en/stable/reference/urllib3.util.html#urllib3.util.Retry) seems like it should reinforce the fact that Requests isn't the owner of that code and that library should be consulted with questions about that class (rather than Requests' support of it).\r\n\r\nI'm curious if maintainers have any feedback about the content or code example. Specifically I was curious whether you have any opinions as to the appropriate standard for the `Retry` import. While `urllib3.util.Retry` is where the class lives and what the `urllib3` docs reference, `from urllib3 import Retry` also works, and in some StackOverflow posts I've seen people use `from requests.adapters import Retry`. I felt that last one would telegraph an ownership by Requests that would be undesirable, but I'm wondering if anyone is particularly picky about the best practice for that import.\r\n\r\nAlso, let me know if this is non-trivial enough to add a HISTORY entry for.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2022-09-22T12:25:46Z",
        "closed_at": "2022-10-06T03:23:51Z",
        "merged_at": null,
        "body": "Issue #6242",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 13,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2022-09-09T08:42:04Z",
        "closed_at": "2023-01-11T22:06:54Z",
        "merged_at": "2023-01-11T22:06:54Z",
        "body": "### Description\r\nThis PR adds minimum token permissions for the GITHUB_TOKEN in GitHub Actions workflows using https://github.com/step-security/secure-workflows.\r\n\r\nThe GitHub Actions workflow has a GITHUB_TOKEN with write access to multiple scopes.\r\nHere is an example of the permissions in one of the workflow runs:\r\nhttps://github.com/psf/requests/runs/8179910695?check_suite_focus=true#step:1:19\r\n\r\nAfter this change, the scopes will be reduced to the minimum needed for the following workflows:\r\n\r\n- codeql-analysis.yml\r\n- lint.yml\r\n- run-tests.yml\r\n\r\nThe following workflow already has the least privileged token permission set:\r\n\r\n- lock-issues.yml\r\n\r\n### Motivation and Context\r\n\r\n- This is a security best practice, so if the GITHUB_TOKEN is compromised due to a vulnerability or compromised Action, the damage will be reduced.\r\n- GitHub recommends defining minimum GITHUB_TOKEN permissions.\r\n  https://docs.github.com/en/actions/security-guides/automatic-token-authentication#modifying-the-permissions-for-the-github_token\r\n- The Open Source Security Foundation (OpenSSF) [Scorecards](https://github.com/ossf/scorecard) also treats not setting token permissions as a high-risk issue. This change will help increase the Scorecard score for this repository.\r\n\r\nSigned-off-by: Ashish Kurmi <akurmi@stepsecurity.io>",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2022-09-07T07:49:28Z",
        "closed_at": "2022-09-09T19:10:15Z",
        "merged_at": "2022-09-09T19:10:15Z",
        "body": "Promote REQUESTS_CA_BUNDLE as it is looked at first",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 15,
        "deletions": 8,
        "changed_files": 2,
        "created_at": "2022-09-05T13:01:22Z",
        "closed_at": "2023-07-30T01:53:09Z",
        "merged_at": null,
        "body": "We wrap our secret a in special subclass of string, that prevents leaking confidential information in some circumstances (i.e. stack traces) etc.\r\n\r\nThe current implementation of the header checks does a `type(val) == str` which is not recommended by PEP8.\r\nDue to this implementation we can't pass this variables as headers. Converting them back to a normal string would defeat the purpose of wrapping them in the first place.\r\n\r\nThis PR fixes both issues.\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 13,
        "deletions": 58,
        "changed_files": 1,
        "created_at": "2022-09-01T00:53:34Z",
        "closed_at": "2023-04-22T23:32:52Z",
        "merged_at": "2023-04-22T23:32:52Z",
        "body": "This PR is the same as #5664 but rebased on to the `main` branch to bring it back up to date. This PR is needed to stay compatible  with future changes in urllib3 introduced by https://github.com/urllib3/urllib3/pull/2649. The comments in that PR offer a lot of detail in the changes in urllib3 but this one provided a good overview https://github.com/urllib3/urllib3/pull/2649#issuecomment-1200197578. ",
        "comments": 10
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2022-08-19T19:11:02Z",
        "closed_at": "2022-08-20T19:00:40Z",
        "merged_at": null,
        "body": "Based on a [security review](https://pypi.openrefactory.com/requests/62ff1f9edd30551cbfff8eeb) of the requests repository, it looks like the `sha1` hashing algorithm should be updated here to avoid collisions. \r\n\r\nI have not added any unit tests since this should be a `no-op` change with the expected behaviour after this change identical to the previous behaviour before the change. I'm also happy to help implement/clean up some of the code here as well. ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2022-08-16T01:02:34Z",
        "closed_at": "2023-07-30T01:50:43Z",
        "merged_at": "2023-07-30T01:50:43Z",
        "body": "Docstrings still called this module as it was in python2.7; update\r\nthem to use the name from python3. Mostly useful as a reference for\r\npeople who need a custom cookiejar.\r\n\r\nCode does still use the compatibility layer for a no-more-supported\r\npython2, however.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 33,
        "deletions": 5,
        "changed_files": 5,
        "created_at": "2022-07-31T20:44:29Z",
        "closed_at": "2022-07-31T22:47:55Z",
        "merged_at": null,
        "body": "- Added support for TRACE method\r\n- Added TRACE method in docs\r\n- Fix docs missing OPTIONS method",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 10,
        "changed_files": 1,
        "created_at": "2022-07-30T11:17:30Z",
        "closed_at": "2022-07-30T19:35:29Z",
        "merged_at": null,
        "body": "`__nonzero__` was used in python2 as we now use `__bool__`. It is not used at all in python3.\r\nAnd since [`setup.py` says](https://github.com/psf/requests/blob/177dd90f18a8f4dc79a7d2049f0a3f4fcc5932a0/setup.py#L10) that `reqeusts` supports only `python >= 3.7`, I don't think that it is really required.\r\n\r\nI found this while working on `typeshed` types for `requests`: https://github.com/python/typeshed/blob/3fe1f5d6c46b39b8b4632aadc70477a729241d25/stubs/requests/requests/models.pyi#L107",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 53,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2022-07-29T10:14:12Z",
        "closed_at": "2022-07-29T15:43:16Z",
        "merged_at": null,
        "body": "Adds a class method to create PreparedRequests from raw HTTP request using Python's builtin BaseHTTPRequestHandler class.\r\n\r\nExample usage:\r\n\r\n```\r\n>>> from requests import PreparedRequest, Session\r\n>>> prq = PreparedRequest.from_raw('GET / HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n', use_https=False)\r\n>>> res = Session().send(prq)\r\n<Response [200]>\r\n```\r\n\r\nThis would be very useful for someone that wants to use the python requests library but with raw HTTP requests.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2022-07-27T15:01:44Z",
        "closed_at": "2022-07-27T17:22:21Z",
        "merged_at": "2022-07-27T17:22:21Z",
        "body": "`requests` no longer supports Python 2. A recent commit, 8bce583b9547c7b82d44c8e97f37cf9a16cbe758\r\nremoved the `chardet` dependency for Python 2:\r\n\r\n```diff\r\n-'chardet>=3.0.2,<5; python_version < \"3\"',\r\n```\r\n\r\nWe should edit the docs to remove mention of behavior on Py2.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2022-07-21T07:36:49Z",
        "closed_at": "2022-07-21T12:51:11Z",
        "merged_at": null,
        "body": "Add response object to JSONDecodeError.\r\n\r\nWe used to use the following code, but since 2.27, errors on json parse failure are now caught as RequestException.\r\nSince there is basically `response` in the `.json()` phase, we would like to add it in JSONDecodeError for convenience.\r\n\r\n```python\r\ndef my_post(url, payload):\r\n    try:\r\n        res = requests.post(url, json=payload)\r\n        res.raise_for_status()\r\n        return res.json()\r\n    except requests.exceptions.RequestException as e:\r\n        logger.warning(\"Failed to send data %s\", e.response.status_code)\r\n    except Exception as e:\r\n        ...\r\n```\r\n```\r\nAttributeError\r\n'NoneType' object has no attribute 'status_code'\r\n```",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2022-07-19T09:44:06Z",
        "closed_at": "2022-07-20T07:56:13Z",
        "merged_at": null,
        "body": "When a JSON response cannot be parsed, requests catch json.JSONDecodeError (or simplejson.JSONDecodeError) and raise requests.exceptions.JSONDecodeError instead. Because this happens in an except block, unhandled exceptions were printed in a chain:\r\n\r\n```\r\nTraceback (most recent call last):\r\n...\r\nsimplejson.errors.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\r\nDuring handling of the above exception, another exception occurred:\r\nTraceback (most recent call last):\r\n...\r\nrequests.exceptions.JSONDecodeError: [Errno Expecting value] ...\r\n```\r\n\r\nThis seems unnecessary and it increases cognitive overhead whean examining errors.\r\n\r\nAs requests.exceptions.JSONDecodeError inherits json.JSONDecodeError and we copy all atrributes from the later to the former, `raise ... from None` seems more approriate than `raise ... from e`.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2022-07-19T09:06:14Z",
        "closed_at": "2022-07-20T23:13:36Z",
        "merged_at": "2022-07-20T23:13:36Z",
        "body": "As a first-time contributor, I was confused when I run `make test` and saw \"This runs all of the tests, on both Python 2 and Python 3.\" in console output.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2022-07-19T08:57:07Z",
        "closed_at": "2023-01-11T22:11:22Z",
        "merged_at": null,
        "body": "When I was studying Contributor\u2019s Guide, I found that links to kenreitz.org are broken.\r\n\r\n- \"The Future of Python HTTP\" was archived by Internet Archive, so I linked there.\r\n- \"Be cordial or be on your way\" was not archived, so I removed the link.\r\n- \"A Kenneth Reitz Project.\" in a footer is broken too, but I did not touch that link.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2022-06-29T15:53:20Z",
        "closed_at": "2023-07-30T01:55:18Z",
        "merged_at": "2023-07-30T01:55:18Z",
        "body": "A dictionary comprehension can create the dictionary on one line, cutting out the clutter of declaring an empty dict and then adding items.\r\n\r\nSqueezing code onto one line can make it more difficult to read, but for comprehensions this isn't the case. All of the elements that you need are nicely presented, and once you are used to the syntax it is actually more readable than the for loop version. Given the attribute names, this is still readable due to lack of conditional behavior.\r\n\r\nAnother point is that the assignment is now more of an atomic operation - we're declaring what `cookie_dict` is rather than giving instructions on how to build it. This makes the code read like more of a narrative, since going forward we will care more about what `cookie_dict` is than the details of its construction.\r\n\r\nFinally comprehensions will usually execute more quickly than building the collection in a loop, which is another factor if performance is a consideration. As cookies are variable in quantity, this may be of value in this location",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2022-06-29T03:22:56Z",
        "closed_at": "2022-06-29T15:09:12Z",
        "merged_at": "2022-06-29T15:09:12Z",
        "body": "2.28.1 (2022-06-29)\r\n-------------------\r\n\r\n**Improvements**\r\n\r\n- Speed optimization in `iter_content` with transition to `yield from`. (#6170)\r\n\r\n**Dependencies**\r\n\r\n- Added support for chardet 5.0.0 (#6179)\r\n- Added support for charset-normalizer 2.1.0 (#6169)",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2022-06-28T14:43:01Z",
        "closed_at": "2023-07-30T01:57:46Z",
        "merged_at": null,
        "body": "Currently at the moment, Lint is behind by one version for this repository and CodeQL Analysis is behind by two versions. I've updated to the latest versions for them and have checked the repositories used in the files and have confirmed that the versions exists.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2022-06-26T03:02:50Z",
        "closed_at": "2022-06-28T02:25:59Z",
        "merged_at": "2022-06-28T02:25:59Z",
        "body": "https://github.com/chardet/chardet/releases/tag/5.0.0 was released on 2022-06-25 with remove of Python 3.6 support, which also align with our Python > 3.6 requirement.\r\n\r\nSigned-off-by: Wong Hoi Sing Edison <hswong3i@pantarei-design.com>",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2022-06-20T13:01:10Z",
        "closed_at": "2022-06-29T02:08:26Z",
        "merged_at": "2022-06-29T02:08:26Z",
        "body": "This merge request updates the stream yield functionality to use `yield from` instead of `yield` within a for loop. Because this is yielding from an iterable, we can use `yield from` which is not only slightly shorter but also on average 15% more performant than using `yield` inside of a loop. This is a result of some of the optimizations included as part of [PEP 380](https://peps.python.org/pep-0380/)",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2022-06-20T07:39:36Z",
        "closed_at": "2022-06-29T02:01:43Z",
        "merged_at": "2022-06-29T02:01:43Z",
        "body": "The current definition `charset_normalizer~=2.0.0` does not allow charset-normalizer 2.1.0 which has been released a couple of hours ago. The newer version seems to be compatible with requests and [the compatibility check](https://github.com/psf/requests/blob/da9996fe4dc63356e9467d0a5e10df3d89a8528e/requests/__init__.py#L80-L84) suggests that requests should allow versions up to 3.0.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 32,
        "deletions": 39,
        "changed_files": 6,
        "created_at": "2022-06-17T15:03:47Z",
        "closed_at": "2022-06-17T16:59:56Z",
        "merged_at": null,
        "body": "1. Use `contextlib.suppress` rather than empty `except`\r\n2. Prefer f-strings to `.format` and `+`-based concatenation for improved performance.\r\n3. Remove empty `elif` via refactoring.\r\n4. Use `yield from` instead of `yield` for 15\u201320% performance gain (on average)\r\n5. Generate `list()` rather than iteration\r\n6. Prefer generators to looped iteration",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 16,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2022-06-08T04:19:31Z",
        "closed_at": "2022-06-08T19:11:11Z",
        "merged_at": "2022-06-08T19:11:11Z",
        "body": "This was intended to be a follow up to #6095 but got lost in the shuffle post PyCon. It's currently failing on a single line change that's addressed in #6154. Once that's merged this should be ready to merge and ensure we don't introduce any future inconsistencies.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 26,
        "deletions": 7,
        "changed_files": 2,
        "created_at": "2022-06-08T04:10:18Z",
        "closed_at": "2022-06-09T14:42:10Z",
        "merged_at": "2022-06-09T14:42:10Z",
        "body": "2.28.0 (2022-06-09)\r\n-------------------\r\n\r\n**Deprecations**\r\n\r\n- \u26a0\ufe0f Requests has officially dropped support for Python 2.7. \u26a0\ufe0f (#6091)\r\n- Requests has officially dropped support for Python 3.6 (including pypy3). (#6091)\r\n\r\n**Improvements**\r\n\r\n- Wrap JSON parsing issues in Request's JSONDecodeError for payloads without\r\n  an encoding to make `json()` API consistent. (#6097)\r\n- Parse header components consistently, raising an InvalidHeader error in\r\n  all invalid cases. (#6154)\r\n- Added provisional 3.11 support with current beta build. (#6155)\r\n- Requests got a makeover and we decided to paint it black. (#6095)\r\n\r\n**Bugfixes**\r\n\r\n- Fixed bug where setting `CURL_CA_BUNDLE` to an empty string would disable\r\n  cert verification. All Requests 2.x versions before 2.28.0 are affected. (#6074)\r\n- Fixed urllib3 exception leak, wrapping `urllib3.exceptions.SSLError` with\r\n  `requests.exceptions.SSLError` for `content` and `iter_content`. (#6057)\r\n- Fixed issue where invalid Windows registry entires caused proxy resolution\r\n  to raise an exception rather than ignoring the entry. (#6149)\r\n- Fixed issue where entire payload could be included in the error message for\r\n  JSONDecodeError. (#6079 ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2022-06-08T04:03:55Z",
        "closed_at": "2022-06-08T16:12:53Z",
        "merged_at": "2022-06-08T16:12:53Z",
        "body": "Start testing 3.11-dev on both Windows and macOS since we're publishing 2.28.0 claiming support for 3.11 with our trove classifier.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 72,
        "deletions": 62,
        "changed_files": 3,
        "created_at": "2022-06-08T04:02:40Z",
        "closed_at": "2022-06-08T18:03:56Z",
        "merged_at": "2022-06-08T18:03:56Z",
        "body": "Following up on #6083, this refactors our header validation function from 2.11.0 to consider the header name. We'd originally avoided adding header name validation because we wanted to limit the change scope to header splitting with new lines. Since then the standard library has made similar changes to ours and now raises a ValueError in `http.client`. This gives us inconsistent errors depending on which portion of the header you provide a bad value.\r\n\r\n```python\r\n>>> requests.get(\"https://httpbin.org/get\", headers={\":bad\": \"header\"})\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/Users/nateprewitt/Work/OpenSource/requests/requests/api.py\", line 73, in get\r\n    return request(\"get\", url, params=params, **kwargs)\r\n  File \"/Users/nateprewitt/Work/OpenSource/requests/requests/api.py\", line 59, in request\r\n    return session.request(method=method, url=url, **kwargs)\r\n  File \"/Users/nateprewitt/Work/OpenSource/requests/requests/sessions.py\", line 587, in request\r\n    resp = self.send(prep, **send_kwargs)\r\n  File \"/Users/nateprewitt/Work/OpenSource/requests/requests/sessions.py\", line 701, in send\r\n    r = adapter.send(request, **kwargs)\r\n  File \"/Users/nateprewitt/Work/OpenSource/requests/requests/adapters.py\", line 489, in send\r\n    resp = conn.urlopen(\r\n  File \"/Users/nateprewitt/Work/OpenSource/urllib3/src/urllib3/connectionpool.py\", line 727, in urlopen\r\n    httplib_response = self._make_request(\r\n  File \"/Users/nateprewitt/Work/OpenSource/urllib3/src/urllib3/connectionpool.py\", line 433, in _make_request\r\n    conn.request(method, url, **httplib_request_kw)\r\n  File \"/Users/nateprewitt/Work/OpenSource/urllib3/src/urllib3/connection.py\", line 309, in request\r\n    super().request(method, url, body=body, headers=headers)\r\n  File \"/Users/nateprewitt/.pyenv/versions/3.10.4/lib/python3.10/http/client.py\", line 1282, in request\r\n    self._send_request(method, url, body, headers, encode_chunked)\r\n  File \"/Users/nateprewitt/.pyenv/versions/3.10.4/lib/python3.10/http/client.py\", line 1323, in _send_request\r\n    self.putheader(hdr, value)\r\n  File \"/Users/nateprewitt/Work/OpenSource/urllib3/src/urllib3/connection.py\", line 274, in putheader\r\n    super().putheader(header, *values)\r\n  File \"/Users/nateprewitt/.pyenv/versions/3.10.4/lib/python3.10/http/client.py\", line 1250, in putheader\r\n    raise ValueError('Invalid header name %r' % (header,))\r\nValueError: Invalid header name b':bad'\r\n```\r\n\r\nThis PR ports the [validation scheme](https://github.com/python/cpython/blob/6b9122483f1f26afb0c41bd676f9754ffe726e18/Lib/http/client.py#L139) from http.client for header names and ensures we raise an `InvalidHeader` error consistently in all supported versions.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2022-06-01T21:51:15Z",
        "closed_at": "2022-06-02T16:13:51Z",
        "merged_at": null,
        "body": "[Software Package Data Exchange (SPDX)](https://spdx.org/) is an open standard for communication software bill of material information.\r\n\r\nAccording to the [SPDX License List](https://spdx.org/licenses) `Apache-2.0` is an unambiguous short identifier for the [Apache License 2.0](https://www.apache.org/licenses/LICENSE-2.0), which holds for the requests project.\r\n\r\nThis PR proposes to use this SPDX Identifier rather than `Apache 2.0` (without hyphen). Note that the proposed change does not change the license of the project but rather declares it unambiguously in a machine-readable format. As a result, the packaged version on PyPi will also be updated once requests is built again and all metadata crawlers will benefit from the change.",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 34,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2022-06-01T15:48:19Z",
        "closed_at": "2022-06-01T17:36:26Z",
        "merged_at": "2022-06-01T17:36:26Z",
        "body": "This PR will address #6104. Requests will now handle bad registry entries more gracefully when checking proxy settings from the host. When invalid entries are encountered, the ProxyEnabled setting will be ignored as if they didn't exist rather than throwing an exception.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2022-05-30T10:38:31Z",
        "closed_at": "2022-05-30T14:17:50Z",
        "merged_at": null,
        "body": "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/80x15.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2022-05-19T15:58:16Z",
        "closed_at": "2022-06-08T16:02:42Z",
        "merged_at": "2022-06-08T16:02:42Z",
        "body": "Hello,\r\n\r\nThe tests in `test_lowlevel.py` use the `testserver.server.Server` thread object.\r\n\r\nWhen using the object as a context manager, we wait until the server thread is ready with a timeout.\r\n\r\nUnfortunately, if the timeout is reached, we would not propagate the error. Instead, we would return from the `__enter__` method and access the `with` body with an uninitialized value for `port` (i.e., `port = 0`).\r\n\r\nTherefore, the tests would fail with:\r\n\r\n```\r\nE           urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fc3a3e30a90>: Failed to establish a new connection: [Errno 111] Connection refused\r\n\r\n/usr/lib/python3/dist-packages/urllib3/connection.py:181: NewConnectionError\r\n```\r\nReading this error does not make it obvious that this is the result of a timeout.\r\n\r\nFixed by raising an error in case of timeout, which makes it more obvious:\r\n\r\n```\r\n        if not self.ready_event.wait(self.WAIT_EVENT_TIMEOUT):\r\n>           raise RuntimeError(\"Timeout waiting for server to be ready.\")\r\nE           RuntimeError: Timeout waiting for server to be ready.\r\n\r\ntests/testserver/server.py:119: RuntimeError\r\n```\r\n_The reason why I had a timeout on my end was because my environment was not resolving \"localhost\" as it should have. Requests were going through the DNS and therefore ended-up hitting the timeout_\r\n\r\n_The name resolution taking forever was happening during this instruction (where `self.host` is `localhost`):_\r\n```\r\nsock.bind((self.host, self.port))\r\n```\r\n\r\nThanks,\r\nOlivier",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 39,
        "deletions": 15,
        "changed_files": 4,
        "created_at": "2022-05-04T06:23:48Z",
        "closed_at": "2023-07-30T01:58:42Z",
        "merged_at": null,
        "body": "Feature described in issue https://github.com/psf/requests/issues/6120\r\n\r\nnew `InvalidRedirectURL` inherits `InvalidURL, InvalidSchema, LocationParseError` for backward compatibility ",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2022-05-03T05:57:40Z",
        "closed_at": "2022-05-03T15:05:37Z",
        "merged_at": null,
        "body": "Resolves #6118\r\n\r\nMakes sure that the input argument to `proxies` is not mutated.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 23,
        "deletions": 22,
        "changed_files": 12,
        "created_at": "2022-03-30T09:54:58Z",
        "closed_at": "2022-03-30T11:53:01Z",
        "merged_at": null,
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2830,
        "deletions": 2399,
        "changed_files": 39,
        "created_at": "2022-03-23T20:15:49Z",
        "closed_at": "2022-04-29T19:16:58Z",
        "merged_at": "2022-04-29T19:16:58Z",
        "body": "### Overview\r\nThis is a draft PR for adding standardized code formatting to Requests. Now that we intend to drop Python 2 support, we have the opportunity to clean up multiple conflicting code styles that have crept into Requests over the years.\r\n\r\nThis PR will introduce a few standard changes:\r\n\r\n* Integration of `black` for code formatting, bringing Requests in-line with what has largely become the standard.\r\n* Integration of `isort` to ensure our imports are automatically grouped and cleaned.\r\n* Integration of `pyupgrade` which will automatically pull most of the code base to Python 3.7 syntax.\r\n* Addition of a `.pre-commit-config.yaml` to orchestrate the above tools.\r\n\r\n### TODO\r\n- [x] Rebase on to #6091 before merge\r\n- [x] Resolve formatting issues with server response line wrapping in `tests/test_lowlevel.py`\r\n- [x] Add .git-blame-ignore-revs file (#6116)\r\n- [x] Fix inconsistent f-string upgrades\r\n- [x] Enable and fix flake8 issues",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 141,
        "deletions": 180,
        "changed_files": 19,
        "created_at": "2022-03-23T00:27:13Z",
        "closed_at": "2022-03-25T16:50:34Z",
        "merged_at": "2022-03-25T16:50:34Z",
        "body": "This PR is a proposal to officially remove support for Python 2.7 as discussed in #6023. The next minor release (Requests 2.28.0) will no longer provide support for any of the end of life Python runtimes. Users are encouraged to upgrade to Python 3.8 or later. If you're unable to do so, we'd recommend pinning to `requests<2.28`.\r\n\r\nThis will be the first of a few PRs that will be doing some general code clean up now that we're moving to a Python 3-only code base. I'll post the others as drafts shortly.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 7,
        "changed_files": 3,
        "created_at": "2022-02-27T02:58:21Z",
        "closed_at": "2022-02-27T13:11:33Z",
        "merged_at": null,
        "body": "See:\r\n\r\n- https://endoflife.date/python\r\n- https://www.python.org/dev/peps/pep-0494/#lifespan",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 49,
        "deletions": 6,
        "changed_files": 2,
        "created_at": "2022-02-25T18:36:12Z",
        "closed_at": "2022-02-26T13:39:28Z",
        "merged_at": "2022-02-26T13:39:28Z",
        "body": "This is a proposal to address #6071. Rather than settling on the final value from `CURL_CA_BUNDLE` we'll end the conditional change with `verify`. This ensures we don't accidentally take a \"falsey\" value and disable verification for misconfigured environments.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2022-02-19T01:38:37Z",
        "closed_at": "2022-02-19T13:34:48Z",
        "merged_at": "2022-02-19T13:34:48Z",
        "body": "Fix for build issue in #6068. The release of `markupsafe==2.1` broke older versions of Jinja2 (specifically <3.0). We're still stuck on Flask<2.0 because our test suite broke when it was released and never got fixed. This is a temporary patch to get the test suite working again and I'm going to open an issue to track resolving the Flask issue.\r\n\r\nUpstream issue: pallets/markupsafe#283",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 13,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2022-02-19T01:24:21Z",
        "closed_at": "2022-02-19T23:04:07Z",
        "merged_at": "2022-02-19T23:04:07Z",
        "body": "This adds a warning around the Session proxies issues in Requests 2.x and cleans up a few erroneous sentences in the following section. Notably, rewording the environment intro to match the warning above, and removing `curl_ca_bundle` which was added in #5670. It's not particularly relevant to this section and is covered elsewhere.\r\n\r\n## Preview Render\r\n<img width=\"738\" alt=\"Screen Shot 2022-02-18 at 6 20 06 PM\" src=\"https://user-images.githubusercontent.com/5271761/154780254-5e7e16ac-b446-4fe8-93d4-917029f8f50e.png\">\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2022-02-13T20:08:08Z",
        "closed_at": "2022-02-14T12:53:31Z",
        "merged_at": null,
        "body": "websockets can also include params and so should be prepared as well",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2022-02-05T01:14:53Z",
        "closed_at": "2022-02-16T20:02:38Z",
        "merged_at": null,
        "body": "Fix session proxy issue where Session.proxies is ignore on self.request().\r\n\r\n#### Reproducible Code\r\n\r\n```python\r\nimport requests\r\ns = requests.Session()\r\ns.proxies = proxy\r\ns.get(\"https://google.com\").text\r\n```\r\n\r\n",
        "comments": 12
    },
    {
        "merged": true,
        "additions": 55,
        "deletions": 5,
        "changed_files": 3,
        "created_at": "2022-02-05T00:41:55Z",
        "closed_at": "2022-02-05T18:56:05Z",
        "merged_at": "2022-02-05T18:56:05Z",
        "body": "This should handle the issue raised in #6056 by wrapping the `SSLError` from urllib3 (`urllib3.exception.SSLError`) with ours (`requests.exception.SSLError`). Test was added to ensure we're doing the expected exception translation for everything we remap on streamed responses.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2022-01-11T15:27:18Z",
        "closed_at": "2022-01-11T17:42:01Z",
        "merged_at": "2022-01-11T17:42:01Z",
        "body": "I noticed the GH actions in my fork are constantly running lock threads which isn't serving a purpose beyond burning compute time. This PR should restrict the action to just the primary repo.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2022-01-09T14:39:49Z",
        "closed_at": "2022-01-09T16:15:57Z",
        "merged_at": null,
        "body": "- defining a new static variable in  HTTPAdapter : _clsHTTPResponse\r\n- using this variable instead of direct HTTPAdapter object creation\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2022-01-07T17:29:38Z",
        "closed_at": "2022-01-07T19:07:31Z",
        "merged_at": "2022-01-07T19:07:31Z",
        "body": null,
        "comments": 0
    },
    {
        "merged": true,
        "additions": 23,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2022-01-07T01:02:24Z",
        "closed_at": "2022-01-13T15:42:49Z",
        "merged_at": "2022-01-13T15:42:49Z",
        "body": "2.27 introduced a change in behavior where now the exception raised by parsing invalid data as json contains the full body of the invalid response. This gets included it's string representation. This can cause problems when the response is very large. This PR tries to limit the size of the response that we store this way, to what might be around the reported error position. But we could also just return to first n bytes or remove the response altogether and let users fetch it, if needed from the error.response object.",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2022-01-06T14:32:42Z",
        "closed_at": "2022-01-06T17:58:00Z",
        "merged_at": "2022-01-06T17:58:00Z",
        "body": "Pygments is mandatory for the Flask server. If Pygments is missing PyTest will not run :\r\n```\r\n=== ERRORS ===\r\n___ ERROR collecting docs/_themes/flask_theme_support.py ___\r\ndocs\\_themes\\flask_theme_support.py:2: in <module>\r\n    from pygments.style import Style\r\nE   ModuleNotFoundError: No module named 'pygments'\r\n=== short test summary info ===\r\nERROR docs/_themes/flask_theme_support.py - ModuleNotFoundError: No module named 'pygments'\r\n```\r\n\r\nPySocks is mandatory for test_lowlevel.py, if PySocks is missing 8 tests could fail: \r\n```\r\nFAILED tests/test_lowlevel.py::test_use_proxy_from_environment[http_proxy-http] - requests.exceptions.InvalidSchema: Missing dependencies for SOCKS support.\r\nFAILED tests/test_lowlevel.py::test_use_proxy_from_environment[https_proxy-https] - requests.exceptions.InvalidSchema: Missing dependencies for SOCKS support.\r\nFAILED tests/test_lowlevel.py::test_use_proxy_from_environment[all_proxy-http] - requests.exceptions.InvalidSchema: Missing dependencies for SOCKS support.\r\nFAILED tests/test_lowlevel.py::test_use_proxy_from_environment[all_proxy-https] - requests.exceptions.InvalidSchema: Missing dependencies for SOCKS support.\r\nFAILED tests/test_lowlevel.py::test_use_proxy_from_environment[HTTP_PROXY-http] - requests.exceptions.InvalidSchema: Missing dependencies for SOCKS support.\r\nFAILED tests/test_lowlevel.py::test_use_proxy_from_environment[HTTPS_PROXY-https] - requests.exceptions.InvalidSchema: Missing dependencies for SOCKS support.\r\nFAILED tests/test_lowlevel.py::test_use_proxy_from_environment[ALL_PROXY-http] - requests.exceptions.InvalidSchema: Missing dependencies for SOCKS support.\r\nFAILED tests/test_lowlevel.py::test_use_proxy_from_environment[ALL_PROXY-https] - requests.exceptions.InvalidSchema: Missing dependencies for SOCKS support.\r\n```",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2022-01-04T16:27:44Z",
        "closed_at": "2022-01-05T15:35:05Z",
        "merged_at": "2022-01-05T15:35:05Z",
        "body": "2.27.1 (2022-01-05)\r\n-------------------\r\n\r\n**Bugfixes**\r\n\r\n- Fixed parsing issue that resulted in the `auth` component being\r\n  dropped from proxy URLs. (#6028)",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 10,
        "changed_files": 3,
        "created_at": "2021-12-29T19:02:13Z",
        "closed_at": "2021-12-29T22:29:09Z",
        "merged_at": "2021-12-29T22:29:09Z",
        "body": "* Cleaning up incorrect example in README\r\n* Updating usage info\r\n* Updating verbiage for Python 2 support\r\n* Adding better trove classifiers for the 2.27.0 release",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-12-29T05:36:12Z",
        "closed_at": "2021-12-29T13:32:11Z",
        "merged_at": "2021-12-29T13:32:11Z",
        "body": "Updating `3.10-dev` to `3.10` in our CI and adding support for `pypy-3.7` since we're likely to be dropping `pypy3` support soon.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 48,
        "deletions": 8,
        "changed_files": 2,
        "created_at": "2021-12-29T04:55:15Z",
        "closed_at": "2022-01-03T14:59:11Z",
        "merged_at": "2022-01-03T14:59:11Z",
        "body": "2.27.0 (2022-01-03)\r\n-------------------\r\n\r\n**Improvements**\r\n\r\n- Officially added support for Python 3.10. (#5928)\r\n\r\n- Added a `requests.exceptions.JSONDecodeError` to unify JSON exceptions between\r\n  Python 2 and 3. This gets raised in the `response.json()` method, and is\r\n  backwards compatible as it inherits from previously thrown exceptions.\r\n  Can be caught from `requests.exceptions.RequestException` as well. (#5856)\r\n\r\n- Improved error text for misnamed `InvalidSchema` and `MissingSchema`\r\n  exceptions. This is a temporary fix until exceptions can be renamed\r\n  (Schema->Scheme). (#6017)\r\n\r\n- Improved proxy parsing for proxy URLs missing a scheme. This will address\r\n  recent changes to `urlparse` in Python 3.9+. (#5917)\r\n\r\n**Bugfixes**\r\n\r\n- Fixed defect in `extract_zipped_paths` which could result in an infinite loop\r\n  for some paths. (#5851)\r\n\r\n- Fixed handling for `AttributeError` when calculating length of files obtained\r\n  by `Tarfile.extractfile()`. (#5239)\r\n\r\n- Fixed urllib3 exception leak, wrapping `urllib3.exceptions.InvalidHeader` with\r\n  `requests.exceptions.InvalidHeader`. (#5914)\r\n\r\n- Fixed bug where two Host headers were sent for chunked requests. (#5391)\r\n\r\n- Fixed regression in Requests 2.26.0 where `Proxy-Authorization` was\r\n  incorrectly stripped from all requests sent with `Session.send`. (#5924)\r\n\r\n- Fixed performance regression in 2.26.0 for hosts with a large number of\r\n  proxies available in the environment. (#5924)\r\n\r\n- Fixed idna exception leak, wrapping `UnicodeError` with\r\n  `requests.exceptions.InvalidURL` for URLs with a leading dot (.) in the\r\n  domain. (#5414)\r\n\r\n**Deprecations**\r\n\r\n- Requests support for Python 2.7 and 3.6 will be ending in 2022. While we\r\n  don't have exact dates, Requests 2.27.x is likely to be the last release\r\n  series providing support.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2021-12-20T02:30:12Z",
        "closed_at": "2021-12-20T14:43:41Z",
        "merged_at": null,
        "body": "Simplifying the code, I'm not sure if there was a specific reason for this design but my implementation should perform the same thing unless I'm misunderstanding. ",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2021-12-19T23:50:36Z",
        "closed_at": "2021-12-20T01:12:30Z",
        "merged_at": null,
        "body": "Add an attribute that returns True when a status code is a success status code(in between 200 and 299 inclusive).",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 10,
        "deletions": 1,
        "changed_files": 3,
        "created_at": "2021-12-09T03:40:19Z",
        "closed_at": "2021-12-29T04:57:40Z",
        "merged_at": null,
        "body": "Fixes an issue with unverified SSL certificates not being rejected",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 58,
        "changed_files": 1,
        "created_at": "2021-12-08T13:37:14Z",
        "closed_at": "2021-12-08T15:03:49Z",
        "merged_at": null,
        "body": null,
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-12-05T07:40:13Z",
        "closed_at": "2021-12-05T10:52:10Z",
        "merged_at": "2021-12-05T10:52:10Z",
        "body": "Grammatical errors corrected.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 18,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2021-12-01T09:52:17Z",
        "closed_at": "2021-12-02T01:21:46Z",
        "merged_at": null,
        "body": "Added class for attaching access token to request object as an alternative for basic auth. I find it useful for services where OAuth is not an option.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-11-30T03:25:51Z",
        "closed_at": "2021-11-30T14:07:59Z",
        "merged_at": "2021-11-30T14:07:59Z",
        "body": "This updates `make test` to run tests in parallel using `tox -p` instead of `detox`. This has been supported since tox 3.7.0 and detox's PyPI page recommends switching to it.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-11-27T09:35:55Z",
        "closed_at": "2021-11-28T01:20:18Z",
        "merged_at": "2021-11-28T01:20:18Z",
        "body": "Modify the nosan_server fixture to cause test_https_warnings to be\r\nskipped when trustme is not installed on the system, rather than causing\r\nthe whole test suite to fail unconditionally.  This makes it possible\r\nto run all the remaining tests on systems where trustme cannot be\r\ninstalled due to its dependencies.",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-11-23T09:14:16Z",
        "closed_at": "2021-11-23T11:46:36Z",
        "merged_at": null,
        "body": "This change will make the hierarchy request **kwargs -> Session args -> environment to be respected. This also solves problems with pip as discussed [here](https://github.com/pypa/pip/issues/9691#issuecomment-791608247)  and  #5735",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2021-11-14T03:03:25Z",
        "closed_at": "2022-02-02T18:03:26Z",
        "merged_at": "2022-02-02T18:03:26Z",
        "body": "Closes #5558\r\n\r\nI also clarified that only one of those environment variables needs to be set.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2021-11-02T06:12:41Z",
        "closed_at": "2021-11-02T11:04:28Z",
        "merged_at": null,
        "body": "You have issue temaplet but i think you also need a pull request template so i created one oull request template at .github it may help you i commented some of the lines of the pull request template you can remove it from comment to code.\r\n\r\nI think it may help you \u263a\u263a",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2021-10-21T02:18:13Z",
        "closed_at": "2021-10-21T12:36:35Z",
        "merged_at": null,
        "body": "I've created a Flask server that accepts multipart data  (uploaded file) and simply proxy it to another server using Requests .\r\nI found that the upload works perfectly except the fact that Requests loses the filename. The uploaded filename is replaced with the field-name of the of the multipart data.\r\n\r\nIt seems that in Flask,  multipart  arrive as type `werkzeug.datastructures.FileStorage` . \r\nThe FileStorage instance includes the \"name\" attribute which is the field-name of the multipart  as well as the \"filename\" attribute which includes the filename.  \r\n\r\nThe `requests.utils.guess_filename`  currently using just the `name` attribute to determine (guess) the filename however in order to be compatible with Flask (and possible other libraries) it would probably be better to try first the \"filename\" attribute.\r\n\r\n\r\n\r\n\r\n\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 12,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2021-09-23T04:00:41Z",
        "closed_at": "2021-09-24T23:02:00Z",
        "merged_at": null,
        "body": "Use case: we would like to set a default `chunk_size` as shown in the new test.\r\n\r\nCurrent behavior errors (as shown in the first test-only commit):\r\n\r\n```\r\n>               self._content = b''.join(self.iter_content(CONTENT_CHUNK_SIZE)) or b''\r\nE               TypeError: iter_content() got multiple values for argument 'chunk_size'\r\n\r\n.tox\\default\\lib\\site-packages\\requests\\models.py:838: TypeError\r\n```\r\n\r\nThe alternative would be adding a new instance attribute to serve as a fallback but I doubt new features are being considered before the next major release and we are currently blocked on this https://github.com/DataDog/integrations-core/pull/10183\r\n\r\ncc @nateprewitt WDYT?",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-09-22T12:09:32Z",
        "closed_at": "2021-09-23T11:44:33Z",
        "merged_at": null,
        "body": "Teste #5",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 10,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-09-15T05:58:52Z",
        "closed_at": "2021-09-16T01:04:34Z",
        "merged_at": null,
        "body": "ignore paths that do not need to be tested.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 2,
        "changed_files": 3,
        "created_at": "2021-09-03T16:41:45Z",
        "closed_at": "2021-09-04T02:03:16Z",
        "merged_at": "2021-09-04T02:03:16Z",
        "body": "This will make sure we don't introduce any regressions into the code base prior to the official 3.10 release. At that point, we'll promote this to the normal test runner on all platforms.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2021-09-02T13:32:25Z",
        "closed_at": "2021-09-02T15:52:11Z",
        "merged_at": null,
        "body": "Fixes #5926\r\n\r\nI\u2019m not a web designer, so the positioning might be adjusted.\r\n\r\nHowever, the logo\u2019s restoration should take priority over bikeshedding.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 45,
        "deletions": 18,
        "changed_files": 3,
        "created_at": "2021-09-02T06:01:26Z",
        "closed_at": "2021-11-24T19:21:01Z",
        "merged_at": "2021-11-24T19:21:01Z",
        "body": "This is a proposal for handling #5888 that's come out of discussion in an alternative PR (#5893). Given that we've stalled out on progress there for a few weeks, this PR is to help drive a conclusion. The approach taken here is to mitigate the incorrect behavior of stripping `Proxy-Authorization` headers off all requests sent with `Session.send`. This will not address the performance concerns from #5891 as that's a more significant problem without a clear answer.\r\n\r\nThe goal of driving this separately from #5891 is that one is an unintended breakage in basic behavior of the library and the second is an unfortunate performance regression. I'd like to address the former more quickly if possible instead of letting the problem fester.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 10,
        "changed_files": 8,
        "created_at": "2021-09-02T03:20:46Z",
        "closed_at": "2021-09-02T15:53:46Z",
        "merged_at": "2021-09-02T15:53:46Z",
        "body": "General fixes for documentation including:\r\n* Adding alt tags to images\r\n* Fixing doc compilation errors\r\n* Updating broken links\r\n* Updating info in README.md\r\n* Updating target branch for repo URLs\r\n* Adding logo back to docs sidebar per Kenneth's request",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 16,
        "deletions": 6,
        "changed_files": 2,
        "created_at": "2021-08-27T19:10:24Z",
        "closed_at": "2021-12-29T13:31:40Z",
        "merged_at": "2021-12-29T13:31:40Z",
        "body": "This addresses the base problem raised in #5855 with the `urlparse` changes in Python 3.9 and potential issues in future 3.7/3.8 releases. We've avoided changing other uses of `urlparse` for now due to issues with `parse_url`'s strict validation requirements when performing parsing.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2021-08-26T05:59:23Z",
        "closed_at": "2021-08-26T10:58:35Z",
        "merged_at": "2021-08-26T10:58:35Z",
        "body": "It looks like our CodeQL workflow has been disabled since swapping the default branch. This patch should fix that.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2021-08-25T00:23:19Z",
        "closed_at": "2021-08-25T18:21:36Z",
        "merged_at": "2021-08-25T18:21:36Z",
        "body": null,
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2021-08-22T09:23:45Z",
        "closed_at": "2021-08-22T13:45:52Z",
        "merged_at": null,
        "body": "byte string is `b'test'`, while unicode string is `'test'`",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 22,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2021-08-20T09:22:40Z",
        "closed_at": "2021-08-25T02:00:18Z",
        "merged_at": "2021-08-25T02:00:17Z",
        "body": "This logic is not currently exercised anywhere in requests' tests.\r\n\r\nFor context, most errors that occur during the process of handling a request can be retried through [urllib3's Retry](https://urllib3.readthedocs.io/en/latest/reference/urllib3.util.html).   Currently, chunked encoding bypasses this, leading to a situation where users of requests are left to roll their own custom error handling for chunked encoding.  #5664 seeks to remedy that, but there are two issues:\r\n\r\nFirst, the current logic around chunked encoding has limited tests, and there is concern that accepting #5664 would introduce a regression.\r\nSecond, switching from requests' internal exceptions to urllib3's exceptions is a breaking change that will require appropriate notification to existing users.\r\n\r\nThis is a first step towards addressing both issues by exercising the chunked encoding logic internally, introducing a test that will break when requests switches to using urllib3's exceptions for chunked encoding, and providing a simple example to start with for any who seek to write further tests for the chunked encoding logic.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 52,
        "deletions": 16,
        "changed_files": 1,
        "created_at": "2021-07-30T03:29:40Z",
        "closed_at": "2021-08-28T04:37:00Z",
        "merged_at": null,
        "body": "Follow-up to the conversation in issue https://github.com/psf/requests/issues/5892.\r\n\r\nAs is, this change is not a breaking change and produces the exact same `_codes` dictionary. However, I\u2019ve separated out the official HTTP status codes from third-party status codes and added references to relevant documentation.\r\n\r\nIt would probably make sense to at least complete the list of [nginx codes](https://www.nginx.com/resources/wiki/extending/api/http/); [IIS codes](https://docs.microsoft.com/en-us/troubleshoot/iis/http-status-code) have non-integer sub-codes which may be problematic to represent here.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2021-07-29T02:56:36Z",
        "closed_at": "2021-12-29T17:06:05Z",
        "merged_at": "2021-12-29T17:06:05Z",
        "body": "\r\nSigned-off-by: David Black <dblack@atlassian.com>",
        "comments": 10
    },
    {
        "merged": false,
        "additions": 25,
        "deletions": 23,
        "changed_files": 1,
        "created_at": "2021-07-29T00:36:58Z",
        "closed_at": "2021-11-24T20:57:08Z",
        "merged_at": null,
        "body": "* do not rebuild proxies if they are configured\r\n* do not remove Proxy-Authorization on initial request\r\n* internal refactoring\r\n\r\n\r\nThis is my attempt to resolve https://github.com/psf/requests/issues/5891 as well as https://github.com/psf/requests/issues/5888.",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-07-28T08:48:27Z",
        "closed_at": "2021-07-28T16:23:08Z",
        "merged_at": "2021-07-28T16:23:08Z",
        "body": "Fix the listen() invocation for the test server not to pass a backlog\r\nvalue of zero.  The value of zero means no backlog which effectively\r\nmeans that the socket can not accept any connections.  This does not\r\nmatter for the majority of platforms since the value is only advisory\r\nand the platform tends to go with a bigger backlog anyway.  However,\r\na few platforms (e.g. alpha or riscv Linux) do take the value literally,\r\nand therefore the tests fail since they are unable to connect to\r\nthe server.  Let Python use a 'default reasonable value' instead.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 17,
        "changed_files": 3,
        "created_at": "2021-07-20T13:03:24Z",
        "closed_at": "2021-07-20T17:22:27Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-07-19T13:05:36Z",
        "closed_at": "2021-07-19T16:44:02Z",
        "merged_at": "2021-07-19T16:44:02Z",
        "body": "I am departing Red Hat so it would be best to contact the Python\r\nmaintenance team there instead of me if a vulnerability is discovered.\r\n\r\nCc: @hroncok ",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2021-07-16T20:28:21Z",
        "closed_at": "2022-02-02T18:39:16Z",
        "merged_at": null,
        "body": "https://tools.ietf.org/html/rfc6839#section-3.1",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 90,
        "deletions": 56,
        "changed_files": 2,
        "created_at": "2021-07-16T14:47:01Z",
        "closed_at": "2021-07-17T18:02:53Z",
        "merged_at": null,
        "body": "With this pull request I am trying to get rid of some differences in the interface definition and doc strings of `requests.api` and `requests.sessions.Session`.\r\n\r\nIn not all cases there was an obvious right choice and some discussion might be necessary.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2021-07-15T15:48:27Z",
        "closed_at": "2021-07-16T18:06:43Z",
        "merged_at": "2021-07-16T18:06:42Z",
        "body": "## Summary\r\n\r\nUpdates API links so the examples will work as expected.\r\n\r\nFixes #5876",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 130,
        "deletions": 52,
        "changed_files": 8,
        "created_at": "2021-07-15T12:24:28Z",
        "closed_at": "2022-05-11T01:26:03Z",
        "merged_at": null,
        "body": "An implementation of #5871 for consideration.\r\n\r\nUnlike my suggestion in #5871, this implementation _prefers_ `chardet` / `charset_normalizer` if it's available, with the idea that those libraries should hopefully do a better job than trying to decode the payload in the two most likely encodings.\r\n\r\nDecoding ASCII and UTF-8 ([\"UTF-8 is used by 97.0% of all the websites whose character encoding we know.\"](https://w3techs.com/technologies/details/en-utf8)) will continue to work without those libraries, and a helpful error is raised in other cases.\r\n\r\nThis is still missing documentation, changelogs, etc. \u2013 help appreciated.\r\n\r\nConsidering the switchover to `charset_normalizer` has broken some users' workflows anyway, I think it wouldn't be too much of an additional breaking change to do this without a major version bump.\r\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 15,
        "changed_files": 1,
        "created_at": "2021-07-15T10:55:38Z",
        "closed_at": "2021-07-16T14:49:15Z",
        "merged_at": null,
        "body": "It's unlikely that someone would be running [a version of cryptography from before June 2016](https://pypi.org/project/cryptography/1.3.3/) these days.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 39,
        "deletions": 4,
        "changed_files": 3,
        "created_at": "2021-07-12T07:24:18Z",
        "closed_at": "2021-07-12T14:44:44Z",
        "merged_at": "2021-07-12T14:44:43Z",
        "body": "pytest-httpbin<1.0 ships with a server certificate with a commonName but\r\nno subjectAltName. urllib3 2.0 will stop supporting those in the future,\r\nso we want to upgrade pytest-httpbin.\r\n\r\nUnfortunately, `test_https_warnings` was relying on this broken\r\ncertificate. With this change, we use `trustme` to create a broken\r\ncertificate specifically for this test, so that we can upgrade\r\npytest-httpbin and make sure that other tests relying on httpbin TLS\r\nsupport will continue to work with urllib3 2.0.\r\n\r\nCloses #5530",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 24,
        "deletions": 7,
        "changed_files": 2,
        "created_at": "2021-07-09T19:45:56Z",
        "closed_at": "2021-07-13T14:52:02Z",
        "merged_at": "2021-07-13T14:52:02Z",
        "body": "2.26.0 (2021-07-13)\r\n-------------------\r\n\r\n**Improvements**\r\n\r\n- Requests now supports Brotli compression, if either the `brotli` or\r\n  `brotlicffi` package is installed. (#5783)\r\n\r\n- `Session.send` now correctly resolves proxy configurations from both\r\n  the Session and Request. Behavior now matches `Session.request`. (#5681)\r\n\r\n**Bugfixes**\r\n\r\n- Fixed a race condition in zip extraction when using Requests in parallel\r\n  from zip archive. (#5707)\r\n\r\n**Dependencies**\r\n\r\n- Instead of `chardet`, use the MIT-licensed `charset_normalizer` for Python3\r\n  to remove license ambiguity for projects bundling requests. If `chardet`\r\n  is already installed on your machine it will be used instead of `charset_normalizer`\r\n  to keep backwards compatibility. (#5797)\r\n\r\n  You can also install `chardet` while installing requests by\r\n  specifying `[use_chardet_on_py3]` extra as follows:\r\n\r\n    ```shell\r\n    pip install \"requests[use_chardet_on_py3]\"\r\n    ```\r\n  Note that installation of `chardet` in your environment through any means will disable use\r\n  of `charset_normalizer`.\r\n\r\n  Python 2.7 still depends upon the `chardet` module.\r\n\r\n- Requests now supports `idna` 3.x on Python 3. `idna` 2.x will continue to\r\n  be used on Python 2 installations. (#5711)\r\n\r\n**Deprecations**\r\n\r\n- The `requests[security]` extra has been converted to a no-op install.\r\n  PyOpenSSL is no longer the recommended secure option for Requests. (#5867)\r\n\r\n- Requests has officially dropped support for Python 3.5. (#5867)\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 21,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2021-07-08T19:34:17Z",
        "closed_at": "2021-07-09T17:51:38Z",
        "merged_at": null,
        "body": "#### Making the example code sample available as a copy and paste and then run in any exiting python file.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-07-05T08:32:16Z",
        "closed_at": "2021-07-06T11:33:30Z",
        "merged_at": null,
        "body": "",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 47,
        "deletions": 18,
        "changed_files": 7,
        "created_at": "2021-07-03T21:08:32Z",
        "closed_at": "2021-07-26T15:56:44Z",
        "merged_at": "2021-07-26T15:56:44Z",
        "body": "## Summary\r\nFixes the inconsistency of errors thrown in the `response.json()` method in `models.py`, while preserving backwards compatibility. \r\n\r\n### What we used to have\r\nDepending on whether or not `simplejson` was installed in the user's library, and whether the user was running Python 3+ versus Python 2, a different exception would get thrown when there was an issue with decoding response text as JSON. If `simplejson` was installed, `simplejson.JSONDecodeError` would get thrown. If not, `json.JSONDecodeError` would get thrown for Python 3+ users, and `ValueError` for Python 2 users. Thus, depending on the scenario, users would find themselves having to catch either `simplejson.JSONDecodeError`, `json.JSONDecodeError`, or `ValueError` in the case of the `response.json()` method failing. This inconsistency is not ideal.\r\n\r\n### What we have now\r\nThere is now one error class in `exceptions.py` that will represent all errors that can be thrown or caught in the `response.json()` method: `requests.JSONDecodeError`. All `simplejson` functionality was replaced with `json` functionality, but the new error type aliases both `json.JSONDecodeError` and `simplejson.JSONDecodeError`. If `simplejson` is not installed, its `JSONDecodError` is replaced with a plain `Exception` when aliased. If the user is running Python 3+, `json.JSONDecodeError` is aliased, but if the user is running Python 2, that is replaced with `ValueError` when aliased, as the `JSONDecodeError` was not previously a part of the `json` library. Now, all five error types, `json.JSONDecodeError`, `simplejson.JSONDecodeError`, `ValueError`, and `requests.JSONDecodeError` and its parent class `requests.RequestException`, will be caught from the `requests.JSONDecodeError` that will be raised.\r\n\r\nFixes #5794\r\n@sigmavirus24 ",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2021-06-30T21:29:35Z",
        "closed_at": "2021-08-03T00:40:35Z",
        "merged_at": "2021-08-03T00:40:34Z",
        "body": "Fixes https://github.com/psf/requests/issues/5850",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-05-18T15:07:30Z",
        "closed_at": "2021-07-18T10:59:38Z",
        "merged_at": "2021-07-18T10:59:38Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 90,
        "deletions": 24,
        "changed_files": 9,
        "created_at": "2021-05-16T15:48:41Z",
        "closed_at": "2021-05-17T12:32:56Z",
        "merged_at": null,
        "body": "This PR extends and updates tox infrastructure of requests\r\nto run tests in different environment - with or without\r\nlgpl extra.\r\n\r\nIt should be merged only after the PR introducing the\r\nlgpl extra has been merged:\r\n\r\nhttps://github.com/psf/requests/pull/5797\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-05-14T02:22:50Z",
        "closed_at": "2021-05-14T03:34:53Z",
        "merged_at": null,
        "body": "initialisation -> initialization",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2021-05-06T19:37:35Z",
        "closed_at": "2021-05-07T16:54:38Z",
        "merged_at": "2021-05-07T16:54:38Z",
        "body": "The current  documentation contains two references to Kenneth Reitz's \"Be Cordial or Be on Your Way\" but the URL for this has now changed. The PR replaces these with the current URL.",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2021-05-04T10:37:03Z",
        "closed_at": "2021-05-06T18:18:58Z",
        "merged_at": "2021-05-06T18:18:58Z",
        "body": "I am attempting to fix #5767 with this PR. Feedback is really appreciated. ",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 12,
        "changed_files": 3,
        "created_at": "2021-05-01T13:48:59Z",
        "closed_at": "2021-05-01T15:44:11Z",
        "merged_at": null,
        "body": "\r\nSigned-off-by: Harmouch101 <mahmoudddharmouchhh@gmail.com>",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 14,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2021-04-25T19:54:52Z",
        "closed_at": "2021-04-26T11:10:46Z",
        "merged_at": null,
        "body": "I often find myself having to do the following when using `Session` with custom retrying logic:\r\n```\r\nretry = Retry(3, backoff_factor=1.)\r\nhttp_adapter = requests.adapters.HTTPAdapter(pool_connections=4, max_retries=retry)\r\nsession = requests.Session()\r\nsession.mount('https://', http_adapter)\r\nsession.mount('http://', http_adapter)\r\n```\r\n\r\nHaving to mount the adapter myself for such a simple use-case seems superfluous, error-prone and not very user-friendly so I'm suggesting we open up the Session constructor a little bit:\r\n\r\n```\r\nretry = Retry(3, backoff_factor=1.)\r\nhttp_adapter = requests.adapters.HTTPAdapter(pool_connections=4, max_retries=retry)\r\nsession = requests.Session(http_adapter=http_adapter)\r\n```",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2021-04-25T03:32:04Z",
        "closed_at": "2021-04-30T02:48:50Z",
        "merged_at": null,
        "body": "This PR mades users understand that the library supports the patch method and the simple use of it quickly.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 119,
        "deletions": 27,
        "changed_files": 10,
        "created_at": "2021-04-22T08:25:50Z",
        "closed_at": "2021-07-06T23:55:03Z",
        "merged_at": "2021-07-06T23:55:02Z",
        "body": "At least for Python 3 -- charset_normalizer doesn't support Python2, so for that chardet is still used -- this means the \"have chardet\" path is also still tested.\r\n\r\nAlthough using the (non-vendored) chardet library is fine for requests itself, but using a LGPL dependency the story is a lot less clear for downstream projects, particularly ones that might like to bundle requests (and thus chardet) in to a single binary -- think something similar to what docker-compose is doing. By including an LGPL'd module it is no longer clear if the resulting artefact must also be LGPL'd.\r\n\r\nBy changing out this dependency for one under MIT we remove all license ambiguity.\r\n\r\nAs an \"escape hatch\" I have made the code so that it will use chardet first if it is installed, but we no longer depend upon it directly, although there is a new extra added, `requests[lgpl]`. This should minimize the impact to users, and give them an escape hatch if charset_normalizer turns out to be not as good. (In my non-exhaustive tests it detects the same encoding as chartdet in every case I threw at it)\r\n\r\nI've read https://github.com/psf/requests/pull/4115, https://github.com/psf/requests/issues/3389, and https://github.com/chardet/chardet/issues/36#issuecomment-768281452 so I'm aware of the history, but I hope that the approach in this PR will allow this to be merged, as right now, the Apache Software Foundation doesn't allow projects to depend upon LGPL'd code (this is something I'm trying to get changed, but it is a _very_ slow process)\r\n",
        "comments": 105
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2021-04-11T19:00:47Z",
        "closed_at": "2021-09-02T15:49:30Z",
        "merged_at": null,
        "body": "\u2026an exception\r\n\r\nThis short-circuit code will skip the steps for decoding response.reason if the status code is not an exception-raising status code.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-04-10T02:01:13Z",
        "closed_at": "2021-04-11T16:25:49Z",
        "merged_at": "2021-04-11T16:25:49Z",
        "body": "Fixes https://github.com/psf/requests/issues/5785\r\n\r\nCould not find the second error as described `This is also a problem on the pypi page under the project description.`",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-03-31T10:25:43Z",
        "closed_at": "2021-03-31T11:32:39Z",
        "merged_at": null,
        "body": "fix typo",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 1,
        "changed_files": 4,
        "created_at": "2021-03-29T18:53:59Z",
        "closed_at": "2021-07-07T13:16:28Z",
        "merged_at": "2021-07-07T13:16:28Z",
        "body": "When the `brotli` or `brotlicffi` packages are installed, `urllib3.util.make_headers()` inserts ',br' in the Accept-Encoding header and decodes br from the answers.",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-03-19T18:38:13Z",
        "closed_at": "2021-03-19T22:09:29Z",
        "merged_at": "2021-03-19T22:09:29Z",
        "body": "Removed `import re` as unnecessary import",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2021-03-19T07:38:02Z",
        "closed_at": "2021-03-19T16:44:20Z",
        "merged_at": "2021-03-19T16:44:20Z",
        "body": "Not a big problem, just remove the redundant param `allow_redirects` in API `get()` and `options()`. Cause the underlying calling `Session.request()` has param `allow_redirects` defaults to `True`.\r\n\r\nOnly leaves\r\n\r\n```python\r\ndef head(url, **kwargs):\r\n    kwargs.setdefault('allow_redirects', False)\r\n    return request('head', url, **kwargs)\r\n```\r\n\r\nin `api.py` to make a contrast that http method `head()` is the only one disallows redirects by default.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2021-03-18T09:06:28Z",
        "closed_at": "2021-03-18T14:36:35Z",
        "merged_at": "2021-03-18T14:36:35Z",
        "body": "% `python2 -c \"import requests ; requests.get('https://github.com').json()\"`\r\n% `python3 -c \"import requests ; requests.get('https://github.com').json()\"`\r\n\r\nPython | Simplejson is installed  | Simplejson is NOT installed\r\n--- | --- | ---\r\nPython 2 | simplejson.JSONDecodeError | ValueError\r\nPython 3 | simplejson.JSONDecodeError | json.JSONDecodeError",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 8,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2021-03-15T15:07:31Z",
        "closed_at": "2021-03-15T17:18:19Z",
        "merged_at": null,
        "body": "## issue\r\n\r\n#5773\r\n\r\n## changes\r\n\r\nCreate a subclass that divides the connect argument of TimeoutSauce by 2.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 21,
        "deletions": 13,
        "changed_files": 2,
        "created_at": "2021-02-20T11:03:52Z",
        "closed_at": "2023-07-30T02:00:07Z",
        "merged_at": null,
        "body": "Fixes #5744",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 77,
        "deletions": 9,
        "changed_files": 2,
        "created_at": "2021-02-17T12:14:50Z",
        "closed_at": "2021-02-17T15:27:59Z",
        "merged_at": null,
        "body": "Add an util's method in `utils.py` named `unfold_complex_data_key`, called by `RequestEncodingMixin._encode_params` to support complex dict struct when content-type is `x-www-form-urlencoded`.\r\nThe function unfold_complex_data_key just do the follow work:\r\nUnfold complex dict which has deep level key or list to simple list[tuple]\r\nwhen requests.post()'s pemeter data is\r\n`{ \"id\": \"857-37-9333\", \"label\": \"User\", \"count\": 0, \"properties\": { \"name\": \"Rich Hintz\", \"city\": \"New Edythstad\", \"gender\": \"male\", \"age\": 24, \"profile\": [ \"Zondy\", \"ZTESoft\", \"YunWen\", \"Ci123\" ] } }`\r\nencoding the date to follow format:\r\n`[('id','857-37-9333'), ('label','User'), ('count',0), ('properties[name]','Rich Hintz'), ('properties[city]','New Edythstad') ('properties[gender]','male'), ('properties[age]',24), ('properties[profile][0]','Zondy'), ('properties[profile][1]','ZTESoft'), ('properties[profile][2]','YunWen'), ('properties[profile][3]','Ci123')]`",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 105,
        "deletions": 9,
        "changed_files": 3,
        "created_at": "2021-02-17T11:00:41Z",
        "closed_at": "2021-02-17T12:08:37Z",
        "merged_at": null,
        "body": "Add an util's method in `utils.py`, named `unfold_complex_data_key`, called by `RequestEncodingMixin._encode_params` to support complex dict struct when content-type is `x-www-form-urlencoded`.\r\nThe function unfold_complex_data_key just do the follow work:\r\nUnfold complex dict which has deep level key or list to simple list[tuple]\r\nwhen requests.post()'s pemeter data is \r\n`\r\n {\r\n           \"id\": \"857-37-9333\",\r\n           \"label\": \"User\",\r\n           \"count\": 0,\r\n           \"properties\": {\r\n               \"name\": \"Rich Hintz\",\r\n               \"city\": \"New Edythstad\",\r\n               \"gender\": \"male\",\r\n               \"age\": 24,\r\n               \"profile\": [\r\n                   \"Zondy\",\r\n                   \"ZTESoft\",\r\n                   \"YunWen\",\r\n                   \"Ci123\"\r\n               ]\r\n           }\r\n}\r\n`\r\nencoding the date to follow format:\r\n`\r\n[\r\n        ('id','857-37-9333'),\r\n        ('label','User'),\r\n        ('count',0),\r\n        ('properties[name]','Rich Hintz'),\r\n        ('properties[city]','New Edythstad')\r\n        ('properties[gender]','male'),\r\n        ('properties[age]',24),\r\n        ('properties[profile][0]','Zondy'),\r\n        ('properties[profile][1]','ZTESoft'),\r\n        ('properties[profile][2]','YunWen'),\r\n        ('properties[profile][3]','Ci123'),\r\n]\r\n`",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2021-02-10T10:57:41Z",
        "closed_at": "2022-05-11T01:28:52Z",
        "merged_at": null,
        "body": "This is a super quick attempt to address https://github.com/psf/requests/issues/5746 -- an invitation for feedback. Would appreciate your opinions. Thanks!",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-01-29T10:36:45Z",
        "closed_at": "2021-01-29T18:27:11Z",
        "merged_at": null,
        "body": "I find myself pinning for this quite a bit.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-01-20T01:28:08Z",
        "closed_at": "2021-01-20T14:58:36Z",
        "merged_at": "2021-01-20T14:58:36Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2021-01-10T15:35:20Z",
        "closed_at": "2021-01-10T17:16:43Z",
        "merged_at": null,
        "body": "Frequently, I find myself doing the following:\r\n```python\r\nr = requests.get(url)\r\nr.raise_for_status()\r\njson = r.json()\r\n```\r\n\r\nI thought it may be useful to be able to do the following instead, where `raise_for_status()` is chainable:\r\n```python\r\nr = requests.get(url)\r\njson = r.raise_for_status().json()\r\n```",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2021-01-08T02:47:03Z",
        "closed_at": "2021-01-08T19:24:55Z",
        "merged_at": null,
        "body": "This PR adds the `json` argument to both the `put` and `patch` function definitions. This is to bring them into agreement with the docstring of each function and to mirror the definition of `post`.\r\nThis should not change any functionally as the `json` arg would be captured by the `**kwargs` expansion. \r\n\r\nObviously, if this difference was intentional, feel free to close without merging. Alternatively, if you prefer I can quickly put together a pr to update the docstring. It was just something that briefly tripped me up and I figured it was quick and easy to change.  ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-01-01T12:31:47Z",
        "closed_at": "2021-07-07T13:25:20Z",
        "merged_at": "2021-07-07T13:25:20Z",
        "body": "Closes https://github.com/psf/requests/issues/5710",
        "comments": 18
    },
    {
        "merged": true,
        "additions": 18,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2020-12-24T19:20:04Z",
        "closed_at": "2021-07-07T00:14:52Z",
        "merged_at": "2021-07-07T00:14:52Z",
        "body": "Extract also creates the folder hierarchy, however we do not need that,\nthe file itself being extracted to a temporary folder is good enough.\nInstead we read the content of the zip and then write it. The write is\nnot locked but it's OK to update the same file multiple times given the\nupdate operation will not alter the content of the file. By not creating\nthe folder hierarchy (default via extract) we no longer can run into the\nproblem of two parallel extracts both trying to create the folder\nhierarchy without exists ok flag, and one must fail.\n\nResolves #5223.\n\nSigned-off-by: Bern\u00e1t G\u00e1bor <bgabor8@bloomberg.net>\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-12-23T05:14:15Z",
        "closed_at": "2020-12-23T14:19:41Z",
        "merged_at": null,
        "body": "A liitle bit of stats update \ud83d\ude04",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2020-12-20T11:25:47Z",
        "closed_at": "2020-12-20T12:47:22Z",
        "merged_at": null,
        "body": "You should check the protocol, not the start of the URL. Otherwise, this will be a valid protocol: `httpfuck://google.com`",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2020-12-20T10:48:01Z",
        "closed_at": "2020-12-20T13:36:27Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 15,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2020-12-20T06:28:32Z",
        "closed_at": "2020-12-20T12:40:07Z",
        "merged_at": null,
        "body": "## The old behavior:\r\n\r\n```python\r\n>>> requests.get('http://127.0.0.1:8080', auth=(None, None))\r\n```\r\n\r\n```http\r\nGET / HTTP/1.1\r\nHost: 127.0.0.1:8080\r\nUser-Agent: python-requests/2.25.0\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\nAuthorization: Basic Tm9uZTpOb25l (None:None)\r\n```\r\n\r\nThe same thing will happen with:\r\n\r\n```python\r\n>>> requests.get('http://127.0.0.1:8080', auth=('None', 'None'))\r\n```\r\n\r\nThis is weird, right!\r\n\r\n## Now:\r\n```python\r\n>>> requests.get('http://127.0.0.1:8080', auth=(None, None))\r\n```\r\n\r\n```http\r\nGET / HTTP/1.1\r\nHost: 127.0.0.1:8080\r\nUser-Agent: python-requests/2.25.0\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\n```\r\n(No authentication)\r\n\r\nThis will be easier if the application allows auth username and password from arguments:\r\n\r\n```python\r\nresponse = self.session.request(\r\n                    self.httpmethod,\r\n                    url,\r\n                    data=self.data,\r\n                    proxies=proxy,\r\n                    verify=False,\r\n                    allow_redirects=self.redirect,\r\n                    headers=dict(self.headers),\r\n                    timeout=self.timeout,\r\n                    auth=(self.user, self.pass)\r\n                )\r\n```\r\n\r\nIf the user didn't provide credentials, which means they don't need to authenticate, then `self.user == None` and `self.pass == None`. And in this situation, `requests` with my update won't perform authentication!\r\n\r\nIn the old version (without my update), it will be like:\r\n\r\n```python\r\nif self.user and self.pass:\r\n    response = self.session.request(\r\n                        self.httpmethod,\r\n                        url,\r\n                        data=self.data,\r\n                        proxies=proxy,\r\n                        verify=False,\r\n                        allow_redirects=self.redirect,\r\n                        headers=dict(self.headers),\r\n                        timeout=self.timeout,\r\n                        auth=(self.user, self.pass)\r\n                    )\r\nelse:\r\n    response = self.session.request(\r\n                        self.httpmethod,\r\n                        url,\r\n                        data=self.data,\r\n                        proxies=proxy,\r\n                        verify=False,\r\n                        allow_redirects=self.redirect,\r\n                        headers=dict(self.headers),\r\n                        timeout=self.timeout\r\n                    )\r\n```",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-12-20T05:46:52Z",
        "closed_at": "2020-12-20T11:34:28Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 29,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-12-20T04:41:32Z",
        "closed_at": "2020-12-20T11:35:18Z",
        "merged_at": null,
        "body": "Create check-pep8.yml",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 8,
        "deletions": 8,
        "changed_files": 3,
        "created_at": "2020-12-19T01:12:57Z",
        "closed_at": "2021-11-28T14:21:10Z",
        "merged_at": null,
        "body": "Requests simply delegates to `urllib3.util.Timeout`, and urllib3 has of course supported ints for a very long time \u2013 at least Sept 2013 per the docstring changes, but likely much longer than that. The [timeout section in the advanced docs](https://github.com/psf/requests/blob/c2b307dbefe21177af03f9feb37181a89a799fcc/docs/user/advanced.rst#timeouts) actually has an example that uses an int, but the API docs (via function docstrings) don't mention this so far.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 13,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2020-12-16T17:56:20Z",
        "closed_at": "2020-12-16T19:34:27Z",
        "merged_at": "2020-12-16T19:34:27Z",
        "body": "2.25.1 (2020-12-16)\r\n-------------------\r\n\r\n**Bugfixes**\r\n\r\n- Requests now treats `application/json` as `utf8` by default. Resolving\r\n  inconsistencies between `r.text` and `r.json` output. (#5673)\r\n\r\n**Dependencies**\r\n\r\n- Requests now supports chardet v4.x.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2020-12-11T01:26:30Z",
        "closed_at": "2020-12-14T17:29:11Z",
        "merged_at": "2020-12-14T17:29:11Z",
        "body": "I just released [chardet 4.0.0](https://github.com/chardet/chardet/releases/tag/4.0.0) today, and it's faster and fully backward compatible with chardet 3.x (as long as you aren't mucking around in the models it uses under-the-hood directly). The next major release will be Python 3.6+, but seeing as it took me three years to put out this one, that's unlikely to be soon.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 40,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2020-12-08T17:39:44Z",
        "closed_at": "2021-01-24T22:59:47Z",
        "merged_at": "2021-01-24T22:59:47Z",
        "body": "- Adds some test cases to highlight the issue, some of those seem excessive, I would like suggestions on how to combine them.\r\n- Rebuilds the proxy configuration on `send`, making it behave like `requests.Session#request` that already did that.  \r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 47,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2020-11-27T11:06:11Z",
        "closed_at": "2020-12-04T19:38:17Z",
        "merged_at": "2020-12-04T19:38:17Z",
        "body": "Hi, I have spent the past 15 years working in professional environments where the http/https proxy was the most annoying issue to myself and all my developer colleagues (in java, matlab, python...). A few years ago I even ended up writing a internal tutorial for our corporate proxy, a public one (https://smarie.github.io/develop-behind-proxy/), and a environment switching tool (https://smarie.github.io/env-switcher-gui/) that is used by many of us especially the ones switching from home office to work place regularly.\r\n\r\nThis introduction just to say that even if this is issue is now fairly trivial to me, I have been helping hundreds of colleagues over the year (and am still from time to time) so I believe that it is not yet easy to understand for most people.\r\n\r\n`requests` is working perfectly fine with proxies. However the way it finds the proxy-related information is not very well documented, and the way one can override this information on a `Session` is quite un-pythonic (a plain dict, therefore possibly error-prone). Some work I did a few months ago using `requests-oauthlib` made me once again think that it would be extremely helpful to have a good helper function on the `Session` object.\r\n\r\nThis PR contains two things:\r\n\r\n - a `Session.set_http_proxy` method with associated unit tests\r\n - an update for the Proxies documentation section\r\n\r\nI had one afterthought after completing this, maybe you'll find this relevant too: instead of providing just one `set_http_proxy` method, maybe it would be better to split it into two : `set_http_proxy` and `set_https_proxy`. Far more simple and elegant in my opinion, but I'll wait for your first feedback before modding anything here.\r\n\r\nThanks for your time and for maintaining this great lib!\r\n",
        "comments": 8
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 58,
        "changed_files": 1,
        "created_at": "2020-11-18T09:16:53Z",
        "closed_at": "2023-04-23T18:05:04Z",
        "merged_at": null,
        "body": "This is a resubmit of Use urllib for chunked requests #5128 which was merged and then pulled without warning.\r\n\r\n\"Resubmit of #4958 with up to date merge. Also addresses #4179.\r\n\r\nSpecifically, in my use case, chunked requests when a proxy is in use results in failure to evaluate the proxy configuration and the request being sent direct. It appears that urllib3 supports chunking as an option so this fork to lower level urllib3 code seems to no longer be required.\"\r\n\r\n[](https://github.com/psf/requests/pull/5128)\r\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-11-18T07:05:01Z",
        "closed_at": "2020-11-18T16:32:03Z",
        "merged_at": "2020-11-18T16:32:03Z",
        "body": "Fixes https://github.com/psf/requests/issues/5662. \r\n\r\n`ubuntu-latest` points to 18.04 and will soon flip to 20.04.\r\n\r\nHowever tests currently fail on 20.04, so let's explicitly pin to 18.04 for now.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 8,
        "changed_files": 7,
        "created_at": "2020-11-17T21:43:17Z",
        "closed_at": "2021-07-12T18:13:58Z",
        "merged_at": null,
        "body": "> Requests v2.25.x will be the last release series with support for Python 3.5.\r\n\r\nhttps://requests.readthedocs.io/en/latest/community/updates/",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-11-15T22:38:41Z",
        "closed_at": "2021-07-12T18:19:46Z",
        "merged_at": null,
        "body": "This PR improves the documentation of the `Session.request()` method. Its `stream` parameter's description used to have remnants of the old `prefetch` parameter (from PR #1283), which are now rephrased slightly.\r\n\r\nThe new sentence is the same as that in the [Body Content Worklflow](https://requests.readthedocs.io/en/latest/user/advanced/#body-content-workflow) section of the documentation.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 48,
        "deletions": 1118,
        "changed_files": 10,
        "created_at": "2020-11-10T22:27:27Z",
        "closed_at": "2020-11-11T18:29:14Z",
        "merged_at": "2020-11-11T18:29:14Z",
        "body": "Moving us to GH Actions since our Travis configs are in relative disarray and we haven't been running Mac/Windows builds for years at this point.\r\n\r\n### Other changes in this PR:\r\n\r\n**Pipenv**\r\nPipenv has caused a lot of friction with users trying to submit PR updates that need dependency changes, so this removes it. I've readded a `requirements-dev.txt` to store dev dependencies.\r\n\r\n**Removal of pytest-xdist**\r\n`pytest-xdist` causes threading issues on macOS for some versions of Python [StackOverflow issue](https://stackoverflow.com/questions/50168647/multiprocessing-causes-python-to-crash-and-gives-an-error-may-have-been-in-progr/52230415). The performance gain on tests is negligible, so I've removed it for config simplicity. If there's strong demand, we could attempt the bash updates or split out the macOS test command in the action definition.\r\n\r\n**Adding Python 3.9**\r\nAdding 3.9 to tests so we can update our trove classifiers before releasing 2.25.\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 25,
        "deletions": 6,
        "changed_files": 4,
        "created_at": "2020-11-10T20:38:36Z",
        "closed_at": "2020-11-11T19:55:51Z",
        "merged_at": "2020-11-11T19:55:51Z",
        "body": "This is getting staged for a release this week to stay in sync with urllib3. This release should also resolve the outstanding doc issues with Requests on pypi (#5501).\r\n\r\n2.25.0 (2020-11-11)\r\n------------------\r\n\r\n**Improvements**\r\n\r\n- Added support for NETRC environment variable. (#5643)\r\n\r\n**Dependencies**\r\n\r\n- Requests now supports urllib3 v1.26.\r\n\r\n**Deprecations**\r\n\r\n- Requests v2.25.x will be the last release series with support for Python 3.5.\r\n- The `requests[security]` extra is officially deprecated and will be removed\r\n  in Requests v2.26.0.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-11-05T15:42:49Z",
        "closed_at": "2021-12-29T17:47:32Z",
        "merged_at": null,
        "body": "Ref. #5646",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2020-10-30T17:20:32Z",
        "closed_at": "2020-11-01T16:52:02Z",
        "merged_at": "2020-11-01T16:52:02Z",
        "body": "Resurecting https://github.com/psf/requests/pull/4339 with incorporated review/feedback\r\n\r\nFixes https://github.com/psf/requests/issues/4318\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 10,
        "deletions": 2,
        "changed_files": 5,
        "created_at": "2020-10-14T10:39:37Z",
        "closed_at": "2020-11-11T19:00:37Z",
        "merged_at": null,
        "body": "# Added Python 3.9 into CI, tox and setup.py\r\n\r\nThis PR is directly related to this issue #5620 \r\n\r\ncloses #5620 \r\n\r\n**This PR is currently a draft**\r\n\r\nI am creating the PR to run test suite/see how CI performs using python3.9 via Actions. I was unable to get a Python3.9 virtual environment working locally so this is my alternative to see if it works. (This is my first open-source contribution so if this approach is poor please go easy on me :) )",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-10-12T08:03:59Z",
        "closed_at": "2020-10-29T20:12:23Z",
        "merged_at": null,
        "body": "- Remove extraneous whitespace in `requires` list\r\n- Add spacing between `requires` and `test_requirements`",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-10-08T04:56:47Z",
        "closed_at": "2020-10-08T13:36:13Z",
        "merged_at": null,
        "body": "PullRequest",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-10-05T00:45:59Z",
        "closed_at": "2020-10-05T18:15:44Z",
        "merged_at": "2020-10-05T18:15:44Z",
        "body": "a small typo was corrected.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 66,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-10-01T14:19:41Z",
        "closed_at": "2020-10-02T22:10:53Z",
        "merged_at": "2020-10-02T22:10:53Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-10-01T09:42:42Z",
        "closed_at": "2020-10-01T16:30:52Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-09-24T07:05:29Z",
        "closed_at": "2021-05-04T20:46:08Z",
        "merged_at": null,
        "body": "Removed import re which looks like its unused in setup.py",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-09-23T11:20:12Z",
        "closed_at": "2020-11-17T01:31:40Z",
        "merged_at": "2020-11-17T01:31:40Z",
        "body": "replaced reference to requests-async with httpx the replacement project",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 174,
        "deletions": 10,
        "changed_files": 2,
        "created_at": "2020-08-27T16:50:29Z",
        "closed_at": "2020-08-27T18:09:02Z",
        "merged_at": "2020-08-27T18:09:02Z",
        "body": "This follows instructions from the Apache Foundation. It also ensures\r\nthat the license will be correctly detected by license scanning tools.\r\n\r\nNote that adding a NOTICE file triggers Section 4.d of the license,\r\nwhich is usually intended by users of the license.\r\n\r\nThe text that was in the LICENSE file before this change is intended\r\n(by the authors of the license) to be used as a file header, and not as\r\na full license notice for a project, but it is commonly used this way,\r\nso I would of course understand if this change is rejected.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 386,
        "deletions": 301,
        "changed_files": 10,
        "created_at": "2020-08-09T20:17:48Z",
        "closed_at": "2021-04-02T07:38:10Z",
        "merged_at": null,
        "body": "This is still a work in progress - I have to make sure that the tests are actually running, not skipped every time \ud83d\ude05 but [I would like to get feedback if the direction is right](https://github.com/psf/requests/blob/master/docs/dev/contributing.rst#get-early-feedback).\r\n\r\nI had to update some deps to make the tests pass after a lot of packages being updated after I added `brotli` to dev-packages. But I assume that this should be done anyway. Especially as there were discrepancies in the versions - f.e. `pytest` version in `setup.py` commit message declared v. 4 compatibility while the version in `Pipenv` was set to be at most v. 3.10.1.\r\n\r\nSpeaking of dependencies I have a doubt how to declare required urllib3 version. Technically the first with brotli support is 1.25.1, but this is a version not supported by Requests... Should I update all the references to require urllib3 >= 1.25.2 then instead of >= 1.25.1?",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-07-29T11:36:18Z",
        "closed_at": "2020-07-29T14:25:16Z",
        "merged_at": null,
        "body": "It looks like the documentation regarding how proxies should be defined is using the wrong scheme for https. I assume that this is a mistake, otherwise it would be good to explain why this is the case in the documentation.  ",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 502,
        "deletions": 1677,
        "changed_files": 47,
        "created_at": "2020-07-28T19:43:37Z",
        "closed_at": "2021-07-12T18:21:06Z",
        "merged_at": null,
        "body": "\u2026on guidelines",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-07-15T11:41:15Z",
        "closed_at": "2020-07-21T06:09:10Z",
        "merged_at": null,
        "body": "Python 3.8.4 is now released, but the version in README is still 3.7.4. Let's update it.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2020-06-22T10:25:12Z",
        "closed_at": "2021-12-29T17:50:00Z",
        "merged_at": null,
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-06-20T06:40:44Z",
        "closed_at": "2020-07-24T04:57:31Z",
        "merged_at": "2020-07-24T04:57:31Z",
        "body": "https://github.com/psf/requests/blob/2b3436e0e7831676044b57f6f2cc9eb7c188293e/requests/sessions.py#L707 supports `CURL_CA_BUNDLE` too so lets list it in docs.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-06-19T02:08:33Z",
        "closed_at": "2020-06-19T16:04:22Z",
        "merged_at": "2020-06-19T16:04:22Z",
        "body": "Closes #5504",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-06-16T11:05:54Z",
        "closed_at": "2020-06-16T20:16:41Z",
        "merged_at": null,
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2020-06-16T10:55:28Z",
        "closed_at": "2020-06-17T15:21:38Z",
        "merged_at": "2020-06-17T15:21:38Z",
        "body": "",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-06-15T17:19:00Z",
        "closed_at": "2020-06-15T19:56:08Z",
        "merged_at": "2020-06-15T19:56:08Z",
        "body": "Update number of repositories depending on requests",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2020-06-15T10:15:28Z",
        "closed_at": "2020-06-15T14:44:38Z",
        "merged_at": "2020-06-15T14:44:38Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 31,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2020-06-13T13:46:25Z",
        "closed_at": "2020-09-16T00:38:51Z",
        "merged_at": null,
        "body": "RFC 7230 says (see section [3.3.3 Message Body Length](https://tools.ietf.org/html/rfc7230#page-32)):\r\n\r\n> If a message is received with both a `Transfer-Encoding` and a `Content-Length` header field, the `Transfer-Encoding` overrides the `Content-Length`.\r\n\r\nSince HTTP servers MUST ignore `Content-Length` if `Transfer-Encoding` is sent, **python-requests** MUST follow the same logic and send payload using `chunked` approach if both are detected in among request headers.\r\n\r\nNormally, `Content-Length` MUST NOT be sent in the same request with `Trasnfer-Encoding`, however, it may happened both intentionally (e.g. malicious intent) and accidentally (e.g. proxying a request downstream).",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-06-11T13:34:20Z",
        "closed_at": "2020-07-21T06:18:59Z",
        "merged_at": null,
        "body": "There are various useful configurations of underlying urllib3 PoolManager not supported by the existing  HTTPAdapter, such as a global timeout, source_address, and many more https://github.com/urllib3/urllib3/blob/29b214a129883301f91ae4a74fd7ef2958cbf7b0/src/urllib3/poolmanager.py#L49-L75\r\n\r\nIt is trivial to support them directly. The construction of the HTTPAdapter's poolmanager at `HTTPAdapter.init_poolmanager(..., **pool_kwargs)` already contains this provision as the arbitrary `pool_kwargs` dict that is passed to the PoolManager constructor. All it takes is to also add this to the HTTPAdapter constructor, and pass it.\r\n\r\nIt also appears that this was the original intention that was somehow forgotten; this `**pool_kwargs` argument is not being passed by any caller of `init_poolmanager()`.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 8,
        "deletions": 34,
        "changed_files": 2,
        "created_at": "2020-06-07T17:35:17Z",
        "closed_at": "2021-09-19T13:43:56Z",
        "merged_at": null,
        "body": "The seuptools test command has been formally deprecated since version\r\n41.5.0 (27 Oct 2019). The project recommends replacing its use with tox\r\nas a project level testing entrypoint.\r\n\r\nFixes the warning when running tests:\r\n\r\n> WARNING: Testing via this command is deprecated and will be removed in\r\n> a future version. Users looking for a generic test entry point\r\n> independent of test runner are encouraged to use tox.\r\n\r\nFor more details, see the setuptools history:\r\nhttps://setuptools.readthedocs.io/en/latest/history.html#v41-5-0\r\n\r\nAnd the command's documentation:\r\nhttps://setuptools.readthedocs.io/en/latest/setuptools.html#test-build-package-and-run-a-unittest-suite",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2020-06-06T05:23:35Z",
        "closed_at": "2020-06-15T15:06:41Z",
        "merged_at": null,
        "body": "More readable",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 39,
        "changed_files": 4,
        "created_at": "2020-05-29T22:19:22Z",
        "closed_at": "2020-06-15T15:11:07Z",
        "merged_at": null,
        "body": "Monkey patching url3 with pyopenssl 3 is no longer a good idea nor even necessary, and actually has security drawbacks, as described in #5267.\r\n\r\nThis also undoes the changes I initially made in #1347, so I guess it means my previous contribution has completed its life cycle.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2020-05-29T02:23:52Z",
        "closed_at": "2020-06-17T20:09:35Z",
        "merged_at": "2020-06-17T20:09:35Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 10,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2020-05-25T20:32:35Z",
        "closed_at": "2021-02-20T14:48:20Z",
        "merged_at": null,
        "body": "When you are using reuqest.request to get large non-text files and you are trying to call r.text, it tries to auto-detect using chardet because there is no header defining the charset.\r\n\r\nWhen chardet is running on large EXE/PDF files (and maybe other file types) it takes quite some time to get the answer, which is None.\r\n\r\nOnce None returns, self.encoding receives the None value. Therefore the next time you call r.text on the same content, it will try to auto-detect again as if you never tried to auto-detect it.\r\n\r\nI know it doesn't make much sense to use r.text when requesting PDF/EXE files but sometimes websites do return EXE/PDF content and not HTML as you would expect.\r\n\r\nI think it can also improve performance when doing multiple calls to r.text on text content that needs to be auto-detected as well.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-05-21T13:44:07Z",
        "closed_at": "2020-06-15T15:23:17Z",
        "merged_at": "2020-06-15T15:23:17Z",
        "body": "Fix typo in README related to installation guidelines",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2020-05-20T19:01:12Z",
        "closed_at": "2021-01-04T23:47:23Z",
        "merged_at": null,
        "body": "Since there is no standard for the NO_PROXY environment variable allow values\r\nto be comma- and space-separated values.",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 11,
        "changed_files": 3,
        "created_at": "2020-05-15T12:45:27Z",
        "closed_at": "2020-07-21T06:29:19Z",
        "merged_at": null,
        "body": "Revert PR  #1440 as discussed in issue #3759 \r\nIt does not make sense to modify the cookie value arbitrarily.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-05-12T22:33:05Z",
        "closed_at": "2021-08-28T04:23:46Z",
        "merged_at": "2021-08-28T04:23:46Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 23,
        "deletions": 13,
        "changed_files": 1,
        "created_at": "2020-05-12T09:01:04Z",
        "closed_at": "2020-05-14T17:37:05Z",
        "merged_at": null,
        "body": "### This pull request  brings the following changes:\r\n\r\n- Ordered the commands to follow Travis CI execution order: <https://docs.travis-ci.com/user/job-lifecycle/#the-job-lifecycle> \r\n\r\n- Adds explicit os and dist commands protecting from changes on Travis default distro\r\n\r\n- Forces the build to use the latest minor version of each python release so build become fully reproducible",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-05-10T03:16:48Z",
        "closed_at": "2021-11-28T14:11:45Z",
        "merged_at": null,
        "body": "add a dot.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-05-09T21:12:38Z",
        "closed_at": "2020-11-17T01:49:54Z",
        "merged_at": null,
        "body": "I think python 3.8 is supported now after I checked some other places in this rep.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 21,
        "deletions": 8,
        "changed_files": 2,
        "created_at": "2020-04-30T13:57:50Z",
        "closed_at": "2020-05-01T23:33:52Z",
        "merged_at": "2020-05-01T23:33:52Z",
        "body": "This is part 1 on removing `requests[security]` extra, for now we can still support SNI-less installations of Python but instead of unconditional monkey-patching we only patch if we detect either no `ssl` module or no `SNI` support.\r\n\r\nRelated: https://github.com/psf/requests/issues/5267\r\ncc @tiran \r\n\r\nAn additional thought I had was if we wanted to warn users about the complete removal of `requests[security]` I don't think there's a way to detect if you were installed via `requests pyopenssl` or `requests[security]` beyond registering a name on PyPI like `requests-security-extra`, trying to import it, and if we do then we know we were installed via `requests[security]` so throw a deprecation warning? Otherwise our \"end-goal\" could be to have `requests[security]` be empty?",
        "comments": 18
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-04-26T13:46:47Z",
        "closed_at": "2020-05-09T04:52:02Z",
        "merged_at": null,
        "body": "when I run pytest in test_requests, an error occurred:\r\n\r\ndef test_conflicting_post_params(self, httpbin):\r\n        url = httpbin('post')\r\n        with open('Pipfile') as f:\r\n>           pytest.raises(ValueError, \"requests.post(url, data='[{\\\"some\\\": \\\"data\\\"}]', files={'some': f})\")\r\nE           TypeError: 'requests.post(url, data=\\'[{\"some\": \"data\"}]\\', files={\\'some\\': f})' object (type: <class 'str'>) must be callable\r\n\r\ntests/test_requests.py:777: TypeError\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 19,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2020-04-25T19:07:50Z",
        "closed_at": "2020-08-17T02:31:06Z",
        "merged_at": "2020-08-17T02:31:06Z",
        "body": "This PR makes the danger of setting `verify=False` clearer to users of requests. In many cases, users may set this to `False` when running into problems locally with self-signed certificates, but not realize the risk they are opening themselves up to.\r\n\r\nAs an example of how the dangers of not verifying TLS (SSL) certificates is communicated, see Go's `InsecureSkipVerify` docs: https://golang.org/pkg/crypto/tls/\r\n\r\n```\r\n    // InsecureSkipVerify controls whether a client verifies the\r\n    // server's certificate chain and host name.\r\n    // If InsecureSkipVerify is true, TLS accepts any certificate\r\n    // presented by the server and any host name in that certificate.\r\n    // In this mode, TLS is susceptible to man-in-the-middle attacks.\r\n    // This should be used only for testing.\r\n```\r\n\r\nHappy to take feedback on the wording / doc-style - this is my first PR to requests but I care a lot about 'safe defaults' in OSS!",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-04-22T13:43:00Z",
        "closed_at": "2022-05-11T01:01:58Z",
        "merged_at": null,
        "body": "Not sure if this is the best way to do it, but some sort of warning that \"hanging forever\" is a possibility is probably important - given that this lib is for \"humans\".",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-04-19T17:18:37Z",
        "closed_at": "2020-04-30T15:49:01Z",
        "merged_at": null,
        "body": "**The problem**: When there is an exception raised on a 400 \"Bad Request\" from the server. The information provided on the exception is not enough to debug problems. \r\n\r\n**Resolution**: Adding \"content\" attribute from the response to understand the error from the server's perspective.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-04-16T10:35:24Z",
        "closed_at": "2020-04-30T15:51:52Z",
        "merged_at": null,
        "body": "",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-04-14T18:41:02Z",
        "closed_at": "2020-04-15T21:49:40Z",
        "merged_at": null,
        "body": "This allows setting `REQUESTS_CA_BUNDLE=SYSTEM` to make Requests behaves like the base python standard library with respect to CA cert trust.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2020-04-05T16:52:04Z",
        "closed_at": "2021-12-29T01:39:37Z",
        "merged_at": "2021-12-29T01:39:36Z",
        "body": "Closes #5367\r\n\r\nAttempting to get `http://.example.com` results in a `UnicodeError` but should be raise `InvalidUrl` as attempting to get `http://*example.com`.\r\n\r\nI've added `InvalidUrl` tests for `http://.example.com` and `http://*example.com`.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-04-05T16:22:25Z",
        "closed_at": "2020-05-09T05:11:01Z",
        "merged_at": null,
        "body": "This property will return the entire HTTP response including the headers. There doesn't seem to be a `test_models.py` file in the tests folder so I'm not sure if I should make a test for this, but if so where would I make it?",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-04-02T08:50:39Z",
        "closed_at": "2021-11-28T14:32:29Z",
        "merged_at": "2021-11-28T14:32:29Z",
        "body": "When packaging requests and pip (which bundles it) in Fedora, we have realised\r\nthat there is a nonexecutable file with a shebang line.\r\n\r\nIt seems that the primary purpose of this file is to be imported from Python\r\ncode and hence the shebang appears to be unnecessary.\r\n\r\nShebangs are hard to handle when doing downstream packaging, because it makes\r\nsense for upstream to use `#!/usr/bin/env python` while in the RPM package, we\r\nneed to avoid that and use a more specific interpreter. Since the shebang was\r\nunused, I propose to remove it to avoid the problems.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 54,
        "deletions": 195,
        "changed_files": 1,
        "created_at": "2020-03-30T19:49:56Z",
        "closed_at": "2020-04-03T21:45:07Z",
        "merged_at": null,
        "body": "Bumps [bleach](https://github.com/mozilla/bleach) from 3.1.1 to 3.1.4.\n<details>\n<summary>Changelog</summary>\n<p><em>Sourced from <a href=\"https://github.com/mozilla/bleach/blob/master/CHANGES\">bleach's changelog</a>.</em></p>\n<blockquote>\n<h2>Version 3.1.4 (March 24th, 2020)</h2>\n<p><strong>Security fixes</strong></p>\n<ul>\n<li>\n<p><code>bleach.clean</code> behavior parsing style attributes could result in a\nregular expression denial of service (ReDoS).</p>\n<p>Calls to <code>bleach.clean</code> with an allowed tag with an allowed\n<code>style</code> attribute were vulnerable to ReDoS. For example,\n<code>bleach.clean(..., attributes={'a': ['style']})</code>.</p>\n<p>This issue was confirmed in Bleach versions v3.1.3, v3.1.2, v3.1.1,\nv3.1.0, v3.0.0, v2.1.4, and v2.1.3. Earlier versions used a similar\nregular expression and should be considered vulnerable too.</p>\n<p>Anyone using Bleach &lt;=v3.1.3 is encouraged to upgrade.</p>\n<p><a href=\"https://bugzilla.mozilla.org/show_bug.cgi?id=1623633\">https://bugzilla.mozilla.org/show_bug.cgi?id=1623633</a></p>\n</li>\n</ul>\n<p><strong>Backwards incompatible changes</strong></p>\n<ul>\n<li>Style attributes with dashes, or single or double quoted values are\ncleaned instead of passed through.</li>\n</ul>\n<p><strong>Features</strong></p>\n<p>None</p>\n<p><strong>Bug fixes</strong></p>\n<p>None</p>\n<h2>Version 3.1.3 (March 17th, 2020)</h2>\n<p><strong>Security fixes</strong></p>\n<p>None</p>\n<p><strong>Backwards incompatible changes</strong></p>\n<p>None</p>\n<p><strong>Features</strong></p>\n<ul>\n<li>\n<p>Add relative link to code of conduct. (<a href=\"https://github-redirect.dependabot.com/mozilla/bleach/issues/442\">#442</a>)</p>\n</li>\n<li>\n<p>Drop deprecated 'setup.py test' support. (<a href=\"https://github-redirect.dependabot.com/mozilla/bleach/issues/507\">#507</a>)</p>\n</li>\n</ul>\n</tr></table> ... (truncated)\n</blockquote>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/mozilla/bleach/commit/6e74a5027b57055cdaeb040343d32934121392a7\"><code>6e74a50</code></a> Update for v3.1.4 release</li>\n<li><a href=\"https://github.com/mozilla/bleach/commit/d6018f2539d271963c3e7f54f36ef11900363c69\"><code>d6018f2</code></a> fix bug 1623633</li>\n<li><a href=\"https://github.com/mozilla/bleach/commit/fc77027e67cc04aff6f4d4885358705f98ad20f4\"><code>fc77027</code></a> Merge branch 'v3.1.0-branch'</li>\n<li><a href=\"https://github.com/mozilla/bleach/commit/e4b1c50e098c33f82c862a34bb2a40f9c4458f46\"><code>e4b1c50</code></a> Update for v3.1.3 release</li>\n<li><a href=\"https://github.com/mozilla/bleach/commit/59cc502cee44bd18adc78619e6baed7a108c3ba1\"><code>59cc502</code></a> Update for v3.1.2 release</li>\n<li><a href=\"https://github.com/mozilla/bleach/commit/3f39d489ab7a1b38df8c245e9bd66217c1698369\"><code>3f39d48</code></a> add wheel to requirements-dev</li>\n<li><a href=\"https://github.com/mozilla/bleach/commit/175f67740e7951e1d80cefb7831e6c3e4efeb986\"><code>175f677</code></a> fix bug 1621692</li>\n<li><a href=\"https://github.com/mozilla/bleach/commit/78a06726dd6c72a42c90c1f7a8fa5d21ebcfa587\"><code>78a0672</code></a> Update for v3.1.2 release</li>\n<li><a href=\"https://github.com/mozilla/bleach/commit/7b625ff9f6888a08037700269fb23e3ef863b8a7\"><code>7b625ff</code></a> add wheel to requirements-dev</li>\n<li><a href=\"https://github.com/mozilla/bleach/commit/e4e9e21e7aebff40c88fafa4319bba4636a602d9\"><code>e4e9e21</code></a> fix bug 1621692</li>\n<li>Additional commits viewable in <a href=\"https://github.com/mozilla/bleach/compare/v3.1.1...v3.1.4\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=bleach&package-manager=pip&previous-version=3.1.1&new-version=3.1.4)](https://help.github.com/articles/configuring-automated-security-fixes)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n\nYou can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/psf/requests/network/alerts).\n\n</details>",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-03-29T10:01:08Z",
        "closed_at": "2020-03-30T04:25:45Z",
        "merged_at": null,
        "body": "typo in options?",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-03-28T23:26:27Z",
        "closed_at": "2020-04-03T20:59:18Z",
        "merged_at": "2020-04-03T20:59:18Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 54,
        "deletions": 195,
        "changed_files": 1,
        "created_at": "2020-03-24T15:11:07Z",
        "closed_at": "2020-03-30T19:50:01Z",
        "merged_at": null,
        "body": "Bumps [bleach](https://github.com/mozilla/bleach) from 3.1.1 to 3.1.2.\n<details>\n<summary>Changelog</summary>\n<p><em>Sourced from <a href=\"https://github.com/mozilla/bleach/blob/master/CHANGES\">bleach's changelog</a>.</em></p>\n<blockquote>\n<h2>Version 3.1.2 (March 11th, 2020)</h2>\n<p><strong>Security fixes</strong></p>\n<ul>\n<li>\n<p><code>bleach.clean</code> behavior parsing embedded MathML and SVG content\nwith RCDATA tags did not match browser behavior and could result in\na mutation XSS.</p>\n<p>Calls to <code>bleach.clean</code> with <code>strip=False</code> and <code>math</code> or\n<code>svg</code> tags and one or more of the RCDATA tags <code>script</code>,\n<code>noscript</code>, <code>style</code>, <code>noframes</code>, <code>iframe</code>, <code>noembed</code>, or\n<code>xmp</code> in the allowed tags whitelist were vulnerable to a mutation\nXSS.</p>\n<p>This security issue was confirmed in Bleach version v3.1.1. Earlier\nversions are likely affected too.</p>\n<p>Anyone using Bleach &lt;=v3.1.1 is encouraged to upgrade.</p>\n<p><a href=\"https://bugzilla.mozilla.org/show_bug.cgi?id=1621692\">https://bugzilla.mozilla.org/show_bug.cgi?id=1621692</a></p>\n</li>\n</ul>\n<p><strong>Backwards incompatible changes</strong></p>\n<p>None</p>\n<p><strong>Features</strong></p>\n<p>None</p>\n<p><strong>Bug fixes</strong></p>\n<p>None</p>\n</blockquote>\n</details>\n<details>\n<summary>Commits</summary>\n<ul>\n<li><a href=\"https://github.com/mozilla/bleach/commit/78a06726dd6c72a42c90c1f7a8fa5d21ebcfa587\"><code>78a0672</code></a> Update for v3.1.2 release</li>\n<li><a href=\"https://github.com/mozilla/bleach/commit/7b625ff9f6888a08037700269fb23e3ef863b8a7\"><code>7b625ff</code></a> add wheel to requirements-dev</li>\n<li><a href=\"https://github.com/mozilla/bleach/commit/e4e9e21e7aebff40c88fafa4319bba4636a602d9\"><code>e4e9e21</code></a> fix bug 1621692</li>\n<li>See full diff in <a href=\"https://github.com/mozilla/bleach/compare/v3.1.1...v3.1.2\">compare view</a></li>\n</ul>\n</details>\n<br />\n\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=bleach&package-manager=pip&previous-version=3.1.1&new-version=3.1.2)](https://help.github.com/articles/configuring-automated-security-fixes)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n\nYou can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/psf/requests/network/alerts).\n\n</details>",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 52,
        "deletions": 1,
        "changed_files": 3,
        "created_at": "2020-03-17T22:01:53Z",
        "closed_at": "2021-11-29T15:58:32Z",
        "merged_at": "2021-11-29T15:58:32Z",
        "body": "Send only one Host header when specifying a custom Host header in a chunked request.\r\n\r\nBefore this fix, the default Host header was sent along with the custom Host header.\r\n\r\nCloses #5274 ",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2020-03-12T07:05:56Z",
        "closed_at": "2020-05-06T09:58:52Z",
        "merged_at": null,
        "body": "When the `charset` is not declared in `Content-type`, the `get_encoding_from_headers` function returns `ISO-8859-1` as the response encoding by default, but the encoding is a single-byte encoding system, so if the response contains other multi-byte encoding languages like Chinese, `Response.text` will return garbage characters.\r\n\r\nSo I think it's better to leave it to `Response.apparent_encoding` to determine the encoding.\r\n\r\nfor example, if the response is like this\r\n```python\r\nr.headers['Content-Type'] == 'text/html'\r\nr.content == b'<title>\\xe4\\xb8\\xad\\xe6\\x96\\x87</title>'\r\nr.encoding == 'ISO-8859-1'\r\nr.text == '<title>\u00e4\u00b8\\xad\u00e6\\x96\\x87</title>' # garbage characters\r\n# but if we leave it to `Response.apparent_encoding`\r\nr.encoding == 'utf-8'\r\nr.text == '<title>\u4e2d\u6587</title>'\r\n```",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2020-03-09T19:29:32Z",
        "closed_at": "2021-12-29T17:46:21Z",
        "merged_at": "2021-12-29T17:46:21Z",
        "body": "As https://stackoverflow.com/q/26685248/2693875 question\r\nand answer popularity shows that there is a lot of people who\r\ndo not understand the distinction.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2020-03-09T12:30:06Z",
        "closed_at": "2020-03-09T14:02:56Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-03-02T21:46:23Z",
        "closed_at": "2021-12-17T02:16:58Z",
        "merged_at": null,
        "body": "Hello!\r\nAfter seeing this [question](https://stackoverflow.com/questions/60358216/python-requests-post-request-dropping-authorization-header), I thought a warning should be added when authentication is stripped from redirected requests, in order to save users a significant amount of debugging time.\r\nApparently the matter has already been discussed in [this issue](https://github.com/psf/requests/issues/2949), and it has been agreed upon that *some* message should be passed to the user, like a debug log or a warning. But requests still does not use logs, and it seems people are still confused by this.\r\nMaybe it is time to add a warning?",
        "comments": 8
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2020-03-01T23:02:36Z",
        "closed_at": "2020-03-03T00:58:12Z",
        "merged_at": null,
        "body": "Changed lower_items() to use iterable unpacking to clarify the intent of the function. Changed copy() and __eq__() to retrieve the class via inspection using type() -- this way behavior will be preserved in classes that inherit from CaseInsensitiveDict.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2020-02-27T04:51:32Z",
        "closed_at": "2020-02-27T18:05:07Z",
        "merged_at": "2020-02-27T18:05:07Z",
        "body": "Updating disclosure info so things reach the correct parties.\r\n\r\n@sethmlarson: PRing for you to proof I have all of your contact info correct.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 152,
        "deletions": 245,
        "changed_files": 1,
        "created_at": "2020-02-24T17:38:10Z",
        "closed_at": "2020-02-27T04:24:39Z",
        "merged_at": null,
        "body": "Bumps [bleach](https://github.com/mozilla/bleach) from 3.1.0 to 3.1.1.\n<details>\n<summary>Changelog</summary>\n\n*Sourced from [bleach's changelog](https://github.com/mozilla/bleach/blob/master/CHANGES).*\n\n> Version 3.1.1 (February 13th, 2020)\n> -----------------------------------\n> \n> **Security fixes**\n> \n> * ``bleach.clean`` behavior parsing ``noscript`` tags did not match\n>   browser behavior.\n> \n>   Calls to ``bleach.clean`` allowing ``noscript`` and one or more of\n>   the raw text tags (``title``, ``textarea``, ``script``, ``style``,\n>   ``noembed``, ``noframes``, ``iframe``, and ``xmp``) were vulnerable\n>   to a mutation XSS.\n> \n>   This security issue was confirmed in Bleach versions v2.1.4, v3.0.2,\n>   and v3.1.0. Earlier versions are probably affected too.\n> \n>   Anyone using Bleach <=v3.1.0 is highly encouraged to upgrade.\n> \n>   https://bugzilla.mozilla.org/show_bug.cgi?id=1615315\n> \n> **Backwards incompatible changes**\n> \n> None\n> \n> **Features**\n> \n> None\n> \n> **Bug fixes**\n> \n> None\n> \n> Bleach changes\n> ==============\n</details>\n<details>\n<summary>Commits</summary>\n\n- [`0d88dd8`](https://github.com/mozilla/bleach/commit/0d88dd83e425c4ba381d5b83fe61bfae5bbbd627) Update for v3.1.1 release\n- [`996cde7`](https://github.com/mozilla/bleach/commit/996cde7a2439a2323f9c4b2567c8b8449d393351) fix bug 1615315\n- See full diff in [compare view](https://github.com/mozilla/bleach/compare/v3.1.0...v3.1.1)\n</details>\n<br />\n\n[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=bleach&package-manager=pip&previous-version=3.1.0&new-version=3.1.1)](https://help.github.com/articles/configuring-automated-security-fixes)\n\nDependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.\n\n[//]: # (dependabot-automerge-start)\n[//]: # (dependabot-automerge-end)\n\n---\n\n<details>\n<summary>Dependabot commands and options</summary>\n<br />\n\nYou can trigger Dependabot actions by commenting on this PR:\n- `@dependabot rebase` will rebase this PR\n- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it\n- `@dependabot merge` will merge this PR after your CI passes on it\n- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it\n- `@dependabot cancel merge` will cancel a previously requested merge and block automerging\n- `@dependabot reopen` will reopen this PR if it is closed\n- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually\n- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)\n- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language\n- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language\n- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language\n- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language\n\nYou can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/psf/requests/network/alerts).\n\n</details>",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 61,
        "deletions": 109,
        "changed_files": 6,
        "created_at": "2020-02-18T23:16:02Z",
        "closed_at": "2020-02-19T00:56:40Z",
        "merged_at": "2020-02-19T00:56:40Z",
        "body": "A number of PRs were merged back in September without any proper review. There are some outstanding issues with the ones included in this PR that will need to be redone before we can put them in an official release.\r\n\r\nI'm going to revert for now to get 2.23.0 out the door, and we can revisit them afterwards as needed. attn: #4965, #4976, #5128",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 7,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-02-18T13:16:39Z",
        "closed_at": "2020-02-18T23:49:44Z",
        "merged_at": null,
        "body": "relevant to #5351",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-02-18T10:59:12Z",
        "closed_at": "2020-02-18T15:16:39Z",
        "merged_at": null,
        "body": "Looks like `idna` 2.9 was released yesterday. Bumping maximum version.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2020-02-17T21:53:32Z",
        "closed_at": "2020-02-18T05:44:34Z",
        "merged_at": "2020-02-18T05:44:34Z",
        "body": "http://pipenv.org is unavailable, so I changed all of the links to https://pipenv.kennethreitz.org.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 11,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-02-17T17:17:58Z",
        "closed_at": "2020-02-18T05:43:22Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 85,
        "deletions": 64,
        "changed_files": 2,
        "created_at": "2020-02-17T17:17:44Z",
        "closed_at": "2020-02-18T05:54:28Z",
        "merged_at": null,
        "body": "And fixed metadata extraction from files.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2020-02-17T17:09:06Z",
        "closed_at": "2020-02-18T14:58:28Z",
        "merged_at": "2020-02-18T14:58:27Z",
        "body": "requests should trust dependent packages to do semver rather than artificially limiting version compatibility, which causes problems for pip.\r\n\r\nFixes https://github.com/psf/requests/issues/5341, https://github.com/psf/requests/issues/5337 and supercedes https://github.com/psf/requests/pull/5226.",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2020-02-17T07:36:47Z",
        "closed_at": "2020-02-23T17:56:47Z",
        "merged_at": "2020-02-23T17:56:46Z",
        "body": "* Removed multiple redundant `pass` from the `Warnings` in `requests/requests/exceptions.py`. This maintains consistency with the previously defined exceptions.\r\n\r\n* Added missing `.` to the docstring for keeping consistency",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 17,
        "changed_files": 4,
        "created_at": "2020-02-13T21:44:12Z",
        "closed_at": "2020-03-25T19:44:52Z",
        "merged_at": "2020-03-25T19:44:52Z",
        "body": "As the end of python 2 has come, I open this PR in order to get rid of the explicit unicode literal in the README file and the documentation.\r\nI know that this could be against the PEP 414 https://www.python.org/dev/peps/pep-0414/ but it should be harmless for the project.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2020-02-05T10:02:42Z",
        "closed_at": "2021-08-28T04:29:07Z",
        "merged_at": null,
        "body": "In `check_compatibility` function in `requests/__init__.py` some codes are redundant. This function distribute three elements of `urllib3_version` and `chardet_version` and after that transform them to integer values. It can be written with `map` function.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-01-25T23:32:59Z",
        "closed_at": "2020-02-01T00:24:53Z",
        "merged_at": "2020-02-01T00:24:53Z",
        "body": "Currently, the [intersphinx_mapping](https://www.sphinx-doc.org/en/master/usage/extensions/intersphinx.html#confval-intersphinx_mapping) for `python` is set to the Requests documentation. This prevents some references from being linked to the Python standard library documentation.\r\n\r\nThis PR reverts the configuration change made in #5236 and sets the URL for `python` back to https://docs.python.org/3/ as (shown in the example in the intersphinx_mapping documentation).\r\n\r\nSome effects of this change can be seen on the Developer Interface page.\r\n\r\nBefore:\r\n\r\n![image](https://user-images.githubusercontent.com/1156625/73128655-84969600-3fa0-11ea-9e43-ffb8e5c7886f.png)\r\n\r\nAfter:\r\n\r\n![image](https://user-images.githubusercontent.com/1156625/73128660-a6901880-3fa0-11ea-87a0-012b185b605f.png)\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-01-25T17:15:41Z",
        "closed_at": "2020-01-25T18:19:35Z",
        "merged_at": "2020-01-25T18:19:35Z",
        "body": "After #5236, the [Installation of Requests](https://requests.readthedocs.io/en/master/user/install/) documentation page links to itself for instructions on how to install pip.\r\n\r\nThis restores the previous link to https://docs.python-guide.org/starting/installation/.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-01-08T22:12:57Z",
        "closed_at": "2021-08-28T04:27:45Z",
        "merged_at": null,
        "body": "Remove needless list()",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 18,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-01-07T14:19:44Z",
        "closed_at": "2020-02-18T06:13:41Z",
        "merged_at": null,
        "body": "Let us introduce [packit service](https://packit.dev) to you - the automation to integrate upstream open source projects into Fedora operating system.\r\n\r\nAfter merging this PR, you are just a few steps away from RPM builds being automatically triggered on your PR's.\r\nIt means, that you'll be able to try and play with your change, packaged as an RPM.\r\n\r\nBut there is more. By using packit, you can for example enable adding new releases into Fedora Rawhide.\r\n\r\nWhat are the next steps?\r\n* Install [Packit-as-a-Service github application](https://github.com/marketplace/packit-as-a-service) in your repo\r\n* In case you are first user, wait for account approval\r\n* Enjoy the built RPMs!\r\n\r\nFor more info, please:\r\n * check out the documentation: https://packit.dev/docs/\r\n * contact [@packit-service/the-packit-team](https://github.com/orgs/packit-service/teams/the-packit-team)",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 10,
        "changed_files": 2,
        "created_at": "2020-01-06T09:29:48Z",
        "closed_at": "2020-01-09T17:06:48Z",
        "merged_at": "2020-01-09T17:06:48Z",
        "body": "Supported versions are 2.7 and 3.5+ (currently to 3.8):\r\n\r\nhttps://github.com/psf/requests/blob/eedd67462819f8dbf8c1c32e77f9070606605231/setup.py#L82-L100\r\n\r\n3.4 was dropped in https://github.com/psf/requests/pull/5092.\r\n\r\nWriting \"3.5+\" means the docs don't need updating when 3.9 is released, only when 3.5 is dropped.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-01-02T15:55:08Z",
        "closed_at": "2020-05-09T04:58:05Z",
        "merged_at": "2020-05-09T04:58:04Z",
        "body": "The non-contextmanager form of pytest.raises was removed in pytest 5.\r\nhttp://doc.pytest.org/en/latest/deprecations.html#raises-warns-with-a-string-as-the-second-argument\r\n\r\nIt was used here to support Python < 2.7, but that is no longer needed.\r\nhttps://github.com/psf/requests/pull/1503#issuecomment-22333666\r\n\r\nFixes https://github.com/psf/requests/issues/5304",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-01-01T21:33:08Z",
        "closed_at": "2020-01-09T17:55:21Z",
        "merged_at": "2020-01-09T17:55:20Z",
        "body": "Fixes: #5211\r\n\r\nSigned-off-by: Sumana Harihareswara <sh@changeset.nyc>",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-12-31T16:29:48Z",
        "closed_at": "2019-12-31T21:04:36Z",
        "merged_at": null,
        "body": "From talking to people and personal experiences, I always feel this is more intuitive. Only downside is inside a REPL, but I think there is a way to detect that?",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-12-18T09:13:37Z",
        "closed_at": "2020-05-09T05:08:51Z",
        "merged_at": "2020-05-09T05:08:51Z",
        "body": "the exception isn't stored it's created new each call",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-12-17T23:07:39Z",
        "closed_at": "2020-01-09T17:26:43Z",
        "merged_at": "2020-01-09T17:26:43Z",
        "body": "Show the current project description.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-12-06T08:16:31Z",
        "closed_at": "2019-12-09T07:23:50Z",
        "merged_at": null,
        "body": "",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 34,
        "deletions": 8,
        "changed_files": 2,
        "created_at": "2019-12-06T06:58:12Z",
        "closed_at": "2020-02-18T06:18:23Z",
        "merged_at": null,
        "body": "Modified call to urlencode to change its default behavior. \r\nIn place of using 'quote_plus' it uses 'quote' now.\r\nfixes #5170\n\nedit: for python 2 no change",
        "comments": 11
    },
    {
        "merged": false,
        "additions": 38,
        "deletions": 41,
        "changed_files": 1,
        "created_at": "2019-12-02T00:31:15Z",
        "closed_at": "2020-05-09T05:23:46Z",
        "merged_at": null,
        "body": "I have noticed that there is a `# noqa: F811` comment at `__init__.py` when we check the version compatibility of urllib3.\r\n\r\nAnd there exist duplicate code to check the compatibility of different packages.\r\n\r\nSo I write a method to handle it.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-11-28T10:44:02Z",
        "closed_at": "2020-02-18T06:27:23Z",
        "merged_at": null,
        "body": "This pr is to fix the test case fail regarding ConnecTimeout, #5279. ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-11-27T14:09:40Z",
        "closed_at": "2020-02-18T07:19:39Z",
        "merged_at": "2020-02-18T07:19:39Z",
        "body": "Previously, dots were not included, which was breaking multiline syntax highlighting in for example in interactive mode. Example:\r\n![Screenshot from 2019-11-27 16-06-00](https://user-images.githubusercontent.com/2760196/69730070-17958a00-1130-11ea-8be2-86728d993478.png)\r\n\r\nHere is how it looks after the fix:\r\n![Screenshot from 2019-11-27 16-02-36](https://user-images.githubusercontent.com/2760196/69730115-2aa85a00-1130-11ea-959d-5b54896bcb92.png)\r\n\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2019-11-13T17:00:02Z",
        "closed_at": "2019-11-23T02:41:30Z",
        "merged_at": null,
        "body": "Added Response 404 Doctest",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-11-12T19:12:06Z",
        "closed_at": "2019-11-23T02:41:41Z",
        "merged_at": null,
        "body": "Testando pull request. ",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2019-11-12T16:13:47Z",
        "closed_at": "2019-11-23T02:47:42Z",
        "merged_at": null,
        "body": "python 3 exception is `JSONDecodeError:  Expecting value: line 1 column 1 (char 0)`\r\n\r\nhttps://github.com/psf/requests/issues/4908",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 98,
        "deletions": 11,
        "changed_files": 5,
        "created_at": "2019-11-04T14:41:46Z",
        "closed_at": "2020-02-24T22:21:10Z",
        "merged_at": null,
        "body": "Requests does not support dict with depth greater than 1 on parameter data for a x-www-form-urlencoded based request.\r\n\r\nWhat I'm proposing here is to remove depth from a dict while keeping actual sent data untouched.\r\n\r\n## Expected Result\r\n\r\n```python\r\nprint(response.request.body)\r\n# auth_user=test&auth_pwd=test&json_data%5Boperation%5D=core%2Fget&json_data%5Bclass%5D=ServiceChange&json_data%5Bkey%5D=SELECT+ServiceChange+WHERE+id%3D429&json_data%5Boutput_fields%5D=request_state&json_data%5Bh%5D%5Bt%5D=1\r\n```\r\n\r\nPHP/jQuery $.params support this syntax out of the box. As requests is not about supporting the way PHP/jQuery $.params work internally, this PR maybe doomed.\r\n\r\n## Actual Result\r\n\r\nWhat happened instead.\r\n\r\n```python\r\nprint(response.request.body)\r\n# auth_user=test&auth_pwd=test&json_data=operation&json_data=class&json_data=key&json_data=output_fields&json_data=h\r\n```\r\n\r\nRemote server only see json_data = h and that is actually wrong.\r\n\r\n## Reproduction Steps\r\n\r\n```python\r\nfrom requests import post\r\nfrom pprint import pprint\r\n\r\nif __name__ == '__main__':\r\n\r\n    response = post(\r\n        'https://api.ipify.org?format=json',\r\n        {\r\n            'auth_user': 'test',\r\n            'auth_pwd': 'test',\r\n            'json_data': {\r\n                'operation': 'core/get',\r\n                'class': 'ServiceChange',\r\n                'key': 'SELECT ServiceChange WHERE id=429',\r\n                'output_fields': 'request_state',\r\n                'h': {\r\n                    't': 1\r\n                }\r\n            }\r\n        }\r\n    )\r\n\r\n    pprint(\r\n        response.request.body\r\n    )\r\n\r\n```",
        "comments": 14
    },
    {
        "merged": false,
        "additions": 12,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2019-11-01T07:49:25Z",
        "closed_at": "2020-05-09T04:58:32Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-10-30T19:16:01Z",
        "closed_at": "2019-11-23T02:50:55Z",
        "merged_at": "2019-11-23T02:50:54Z",
        "body": "The link for `Requests-Threads` was missing a trailing `_` causing it to be italicized instead of being a proper link.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-10-24T09:36:45Z",
        "closed_at": "2021-11-28T14:15:03Z",
        "merged_at": null,
        "body": "The current documentation says that the function is encoding - actually, it is decoding!\r\n\r\nI'm also wondering if it might be worth putting in some type annotations at some point",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 24,
        "deletions": 6,
        "changed_files": 2,
        "created_at": "2019-10-23T09:38:18Z",
        "closed_at": "2020-02-17T18:25:52Z",
        "merged_at": null,
        "body": "This PR adds an option on raise_for_status function that hides the url from the log message so it is possible to protect the sensitive data from the url without having to do complex parsing of it.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-10-22T15:47:28Z",
        "closed_at": "2019-10-25T02:32:26Z",
        "merged_at": "2019-10-25T02:32:26Z",
        "body": "The Trove classifier is already added:\r\n \r\nhttps://github.com/psf/requests/blob/fab1fd10d0b115e635b9ef1364f8444089725000/setup.py#L98\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 42,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2019-10-22T13:03:54Z",
        "closed_at": "2021-05-20T16:53:48Z",
        "merged_at": null,
        "body": "Improved support for setup.py upload command.\r\nReplaced method of accepting `upload` command using `sys-command-line-arguments`, with `UploadCommand` class and added it in cmdClass.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-10-21T12:50:26Z",
        "closed_at": "2020-02-15T06:49:51Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2019-10-21T12:40:06Z",
        "closed_at": "2019-10-25T02:35:02Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 22,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2019-10-21T11:55:23Z",
        "closed_at": "2021-11-28T20:03:31Z",
        "merged_at": "2021-11-28T20:03:31Z",
        "body": "This allows it to handle files obtained via `Tarfile.extractfile()`.\r\n\r\nFixes #5229.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 14,
        "changed_files": 2,
        "created_at": "2019-10-19T00:35:38Z",
        "closed_at": "2019-10-25T02:46:05Z",
        "merged_at": "2019-10-25T02:46:05Z",
        "body": "This modifies links to translations of the `requests` documentation for non-English languages to https instead of http",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 16,
        "deletions": 16,
        "changed_files": 11,
        "created_at": "2019-10-18T16:29:33Z",
        "closed_at": "2019-10-25T03:02:55Z",
        "merged_at": "2019-10-25T03:02:55Z",
        "body": "Fixes: #5212",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-10-17T20:37:53Z",
        "closed_at": "2019-10-19T00:36:05Z",
        "merged_at": null,
        "body": "[This commit](https://github.com/psf/requests/commit/74b72ce4265583db0430080ab67d3d5e0c4b44b2) removed several references to the URL 2.python-requests.org but left several behind. This PR cleans those up and replaces with requests.readthedocs.io",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 8,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2019-10-16T11:43:00Z",
        "closed_at": "2022-05-11T00:55:50Z",
        "merged_at": null,
        "body": "See #3070 and [this](https://stackoverflow.com/questions/41295142/is-there-a-way-to-globally-override-requests-timeout-setting). Also, compare #3341 \r\n\r\nTODO:\r\n- [ ] docs for the session instance attributes\r\n- [ ] tests for this attributes' usage\r\n- [ ] decision on default value for timeout\r\n\r\n----------------------------\r\n\r\nAt first commits I've added session-level `timeout=None` and `allow_redirects=True` attributes that are now used in `x or self.x` in `request(...)` method. I've also removed `allow_redirects` defaults in `get(...)` and friends.\r\n\r\nDefault values are a subject for discussion, but let's start at least drafting this.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-10-10T20:49:41Z",
        "closed_at": "2020-02-18T15:16:12Z",
        "merged_at": null,
        "body": "Hello everyone,\r\n\r\nThe `idna` is in the `install_requires` already, so it makes sense to remove it from extra requirements.\r\n\r\nAlso, `poetry` has been confused by this duplicated requirement.\r\nhttps://github.com/sdispater/poetry/issues/1449\r\n\r\nBest regards!",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-10-10T09:49:36Z",
        "closed_at": "2020-05-09T05:54:05Z",
        "merged_at": null,
        "body": "This makes debugging the reason for the error much easier, e.g. in keycloak / OpenID.\r\n\r\nBefore the patch:\r\n400 Client Error: Bad Request for url: <url>\r\n\r\nAfter the patch:\r\n400 Client Error: Bad Request for url: <url>, response body is {\"error\":\"unauthorized_client\",\"error_description\":\"Invalid client secret\"}",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2019-10-01T19:58:06Z",
        "closed_at": "2022-05-11T00:53:03Z",
        "merged_at": null,
        "body": "This PR changes the requests version of `ConnectionError` to also inherit from the built-in `ConnectionError`, see #5162 ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-09-29T16:11:17Z",
        "closed_at": "2019-09-30T09:52:29Z",
        "merged_at": "2019-09-30T09:52:29Z",
        "body": "websites is down, link to requests.readthedocs.io",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 32,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2019-09-23T18:55:15Z",
        "closed_at": "2022-04-12T18:33:39Z",
        "merged_at": null,
        "body": "To fix #5209 (more details in the issue)\r\n\r\nResults for the [newly-added test](https://github.com/fopina/requests/blob/ca_cert_instance_versus_env/tests/test_requests.py#L1946)\r\n\r\n```\r\n\u279c  git checkout master \r\n\u279c  git checkout ca_cert_instance_versus_env -- tests/test_requests.py\r\n\u279c  pipenv run py.test tests/test_requests.py::TestRequests::test_session_merge_environment_settings_verify\r\n============================================================================================================================= test session starts ==============================================================================================================================\r\nplatform linux -- Python 3.7.4, pytest-3.10.1, py-1.8.0, pluggy-0.13.0\r\nrootdir: /home/fopina/Documents/stuff/requests, inifile: pytest.ini\r\nplugins: cov-2.7.1, xdist-1.25.0, httpbin-0.3.0, forked-1.0.2, mock-1.10.4\r\ncollected 1 item                                                                                                                                                                                                                                                               \r\n\r\ntests/test_requests.py F                                                                                                                                                                                                                                                 [100%]\r\n....\r\n        session.verify = OTHER_PEM\r\n        args[3] = None\r\n        with override_environ(REQUESTS_CA_BUNDLE=SOME_PEM):\r\n>           assert session.merge_environment_settings(*args)['verify'] == OTHER_PEM\r\nE           AssertionError: assert 'x.pem' == 'y.pem'\r\nE             - x.pem\r\nE             ? ^\r\nE             + y.pem\r\nE             ? ^\r\n\r\ntests/test_requests.py:1973: AssertionError\r\n=========================================================================================================================== 1 failed in 0.48 seconds ===========================================================================================================================\r\n```\r\n```\r\n\u279c  git checkout ca_cert_instance_versus_env \r\n\u279c  pipenv run py.test tests/test_requests.py::TestRequests::test_session_merge_environment_settings_verify\r\n============================================================================================================================= test session starts ==============================================================================================================================\r\n\r\ntests/test_requests.py .                                                                                                                                                                                                                                                 [100%]\r\n\r\n=========================================================================================================================== 1 passed in 0.35 seconds ===========================================================================================================================\r\n```",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 20,
        "changed_files": 6,
        "created_at": "2019-09-23T18:27:34Z",
        "closed_at": "2019-09-23T20:08:41Z",
        "merged_at": "2019-09-23T20:08:41Z",
        "body": "Love & Hated appear orthogonal, yet are extracted from the same substance & essences. The opposite of Love is not Hatred \u2014 but Apathy.\r\n\r\n> Everything is dual; Everything has poles; Everything has its pair of opposites; Like and unlike are the same; Opposites are identical in nature, but different in degree; Extremes meet; All truths, are but half-truths; All paradoxes may be reconciled.\r\n\r\n[As above, so below](https://www.kennethreitz.org/as-above-so-below).\r\n\r\n\u2624",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2019-09-23T14:29:26Z",
        "closed_at": "2019-09-26T22:06:30Z",
        "merged_at": "2019-09-26T22:06:30Z",
        "body": "Python 3.8.0 is due out in a month on 2019-10-21.\r\n\r\n* https://www.python.org/dev/peps/pep-0569/#schedule\r\n\r\nTest now to help test both Python 3.8 before it's released, and to make sure requests works on 3.8.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 7,
        "changed_files": 3,
        "created_at": "2019-09-23T11:23:31Z",
        "closed_at": "2020-01-19T15:41:10Z",
        "merged_at": "2020-01-19T15:41:10Z",
        "body": "These files can live under `.github/`, and there are already community files there.\r\n\r\nLet's keep them together to keep the root directory a bit neater.\r\n\r\n* https://help.github.com/en/articles/about-community-profiles-for-public-repositories\r\n\r\nAlso: \r\n\r\n* Fix the image for Markdown not RST\r\n* Fix headers, compare https://github.com/not-kennethreitz/requests3/blob/9b8206fdb74e4b9649b2bf3367af7a506f9b30a6/docs/community/vulnerabilities.rst",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-09-19T09:52:42Z",
        "closed_at": "2019-09-19T15:31:06Z",
        "merged_at": null,
        "body": "certianly -> certainly",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-09-18T11:09:41Z",
        "closed_at": "2019-09-19T15:29:30Z",
        "merged_at": "2019-09-19T15:29:30Z",
        "body": "Just noticed a small typo!",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2019-09-17T12:36:50Z",
        "closed_at": "2019-09-19T15:32:14Z",
        "merged_at": "2019-09-19T15:32:14Z",
        "body": "Currently the [website][1] looks like this:\r\n![image](https://user-images.githubusercontent.com/15225902/65042108-5ebe0c80-d982-11e9-9555-a97c89866b6b.png)\r\n\r\n[1]: https://2.python-requests.org/en/master/api/#status-code-lookup",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2019-09-13T00:38:38Z",
        "closed_at": "2020-01-21T17:00:51Z",
        "merged_at": "2020-01-21T17:00:51Z",
        "body": "`setup.py` and [`README.md`](https://github.com/psf/requests/blob/3c01cd708033295c65be3fd85dea9d453506c854/README.md#feature-support) explicitly list PyPy support. This PR extends testing to PyPy3 (which is currently Python 3.6-compatible). This will help ensure that support for PyPy3 does not regress.",
        "comments": 17
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 1,
        "changed_files": 3,
        "created_at": "2019-09-05T23:24:51Z",
        "closed_at": "2019-09-15T01:39:24Z",
        "merged_at": null,
        "body": "Signed-off-by: G\u00e1bor Lipt\u00e1k <gliptak@gmail.com>\r\n\r\nfailing build https://travis-ci.com/psf/requests/jobs/228220372",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-09-05T12:23:04Z",
        "closed_at": "2020-07-21T06:45:04Z",
        "merged_at": null,
        "body": "If data contains a dict in dict value like {'a': 'b', 'c': {'d': 'e'}}, it will be encoded as a=b&c=d which is obviously wrong.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-09-04T07:58:19Z",
        "closed_at": "2020-05-09T05:57:26Z",
        "merged_at": null,
        "body": "fix #5180 ",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-08-30T20:16:06Z",
        "closed_at": "2019-10-25T02:59:36Z",
        "merged_at": null,
        "body": "#4987 had [removed the existence of a blank line before a doctest block](https://github.com/psf/requests/pull/4987/files#diff-35c843f55d3e3abf0fca8d08b73bc26cL7), which results in [the documentation for `requests.codes`](https://2.python-requests.org/en/master/api/#status-code-lookup) being improperly rendered:\r\n![Screen Shot 2019-08-30 at 1 04 03 PM](https://user-images.githubusercontent.com/7754936/64048738-70e91f80-cb27-11e9-9d66-251ad9cce653.png)\r\n\r\nThis PR re-introduces the blank line, which appears to be? suggested by [reST spec](http://docutils.sourceforge.net/docs/ref/rst/restructuredtext.html#doctest-blocks) and worked for NumPy as well [at some point](https://github.com/numpy/numpy/pull/14085).",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-08-24T05:15:09Z",
        "closed_at": "2019-09-19T17:18:16Z",
        "merged_at": null,
        "body": "Issue introduced here: https://github.com/psf/requests/pull/4983/files#diff-28e67177469c0d36b068d68d9f6043bfR425",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-08-19T16:45:59Z",
        "closed_at": "2019-08-19T17:54:32Z",
        "merged_at": "2019-08-19T17:54:32Z",
        "body": "Requests pulls over 50+ million downloads per month while the old figure is at 11.\r\n\r\nhttps://pepy.tech/project/requests",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-08-16T01:45:56Z",
        "closed_at": "2019-08-19T17:55:41Z",
        "merged_at": "2019-08-19T17:55:41Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 44,
        "deletions": 44,
        "changed_files": 17,
        "created_at": "2019-08-13T22:00:51Z",
        "closed_at": "2019-08-19T22:57:16Z",
        "merged_at": "2019-08-19T22:57:16Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2019-07-28T20:38:05Z",
        "closed_at": "2019-07-29T16:11:39Z",
        "merged_at": null,
        "body": "Remove unnecessary break-line - it just looks better now :)",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-07-25T02:36:00Z",
        "closed_at": "2019-07-29T16:06:12Z",
        "merged_at": "2019-07-29T16:06:12Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 2,
        "changed_files": 4,
        "created_at": "2019-07-20T22:35:03Z",
        "closed_at": "2019-07-21T03:57:01Z",
        "merged_at": "2019-07-21T03:57:01Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2019-07-19T15:46:51Z",
        "closed_at": "2019-07-23T16:53:22Z",
        "merged_at": "2019-07-23T16:53:22Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 23,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2019-07-10T03:52:00Z",
        "closed_at": "2022-05-11T00:50:54Z",
        "merged_at": null,
        "body": "This fixes the is_ipv4_address function. Initially intended to be a workaround for Issue #5131 it is now a removal of an external dependency. Since the check is a simple one, there is no need to rely on external sources.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 13,
        "deletions": 58,
        "changed_files": 1,
        "created_at": "2019-07-02T10:13:18Z",
        "closed_at": "2019-08-20T04:15:45Z",
        "merged_at": "2019-08-20T04:15:45Z",
        "body": "Resubmit of [https://github.com/kennethreitz/requests/pull/4958](https://github.com/kennethreitz/requests/pull/4958 ) with up to date merge. Also addresses https://github.com/kennethreitz/requests/pull/4179. \r\n\r\nSpecifically, in my use case, chunked requests when a proxy is in use results in failure to evaluate the proxy configuration and the request being sent direct. It appears that urllib3 supports chunking as an option so this fork to lower level urllib3 code seems to no longer be required.",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-07-01T19:42:01Z",
        "closed_at": "2019-07-12T00:18:43Z",
        "merged_at": "2019-07-12T00:18:43Z",
        "body": "Related: kennethreitz/requests#4274",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-06-26T19:21:19Z",
        "closed_at": "2019-07-29T16:19:28Z",
        "merged_at": null,
        "body": "Looking for early feedback.\r\n\r\n`requests` should have a native solution to dealing with non-3XX redirects i.e. https://stackoverflow.com/questions/56366175/how-to-handle-redirects-that-do-not-use-3xx-status-codes. But should such a new feature be tied to a preexisting flag `allow_redirects`, or should there be a new flag such as `allow_meta_redirects`? I understand the use case between not allowing redirects and allowing redirects, but I am not sure if there is a use case where you want to handle 2XX redirects but do not want to handle 3XX redirects or vice versa.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2019-06-24T17:13:07Z",
        "closed_at": "2019-08-20T04:11:23Z",
        "merged_at": "2019-08-20T04:11:23Z",
        "body": "Use `.format()` over `%` given PEP 3101",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-06-05T23:08:45Z",
        "closed_at": "2019-08-20T04:14:01Z",
        "merged_at": null,
        "body": "fix to bug #5113",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-06-04T20:05:37Z",
        "closed_at": "2020-02-18T17:17:22Z",
        "merged_at": "2020-02-18T17:17:22Z",
        "body": "The extra attribute in `Session.__attrs__` makes an unpickled session have one more attribute than the original.  Removing it makes the original and the unpickled be identical.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-06-03T06:46:22Z",
        "closed_at": "2019-06-03T14:01:03Z",
        "merged_at": "2019-06-03T14:01:03Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2019-05-29T18:49:53Z",
        "closed_at": "2019-08-20T04:14:37Z",
        "merged_at": "2019-08-20T04:14:37Z",
        "body": "-Made removing a key-value pair more modular\r\n-Remove unneeeded return statement",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 19,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2019-05-29T08:52:34Z",
        "closed_at": "2022-10-15T07:32:04Z",
        "merged_at": null,
        "body": "Look at https://github.com/kennethreitz/requests/blob/master/requests/models.py#L100 or\r\nhttps://github.com/kennethreitz/requests/blob/master/requests/models.py#L131\r\n```\r\nfor v in vs:\r\n    if v is not None:\r\n        ...\r\n```\r\nWhen the type of `vs` is `dict`, `v` will be the field key, but not field value, the body of the request will be puzzling.\r\nIt would be better to prevent it.\r\n\r\nSigned-off-by: weiyang <weiyang.ones@gmail.com>",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-05-20T07:00:57Z",
        "closed_at": "2019-05-20T15:35:42Z",
        "merged_at": "2019-05-20T15:35:41Z",
        "body": "Hello,\r\n\r\nAlthough providing a non-string password would be very rear, it would be better the value of the password (even if it is incorrectly set) to not take part in the warning message.\r\n\r\nRegards ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 383,
        "deletions": 280,
        "changed_files": 7,
        "created_at": "2019-05-15T19:47:07Z",
        "closed_at": "2019-05-16T05:12:48Z",
        "merged_at": "2019-05-16T05:12:48Z",
        "body": "2.22.0 (2019-05-15)\r\n-------------------\r\n\r\n**Dependencies**\r\n\r\n- Requests now supports urllib3 v1.25.2.\r\n  (note: 1.25.0 and 1.25.1 are incompatible)\r\n\r\n**Deprecations**\r\n\r\n- Requests has officially stopped support for Python 3.4.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-05-15T14:46:21Z",
        "closed_at": "2019-08-20T04:12:22Z",
        "merged_at": null,
        "body": "It looks like a few of the resources on https://docs.pipenv.org/en/latest/ are broken, like the gif under \"A short animation of pipenv at work\" and the installation instructions are a bit behind what's on the GitHub repo. Maybe we should link to the repo directly? \r\n\r\nFirst time contributing, feel free to reject this!",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-05-14T18:36:16Z",
        "closed_at": "2019-05-16T05:20:46Z",
        "merged_at": "2019-05-16T05:20:46Z",
        "body": "This is a quick fix that will make it a little easier for potential contributors who are new to GitHub to learn how the site works.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 63,
        "deletions": 4,
        "changed_files": 3,
        "created_at": "2019-05-14T09:18:13Z",
        "closed_at": "2019-08-20T04:16:35Z",
        "merged_at": "2019-08-20T04:16:35Z",
        "body": "#4965 Issue: Accessing response.content twice removes forgets read error.\r\n\r\nAdded variable to save errors, and added a check that returns a re-error when accessed.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2019-05-09T18:40:04Z",
        "closed_at": "2019-05-09T21:37:33Z",
        "merged_at": "2019-05-09T21:37:33Z",
        "body": "For potential contributors who are new to GitHub and prefer to learn via structured processes, linking the Contributor's Guide and development philosophy documents in the README will make it easier for them to find this information. This will increase the quality of their contributions and make them more comfortable contributing to the project.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-05-02T11:40:30Z",
        "closed_at": "2019-05-02T15:45:07Z",
        "merged_at": null,
        "body": "https://app.snyk.io/vuln/SNYK-PYTHON-URLLIB3-174323 (CVE-2019-11236) is CRLF injection a vulnerability in the urllib3 library.\r\nThis PR bumps its version.\r\nThis might not be directly related to requests, but would forbid projects using requests from using a fixed version of `urllib3`",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-04-30T16:37:54Z",
        "closed_at": "2019-08-20T04:38:22Z",
        "merged_at": "2019-08-20T04:38:22Z",
        "body": "Could the missing colon on line 612 in models.py be the reason for the missing reference in the docs as described in issue #4945?",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-04-30T09:50:38Z",
        "closed_at": "2019-08-20T04:16:59Z",
        "merged_at": null,
        "body": "Remove unneeded `kwargs.setdefault('allow_redirects', True)` calls from \r\n`Session.get` and `Session.options`. The `allow_redirects` argument of \r\n`Session.request`already has a default value of `True`.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 45,
        "deletions": 29,
        "changed_files": 10,
        "created_at": "2019-04-28T02:30:52Z",
        "closed_at": "2020-02-18T07:01:53Z",
        "merged_at": null,
        "body": "Hi @kenneth-reitz,\r\n\r\nI've fixed some style issues in the codebase to improve adherence to general best practices. \ud83d\ude80 \r\n\r\nThese issues were highlighted when I ran a DeepSource analysis on my fork of requests. I've added the DeepSource config file as well, which can be used to connect requests to DeepSource -- so this analysis runs on every pull-request, which will make it easier to maintain quality on contributions. DeepSource is used by some popular open-source projects, like [uber/ludwig](https://deepsource.io/gh/uber/ludwig/). The product is, and will forever remain, free for open-source.\r\n\r\nTo connect requests and run analysis on every PR, there are three simple steps:\r\n1. **Merge this PR.** I've added a customised `.deepsource.toml` for requests.\r\n2. **Sign up on DeepSource** and grant access to this repository [here](https://deepsource.io/signup/).\r\n3. **Activate analysis** on requests [here](https://deepsource.io/gh/kennethreitz/requests/).\r\n\r\n*Disclaimer: I'm a co-founder of DeepSource. We use requests for our code of course, and would love to give back!*",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 10,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2019-04-24T14:12:39Z",
        "closed_at": "2019-04-27T13:11:37Z",
        "merged_at": null,
        "body": "Added a requirements.txt file for the project in case someone would want to install dependencies manually, or build from source etc.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 42,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2019-04-23T05:52:33Z",
        "closed_at": "2019-04-23T12:23:58Z",
        "merged_at": "2019-04-23T12:23:58Z",
        "body": "\ud83d\udc4b team,\r\n\r\nTL;DR: Add same search experience as https://pipenv.readthedocs.io/en/latest/\r\n\r\nI'm working at Algolia on the a project called [DocSearch](https://community.algolia.com/docsearch/) which goal is to enhance documentation websites with exhaustive, fast and relevant search. You might have seen DocSearch live already on websites like [pipenv](https://pipenv.readthedocs.io/en/latest/), [Bootstrap](https://getbootstrap.com/), [Brew](https://brew.sh/) or [jQuery](https://jquery.com/).\r\n\r\nI have created [a preview of this PR](https://docsearch-requests.netlify.com/) and what DocSearch on the requests website could will look like here. Feel free to try it and let us know what you think. Please not the learn-as-you-type experience and the typo tolerance:\r\n\r\n[![demo of DocSearch + requests](https://cl.ly/4241871af591/download/Screen%20Recording%202019-04-23%20at%2007.50%20AM.gif)](https://docsearch-requests.netlify.com/)\r\n\r\nThe way DocSearch works is by crawling your content, pushing the results into an Algolia index, and then requesting this index directly from the website front-end through JavaScript.\r\n\r\nWe'll take care of crawling your website and populating the Algolia index with the latest changes every 24h for you. You don't need to change anything to your deployment process. The only thing you need to add are the following CSS and JS snippets that will bind the dropdown to your searchbox.\r\n\r\nWe built DocSearch with the idea of giving back to the Open-Source community. This is why your [crawling configuration](https://github.com/algolia/docsearch-configs/blob/master/configs/python-requests.json) is available on GitHub if you want to change it. We also have our own [documentation](https://community.algolia.com/docsearch/documentation/) to help you tweak the dropdown to your needs. You'll also have access to *analytics on the most searched terms* or those with *no results*. All of this is of course *entirely free*.\r\n\r\nFollow realpython/python-guide#932, pypa/pipenv#3703, kennethreitz/requests-html#292, kennethreitz/requests3#14, kennethreitz/responder#347",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2019-04-20T23:30:58Z",
        "closed_at": "2019-04-29T02:15:04Z",
        "merged_at": null,
        "body": "1.25.x will include a fix for `CVE-2019-11236`\r\n\r\nhttps://github.com/urllib3/urllib3/issues/1553#issuecomment-484213670",
        "comments": 13
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-04-20T20:07:40Z",
        "closed_at": "2019-04-27T13:12:10Z",
        "merged_at": "2019-04-27T13:12:10Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-04-11T11:03:53Z",
        "closed_at": "2019-05-09T21:38:20Z",
        "merged_at": "2019-05-09T21:38:20Z",
        "body": "Should add this import statement to make it more user friendly, especially for the beginners in Python.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2019-04-08T16:12:59Z",
        "closed_at": "2019-08-20T04:12:59Z",
        "merged_at": "2019-08-20T04:12:59Z",
        "body": "Fixes https://github.com/kennethreitz/requests/issues/5048\r\n\r\nSee https://docs.pytest.org/en/latest/deprecations.html#marks-in-pytest-mark-parametrize",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 239,
        "deletions": 312,
        "changed_files": 2,
        "created_at": "2019-04-08T09:06:58Z",
        "closed_at": "2019-06-27T05:53:27Z",
        "merged_at": null,
        "body": "Removes the call to <4.1 pytest. Pytest 4.4 was released this week breaking CI/CD\r\n\r\nRebuild graph and Pipfile.lock.\r\n\r\nAlso removed `detox` as it's now built into tox :-)",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-04-07T06:03:32Z",
        "closed_at": "2019-04-27T13:13:17Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 10,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2019-04-06T13:59:18Z",
        "closed_at": "2019-08-20T04:17:31Z",
        "merged_at": null,
        "body": "Add a request hook that fires when a request is sent. This resolves kennethreitz/requests#5037.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 61,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-04-06T13:14:53Z",
        "closed_at": "2019-08-20T04:18:27Z",
        "merged_at": null,
        "body": "Python supports the inclusion of a `__main__.py` file withing ones packages. I though it might be nice to include such a  file within requests to handle the more common tasks from the command line e.g. `GET`, `HEAD`, `PUT` and `POST`. I have included an example for both `HEAD` and `GET` though I'm not certain of their utility. \r\n\r\nMore often then not it is necessary to download a file from a given url and I have added a `download` option to assist with that as well.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-03-27T10:09:40Z",
        "closed_at": "2019-04-27T13:13:43Z",
        "merged_at": "2019-04-27T13:13:43Z",
        "body": "Links to https://github.com/encode/requests-async for an asyncio non-blocking option.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2019-03-27T07:19:48Z",
        "closed_at": "2019-08-20T04:20:05Z",
        "merged_at": null,
        "body": "Add return to raise_for_status for writing `resp = requests.get('SOME_URL').raise_for_status()` and same code.",
        "comments": 14
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 9,
        "changed_files": 1,
        "created_at": "2019-03-25T15:50:43Z",
        "closed_at": "2019-08-20T04:19:20Z",
        "merged_at": null,
        "body": "Take proxy configuration from session if not specify in args of request method",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 14,
        "changed_files": 1,
        "created_at": "2019-03-10T15:08:28Z",
        "closed_at": "2019-08-20T04:17:54Z",
        "merged_at": "2019-08-20T04:17:54Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 8,
        "changed_files": 2,
        "created_at": "2019-03-09T23:47:36Z",
        "closed_at": "2019-08-20T04:24:41Z",
        "merged_at": null,
        "body": "Rearrange a try/except so that these two programs give similar error\r\nmessages.\r\n\r\nProgram 1:\r\n\r\n```\r\nimport requests\r\nrequests.get(\"https://random.org, timeout=(True, True))\r\n```\r\n\r\nProgram 2:\r\n\r\n```\r\nimport requests\r\nrequests.get(\"https://random.org, timeout=True)\r\n```\r\n\r\nBefore this commit, _Program 2_ raised an error in `urllib3` asking for\r\nan \"int, float or None\" timeout.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2019-02-27T02:30:17Z",
        "closed_at": "2019-03-02T00:57:10Z",
        "merged_at": null,
        "body": "[pytest-httpbin](https://github.com/kevin1024/pytest-httpbin) release 1.0.0 updated the `subjectAltName` field to the certificate which our unit tests assume doesn't have an IP Address entry in order to test warning generation.  [Changelog for 1.0.0 even mentions this breakage in our unit tests.](https://github.com/kevin1024/pytest-httpbin/commit/be3c3205972195ca632949ed7af1dc7086cb7899)",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 8,
        "deletions": 7,
        "changed_files": 5,
        "created_at": "2019-02-25T07:02:46Z",
        "closed_at": "2019-08-20T04:20:26Z",
        "merged_at": null,
        "body": "fix some pep8 errors.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-02-23T13:26:00Z",
        "closed_at": "2019-08-20T04:21:32Z",
        "merged_at": "2019-08-20T04:21:32Z",
        "body": "Warehouse now uses the `project_urls` provided to display links in the sidebar on [this screen](https://pypi.org/project/requests/), as well as including them in API responses to help automation tool find the source code for Requests. For example, see Django's [setup.py](https://github.com/django/django/blob/master/setup.py) and [PyPI listing](https://pypi.org/project/Django/).",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-02-22T10:04:41Z",
        "closed_at": "2019-08-20T04:24:09Z",
        "merged_at": "2019-08-20T04:24:09Z",
        "body": "So the user has a pointer to the documentation about the searched topic.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 18,
        "deletions": 9,
        "changed_files": 8,
        "created_at": "2019-02-17T18:47:44Z",
        "closed_at": "2019-08-20T04:25:51Z",
        "merged_at": "2019-08-20T04:25:51Z",
        "body": "## Why this PR\r\nRunning the command:\r\n`\r\n$ py.test --doctest-module requests\r\n`\r\ngives failing doctests. This PR aims to fix these failing doctests.\r\n\r\nIssue Link: https://github.com/kennethreitz/requests/issues/4986\r\n\r\n## How to test\r\n`\r\n$ py.test --doctest-module requests\r\n`\r\nAll the 11 doctests should pass.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-02-15T04:21:37Z",
        "closed_at": "2019-08-20T04:23:53Z",
        "merged_at": "2019-08-20T04:23:53Z",
        "body": "Solution for #2949 \r\n\r\nAllows setting a list of domains that are \"trusted\", so the authorization header isn't stripped upon being redirected there.\r\n\r\nDefault functionality remains unchanged. ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 63,
        "deletions": 228,
        "changed_files": 4,
        "created_at": "2019-02-12T13:26:21Z",
        "closed_at": "2019-08-20T04:21:13Z",
        "merged_at": "2019-08-20T04:21:13Z",
        "body": "Use official framework for the \"custom\" ad design integration.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 39,
        "deletions": 0,
        "changed_files": 4,
        "created_at": "2019-02-09T21:30:47Z",
        "closed_at": "2019-08-20T04:27:00Z",
        "merged_at": "2019-08-20T04:27:00Z",
        "body": "As per discussion in the PR [Azure/msrest-for-python/#145](https://github.com/Azure/msrest-for-python/pull/145), there some issues with server responses (specially from Microsoft) that have BOM in it. You can see errors in the tests from my branch [here](https://github.com/eduardomourar/requests/runs/61195184) reproducing the same behavior when trying to parse both text and JSON.\r\n\r\nThis has been fixed by forcing encoding to `utf-8-sig` when HTTP header has signalized `utf-8` or leave to _chardet_ when no encoding has been identified. That way the parsing works as expected and no errors are thrown.",
        "comments": 10
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-02-04T13:30:48Z",
        "closed_at": "2019-02-04T15:22:41Z",
        "merged_at": "2019-02-04T15:22:41Z",
        "body": "This resolves a very minor documentation issue for the proxies argument in 'merge_environment_settings' See #4959 ",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 58,
        "changed_files": 1,
        "created_at": "2019-02-03T14:29:23Z",
        "closed_at": "2020-03-17T09:50:18Z",
        "merged_at": null,
        "body": "This MR removes the custom handling of sending chunked HTTP requests from requests to delegate to the equivalent logic in urllib3 (https://github.com/urllib3/urllib3/blob/4325867d1ae0d139a11c8689c2d2a5ba2c666c83/src/urllib3/connectionpool.py#L351).\r\n\r\nAs far as I can tell this has a couple of advantages:\r\n* Remove code that is duplicated between the two libraries\r\n* Allow fixes for outstanding issues in this area to be made in urllib3 so that users of both libraries benefit (I noticed #4445 when having a quick trawl of the issues but I guess there are more)\r\n* All requests are now logged by the urllib3 debug logger (which was the issue I was originally trying to diagnose)",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-01-30T09:32:01Z",
        "closed_at": "2019-01-30T12:13:37Z",
        "merged_at": null,
        "body": "1. The removed blank line was added at commit 8a2014e26 by Kenneth Reitz at\r\n2017-05-26 22:51:40.\r\nThe blank line under it was created at 2012, there is a 5 year gap\r\nbetween them.\r\n\r\n2. It has conflict with the style used on line 63.\r\n\r\nSo I assume it was misadded and removed it.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 10,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2019-01-21T16:26:24Z",
        "closed_at": "2021-02-20T14:51:02Z",
        "merged_at": null,
        "body": "This is mostly to tell the reader about when HTTP error must be handled, and to better link to the other places in the doc. where this is explained.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 14,
        "deletions": 8,
        "changed_files": 3,
        "created_at": "2019-01-21T03:32:28Z",
        "closed_at": "2019-02-08T12:39:21Z",
        "merged_at": null,
        "body": "Pytest itself would fail, until I fixed the semantics of the pytest params in the decorator for `test_io_streams`. I am not certain unittests are being used currently, as many tests failed prior to changing anything. Am I not using them correctly?\r\n\r\nI also wanted to start a discussion and share thoughts on default_ports, I believe it should be written in the same manner as default_headers.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-01-20T03:49:50Z",
        "closed_at": "2019-02-14T14:13:27Z",
        "merged_at": null,
        "body": "make proxies.update  can use in get or post",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2019-01-17T01:59:35Z",
        "closed_at": "2019-01-21T18:50:28Z",
        "merged_at": "2019-01-21T18:50:28Z",
        "body": "TravisCI has migrated their infrastructure: https://blog.travis-ci.com/2018-11-19-required-linux-infrastructure-migration",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-01-11T22:32:42Z",
        "closed_at": "2019-08-21T22:46:13Z",
        "merged_at": null,
        "body": "Was trying to get docker-py working with a remote host, i.e. using a key.pem, cert.pem, and ca.pem. Had SSL issues. Ultimately figured out that it was due to the APIClient being derived from requests.sessions. In particular, even if verify is set for the session, it will not actually be used since the kwargs for the get() are directly passed into the request() method (which defaults verify to None).\r\nAs additional info., curling worked when passing the cert.pem, ca.pem, and key.pem, requests worked when merely using requests.get(url, cert=(cert, key), verify=ca), and sessions worked as long as verify was always passed into the get() method, i.e. s.get(url, verify=ca, ...)",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2019-01-08T20:16:04Z",
        "closed_at": "2019-01-12T23:52:46Z",
        "merged_at": null,
        "body": "Enables loading of certificate bundles from SSL_CERT_FILE or\r\nSSL_CERT_DIR as mentioned in https://legacy.python.org/dev/peps/pep-0476/\r\n\r\nCurrent patch keeps backwards compatibility by preferring the more\r\nspecific options and using the new ones only as fallbacks.\r\n\r\nFixes: #2899",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-01-06T01:32:55Z",
        "closed_at": "2019-08-20T04:37:48Z",
        "merged_at": null,
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 13,
        "deletions": 7,
        "changed_files": 5,
        "created_at": "2018-12-29T15:43:49Z",
        "closed_at": "2019-08-20T04:22:33Z",
        "merged_at": "2019-08-20T04:22:33Z",
        "body": "The shim is the same on both Python 2 & 3. It is always `collections.OrderedDict`. Avoid the indirection and import from Python stdlib instead.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2018-12-28T14:21:03Z",
        "closed_at": "2019-03-16T23:11:20Z",
        "merged_at": null,
        "body": "Allows using Python version 3.7 without sudo declarations.\r\n\r\nTravis officially added support for Xenial on 2018-11-08.\r\n\r\nhttps://blog.travis-ci.com/2018-11-08-xenial-release\r\n\r\nCan remove unused Python 2.6 check.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 5,
        "changed_files": 4,
        "created_at": "2018-12-28T14:05:59Z",
        "closed_at": "2019-08-20T04:37:26Z",
        "merged_at": null,
        "body": "Both Python 2.7 & Python 3 have the type `bytes`. On Python 2.7, it is an alias of `str`, same as what was defined in `compat.py`.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 13,
        "deletions": 4,
        "changed_files": 4,
        "created_at": "2018-12-23T21:54:59Z",
        "closed_at": "2019-01-21T13:58:33Z",
        "merged_at": "2019-01-21T13:58:33Z",
        "body": "urllib3 replaced it's URL parser with `rfc3986` for more compliant parsing (urllib3/urllib3#1487). We've also got an effort underway to run downstream tests before releases (urllib3/urllib3#1508) and during that process we've discovered that requests requires percent-encoded bytes to keep their casing.\r\n\r\nAdding this to the unit tests would allow either version of pre- and post-rfc3986 urllib3 to pass requests unit tests. I don't know if the `Request.url` attribute needs to maintain it's casing in this situation or not, if it does this is not the solution. Just putting this together as a potential solution.",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-12-13T14:57:21Z",
        "closed_at": "2018-12-13T21:34:11Z",
        "merged_at": "2018-12-13T21:34:11Z",
        "body": "'params' is sent to the query string, not the body.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 7,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-12-13T10:22:36Z",
        "closed_at": "2018-12-13T13:57:09Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2018-12-05T12:51:22Z",
        "closed_at": "2021-11-28T14:28:13Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-12-04T19:16:36Z",
        "closed_at": "2018-12-10T05:41:15Z",
        "merged_at": "2018-12-10T05:41:15Z",
        "body": "",
        "comments": 12
    },
    {
        "merged": true,
        "additions": 56,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2018-11-12T19:27:56Z",
        "closed_at": "2018-11-13T12:11:50Z",
        "merged_at": "2018-11-13T12:11:50Z",
        "body": "Currently, CI and PR validation are run on AppVeyor and Travis using pretty different configurations.  This PR shows how [Azure Pipelines](https://azure.microsoft.com/en-us/services/devops/pipelines/) could be used to unify the pipeline configuration and run CI and PR checks more quickly. Azure Pipelines offers unlimited minutes with 10 parallel jobs.\r\n\r\nThe first commit attempts to match the AppVeyor and Travis builds apples to apples. You can see in the [build results](https://dev.azure.com/kaylangan-github/kangantest-requests/_build/results?buildId=229&view=logs) that Azure Pipelines typically runs the Linux jobs in <2 minutes and the Windows jobs in ~5 minutes. The Linux jobs are slightly faster than on Travis; the Windows jobs, though individually slower than on AppVeyor, are faster because of the additional parallelism.\r\n\r\nThe second commit unifies the build using a single configuration. CI is run only on Linux and coverage only on Windows. Here's an example of the [build results](https://dev.azure.com/kaylangan-github/kangantest-requests/_build/results?buildId=245&view=logs). I also hooked up test reporting for the Linux builds which you can see [here](https://dev.azure.com/kaylangan-github/kangantest-requests/_build/results?buildId=245&view=ms.vss-test-web.test-result-details):\r\n![image](https://user-images.githubusercontent.com/20052233/48370045-25dc4980-e686-11e8-9d05-ec50571a5d75.png)\r\n\r\nI was a little concerned that the Windows builds appear to fail intermittently, but I noticed that AppVeyor seems to have the same flakiness?\r\n\r\nWould you consider trying out Azure Pipelines and adding it as additional validation for PR/CI?\r\n\r\nDisclaimer: I'm a Program Manager on Azure Pipelines.",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-11-11T20:02:36Z",
        "closed_at": "2018-11-13T12:51:37Z",
        "merged_at": "2018-11-13T12:51:37Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-11-11T19:55:31Z",
        "closed_at": "2018-11-13T12:52:07Z",
        "merged_at": "2018-11-13T12:52:07Z",
        "body": "Tox installs the package to the virtualenv by default. PySocks is\r\nalready included in test_requirements. Don't need to install these\r\nexplicitly.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-11-09T12:06:49Z",
        "closed_at": "2018-11-13T12:52:27Z",
        "merged_at": null,
        "body": "I believe that it was not cleat, what the modified snippet referred to",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 111,
        "deletions": 6,
        "changed_files": 3,
        "created_at": "2018-11-08T05:06:11Z",
        "closed_at": "2018-11-08T17:27:52Z",
        "merged_at": null,
        "body": "This change makes requests more tolerant of a misconfigured Apache server that escapes percent signs in its redirects.  The change includes tests that fail without the change and pass with the change.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-11-06T17:36:12Z",
        "closed_at": "2018-11-09T20:44:35Z",
        "merged_at": "2018-11-09T20:44:35Z",
        "body": "The docs just read a bit strange with `decode_unicode=None` as opposed to `False`.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-11-06T14:26:58Z",
        "closed_at": "2018-11-06T15:47:23Z",
        "merged_at": null,
        "body": "when a class overrode `__getattr__` method and always return something even `None`, this check would fail.\r\nadding `callable` check to ensure there is an existing method `read`.\r\n\r\nbelow is fail case which is used widely to use dot access for a dict:\r\n```\r\nclass DotDict(dict):\r\n    \"\"\"dot.notation access to dictionary attributes\"\"\"\r\n    __setattr__ = dict.__setitem__\r\n    __delattr__ = dict.__delitem__\r\n    __getattr__ = dict.get\r\n\r\n```\r\n",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 31,
        "deletions": 18,
        "changed_files": 4,
        "created_at": "2018-11-04T22:08:58Z",
        "closed_at": "2018-11-05T17:32:46Z",
        "merged_at": null,
        "body": "Code readability :)\r\nJust thought it would be nice to use the suppress instead of the except...pass usage.\r\n",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2018-10-31T00:33:31Z",
        "closed_at": "2018-11-13T12:52:37Z",
        "merged_at": null,
        "body": "Each job already defines its `script`, so need \r\nto define it at the top level.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-10-30T03:26:56Z",
        "closed_at": "2018-11-06T15:50:57Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-10-29T19:56:51Z",
        "closed_at": "2018-10-30T06:13:57Z",
        "merged_at": "2018-10-30T06:13:57Z",
        "body": "The function `requests.utils.from_key_val_list` raises ValueError with message `cannot encode objects that are not 2-tuples`.\r\nOn the function comments it show that it  raises ValueError with message `need more than 1 value to unpack`",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 24,
        "deletions": 2,
        "changed_files": 3,
        "created_at": "2018-10-29T06:34:28Z",
        "closed_at": "2018-10-29T12:48:37Z",
        "merged_at": "2018-10-29T12:48:37Z",
        "body": "This is an attempt to address the default port issues presented in #4850. Our recent changes around auth stripping to handle downgrade attacks in #4718 broke compatibility for cases like http://example.com:80 -> http://example.com. This will allow the use of \"default\" ports and no port interchangeably.\r\n\r\nIf you get a moment @sigmavirus24, I'd like a second pair of eyes on this. I'm not ecstatic about continuing to expand this function, but I don't think there's an easier simplification of what we have.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 286,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-10-27T10:39:23Z",
        "closed_at": "2018-10-27T16:38:01Z",
        "merged_at": null,
        "body": "`.gitignore` has been changed.\r\n\r\n# Rationale\r\nDevelopers/contributors might use different tools. These tools might provide undesired files about tests, test reports, binary files et cetera. That's why `.gitignore` had to be updated.\r\n\r\n# What has changed?\r\nOld entries are still present at the end of file so that maintainers can still have the same result. The file was generated by [gitignore.io](https://www.gitignore.io). A full path to what aspects have been included can be seen in the first line of `.gitignore` file. Anyway, to be verbose:\r\n\r\n - **Jetbrains + Pycharm** caches, configs etc.\r\n - Generic **Python** files which are not supposed to be in the repository such as archived sources, compiled `pyc` files etc. This section also contains some files for `pytest`, `coverage` and `tox`.\r\n - **Virtualenv** has been extended. Other developers/tools might use different path for virtualenv. Pycharm default is `.venv` while current gitignore does not have that, instead, it has `env/` entry.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-10-20T21:56:10Z",
        "closed_at": "2018-10-20T23:36:10Z",
        "merged_at": "2018-10-20T23:36:10Z",
        "body": "A find/replace from a few weeks ago made the redirection sample not demonstrate redirection anymore",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 46,
        "deletions": 7,
        "changed_files": 2,
        "created_at": "2018-10-20T17:01:18Z",
        "closed_at": "2019-02-14T14:16:53Z",
        "merged_at": null,
        "body": "This is a bug fix, because sending such an object currently will cause an exception:\r\n```python\r\n  File \"test.py\", line 81, in client\r\n    r = session.post(url, data=DataWithoutLength(a)).text\r\n  File \"/Users/icebreak/source/requestssux/requests/requests/sessions.py\", line 572, in post\r\n    return self.request('POST', url, data=data, json=json, **kwargs)\r\n  File \"/Users/icebreak/source/requestssux/requests/requests/sessions.py\", line 524, in request\r\n    resp = self.send(prep, **send_kwargs)\r\n  File \"/Users/icebreak/source/requestssux/requests/requests/sessions.py\", line 637, in send\r\n    r = adapter.send(request, **kwargs)\r\n  File \"/Users/icebreak/source/requestssux/requests/requests/adapters.py\", line 449, in send\r\n    timeout=timeout\r\n  File \"/Users/icebreak/source/requestssux/.venv2/lib/python2.7/site-packages/urllib3/connectionpool.py\", line 600, in urlopen\r\n    chunked=chunked)\r\n  File \"/Users/icebreak/source/requestssux/.venv2/lib/python2.7/site-packages/urllib3/connectionpool.py\", line 354, in _make_request\r\n    conn.request(method, url, **httplib_request_kw)\r\n  File \"/Users/icebreak/miniconda2/lib/python2.7/httplib.py\", line 1042, in request\r\n    self._send_request(method, url, body, headers)\r\n  File \"/Users/icebreak/miniconda2/lib/python2.7/httplib.py\", line 1082, in _send_request\r\n    self.endheaders(body)\r\n  File \"/Users/icebreak/miniconda2/lib/python2.7/httplib.py\", line 1038, in endheaders\r\n    self._send_output(message_body)\r\n  File \"/Users/icebreak/miniconda2/lib/python2.7/httplib.py\", line 886, in _send_output\r\n    self.send(message_body)\r\n  File \"/Users/icebreak/miniconda2/lib/python2.7/httplib.py\", line 858, in send\r\n    self.sock.sendall(data)\r\n  File \"/Users/icebreak/miniconda2/lib/python2.7/socket.py\", line 228, in meth\r\n    return getattr(self._sock,name)(*args)\r\nTypeError: sendall() argument 1 must be convertible to a buffer, not DataWithoutLength\r\n```\r\nThe patch makes sure that it will only fix this specific instance.",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 88,
        "deletions": 102,
        "changed_files": 20,
        "created_at": "2018-10-17T15:55:17Z",
        "closed_at": "2018-10-18T15:44:50Z",
        "merged_at": "2018-10-18T15:44:50Z",
        "body": "2.20.0 (2018-10-??)\r\n-------------------\r\n**Bugfixes**\r\n\r\n-   Content-Type header parsing is now case-insensitive (e.g.\r\n    charset=utf8 v Charset=utf8).\r\n-   Fixed exception leak where certain redirect urls would raise\r\n    uncaught urllib3 exceptions.\r\n-   Requests removes Authorization headers from requests redirected\r\n    from https to http on the same hostname. (CVE-2018-18074)\r\n-   `should_bypass_proxies` now handles URIs without hostnames, e.g. files.\r\n\r\n**Dependencies**\r\n- We now support urllib3 v1.24.\r\n\r\n**Deprecations**\r\n- Requests has officially stopped support for Python 2.6.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2018-10-17T10:45:50Z",
        "closed_at": "2018-10-17T13:45:08Z",
        "merged_at": null,
        "body": "Changelog: https://github.com/urllib3/urllib3/blob/1.24/CHANGES.rst#124-2018-10-16",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-10-17T00:24:46Z",
        "closed_at": "2018-10-17T01:36:19Z",
        "merged_at": null,
        "body": "Use it if available rather than relying on urllib3 to provide it.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 21,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-10-15T16:58:46Z",
        "closed_at": "2020-08-18T21:51:47Z",
        "merged_at": null,
        "body": "This was added back in #2195.\r\n\r\nThis started as I was trying to understand why we had PyOpenSSL installed on the project I joined recently. After a bit of digging, it seems that it came from the time when we were using Python 2 and was for Requests/urllib3.\r\n\r\nHowever, looking at Requests' documentation, I couldn't find a clear explanation about this feature, so this is my attempt at fixing this.\r\n\r\nDisclaimer: I'm by no means an expert at SNI, so please correct me on anything wrong that follows.\r\n\r\nHere are what I could find:\r\n\r\n- The intend was to [document this feature](https://github.com/requests/requests/pull/2195#issuecomment-54524390) after merging it, so I assume this contribution is welcome.\r\n- Looking at [the documentation from urllib3](https://urllib3.readthedocs.io/en/latest/user-guide.html#ssl-py2), it seems that the extra dependencies aren't needed in Python 3* and by the look of #4315 it can slow down importing Requests when we have PyOpenSSL.\r\n- Another open pull request (#4591) is trying to change this, but @sigmavirus24 comment implies that there is more to SNI in Requests?\r\n\r\nI'm not sure if this is the best place to document this, adding it to the \"install\" section feels overwhelming for beginners, and I felt like it belongs close to the SSL & certificates verification of the advanced section. Happy to move it somewhere else.\r\n\r\n*Edit:*\r\n\r\n(*) Actually, it seems it was implemented in [PEP 476](https://www.python.org/dev/peps/pep-0476/) which covers Python >=2.7.9 or >=[3.4.3](https://docs.python.org/3.4/whatsnew/changelog.html#python-3-4-3-final), so not any Python 3 versions.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 69,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2018-10-13T09:12:11Z",
        "closed_at": "2018-10-13T10:19:45Z",
        "merged_at": null,
        "body": "Since authentication using 'Authorization' header is quite popular situation, I added `HTTPHeaderAuth` class to make it easier.\r\n\r\nWith this, instead of doing this\r\n\r\n```python\r\nrequests.get(url, header={'Authorization': 'token xxx'})\r\n```\r\n\r\n(this will be overwritten by netrc!)\r\n\r\nor\r\n\r\n```python\r\ndef auth_header(r):\r\n    r.haeders['Authorization'] = 'token xxx'\r\n    return r\r\nrequests.get(url, auth=auth_header)\r\n```\r\n\r\nyou can do\r\n\r\n```python\r\nrequests.get(url, auth=HTTPHeaderAuth('token xxx'))\r\n```\r\n\r\nThis is easier, clearer and no overwrite by netrc file.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 50,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-10-11T14:44:02Z",
        "closed_at": "2018-10-11T17:14:47Z",
        "merged_at": null,
        "body": "The traditional 'read' interface is useful in some cases.\r\nAt very least it may be easier for code that expectes file-handle\r\nlike objects to just add requests support.\r\n\r\nDue to gzip/deflate content-encoding it is not really possible for\r\nthe caller to use just use Response.raw.read().  If gzip was used\r\nthat would return compressed bytes.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-10-08T09:36:51Z",
        "closed_at": "2018-10-10T11:14:43Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 29,
        "deletions": 28,
        "changed_files": 3,
        "created_at": "2018-10-05T08:56:31Z",
        "closed_at": "2018-10-05T16:29:48Z",
        "merged_at": null,
        "body": "Fixed some pep8 issues in docs code snippets.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 90,
        "deletions": 90,
        "changed_files": 20,
        "created_at": "2018-09-23T20:56:44Z",
        "closed_at": "2018-10-01T00:27:24Z",
        "merged_at": "2018-10-01T00:27:24Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-09-23T20:47:10Z",
        "closed_at": "2018-09-30T20:04:01Z",
        "merged_at": "2018-09-30T20:04:01Z",
        "body": "The link does not link Requests stickers as the text suggests.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-09-19T13:17:39Z",
        "closed_at": "2018-09-19T16:23:54Z",
        "merged_at": null,
        "body": "If this header is multiline we can found 'Digest\\r\\n  realm=\"...\"\\r\\n ' instead of \"Digest \".",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-09-17T13:24:55Z",
        "closed_at": "2018-09-30T20:17:54Z",
        "merged_at": null,
        "body": "Adding a header field to proxies will pass any headers to the proxy connection.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-09-15T10:27:59Z",
        "closed_at": "2018-09-15T13:44:27Z",
        "merged_at": "2018-09-15T13:44:27Z",
        "body": "Broken a long line into multiple lines inside tuple parenthesis.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-09-14T14:40:33Z",
        "closed_at": "2018-09-17T13:22:44Z",
        "merged_at": null,
        "body": "Adding a `header` field to `proxies` will pass any headers to the proxy connection.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-09-14T01:05:10Z",
        "closed_at": "2018-09-15T00:08:44Z",
        "merged_at": "2018-09-15T00:08:44Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2018-09-10T17:18:03Z",
        "closed_at": "2018-09-10T19:35:08Z",
        "merged_at": "2018-09-10T19:35:08Z",
        "body": "Move the CTA button so the floating version label doesn\u2019t overlap with the ad. Make the expanded ad more compact to take less vertical space. Hope I don\u2019t make more edit to the ads. \ud83d\ude1f ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 44,
        "deletions": 38,
        "changed_files": 1,
        "created_at": "2018-08-13T19:11:49Z",
        "closed_at": "2022-05-11T01:04:18Z",
        "merged_at": "2022-05-11T01:04:18Z",
        "body": "Hello,\r\n\r\nI do not know if you are interested in fixing `ResourceWarning`s in tests, but I will take my chance :)\r\nThere was 10 unclosed files in `test_requests.py`.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 23,
        "deletions": 4,
        "changed_files": 3,
        "created_at": "2018-08-11T20:00:13Z",
        "closed_at": "2018-10-01T02:23:58Z",
        "merged_at": "2018-10-01T02:23:57Z",
        "body": "This should address #4746 by catching and wrapping all `LocationValueError`s and rewrapping them under the Requests namespace as `InvalidURL`.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-08-01T08:21:19Z",
        "closed_at": "2018-08-02T17:53:44Z",
        "merged_at": "2018-08-02T17:53:44Z",
        "body": "http://docs.python-requests.org/en/master/api/#api-cookies",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 3,
        "created_at": "2018-07-24T20:43:42Z",
        "closed_at": "2018-08-02T17:55:41Z",
        "merged_at": "2018-08-02T17:55:41Z",
        "body": "Official support was added in 6686ac173011a302c26c4aedbd992f96d6e58357.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 26,
        "deletions": 13,
        "changed_files": 3,
        "created_at": "2018-07-13T09:49:48Z",
        "closed_at": "2018-07-17T22:16:03Z",
        "merged_at": "2018-07-17T22:16:03Z",
        "body": "Fix a few inconsistencies in the doc found while working on [MechanicalSoup](https://github.com/MechanicalSoup/MechanicalSoup/pull/219).",
        "comments": 9
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2018-07-12T11:00:04Z",
        "closed_at": "2018-08-06T12:48:26Z",
        "merged_at": null,
        "body": "Hi guys,\r\n\r\nTo troubleshoot requests queries, I found useful to be able to access the connection SSL certificate details. Once the connection is closed, urllib3 call release_conn() and this information is not available afterwards, therefore I suggest to set a new attribute peercert in Response and set it in the HTTPAdapter.\r\n\r\nPython 3.6\r\n\r\n```python\r\n(Pdb) type(response.raw._connection)\r\n<class 'urllib3.connection.VerifiedHTTPSConnection'>\r\n(Pdb) type(response.raw._connection.sock)\r\n<class 'ssl.SSLSocket'>\r\n````\r\n\r\n```python\r\n>>> resp = requests.get('https://s3.eu-west-1.amazonaws.com/')\r\n>>> resp.peercert\r\n{'subject': ((('commonName', 'aws.amazon.com'),),), 'issuer': ((('countryName', 'US'),), (('organizationName', 'Amazon'),), (('organizationalUnitName', 'Server CA 1B'),), (('commonName', 'Amazon'),)), 'version': 3, 'serialNumber': '0E9C9BE31387FA07A147D4406982B417', 'notBefore': 'Mar 28 00:00:00 2018 GMT', 'notAfter': 'Mar 28 12:00:00 2019 GMT', 'subjectAltName': (('DNS', 'aws.amazon.com'), ('DNS', 'www.aws.amazon.com'), ('DNS', 'aws-us-east-1.amazon.com'), ('DNS', 'aws-us-west-2.amazon.com'), ('DNS', 'amazonaws-china.com'), ('DNS', 'www.amazonaws-china.com')), 'OCSP': ('http://ocsp.sca1b.amazontrust.com',), 'caIssuers': ('http://crt.sca1b.amazontrust.com/sca1b.crt',), 'crlDistributionPoints': ('http://crl.sca1b.amazontrust.com/sca1b.crl',)}\r\n```\r\n\r\nWith python 2.7 information are based on pyopenssl and less details are available though:\r\n\r\n```\r\n>>> resp = requests.get('https://s3.eu-west-1.amazonaws.com/')\r\n>>> resp.peercert\r\n{'subject': ((('commonName', u'aws.amazon.com'),),),\r\n 'subjectAltName': [('DNS', 'aws.amazon.com'),\r\n  ('DNS', 'www.aws.amazon.com'),\r\n  ('DNS', 'aws-us-east-1.amazon.com'),\r\n  ('DNS', 'aws-us-west-2.amazon.com'),\r\n  ('DNS', 'amazonaws-china.com'),\r\n  ('DNS', 'www.amazonaws-china.com')]}\r\n```\r\n\r\n```python\r\nPdb) type(response.raw._connection.sock)\r\n<class 'urllib3.contrib.pyopenssl.WrappedSocket'>\r\n(Pdb) type(response.raw._connection)\r\n<class 'urllib3.connection.VerifiedHTTPSConnection'>\r\n```\r\nI also found people interested by this on [stackoverflow](https://stackoverflow.com/questions/16903528/how-to-get-response-ssl-certificate-from-requests-in-python)",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 11,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-07-12T08:53:35Z",
        "closed_at": "2018-07-12T13:35:37Z",
        "merged_at": null,
        "body": "I want to create logger for pytest in my project. And logging last response from session. This field is necessary for me ;)",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-07-11T15:08:46Z",
        "closed_at": "2022-05-11T00:26:08Z",
        "merged_at": null,
        "body": "Even I used custom cookie jar class to manage cookie values, redirecting link only used default `RequestCookieJar` class and it seemed there was not work around.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-07-08T17:12:29Z",
        "closed_at": "2018-07-09T12:19:50Z",
        "merged_at": "2018-07-09T12:19:50Z",
        "body": "Fix errors like this:\r\n```\r\n$ python -W error -c 'import requests'\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/Users/yen/Projects/requests/requests/__init__.py\", line 114, in <module>\r\n    from .models import Request, Response, PreparedRequest\r\n  File \"/Users/yen/Projects/requests/requests/models.py\", line 43, in <module>\r\n    from .status_codes import codes\r\n  File \"/Users/yen/Projects/requests/requests/status_codes.py\", line 18\r\n    \"\"\"\r\nSyntaxError: invalid escape sequence \\o\r\n```\r\nContext: the [buildbot](https://github.com/buildbot/buildbot) test suite treats all warnings as errors.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-07-06T09:42:24Z",
        "closed_at": "2018-07-06T12:49:34Z",
        "merged_at": null,
        "body": "-- Removed b at the beginning of printing of content of a response\r\n\r\nFixes to Issue: #4724\r\n\r\nSigned-off-by: Shivesh <shankeyshivesh@gmail.com>",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2018-07-05T23:04:26Z",
        "closed_at": "2018-08-13T16:54:33Z",
        "merged_at": "2018-08-13T16:54:33Z",
        "body": "Commit 2255c34a65b5b1353004dc8d49cc397cd794ec15 in https://github.com/requests/requests/pull/4427 makes the assumption that all URLs have hostnames.  Or perhaps the assumption was that `urlparse()` returns an empty string for the `hostname` attribute rather than `None`.  Either way, the assumption blows up both for `is_ipv4_address(parsed.hostname)` and also for\r\n\r\n```python\r\nhost_with_port = parsed.hostname\r\nif parsed.port:\r\n    host_with_port += ':{0}'.format(parsed.port)\r\n```\r\n\r\nwhen `parsed.hostname` is `None`.  Example circumstances of where this all blows up is when a `NO_PROXY` environment variable is set during use of something like conda's [adapter](https://github.com/conda/conda/blob/4.5.5/conda/gateways/connection/adapters/localfs.py) to handle `file:///` urls.  It results in a stack trace like\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/circleci/conda/tests/gateways/test_connection.py\", line 62, in test_local_file_adapter_200\r\n    r = session.get(test_url)\r\n  File \"/opt/conda/lib/python3.6/site-packages/requests/sessions.py\", line 525, in get\r\n    return self.request('GET', url, **kwargs)\r\n  File \"/opt/conda/lib/python3.6/site-packages/requests/sessions.py\", line 503, in request\r\n    prep.url, proxies, stream, verify, cert\r\n  File \"/opt/conda/lib/python3.6/site-packages/requests/sessions.py\", line 676, in merge_environment_settings\r\n    env_proxies = get_environ_proxies(url, no_proxy=no_proxy)\r\n  File \"/opt/conda/lib/python3.6/site-packages/requests/utils.py\", line 760, in get_environ_proxies\r\n    if should_bypass_proxies(url, no_proxy=no_proxy):\r\n  File \"/opt/conda/lib/python3.6/site-packages/requests/utils.py\", line 716, in should_bypass_proxies\r\n    if is_ipv4_address(parsed.hostname):\r\n  File \"/opt/conda/lib/python3.6/site-packages/requests/utils.py\", line 640, in is_ipv4_address\r\n    socket.inet_aton(string_ip)\r\nTypeError: inet_aton() argument 1 must be str, not None\r\n```\r\n\r\nI *think* the correct solution here is to just return `True` in the `should_bypass_proxies()` function when there is no hostname in the URL.  Definitely know that sending `None` to `inet_aton(string_ip)` or trying to add `None` to a port string definitely isn't correct.",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-07-04T19:51:40Z",
        "closed_at": "2018-07-04T23:04:22Z",
        "merged_at": null,
        "body": "Fixed pep8 issues below: \r\n\r\ntest_help.py:10:47: E231 missing whitespace after ','\r\ntest_help.py:10:80: E501 line too long (83 > 79 characters)\r\ntest_help.py:18:42: E231 missing whitespace after ','\r\ntest_help.py:38:80: E501 line too long (81 > 79 characters)\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 44,
        "deletions": 11,
        "changed_files": 2,
        "created_at": "2018-06-28T14:48:34Z",
        "closed_at": "2018-09-14T12:08:05Z",
        "merged_at": "2018-09-14T12:08:05Z",
        "body": "Previously the header was stripped only if the hostname changed, but in\r\nan https -> http redirect that can leak the credentials on the wire\r\n(#4716). Based on with RFC 7235 section 2.2, the header is now stripped\r\nif the \"canonical root URL\" (scheme+authority) has changed.\r\n\r\nCloses #4716.",
        "comments": 16
    },
    {
        "merged": true,
        "additions": 30,
        "deletions": 11,
        "changed_files": 3,
        "created_at": "2018-06-28T06:32:11Z",
        "closed_at": "2018-07-24T14:44:38Z",
        "merged_at": "2018-07-24T14:44:38Z",
        "body": "Python 3.7 was just released [1]. This is a small change to\r\nenable support in requests.\r\n\r\n[1] https://docs.python.org/3.7/whatsnew/3.7.html\r\n\r\nSigned-off-by: Eric Brown <browne@vmware.com>",
        "comments": 12
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-06-26T18:58:55Z",
        "closed_at": "2018-06-26T20:32:33Z",
        "merged_at": "2018-06-26T20:32:33Z",
        "body": "The 'proxy' parameter was misspelled as 'proxies' in the docstring.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2018-06-26T18:32:35Z",
        "closed_at": "2018-07-18T02:39:19Z",
        "merged_at": "2018-07-18T02:39:19Z",
        "body": "httpbin is used to mock HTTP endpoints. In these methods, the parameter goes unused.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-06-25T16:56:32Z",
        "closed_at": "2018-06-25T18:11:40Z",
        "merged_at": "2018-06-25T18:11:40Z",
        "body": "Twitter expanded the maximum character count per tweet from 140 to 280 in November 2017.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-06-23T15:02:21Z",
        "closed_at": "2018-07-04T19:31:04Z",
        "merged_at": null,
        "body": "First of all, thanks for Requests!\r\n\r\nWould you be up for adding a badge that shows how SemVer compliant / bug free new releases are? I was looking through the data we gather at Dependabot and realised we could put one together, so threw together the below:\r\n\r\n[![SemVer](https://api.dependabot.com/badges/compatibility_score?dependency-name=requests&package-manager=pip&version-scheme=semver)](https://dependabot.com/compatibility-score.html?dependency-name=requests&package-manager=pip&version-scheme=semver)\r\n\r\nIf you click through then there's a description of how it's calculated - basically it takes all of the relevant updates Dependabot has done for projects that use Requests and checks what percentage of the time specs pass on the upgrade PR.\r\n\r\nThe score is slightly lower than 100% because some projects have flaky specs, but I'm working on filtering them out from the data, too :octocat:.",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 25,
        "deletions": 18,
        "changed_files": 1,
        "created_at": "2018-06-21T20:37:34Z",
        "closed_at": "2018-08-11T18:27:49Z",
        "merged_at": null,
        "body": "- References to depreciated method `session()` now initialize `Session()` directly.\r\n- Added test for depreciated `session()` method.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 19,
        "deletions": 6,
        "changed_files": 3,
        "created_at": "2018-06-20T19:26:18Z",
        "closed_at": "2018-07-20T16:56:29Z",
        "merged_at": "2018-07-20T16:56:28Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 19,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-06-20T18:29:16Z",
        "closed_at": "2018-06-21T02:43:30Z",
        "merged_at": null,
        "body": "Ensure that `BaseAdapter` supports multi-class inheritance. This means a subclass of `BaseAdapter` will invoke all parent classes when inheriting from multiple classes.\r\n\r\nSee: https://github.com/requests/requests/pull/4697#issuecomment-398814166\r\n\r\n    class BaseAdapter(object):  # pass\r\n        def __init__(self):\r\n            super(BaseAdapter, self).__init__()\r\n\r\n    class BaseAdapter(object):  # pass\r\n        pass\r\n\r\n    class BaseAdapter(object):  # fail\r\n        def __init__(self):\r\n            BaseAdapter.__init__(self)\r\n\r\n    class BaseAdapter(object):  # fail\r\n        def __init__(self):\r\n            object.__init__(self)\r\n\r\n    class BaseAdapter(object):  # fail\r\n        def __init__(self):\r\n            pass",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-06-20T06:33:39Z",
        "closed_at": "2018-07-02T20:45:51Z",
        "merged_at": null,
        "body": "In #4690, an scenario is provided where if you make a post using as `data` a dictionary with empty values, the request library will treat this post as a chunked request. (More detail explanaition in my comment in the issue)\r\n\r\nThis PR fix that problem, creating the encoded data first to check if there is really data to sent in the data dictionary.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-06-13T16:43:14Z",
        "closed_at": "2018-06-21T19:09:06Z",
        "merged_at": "2018-06-21T19:09:06Z",
        "body": "According to requests/api.rst, the `Session` class was originally named session in 0.x. [When the class name was capitalized in 1.x](https://github.com/requests/requests/blob/265ef609d5903151374fba480aa81aafe68126ff/docs/api.rst#migrating-to-1x), the `session()` method was added for backwards compatibility.\r\n\r\nThis adds a docstring note that `requests.Session` should be used instead",
        "comments": 11
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-06-12T21:55:41Z",
        "closed_at": "2018-06-13T15:24:46Z",
        "merged_at": "2018-06-13T15:24:46Z",
        "body": "Following https://github.com/requests/requests/pull/4394/files, with PYTHONOPTIMIZE=2, the current code breaks with TypeError due to None as the docstring. This broke dask tests https://github.com/dask/dask/pull/3594 .",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 19,
        "deletions": 22,
        "changed_files": 3,
        "created_at": "2018-06-10T17:52:04Z",
        "closed_at": "2018-08-12T03:35:00Z",
        "merged_at": "2018-08-12T03:35:00Z",
        "body": "The intersphinx extension can generate automatic links to the documentation of objects in other projects. It was already used for urllib3. For complete details on intersphinx, see:\r\n\r\nhttp://www.sphinx-doc.org/en/master/ext/intersphinx.html",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 7,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-06-10T13:24:41Z",
        "closed_at": "2018-06-11T13:12:37Z",
        "merged_at": null,
        "body": "Just Fixed bug in [issue4649](https://github.com/requests/requests/issues/4649)",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2018-06-10T03:34:44Z",
        "closed_at": "2018-06-10T15:37:09Z",
        "merged_at": "2018-06-10T15:37:09Z",
        "body": "The Python 3 docs are better maintained and are the future of Python development.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 5,
        "changed_files": 4,
        "created_at": "2018-06-06T05:07:17Z",
        "closed_at": "2018-06-11T14:13:14Z",
        "merged_at": "2018-06-11T14:13:14Z",
        "body": "This will remove our \"official\" support for 2.6 from the documentation only. We'll keep the work done to remove Python 2.6 code from the Requests code base (#4118) in the Requests3 branch so we don't forcibly break users installs with the 2.19.0 release.\r\n\r\n@sigmavirus24 I looked at moving to urllib3's `secure` options, but wasn't immediately able to get `        'security': ['urllib3[secure]>=1.23']` working in our setup.py. That's likely the last step to close out #4659 if we're ok with urllib3 managing the security dependencies. I'll try to look closer later this week.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-06-05T12:06:27Z",
        "closed_at": "2018-06-05T13:35:09Z",
        "merged_at": "2018-06-05T13:35:09Z",
        "body": "Changelog: https://github.com/urllib3/urllib3/blob/1.23/CHANGES.rst#123-2018-06-04",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 335,
        "deletions": 211,
        "changed_files": 1,
        "created_at": "2018-05-16T14:57:14Z",
        "closed_at": "2018-05-16T19:31:49Z",
        "merged_at": "2018-05-16T19:31:49Z",
        "body": "The Pipfile has strayed a bit from our current build constraints and contains information that's no longer consistent with Warehouse. Updating should help with installation and prevent problems like pypa/packaging-problems#147 from reoccurring when users pick Requests as a model for their packages.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 8,
        "changed_files": 2,
        "created_at": "2018-05-16T06:04:37Z",
        "closed_at": "2018-05-16T13:14:38Z",
        "merged_at": "2018-05-16T13:14:38Z",
        "body": "I don't know what's going on with Appveyor/Pipenv but it's no longer liking `-e .` installs out of the Pipfile. I went back to a version of Pipenv that we have successful builds for and it's still broken. I'd like to get builds fixed while we determine root cause.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-05-15T20:40:38Z",
        "closed_at": "2018-05-16T06:38:23Z",
        "merged_at": null,
        "body": "- Lockfile was created when only the sdist was available",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-05-08T07:01:47Z",
        "closed_at": "2018-05-12T14:53:35Z",
        "merged_at": null,
        "body": "fixes #4635\r\nIn function merge_environment_settings before entering the loop",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-05-07T17:52:02Z",
        "closed_at": "2018-05-08T11:12:33Z",
        "merged_at": "2018-05-08T11:12:33Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-05-05T00:58:18Z",
        "closed_at": "2018-05-13T17:30:58Z",
        "merged_at": "2018-05-13T17:30:58Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-05-04T11:13:35Z",
        "closed_at": "2018-05-17T14:34:07Z",
        "merged_at": "2018-05-17T14:34:07Z",
        "body": "See:\r\n- https://packaging.python.org/guides/making-a-pypi-friendly-readme/\r\n- https://pypi.org/p/requests/",
        "comments": 9
    },
    {
        "merged": false,
        "additions": 15,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2018-05-04T04:36:22Z",
        "closed_at": "2018-05-04T13:42:58Z",
        "merged_at": null,
        "body": "In `Response.iter_lines`, if a `\\r\\n` sequence (the only multi-character line boundary) straddles two chunks, the `\\r` and `\\n` are treated as two separate boundaries. Consequently, `iter_lines` will yield one extra blank line, as an empty string.\r\n\r\nThis addresses the issue by checking if a chunk ends with `\\r`, and when appropriate, leaving the trailing line in `pending` until the next chunk or EOF arrives.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-05-03T15:48:07Z",
        "closed_at": "2018-05-14T16:22:11Z",
        "merged_at": "2018-05-14T16:22:11Z",
        "body": "http://certifi.io/ -> https://certifiio.readthedocs.io/",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-05-03T04:31:17Z",
        "closed_at": "2018-05-03T14:16:38Z",
        "merged_at": null,
        "body": "This will make the readme render correctly on pypi.\r\n\r\nhttps://packaging.python.org/tutorials/distributing-packages/#description",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-04-30T23:19:08Z",
        "closed_at": "2021-11-28T03:27:30Z",
        "merged_at": null,
        "body": "Set up `proxies` safely for the `.setdefault()` call a few lines below by coercing it into a dict if passed in as `None`, and adjust the one line that was potentially expecting a `None`.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-04-29T17:38:03Z",
        "closed_at": "2018-04-29T23:56:10Z",
        "merged_at": "2018-04-29T23:56:10Z",
        "body": "Appveyor isn't able to replace the running executable. We'll run it\r\nfrom inside the interpreter to fix build issues. This is lifted from the fix over on urllib3/urllib3#1369 which was configured to run the same way.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-04-27T15:48:46Z",
        "closed_at": "2018-05-23T19:07:08Z",
        "merged_at": null,
        "body": "Adds a docstring to `__version__.py`.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-04-26T14:05:23Z",
        "closed_at": "2018-04-30T15:00:20Z",
        "merged_at": "2018-04-30T15:00:20Z",
        "body": "- the Request class doesn't accept JSON, but a JSON serializable object",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 9,
        "changed_files": 4,
        "created_at": "2018-04-24T10:13:17Z",
        "closed_at": "2018-04-24T13:59:07Z",
        "merged_at": null,
        "body": "This was previously fixed in e7c9bbb96 and broken again in\r\n4c82dbab6fc. Add a comment this time to prevent people from breaking\r\nit again.",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-04-21T07:16:59Z",
        "closed_at": "2018-04-21T08:31:20Z",
        "merged_at": null,
        "body": "# Nicer URL formatting with lists\r\n\r\n### Purpose\r\n\r\nUsing `['https://example.com', route1, route2]` as URL parameter as compared to `'https://example.com/{}/{}'.format(route1, route2)` or `'https://example.com/'+route1+'/'+route2`\r\n\r\n### Examples\r\n\r\n```python\r\nimport requests\r\n\r\nslug = 1\r\nr = requests.get(['https://api.jikan.me/anime', slug])\r\nr.url\r\n# 'https://api.jikan.me/anime/1'\r\n\r\ncategory, item = 'jokes', 'random'\r\nr = requests.get(['https://api.chucknorris.io', category, item])\r\nr.url\r\n# 'https://api.chucknorris.io/jokes/random'\r\n```",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 10,
        "deletions": 10,
        "changed_files": 6,
        "created_at": "2018-04-19T05:05:55Z",
        "closed_at": "2018-04-19T06:19:25Z",
        "merged_at": null,
        "body": "According to [1], the PyPI website of pypi.python.org has changed\r\nto https://pypi.org. This patch updates all references to the\r\nlegacy site.\r\n\r\n[1] https://pythoninsider.blogspot.ca/2018/04/new-pypi-launched-legacy-pypi-shutting.html\r\n\r\nSigned-off-by: Eric Brown <browne@vmware.com>",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 9,
        "changed_files": 5,
        "created_at": "2018-04-19T03:28:52Z",
        "closed_at": "2018-04-19T10:41:37Z",
        "merged_at": "2018-04-19T10:41:37Z",
        "body": "For details on the new PyPI, see the blog post:\r\n\r\nhttps://pythoninsider.blogspot.ca/2018/04/new-pypi-launched-legacy-pypi-shutting.html",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 12,
        "deletions": 10,
        "changed_files": 1,
        "created_at": "2018-04-16T06:25:06Z",
        "closed_at": "2020-08-18T21:49:52Z",
        "merged_at": null,
        "body": "Since recent Python supports SNI, importing pyOpenSSL\nis avoidable now.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-04-12T15:02:43Z",
        "closed_at": "2018-04-12T17:33:14Z",
        "merged_at": null,
        "body": "Simple fix to get method of Session class allowing it to receive params, just as requests.get would allow",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-04-11T22:59:58Z",
        "closed_at": "2018-05-13T13:15:57Z",
        "merged_at": "2018-05-13T13:15:57Z",
        "body": "As suggested by @sigmavirus24 for the follow-up of issue #4579 ",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-04-04T14:50:14Z",
        "closed_at": "2018-04-04T16:29:54Z",
        "merged_at": null,
        "body": "via status_codes.py.\r\nfixes #4572",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2018-04-03T12:07:41Z",
        "closed_at": "2019-06-08T13:19:45Z",
        "merged_at": null,
        "body": "PR resolving the issue : #4557 .",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-03-27T21:38:44Z",
        "closed_at": "2018-03-28T12:03:11Z",
        "merged_at": null,
        "body": "small patch that respects replay-after only in automatic redirects .. similar to chrome, firefox and others.\r\n\r\n reply-after is not handled for other status codes such as 503, and 429 as the handling may application specific.  \r\n\r\nhttps://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Retry-After",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-03-27T16:47:16Z",
        "closed_at": "2018-03-27T17:48:16Z",
        "merged_at": null,
        "body": "This is a very minimal PR that aims to allow developers to assign a default timeout to requests made using `Requests`, while not breaking any existing usage of the library. I open it following bumping into the problem of a request hanging indefinitely several times and reading through the open issues - specifically @kennethreitz 's comment here regarding assigning a default timeout to the lib: https://github.com/requests/requests/issues/3070#issuecomment-318926146\r\n\r\nIn essence, it allows a user to set a default timeout for a `Session` object so that any request made using that session will default to the session timeout unless specifically assigned a timeout of its own. I attempted to circumvent the entire issue of breaking existing code or deciding on the right default timeout for the library itself, instead just giving the user a tool to set it per session where necessary, instead of once per request.\r\n\r\nThe only open issue I am aware of is that if a request is specifically assigned to never timeout (`timeout=None`) and the session it is sent from has a default timeout set, then the session timeout will take. However, I believe that in such a case it makes sense to send the request from a new session.\r\n\r\nHappy to receive any feedback. Thanks in advance!",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2018-03-21T19:38:06Z",
        "closed_at": "2018-06-14T14:39:14Z",
        "merged_at": "2018-06-14T14:39:14Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 3472,
        "deletions": 2803,
        "changed_files": 51,
        "created_at": "2018-03-15T21:16:24Z",
        "closed_at": "2021-11-28T03:24:03Z",
        "merged_at": null,
        "body": "I'll be logging what I'm working on in this pull request. \r\n\r\nSo far: \r\n\r\n- Removed all Python 2-specific code.\r\n- Ran codebase through Black (White, actually) (new `setup.py format` command).\r\n- Converted many `str.format`s to f-strings.\r\n- Removed many \"if bytes\" code paths.\r\n- Integrated rfc3986 for URL Parsing (needs to be done in `utils.py` still.\r\n- Integrated new `HTTPHeaderDict`. \r\n- Typed out `api.py` and `utils.py` (I think, correctly), added a new types module, `types.py`. \r\n- Updated test suite to use a session fixture. \r\n- Added `__slots__` to most heavily-used classes.\r\n\r\n**This pull request is not a request for feedback.**\r\n\r\nAll tests passing.\r\n\r\nThink that's everything. Will add comments as I go.",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-03-13T06:43:00Z",
        "closed_at": "2018-03-13T13:52:06Z",
        "merged_at": "2018-03-13T13:52:06Z",
        "body": "This my first PR to this project please review and give feedback to me how can I improve.",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-03-07T10:09:28Z",
        "closed_at": "2018-03-08T17:59:50Z",
        "merged_at": null,
        "body": "Update MANIFEST.in (Issue #4518)",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 16,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2018-02-26T22:21:04Z",
        "closed_at": "2018-02-27T06:29:14Z",
        "merged_at": null,
        "body": "Many packages have established PURGE as a defacto HTTP verb for flushing caches.\r\nThis implements the new verb.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 13,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2018-02-14T16:45:26Z",
        "closed_at": "2018-06-12T05:13:08Z",
        "merged_at": "2018-06-12T05:13:08Z",
        "body": "",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 463,
        "deletions": 99,
        "changed_files": 28,
        "created_at": "2018-02-09T12:16:37Z",
        "closed_at": "2018-02-12T15:50:18Z",
        "merged_at": null,
        "body": "In addition to  #4434 I found a possible solution not only for Kodi. Could you try such idea jsergio123/script.module.resolveurl@2e3f773 to solve the iOS issue 'No child processes' ?",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2018-02-07T18:38:39Z",
        "closed_at": "2018-02-08T00:25:23Z",
        "merged_at": "2018-02-08T00:25:23Z",
        "body": "Fixed typos:\r\nnonexistant -> nonexistent\r\nneccessary -> necessary",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 16,
        "deletions": 10,
        "changed_files": 2,
        "created_at": "2018-02-07T03:10:47Z",
        "closed_at": "2021-11-28T03:25:18Z",
        "merged_at": null,
        "body": "Try to fix #4489 : Python 2.x IOError cannot handle unicode argument, and HTTPError is a IOError.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 19,
        "changed_files": 7,
        "created_at": "2018-02-05T04:19:41Z",
        "closed_at": "2018-06-12T05:15:01Z",
        "merged_at": "2018-06-12T05:15:01Z",
        "body": "In Python 3.7, there is a warning that the abstract bases in collections.abc will no longer be accessible through the regular collections module in Python 3.8.  This patch future-proofs requests.\r\n\r\nI wasn't able to run the test suite locally, so this needs a thorough test going forward.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 30,
        "changed_files": 4,
        "created_at": "2018-02-05T03:16:18Z",
        "closed_at": "2018-03-08T18:00:50Z",
        "merged_at": "2018-03-08T18:00:50Z",
        "body": "As v3.0.0 already includes other backwards incompatible changes, it is a good time to remove the old entry point for vendored packages. Cleans up compatibility shims.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 13,
        "changed_files": 5,
        "created_at": "2018-02-05T02:50:07Z",
        "closed_at": "2018-02-17T14:15:55Z",
        "merged_at": "2018-02-17T14:15:55Z",
        "body": "As the vendored packages were removing in version 2.16, all remaining\r\ndoc references should be replaced with newer practices.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 16,
        "changed_files": 8,
        "created_at": "2018-02-04T19:57:42Z",
        "closed_at": "2018-02-05T16:37:19Z",
        "merged_at": "2018-02-05T16:37:19Z",
        "body": "Many editors clean up trailing white space on save. By removing it all in one go, it helps keep future diffs cleaner by avoiding spurious white space changes on unrelated lines.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 9,
        "changed_files": 1,
        "created_at": "2018-02-03T00:01:39Z",
        "closed_at": "2018-02-16T01:56:01Z",
        "merged_at": "2018-02-16T01:56:01Z",
        "body": "Since commit 0d7de6430eef0cf09f9662746daf0c28d83f144e, certifi is always used for certificates. Certify became a hard dependency of the package in 628633143d5b8590b1dbdf5371fe81fb8250dffd.\r\n\r\nNow update the docs to clarify that Request will always use certificates from certifi.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-02-02T18:21:57Z",
        "closed_at": "2018-02-03T13:40:45Z",
        "merged_at": "2018-02-03T13:40:45Z",
        "body": "The docstring for `HTTPAdapter.add_headers` implies that keyword args from the `send` call will be passed into `add_headers` \u2013 this change passes them in.  This would be helpful, particularly for kwargs like `timeout`, which may influence the headers that need to be added by an `HTTPAdapter` subclass.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-02-01T08:40:50Z",
        "closed_at": "2018-02-03T14:43:31Z",
        "merged_at": "2018-02-03T14:43:31Z",
        "body": "Given that 3.7 is [now in beta](https://twitter.com/gvanrossum/status/958930025603977216) and scheduled for release in ~4 months, we should probably start testing it again.\r\n\r\nEDIT: As far as I can tell appveyor hasn't had support for 3.7 added yet, likely due to it being an alpha release. We'll want to add that later when it becomes available.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2018-01-13T00:42:07Z",
        "closed_at": "2018-01-14T01:13:30Z",
        "merged_at": "2018-01-14T01:13:30Z",
        "body": "The issue also has duplicates  #2620 and my recent #4467",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-01-11T02:38:08Z",
        "closed_at": "2018-01-11T14:41:08Z",
        "merged_at": "2018-01-11T14:41:08Z",
        "body": "Python 3.3 is not a supported version so don't test it.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-01-11T02:34:04Z",
        "closed_at": "2018-01-13T04:06:59Z",
        "merged_at": "2018-01-13T04:06:59Z",
        "body": "Helps pip decide what version of the library to install.\r\n\r\nhttps://packaging.python.org/tutorials/distributing-packages/#python-requires\r\n\r\n> If your project only runs on certain Python versions, setting the\r\n> python_requires argument to the appropriate PEP 440 version specifier\r\n> string will prevent pip from installing the project on other Python\r\n> versions.\r\n\r\nhttps://setuptools.readthedocs.io/en/latest/setuptools.html#new-and-changed-setup-keywords\r\n\r\n> python_requires\r\n>\r\n> A string corresponding to a version specifier (as defined in PEP 440)\r\n> for the Python version, used to specify the Requires-Python defined in\r\n> PEP 345.",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 86,
        "deletions": 1,
        "changed_files": 3,
        "created_at": "2018-01-07T21:28:31Z",
        "closed_at": "2018-01-21T18:41:47Z",
        "merged_at": "2018-01-21T18:41:47Z",
        "body": "This PR should address #4443 by appending the original request's fragment to subsequent redirects, unless a new fragment is provided in the Location header. This behaviour should bring us into compliance with [RFC 7230 \u00a7 7.1.2](https://tools.ietf.org/html/rfc7231#section-7.1.2). I also wrote a test to confirm we don't send fragment information to new servers, our underlying implementation strips that.\r\n\r\nOne outstanding question I do have though is about chained redirects. \r\n\r\n-----\r\n\r\nLet's say we make a request (`http://url#alice`) and get a 302 response (`http://new_url#bob`). We would leave `#bob` as the fragment for the second request. When we request `http://new_url#bob`, we get back another 301 to `http://final_url/`. Do we append `alice` or `bob` at this point? \r\n\r\nI went with the assumption that the \"original\" request is the first one in the chain. I could see an argument that all requests are stateless though, and that the `new_url#bob` is the only originating request in scope for the second redirect.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 20,
        "changed_files": 9,
        "created_at": "2018-01-06T19:25:15Z",
        "closed_at": "2018-01-06T23:23:00Z",
        "merged_at": "2018-01-06T23:23:00Z",
        "body": "- Fixed Read the Docs links\r\n- Fixed GitHub links\r\n- Fixed PyPI links",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 51,
        "deletions": 21,
        "changed_files": 1,
        "created_at": "2018-01-04T22:29:10Z",
        "closed_at": "2018-01-11T03:12:35Z",
        "merged_at": null,
        "body": "Initial version of a fix for issue #4445.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 67,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2017-12-31T21:15:20Z",
        "closed_at": "2018-01-04T22:32:40Z",
        "merged_at": "2018-01-04T22:32:40Z",
        "body": "In response to issue #4313 , I removed the cgi module import and added a parse_header function nested inside get_encoding_from_headers in utils.py.  I have run the tests both before and after making these changes.  The test_util cases all passed before and they still do now.  Please let me know about any suggestions to this code.  ",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-12-28T09:17:44Z",
        "closed_at": "2018-01-21T14:36:32Z",
        "merged_at": "2018-01-21T14:36:32Z",
        "body": "certifi.io doesn't available at least since 07.11.2017\r\n(https://github.com/certifi/certifi.io/issues/16)",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 37,
        "deletions": 11,
        "changed_files": 4,
        "created_at": "2017-12-12T15:08:10Z",
        "closed_at": "2018-01-16T14:07:27Z",
        "merged_at": "2018-01-16T14:07:26Z",
        "body": "Fixes #4275 and fixes #4158 by passing only the hostname/IP to urllib's `proxy_bypass` function which was timing out further down in `socket.gethostbyname` when passed a hostname or IP that contained authentication credentials.\r\n\r\nWhile fixing the parameter passed to `proxy_bypass`, I also took the chance to replace other uses of `netloc` with `hostname` in the `should_bypass_function`. ",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-12-11T15:51:45Z",
        "closed_at": "2017-12-12T13:03:17Z",
        "merged_at": null,
        "body": "The plural of `status` is `statuses` or `stat\u016bs`. Please disregard if it's here for a particular reason. \r\n\r\nhttps://en.wiktionary.org/wiki/status#English \r\nhttps://en.wiktionary.org/wiki/status#Etymology_2_2",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 64,
        "deletions": 41,
        "changed_files": 2,
        "created_at": "2017-11-29T14:12:38Z",
        "closed_at": "2018-05-16T14:06:58Z",
        "merged_at": "2018-05-16T14:06:58Z",
        "body": "Added SHA-256 and SHA-512 auth algorithms to requests/auth.py   Added test code to test_requests.py\r\n\r\nRequires SHA-256 and SHA-512 in the httpbin test framework.",
        "comments": 15
    },
    {
        "merged": false,
        "additions": 122,
        "deletions": 72,
        "changed_files": 3,
        "created_at": "2017-11-29T05:24:49Z",
        "closed_at": "2017-12-10T21:07:08Z",
        "merged_at": null,
        "body": "Creates default SSLContext object for each HTTPAdapter that is expected to be used for https requests.\r\n\r\nThere are just a few small changes for:\r\n- Adding a default SSLContext object only to the https HTTPAdapter in each session (not the http one)\r\n- Creating the default object using the same urllib3 function that would be used to create a default SSLContext for each connection\r\n- Adding ssl_context to poolmanager's connection_pool_kw to get passed down to all connections\r\n- Pickling HTTPAdapter with the new attribute\r\n- Breaking up the HTTPAdapter's send method a little (this is not related, I was just there anyway.  I'm happy to undo that if it's not wanted.  There are separate functions for getting the timeout and sending chunked now.)\r\n\r\nAny feedback is welcome!  This is for https://github.com/requests/requests/issues/4322\r\n\r\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2017-11-28T08:30:51Z",
        "closed_at": "2017-11-29T21:18:55Z",
        "merged_at": null,
        "body": "I have trouble in uploading empty files  to AWS S3 using requests, the point is that AWS S3 doesn't support Transfer-Encoding: chunked to upload files.\r\n\r\nDealing with the file pointer(fp) which points to an empty file, requests  set it to Transfer-Encoding: chunked. In fact, the length of empty file can be calculated by the function super_len() without raising exception, the length is zero, but requests treats it same with None(caused by exceptions)!\r\n```python\r\ntry:\r\n    length = super_len(data)\r\nexcept (TypeError, AttributeError, UnsupportedOperation):\r\n    length = None\r\n```\r\nI touched an empty file named empty.txt, and the result is 'Transfer-Encoding': 'chunked' instead of 'Content-Length': '0'. In this situation, i think the result should be 'Content-Length': '0', since the length of the file can be calculated!\r\n```python\r\n>>> import requests\r\n>>> fp = open('empty.txt', 'rb')\r\n>>> r = requests.put('http://httpbin.org/put', data=fp)\r\n>>> r.request.headers\r\n{'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'User-Agent': 'python-requests/2.18.4'}\r\n>>> fp.close()\r\n'''\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 34,
        "deletions": 16,
        "changed_files": 2,
        "created_at": "2017-11-21T21:31:13Z",
        "closed_at": "2017-11-23T20:19:13Z",
        "merged_at": "2017-11-23T20:19:13Z",
        "body": "There was no way to determine what actual names were available outside\r\nof looking at the source code. They were not listed in the documentation\r\nor accessible through the interactive help.\r\n\r\nIn addition, doing `pydoc requests.status_codes` displayed some pretty\r\nunhelpful information - the utf-8 encoding string was included in the\r\nmodule name, there was no description, and internal variables used for\r\ninitialisation leaked into the module scope:\r\n\r\n    DATA\r\n        code = 511\r\n        codes = <lookup 'status_codes'>\r\n        title = 'network_authentication'\r\n        titles = ('network_authentication_required', 'network_auth', ...\r\n\r\nThis change prevents the internal variables from leaking, adds a\r\ndocstring (which has the side-effect of correcting the module name), and\r\nappends information on the allowed status code names to the docstring\r\nwhen the module is initialised.\r\n\r\nThe improved module documentation is then used in the API documentation\r\nto provide another easy reference to the complete list of status codes.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-11-20T09:19:38Z",
        "closed_at": "2017-11-20T13:18:01Z",
        "merged_at": "2017-11-20T13:18:01Z",
        "body": "This is a tiny documentation fix, just to be super-duper explicit about the return value of `response.ok`.\r\n\r\n(I wanted to check I could use its value in a function that\u2019s meant to return a boolean, but the docs weren\u2019t clear about what a non-Truthy return value would be.)",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-11-17T21:38:49Z",
        "closed_at": "2017-11-18T09:44:29Z",
        "merged_at": "2017-11-18T09:44:29Z",
        "body": "It's a small change but this would have saved me a bit of time today.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-11-16T08:00:32Z",
        "closed_at": "2017-11-16T16:01:45Z",
        "merged_at": "2017-11-16T16:01:45Z",
        "body": "The quickstart doc apparently wanted to mention that \"HTML and XML have ways of specifying their encoding in their body\".",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2017-11-10T07:35:33Z",
        "closed_at": "2017-11-27T20:39:16Z",
        "merged_at": "2017-11-27T20:39:16Z",
        "body": "UWP has no API to get access to windows registry, so python has no winreg module on UWP.\r\nThis fixes unexpected error on UWP.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 12,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-11-09T01:38:02Z",
        "closed_at": "2017-11-29T14:08:31Z",
        "merged_at": null,
        "body": "While working with some FIPS libraries that disabled MD5, we ran into a problem with our Requests based tools not being able to talk to our server. \r\n\r\n<img width=\"1440\" alt=\"screen shot 2017-11-08 at 4 19 47 pm\" src=\"https://user-images.githubusercontent.com/438131/32584052-c4a29c36-c4b3-11e7-8ca1-7601c60c60f2.png\">\r\n\r\nI haven't fully read the RFC-7616 SHA-256 and SHA-512 standards but this patch works.\r\n\r\nThanks for Requests!\r\n",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2017-11-07T14:25:49Z",
        "closed_at": "2017-11-20T20:01:05Z",
        "merged_at": "2017-11-20T20:01:05Z",
        "body": "",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 71,
        "deletions": 5,
        "changed_files": 5,
        "created_at": "2017-11-04T00:27:37Z",
        "closed_at": "2017-11-06T21:08:46Z",
        "merged_at": "2017-11-06T21:08:45Z",
        "body": "Resolves #4369 by checking whether the default CA certificate bundle is being imported from a zip archive. If it is, extract the certificate bundle to a temp folder so it can be handled by the standard OpenSSL libraries.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-11-03T23:56:54Z",
        "closed_at": "2017-11-04T08:44:34Z",
        "merged_at": null,
        "body": "Not serious. Not cool.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-11-03T13:53:31Z",
        "closed_at": "2017-11-22T15:56:10Z",
        "merged_at": "2017-11-22T15:56:10Z",
        "body": "`json` is ignored if `data` is not empty.",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 29,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2017-10-30T09:23:22Z",
        "closed_at": "2017-11-27T13:16:12Z",
        "merged_at": null,
        "body": "PoolManager object was initialized once and assigned to self.poolmanager property of HTTPAdapter class. Thats why updating settings (for example - verify=False to verify=True) does not affect. I reinitialized PoolManager on every connection and problem solved.\r\n\r\nadapters.py:166\r\n```\r\ndef init_poolmanager(self ...):\r\n   ....\r\n   self.poolmanager = PoolManager(num_pools=connections, maxsize=maxsize,\r\n                                       block=block, strict=True, **pool_kwargs)\r\n   return self.poolmanager\r\n```\r\n\r\nadapters.py:320\r\n```\r\ndef get_connection(self...):\r\n   ...\r\n   conn = self.init_poolmanager(self._pool_connections, self._pool_maxsize, block=self._pool_block).connection_from_url(url)\r\n```",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 21,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2017-10-30T09:09:14Z",
        "closed_at": "2017-10-31T04:34:33Z",
        "merged_at": null,
        "body": "- Added new function validate_url into the file utils.py at the line 858\r\n- Before to call prepend_scheme_if_needed function we are checking validity of proxy url in the file adapters.py at the line 307, if wrong then raising ProxyError exception with clear error message\r\n\r\nby Azerbaijan Python User Group",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 5,
        "changed_files": 3,
        "created_at": "2017-10-29T07:04:45Z",
        "closed_at": "2017-10-29T08:09:00Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-10-27T21:46:03Z",
        "closed_at": "2018-05-18T14:02:18Z",
        "merged_at": null,
        "body": "Hi!\r\nI found that it's impossible to read headers and response code when ChunkedEncodingError occured.\r\n\r\nHere is demonstration code.\r\nServer code:\r\n```\r\n#!/usr/bin/env python\r\n\r\nimport BaseHTTPServer\r\nimport SocketServer\r\n\r\nclass ChunkingHTTPServer(SocketServer.ThreadingMixIn,\r\n                        BaseHTTPServer.HTTPServer):\r\n    daemon_threads = True\r\n\r\nclass ChunkingRequestHandler(BaseHTTPServer.BaseHTTPRequestHandler):\r\n    ALWAYS_SEND_SOME = False\r\n    ALLOW_GZIP = False\r\n    protocol_version = 'HTTP/1.1'\r\n    def do_GET(self):\r\n        self.send_response(200)\r\n        self.send_header('Transfer-Encoding', 'chunked')\r\n        self.send_header('Content-type', 'text/plain')\r\n        raise Exception()\r\n\r\nif __name__ == '__main__':\r\n    server = ChunkingHTTPServer(\r\n        ('127.0.0.1', 8000), ChunkingRequestHandler)\r\n    print 'Starting server, use <Ctrl-C> to stop'\r\n    server.serve_forever()\r\n```\r\n\r\nClient code:\r\n```\r\n#!/usr/bin/env python\r\n\r\nimport requests\r\n\r\ntry:\r\n    requests.get('http://127.0.0.1:8000')\r\nexcept requests.exceptions.ChunkedEncodingError as e:\r\n    print(e.response)\r\n```\r\n\r\nBefore patch: None\r\nAfter patch: <Response [200]>\r\n\r\nI have problem with presenting this code for testing, just have no idea how to integrate it. Could someone help me with it, please.\r\n\r\nAlso I think that the same behavior is here:\r\n - https://github.com/requests/requests/blob/master/requests/models.py#L750\r\n - https://github.com/requests/requests/blob/master/requests/models.py#L752\r\nBut I don't know how to emulate these types of error\r\n\r\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 26,
        "deletions": 2,
        "changed_files": 5,
        "created_at": "2017-10-26T14:41:40Z",
        "closed_at": "2017-11-15T22:16:34Z",
        "merged_at": "2017-11-15T22:16:34Z",
        "body": "According to RFC3986, the authority section can be empty for a given URL,\r\nhowever, for a proxy URL, it shouldn't be. This patch adds a check to verify\r\nthat the parsed URL will have a valid host before creating the proxy manager.\r\n\r\nFixes #4353",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 26,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-10-23T07:31:21Z",
        "closed_at": "2017-10-24T18:50:03Z",
        "merged_at": "2017-10-24T18:50:03Z",
        "body": "I had to work this out by reading the source code for `Session` \u2013 better to put it front-and-centre in the docs.",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 39,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2017-10-18T17:35:37Z",
        "closed_at": "2017-10-21T13:26:32Z",
        "merged_at": "2017-10-21T13:26:32Z",
        "body": "While trying to get the adapter for an url, the url is lowered before comparing with the prefix, but the prefix is not, so if it contains non-lowercase characters (eg. `https://example.com/sOmE_WeiRD_pReFIX/`), it won't return the correct adapter.\r\n\r\nThe other solution is to lower the prefix while adding the adapter. I have opted for the first solution to isolate in one place the case-insensitivity feature.\r\n\r\nEdit:\r\nAnother alternative could be to document that the prefix should be passed lowered to Session.mount() (this is what I am doing for now to work-around the issue).",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-10-16T02:48:47Z",
        "closed_at": "2017-10-16T08:21:20Z",
        "merged_at": "2017-10-16T08:21:20Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-10-16T02:45:47Z",
        "closed_at": "2017-10-21T23:53:02Z",
        "merged_at": "2017-10-21T23:53:02Z",
        "body": "The wheel package format supports including the license file. This is done using the `[metadata]` section in the `setup.cfg` file. For additional information on this feature, see:\r\n\r\nhttps://wheel.readthedocs.io/en/stable/index.html#including-the-license-in-the-generated-wheel-file",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2017-10-15T16:56:46Z",
        "closed_at": "2017-10-15T20:35:53Z",
        "merged_at": "2017-10-15T20:35:53Z",
        "body": "We don't actually test on 3.7 and 3.7 isn't released for another eight months, so don't yet claim support.\r\n\r\nRe: https://github.com/requests/requests/pull/4329#pullrequestreview-69421398 and closes https://github.com/requests/requests/pull/4329.\r\n\r\nAlso, Python 3.3 was also dropped in https://github.com/requests/requests/pull/4231 so remove mention of those.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2017-10-13T18:11:03Z",
        "closed_at": "2018-03-08T18:02:46Z",
        "merged_at": null,
        "body": "If the NETRC environment variable is set, use it to\r\nload the user's netrc file. If not set, default to\r\nsearching the user's home directory for  a `.netrc`\r\nor `_netrc` file.\r\n\r\nIssue #4318",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 18,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2017-10-10T17:24:31Z",
        "closed_at": "2017-10-14T15:41:03Z",
        "merged_at": "2017-10-14T15:41:03Z",
        "body": "Give a warning when `cryptography < 1.3.4` and `pyOpenSSL < 16.0.0` as discussed in #4309 ",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-10-10T08:15:49Z",
        "closed_at": "2018-03-08T18:01:55Z",
        "merged_at": null,
        "body": "The data param also accepts a list of tuples. It says so in the docs for request() but not for post(), put() and patch()",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2017-10-06T06:18:21Z",
        "closed_at": "2017-10-15T20:35:53Z",
        "merged_at": null,
        "body": "The README says \"Requests officially supports Python 2.6\u20132.7 & 3.3\u20133.7, and runs great on PyPy.\" so update the version in some other places too.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 15,
        "changed_files": 7,
        "created_at": "2017-10-06T06:09:11Z",
        "closed_at": "2017-10-19T16:58:54Z",
        "merged_at": "2017-10-19T16:58:54Z",
        "body": "Same as https://github.com/requests/requests/pull/4326 but for the proposed/3.0.0 branch.\r\n\r\nThe good news is nearly everything was already in this branch from https://github.com/requests/requests/pull/4118, except for tidying up some OrderedDict compat stuff.\r\n\r\nAlso, pytest>=3.0.0 is required for the Python 3.3 build, otherwise:\r\n```\r\npy.test -n 8 --boxed --junitxml=report.xml\r\nTraceback (most recent call last):\r\n  File \"/home/travis/virtualenv/python3.3.6/bin/py.test\", line 11, in <module>\r\n    sys.exit(main())\r\n  File \"/home/travis/virtualenv/python3.3.6/lib/python3.3/site-packages/_pytest/config.py\", line 39, in main\r\n    config = _prepareconfig(args, plugins)\r\n  File \"/home/travis/virtualenv/python3.3.6/lib/python3.3/site-packages/_pytest/config.py\", line 118, in _prepareconfig\r\n    pluginmanager=pluginmanager, args=args)\r\n  File \"/home/travis/virtualenv/python3.3.6/lib/python3.3/site-packages/_pytest/vendored_packages/pluggy.py\", line 724, in __call__\r\n    return self._hookexec(self, self._nonwrappers + self._wrappers, kwargs)\r\n  File \"/home/travis/virtualenv/python3.3.6/lib/python3.3/site-packages/_pytest/vendored_packages/pluggy.py\", line 338, in _hookexec\r\n    return self._inner_hookexec(hook, methods, kwargs)\r\n  File \"/home/travis/virtualenv/python3.3.6/lib/python3.3/site-packages/_pytest/vendored_packages/pluggy.py\", line 333, in <lambda>\r\n    _MultiCall(methods, kwargs, hook.spec_opts).execute()\r\n  File \"/home/travis/virtualenv/python3.3.6/lib/python3.3/site-packages/_pytest/vendored_packages/pluggy.py\", line 595, in execute\r\n    return _wrapped_call(hook_impl.function(*args), self.execute)\r\n  File \"/home/travis/virtualenv/python3.3.6/lib/python3.3/site-packages/_pytest/vendored_packages/pluggy.py\", line 249, in _wrapped_call\r\n    wrap_controller.send(call_outcome)\r\n  File \"/home/travis/virtualenv/python3.3.6/lib/python3.3/site-packages/_pytest/helpconfig.py\", line 28, in pytest_cmdline_parse\r\n    config = outcome.get_result()\r\n  File \"/home/travis/virtualenv/python3.3.6/lib/python3.3/site-packages/_pytest/vendored_packages/pluggy.py\", line 278, in get_result\r\n    raise ex[1].with_traceback(ex[2])\r\n  File \"/home/travis/virtualenv/python3.3.6/lib/python3.3/site-packages/_pytest/vendored_packages/pluggy.py\", line 264, in __init__\r\n    self.result = func()\r\n  File \"/home/travis/virtualenv/python3.3.6/lib/python3.3/site-packages/_pytest/vendored_packages/pluggy.py\", line 596, in execute\r\n    res = hook_impl.function(*args)\r\n  File \"/home/travis/virtualenv/python3.3.6/lib/python3.3/site-packages/_pytest/config.py\", line 861, in pytest_cmdline_parse\r\n    self.parse(args)\r\n  File \"/home/travis/virtualenv/python3.3.6/lib/python3.3/site-packages/_pytest/config.py\", line 966, in parse\r\n    self._preparse(args, addopts=addopts)\r\n  File \"/home/travis/virtualenv/python3.3.6/lib/python3.3/site-packages/_pytest/config.py\", line 927, in _preparse\r\n    self.pluginmanager.load_setuptools_entrypoints(\"pytest11\")\r\n  File \"/home/travis/virtualenv/python3.3.6/lib/python3.3/site-packages/_pytest/vendored_packages/pluggy.py\", line 501, in load_setuptools_entrypoints\r\n    plugin = ep.load()\r\n  File \"/home/travis/virtualenv/python3.3.6/lib/python3.3/site-packages/pkg_resources/__init__.py\", line 2404, in load\r\n    self.require(*args, **kwargs)\r\n  File \"/home/travis/virtualenv/python3.3.6/lib/python3.3/site-packages/pkg_resources/__init__.py\", line 2427, in require\r\n    items = working_set.resolve(reqs, env, installer, extras=self.extras)\r\n  File \"/home/travis/virtualenv/python3.3.6/lib/python3.3/site-packages/pkg_resources/__init__.py\", line 872, in resolve\r\n    raise VersionConflict(dist, req).with_context(dependent_req)\r\npkg_resources.VersionConflict: (pytest 2.9.2 (/home/travis/virtualenv/python3.3.6/lib/python3.3/site-packages), Requirement.parse('pytest>=3.0.0'))\r\n```\r\nhttps://travis-ci.org/hugovk/requests/jobs/284048190\r\n\r\nThe other CI failures are related to cookies and also occur in latest master and fresh builds of proposed/3.0.0.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 15,
        "deletions": 15,
        "changed_files": 3,
        "created_at": "2017-10-05T17:16:00Z",
        "closed_at": "2017-10-15T15:44:36Z",
        "merged_at": null,
        "body": "The documentation has a bunch of examples showing unicode literals in Python 2's `u'foo'` syntax, including one in the front page right below the note encouraging users to switch to Python 3.",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 26,
        "deletions": 62,
        "changed_files": 16,
        "created_at": "2017-10-05T13:07:16Z",
        "closed_at": "2017-10-05T15:32:19Z",
        "merged_at": null,
        "body": "Python 2.6 support was dropped in https://github.com/requests/requests/pull/4118.\r\n\r\nThis removes some other redundant 2.6 code. \r\n\r\nAlso mention Python 3.7 as officially supported, to reflect the README.\r\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2017-09-30T16:09:53Z",
        "closed_at": "2017-10-20T00:47:40Z",
        "merged_at": "2017-10-20T00:47:40Z",
        "body": "platform module is relatively large: it takes about 5ms to import.",
        "comments": 8
    },
    {
        "merged": false,
        "additions": 15,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-09-25T21:54:03Z",
        "closed_at": "2017-09-26T14:04:19Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 73,
        "deletions": 8,
        "changed_files": 2,
        "created_at": "2017-09-22T17:56:57Z",
        "closed_at": "2018-04-29T19:10:43Z",
        "merged_at": null,
        "body": "\r\nAlso updated tests to include user@ and user@password: scenarios\r\n\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 356,
        "deletions": 5,
        "changed_files": 7,
        "created_at": "2017-09-12T22:37:31Z",
        "closed_at": "2018-03-15T13:18:13Z",
        "merged_at": null,
        "body": "Same changes as my other pull request #4282, but this against the proposed/3.0.0 branch.",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 356,
        "deletions": 6,
        "changed_files": 6,
        "created_at": "2017-09-10T15:36:22Z",
        "closed_at": "2017-09-12T22:41:31Z",
        "merged_at": null,
        "body": "I personally wanted something like this while writing [my own Requests-related library](https://github.com/the-allanc/pyriform), but I can see other people also have wanted something like this - #3957 and #4214 both mention it in terms of handling `Set-Cookie` headers.\r\n\r\nI've written an subclass implementation of `CaseInsensitiveDict` which is compatible with all the current usage (according to the tests), but adds new methods for clients that want to deal directly with unjoined headers. I've also added quite a number of tests and made slight changes to the documentation in relation to it.",
        "comments": 17
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2017-09-05T19:16:55Z",
        "closed_at": "2018-03-08T18:05:14Z",
        "merged_at": null,
        "body": "",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-09-02T20:15:39Z",
        "closed_at": "2017-10-19T12:45:47Z",
        "merged_at": null,
        "body": "Basically, a lot of people are installing pipenv in envs which also have `requests[security]` installed, which slows down the CLI tool quite a bit (at import time). \r\n\r\nThis patch would allow pipenv to disable the upgrade within itself, speeding up the experience for those users. \r\n\r\n/cc @Lukasa @alex ",
        "comments": 25
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-08-27T19:16:18Z",
        "closed_at": "2018-03-08T18:01:26Z",
        "merged_at": null,
        "body": "The upstream bug has been fixed \r\n\r\nSee also: \r\n* requests/requests#4261\r\n* requests/requests#4258\r\n* requests/requests#4259",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-08-27T07:55:16Z",
        "closed_at": "2017-08-27T13:00:38Z",
        "merged_at": "2017-08-27T13:00:38Z",
        "body": "The release of httpbin 0.6.0 seems to have broken pytest-httpbin in a surprising way. We want to pin that version out, and probably also alert @kevin1024 about the problem.\r\n\r\nResolves #4259.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 11,
        "deletions": 6,
        "changed_files": 4,
        "created_at": "2017-08-26T21:20:51Z",
        "closed_at": "2017-08-27T07:53:04Z",
        "merged_at": null,
        "body": "",
        "comments": 11
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 1,
        "changed_files": 3,
        "created_at": "2017-08-17T02:14:02Z",
        "closed_at": "2017-08-17T19:34:07Z",
        "merged_at": "2017-08-17T19:34:07Z",
        "body": "When receiving an empty `Link:` header, one bogus entry was returned anyway. This breaks some applications.\r\n\r\nI agree that web servers shouldn't be sending those but they do so here we are. Also fixes docstring with proper return type.\r\n\r\nFixes https://github.com/halcy/Mastodon.py/issues/74",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 20,
        "changed_files": 3,
        "created_at": "2017-08-11T20:06:33Z",
        "closed_at": "2018-02-24T14:53:50Z",
        "merged_at": null,
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 5,
        "changed_files": 3,
        "created_at": "2017-08-11T19:49:57Z",
        "closed_at": "2017-08-12T14:41:28Z",
        "merged_at": "2017-08-12T14:41:27Z",
        "body": "Adds the name of the header to the invalid header exception raised on TypeError.\r\n\r\nFixes #4239 ",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-08-10T09:46:28Z",
        "closed_at": "2017-08-10T15:11:11Z",
        "merged_at": null,
        "body": "#4233 \r\n\r\nPotential implementation of my feature suggestion",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 10,
        "changed_files": 6,
        "created_at": "2017-08-09T18:02:49Z",
        "closed_at": "2017-08-10T18:03:37Z",
        "merged_at": "2017-08-10T18:03:37Z",
        "body": "At this point, urllib3 is dropping 3.3 support. I think we should do so as well: 3.3 is long past support and never had the usage that 2.6 did, so we should probably abandon it. As a bonus reason, our CI is breaking on 3.3, so we should probably take the easy route out of that problem.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-08-09T12:42:35Z",
        "closed_at": "2017-08-09T17:56:40Z",
        "merged_at": "2017-08-09T17:56:40Z",
        "body": "Update the docs for issue #3863 .",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-08-08T23:17:03Z",
        "closed_at": "2017-08-09T17:57:03Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2017-08-08T12:33:55Z",
        "closed_at": "2017-08-08T14:42:55Z",
        "merged_at": "2017-08-08T14:42:55Z",
        "body": "Resolves #4222.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-07-27T00:24:53Z",
        "closed_at": "2017-07-27T04:40:04Z",
        "merged_at": "2017-07-27T04:40:04Z",
        "body": "This does not seem to be necessary anymore since there is no longer a `BaseResponse` object from which `Response` inherits.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-07-21T03:49:32Z",
        "closed_at": "2017-07-21T06:05:11Z",
        "merged_at": "2017-07-21T06:05:11Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-07-20T09:09:54Z",
        "closed_at": "2017-07-20T11:52:12Z",
        "merged_at": "2017-07-20T11:52:12Z",
        "body": "Based on the changelog this should be safe for us to use.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-07-15T04:45:56Z",
        "closed_at": "2017-07-15T06:39:02Z",
        "merged_at": "2017-07-15T06:39:02Z",
        "body": "Three tests [1] rely on `requirements.txt` being available. If the file is not present, the following error is observed in those tests:\r\n\r\n```\r\n  >       with open('requirements.txt') as f:\r\n  E       IOError: [Errno 2] No such file or directory: 'requirements.txt'\r\n```\r\n\r\nThe latest (2.18.1) source distribution on PyPI does not include requirements.txt, which precludes successfully passing the tests.\r\n\r\nThis change adds the required file to the source distribution. An alternative is to use a different file already included in the sdist.\r\n\r\nAdditionally, skipping tests if a required resource (library, file, etc) is not available would be a user experience improvement.\r\n\r\n[1] test_POSTBIN_GET_POST_FILES, test_POSTBIN_GET_POST_FILES_WITH_DATA, test_conflicting_post_params,\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2017-07-08T18:46:33Z",
        "closed_at": "2018-04-29T19:08:16Z",
        "merged_at": null,
        "body": "Fixes issue #4158.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 28,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2017-07-03T23:47:34Z",
        "closed_at": "2017-07-04T08:16:03Z",
        "merged_at": "2017-07-04T08:16:03Z",
        "body": "This will resolve the test failures discovered in #4182. We were retrieving the `OPENSSL_VERSION_NUMBER` from the system `ssl` module in all cases before now. This attribute doesn't exist in Python 2.6 causing new tests for the `info()` method to fail. This patch will return an empty value for Python 2.6 since we don't seem to have a way to reliably check the openssl version.\r\n\r\n@Lukasa @sigmavirus24, I've pushed this branch up to the requests repo directly, so feel free to chop this up or do anything you feel is necessary to get #4182 moving. I don't know that the provided test is especially useful, but it does show that the fix here works.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 26,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2017-07-03T22:32:02Z",
        "closed_at": "2017-07-27T20:54:10Z",
        "merged_at": "2017-07-27T20:54:10Z",
        "body": "Resolves #4180.",
        "comments": 11
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-06-27T15:27:33Z",
        "closed_at": "2020-01-10T22:57:13Z",
        "merged_at": null,
        "body": "This is a patch applying @bpitman's proposed fix for #3844.\r\n\r\nAssuming a proxy is running on port 8875 (`docker run --rm --name='tinyproxy' -p 8875:8888 dannydirect/tinyproxy:latest ANY` works for me), the issue can be reproduced with\r\n\r\n```\r\nrequests.put('https://www.google.com', data=iter('Hello World'), proxies={'https': 'http://localhost:8875'})\r\n```",
        "comments": 14
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-06-25T16:51:24Z",
        "closed_at": "2017-07-27T15:51:34Z",
        "merged_at": "2017-07-27T15:51:33Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 270,
        "deletions": 79,
        "changed_files": 2,
        "created_at": "2017-06-24T23:12:46Z",
        "closed_at": "2017-06-27T13:54:40Z",
        "merged_at": "2017-06-27T13:54:40Z",
        "body": "This addresses an issue where making HTTPS through proxies used the\r\ndefault urllib3 connection pool settings.\r\n\r\nfixes #3633",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 1,
        "changed_files": 4,
        "created_at": "2017-06-10T23:47:57Z",
        "closed_at": "2017-06-11T09:26:52Z",
        "merged_at": "2017-06-11T09:26:52Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 22,
        "deletions": 35,
        "changed_files": 2,
        "created_at": "2017-06-09T16:55:15Z",
        "closed_at": "2018-02-27T17:11:36Z",
        "merged_at": null,
        "body": "Reverts requests/requests#4144",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 35,
        "deletions": 22,
        "changed_files": 2,
        "created_at": "2017-06-08T21:07:53Z",
        "closed_at": "2017-06-09T01:40:08Z",
        "merged_at": "2017-06-09T01:40:08Z",
        "body": "This patch will convert the dependency exceptions into warnings, preventing the forced halt while importing Requests. I condensed the message into a single response, but we can expand that out if needed. It just seemed like another place for updates to be forgotten.\r\n\r\nI'd also like to test this function, but due to the requirements changing with each release, it's hard to write something that won't need to be updated in parallel. We could look at parsing the requirements out of `requires` but that seems less than ideal. If I'm being honest, I'm not crazy about expanding the code around this any more than we absolutely have to.",
        "comments": 12
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-06-07T12:50:46Z",
        "closed_at": "2017-06-09T17:30:57Z",
        "merged_at": "2017-06-09T17:30:57Z",
        "body": "Resolves #4138.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 6,
        "changed_files": 5,
        "created_at": "2017-06-06T22:27:04Z",
        "closed_at": "2017-06-07T07:51:42Z",
        "merged_at": "2017-06-07T07:51:42Z",
        "body": "This saves having to wrap the call to requests with `contextlib.closing()`, allowing it to be used directly in a `with` statement, like so:\r\n\r\n```python\r\nwith requests.get('http://httpbin.org/get', stream=True) as r:\r\n    # Do things with the response here.\r\n```\r\n\r\nFixes #4136.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 37,
        "deletions": 10,
        "changed_files": 4,
        "created_at": "2017-06-06T21:30:12Z",
        "closed_at": "2017-06-09T18:34:57Z",
        "merged_at": "2017-06-09T18:34:56Z",
        "body": "fixes #4127",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-06-06T20:49:25Z",
        "closed_at": "2017-06-07T15:07:01Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 57,
        "deletions": 7,
        "changed_files": 5,
        "created_at": "2017-06-03T12:15:30Z",
        "closed_at": "2017-06-03T21:11:20Z",
        "merged_at": null,
        "body": null,
        "comments": 4
    },
    {
        "merged": true,
        "additions": 626,
        "deletions": 32595,
        "changed_files": 136,
        "created_at": "2017-05-31T09:30:42Z",
        "closed_at": "2017-06-10T06:57:24Z",
        "merged_at": "2017-06-10T06:57:24Z",
        "body": "This was a gnarly merge, and the odds of it going right first time are pretty low, so let's have the CI prove or disprove the success of it for me.",
        "comments": 15
    },
    {
        "merged": true,
        "additions": 41,
        "deletions": 65,
        "changed_files": 18,
        "created_at": "2017-05-30T22:33:15Z",
        "closed_at": "2017-07-26T19:59:40Z",
        "merged_at": "2017-07-26T19:59:40Z",
        "body": "Drop support for python2.6. Fixes #3928\r\n\r\nNote that this targets the 3.0.0 branch, not master.",
        "comments": 16
    },
    {
        "merged": false,
        "additions": 49,
        "deletions": 21,
        "changed_files": 4,
        "created_at": "2017-05-30T14:21:56Z",
        "closed_at": "2017-05-30T19:45:53Z",
        "merged_at": null,
        "body": "I created this pull-request for #4112 ",
        "comments": 14
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2017-05-30T10:03:05Z",
        "closed_at": "2017-05-30T12:54:32Z",
        "merged_at": "2017-05-30T12:54:32Z",
        "body": "resolves #4113 ",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 14,
        "deletions": 13,
        "changed_files": 1,
        "created_at": "2017-05-30T04:56:03Z",
        "closed_at": "2017-05-30T06:52:35Z",
        "merged_at": null,
        "body": "A user complained about this this weekend. Open to review / comments. ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 52,
        "deletions": 52,
        "changed_files": 17,
        "created_at": "2017-05-29T16:12:09Z",
        "closed_at": "2017-05-29T17:15:21Z",
        "merged_at": "2017-05-29T17:15:21Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 29,
        "deletions": 15,
        "changed_files": 2,
        "created_at": "2017-05-29T10:33:18Z",
        "closed_at": "2017-05-29T17:24:48Z",
        "merged_at": null,
        "body": "This avoids runtime warnings when using the `requests` module for the first time when it is no longer in `sys.modules`. \r\n\r\n```\r\n[...]\\Lib\\site-packages\\requests\\utils.py:164: RuntimeWarning: Parent module 'requests' not found while handling absolute import\r\n  from netrc import netrc, NetrcParseError\r\n[...]\\Lib\\site-packages\\requests\\utils.py:49: RuntimeWarning: Parent module 'requests' not found while handling absolute import\r\n  import _winreg as winreg\r\n```\r\n\r\nSeeing this warning is very common for me, since I develop Python plugins for an application that embeds Python. To ensure that no dependencies between plugins are conflicting, every plugin develiers its own dependencies and makes sure they leave no trace in `sys.modules` and `sys.path`.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-05-29T06:01:26Z",
        "closed_at": "2017-05-29T15:40:06Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-05-29T03:36:35Z",
        "closed_at": "2017-05-29T05:01:35Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 7,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2017-05-29T01:29:45Z",
        "closed_at": "2017-05-29T03:36:01Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 56,
        "deletions": 159,
        "changed_files": 13,
        "created_at": "2017-05-29T00:18:28Z",
        "closed_at": "2017-05-29T01:51:22Z",
        "merged_at": null,
        "body": "",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 13,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2017-05-28T16:54:31Z",
        "closed_at": "2017-05-28T18:38:52Z",
        "merged_at": "2017-05-28T18:38:52Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-05-27T23:05:01Z",
        "closed_at": "2017-05-28T02:05:42Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 29,
        "deletions": 21,
        "changed_files": 3,
        "created_at": "2017-05-25T15:32:14Z",
        "closed_at": "2017-05-25T16:39:44Z",
        "merged_at": "2017-05-25T16:39:44Z",
        "body": "",
        "comments": 14
    },
    {
        "merged": false,
        "additions": 28,
        "deletions": 18,
        "changed_files": 3,
        "created_at": "2017-05-25T00:47:56Z",
        "closed_at": "2017-05-25T15:48:11Z",
        "merged_at": null,
        "body": "Move all of our metadata into `requests/__about__.py` while keeping a\r\nbackwards compatible aliasing of metadata attributes. Also use this to\r\nspecify metadata in our setup.py\r\n\r\nCloses #4057 \r\n\r\n---\r\n\r\nFor what it's worth, I based this off of [pypa/packaging](https://github.com/pypa/packaging/blob/master/setup.py)",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-05-24T05:51:20Z",
        "closed_at": "2017-05-27T01:34:30Z",
        "merged_at": "2017-05-27T01:34:30Z",
        "body": "\u2026bdcf76cc0e\r\n\r\n  - The added optional parameter changes API and should default to None\r\n\r\n    This utility call is used by for example requestbuilder package directly\r\n    which breaks because it passes only one argument to the function as it\r\n    used to be.",
        "comments": 17
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 1,
        "changed_files": 4,
        "created_at": "2017-05-23T17:50:04Z",
        "closed_at": "2018-05-17T20:56:18Z",
        "merged_at": "2018-05-17T20:56:18Z",
        "body": "The library raises NoneType error when file-pointer (fp) resolves to None.\r\n\r\n```\r\n>>> from requests import post\r\n>>> r = post(\"https://example.com\", files={\"file-name\": None})\r\nAttributeError: 'NoneType' object has no attribute 'read'\r\n```\r\n\r\nHowever, when a param value or json field is None they are not included in the request body.\r\n\r\n```\r\n>>> from requests import get\r\n>>> r = get(\"https://example.com\", params={\"file-name\": None})\r\n>>> r.request.url\r\n```\r\n\r\nThis commit makes the beahviour consistent for files.",
        "comments": 12
    },
    {
        "merged": false,
        "additions": 59,
        "deletions": 4,
        "changed_files": 4,
        "created_at": "2017-05-23T08:35:52Z",
        "closed_at": "2017-05-24T04:12:30Z",
        "merged_at": null,
        "body": "When using dict_from_cookiejar, I can only get name and value from cookie object, otherwise other cookie attributes are lost. So I want to make an enhancement about two methods dict_from_cookiejar and cookiejar_from_dict, which can be more flexible and safe to do cookie transformation and persistence like the following code.\r\n\r\n```\r\nimport requests\r\nfrom requests.utils import dict_from_cookiejar\r\n\r\nres = requests.get('https://github.com/justdoit0823/notes')\r\n\r\ndict_from_cookiejar(res.cookies)\r\n\r\ndict_from_cookiejar(res.cookies, with_cookie_attr=True)\r\n```\r\n\r\nAnd the output:\r\n\r\n```\r\n#  with_cookie_attr is False\r\n{'_gh_sess': 'somevalue', 'logged_in': 'no'}\r\n\r\n#  with_cookie_attr is True\r\n{'_gh_sess': {'discard': True,\r\n  'domain': 'github.com',\r\n  'name': '_gh_sess',\r\n  'path': '/',\r\n  'rest': {'HttpOnly': None},\r\n  'rfc2109': False,\r\n  'secure': True,\r\n  'value': 'somevalue',\r\n  'version': 0},\r\n 'logged_in': {'discard': False,\r\n  'domain': '.github.com',\r\n  'expires': 2126671044,\r\n  'name': 'logged_in',\r\n  'path': '/',\r\n  'rest': {'HttpOnly': None},\r\n  'rfc2109': False,\r\n  'secure': True,\r\n  'value': 'no',\r\n  'version': 0}}\r\n```",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 16,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2017-05-22T21:17:24Z",
        "closed_at": "2017-05-24T17:57:58Z",
        "merged_at": null,
        "body": "So I tried to add more verbose exception handling without breaking current functionality (this feels really hacky).  It seems to me that it may be pertinent to break these out and not raise a connection error for each request (as denoted in : https://github.com/kennethreitz/requests/issues/2876)\r\n\r\nIn the current implementation, a ConnectionError is raised for each call, as well as a max retries message.  It seems like the max retries message error should either be removed or made as more of a general string response statement.  This general string response is here:\r\nhttps://github.com/kennethreitz/requests/blob/master/requests/adapters.py#L503\r\n\r\nDoing so would require removing that line and adding explicit responses within that max retry block, but this might break current functionality if people are depending on the response from requests to make other decisions.\r\n\r\nLooking forward to a discussion on this topic.\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 17,
        "deletions": 9,
        "changed_files": 1,
        "created_at": "2017-05-21T15:39:06Z",
        "closed_at": "2017-05-30T17:12:52Z",
        "merged_at": null,
        "body": "When using requests on GAE, the urllib3 response containing cookies\r\nis a little bit different, therefore we have to extract the cookies\r\nfrom the returned headers directly from the response object.\r\n\r\nFix issue #4039",
        "comments": 18
    },
    {
        "merged": true,
        "additions": 34,
        "deletions": 4,
        "changed_files": 3,
        "created_at": "2017-05-21T00:06:13Z",
        "closed_at": "2017-05-23T14:39:37Z",
        "merged_at": "2017-05-23T14:39:37Z",
        "body": "This is a followup for #3463, but refactored without the persistence flag which makes this a breaking change. Currently, Requests silently throws away any cookie policies set on a CookieJar as noted in #3416. This patch will preserve the CookiePolicy set on a session-level CookieJar for both redirected and subsequent requests.\r\n\r\nThe only caveat here is this won't work for a non-RequestsCookieJar since the policy isn't exposed publicly. We may want to add some documentation about this caveat but given the rarity of this case, the information in the issue tracker may be sufficient.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 2,
        "changed_files": 4,
        "created_at": "2017-05-17T17:47:58Z",
        "closed_at": "2017-05-18T01:41:01Z",
        "merged_at": "2017-05-18T01:41:01Z",
        "body": "Resolves #4030.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 84,
        "deletions": 117,
        "changed_files": 5,
        "created_at": "2017-05-17T14:32:46Z",
        "closed_at": "2017-05-18T16:05:41Z",
        "merged_at": null,
        "body": "Fixes #4025 by basically not doing anything when HTTP is used",
        "comments": 10
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-05-16T23:24:10Z",
        "closed_at": "2017-05-18T15:24:27Z",
        "merged_at": null,
        "body": "Fixes: https://github.com/kennethreitz/requests/issues/4024",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-05-16T23:02:02Z",
        "closed_at": "2017-05-18T14:50:40Z",
        "merged_at": "2017-05-18T14:50:40Z",
        "body": "Fixes: https://github.com/kennethreitz/requests/issues/4024",
        "comments": 10
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-05-10T16:06:54Z",
        "closed_at": "2017-05-10T19:04:04Z",
        "merged_at": "2017-05-10T19:04:04Z",
        "body": "This is a trivial fix to address a warning pointed out in #4012.\r\n\r\n`test_requests.py` was moved from the top level directory into the `tests` directory in 2.10.0 but the MANIFEST.in wasn't updated afterwards. Installing from setup.py produces a warning (`no files found matching 'test_requests.py'`). This patch will remove the unneeded listing and keep the warning from cluttering stderr.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 5919,
        "deletions": 4861,
        "changed_files": 65,
        "created_at": "2017-05-09T08:38:51Z",
        "closed_at": "2017-05-09T15:42:02Z",
        "merged_at": "2017-05-09T15:42:02Z",
        "body": "Changelog updated, vendored libraries all updated. Let's see how this goes. Looks like it'll be a good release!",
        "comments": 11
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-05-07T01:26:09Z",
        "closed_at": "2017-05-07T04:07:02Z",
        "merged_at": "2017-05-07T04:07:02Z",
        "body": "Signed-off-by: Randy Barlow <randy@electronsweatshop.com>",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 63,
        "deletions": 11,
        "changed_files": 7,
        "created_at": "2017-05-04T23:00:12Z",
        "closed_at": "2018-04-29T18:58:10Z",
        "merged_at": null,
        "body": "We use requests for some service-to-service communication, neither side\r\nof which utilizes cookies.  When we profiled our services, we see ~13%\r\nof the time spend sending requests is either creating cookie jars or\r\nextracting cookies to jars.\r\n\r\nThis PR will enable us to disable cookies for a given `requests.Session`\r\nby setting `session.cookies = None`.  If `sessions.cookies` is None, we\r\nwon't create any cookies for the request nor will we parse them on the\r\nresponse.",
        "comments": 15
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 6,
        "changed_files": 4,
        "created_at": "2017-04-25T20:52:20Z",
        "closed_at": "2017-04-26T12:09:35Z",
        "merged_at": "2017-04-26T12:09:35Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 30,
        "deletions": 11,
        "changed_files": 6,
        "created_at": "2017-04-24T17:36:21Z",
        "closed_at": "2017-05-03T17:25:26Z",
        "merged_at": "2017-05-03T17:25:26Z",
        "body": "This PR will track work as I try to work out where the hell `make` is on appveyor.",
        "comments": 44
    },
    {
        "merged": true,
        "additions": 87,
        "deletions": 38,
        "changed_files": 2,
        "created_at": "2017-04-21T13:48:45Z",
        "closed_at": "2017-04-26T15:07:46Z",
        "merged_at": "2017-04-26T15:07:46Z",
        "body": "When a \"\\r\\n\" CRLF pair is splitted into two chunks accidentally, iter_lines() generates two line breaks instead of one. This patch fixes the incorrect behavior and closes issue #3980.",
        "comments": 12
    },
    {
        "merged": true,
        "additions": 290,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2017-04-21T11:09:03Z",
        "closed_at": "2017-04-24T16:49:26Z",
        "merged_at": "2017-04-24T16:49:25Z",
        "body": "In general it'd be good to have more testing, but it's also possible that via PR #3979 we'll get unexpected different behaviour on Windows than on other platforms. For this reason, we should start also testing on Windows.\r\n\r\nThis PR takes the configuration used for urllib3, updates it for Requests, and then provides it. We'll still need to actually enable Appveyor so that it'll try to build, which I cannot do as I don't have admin on the repo. @kennethreitz, mind giving that a try?",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 113,
        "deletions": 177,
        "changed_files": 6,
        "created_at": "2017-04-20T13:42:43Z",
        "closed_at": "2017-05-04T14:18:30Z",
        "merged_at": "2017-05-04T14:18:30Z",
        "body": "See #3976",
        "comments": 19
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 5,
        "changed_files": 3,
        "created_at": "2017-04-20T12:23:41Z",
        "closed_at": "2017-04-20T13:44:20Z",
        "merged_at": "2017-04-20T13:44:20Z",
        "body": null,
        "comments": 0
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 11,
        "changed_files": 2,
        "created_at": "2017-04-17T18:34:45Z",
        "closed_at": "2017-04-18T16:20:23Z",
        "merged_at": "2017-04-18T16:20:23Z",
        "body": "fix for #3888 ",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 40,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2017-04-12T16:49:28Z",
        "closed_at": "2017-04-14T20:13:50Z",
        "merged_at": "2017-04-14T20:13:50Z",
        "body": "as discussed on #3959 , fix the UnicodeDecodeError happening because implicit decoding of str string into unicode while using python2.\r\n\r\nThis issue happens when handling redirection without scheme  (i.e. Location: //URL) on python2 and only if the location is unicode.\r\n\r\nFirst time applying a PR on GitHub so let me know if there is something I can do to make it better :).\r\n\r\nThanks,\r\nShmulik",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 32,
        "deletions": 9,
        "changed_files": 2,
        "created_at": "2017-03-29T15:42:47Z",
        "closed_at": "2017-04-03T15:45:12Z",
        "merged_at": "2017-04-03T15:45:12Z",
        "body": "This PR allows to use urllib3 ``Timeout`` objects as ``timeout`` argument in ``HTTPAdapter.send()``.\r\n\r\nBesides it omits the ``timeout`` argument when calling ``conn.urlopen()`` if ``HTTPAdapter.send()`` is called without a timeout. This allows setting a default timeout at connection pool level:\r\n`adapter.poolmanager.connection_pool_kw['timeout'] = urllib3.Timeout(...)`",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 99,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-03-23T12:25:33Z",
        "closed_at": "2017-05-27T20:45:43Z",
        "merged_at": null,
        "body": "The suggested usage in a bug report would be\r\n\r\n    python -c 'from requests import _bug; _bug.print_information()'\r\n\r\nThis should generate most of the information we tend to ask for\r\nrepeatedly from bug reporters.\r\n\r\n----\r\n\r\n**Note** This is merely a POC and an idea I had this morning. I've done similar things in other projects with varying success. Most of the success will ride on us adding a `.github` folder with an issue template. This just makes the bug report process easier for users.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 40,
        "deletions": 8,
        "changed_files": 4,
        "created_at": "2017-03-17T22:03:26Z",
        "closed_at": "2017-03-22T20:41:08Z",
        "merged_at": "2017-03-22T20:41:08Z",
        "body": "Use IOError whenever invalid paths are used for ssl certificates (#3926)",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 107,
        "deletions": 8,
        "changed_files": 2,
        "created_at": "2017-03-14T18:41:10Z",
        "closed_at": "2017-03-16T09:53:04Z",
        "merged_at": "2017-03-16T09:53:04Z",
        "body": "2 years after the original #2431, and after #3745\r\nI encountered the strange behavior of `r.iter_lines()`, found this and tried to complete it.\r\nRebased once more and added more tests using the breakdown of @ianepperson https://github.com/kennethreitz/requests/pull/2431#issuecomment-72333964",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 19,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2017-03-08T03:07:14Z",
        "closed_at": "2017-03-08T08:29:14Z",
        "merged_at": null,
        "body": "Test the selector before making it the default selector. This is due to issue reported by myself at https://github.com/kennethreitz/requests/issues/3906",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 472,
        "deletions": 169,
        "changed_files": 13,
        "created_at": "2017-03-06T05:56:02Z",
        "closed_at": "2017-03-06T08:10:59Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 41,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2017-03-01T19:07:25Z",
        "closed_at": "2017-05-27T21:25:48Z",
        "merged_at": "2017-05-27T21:25:48Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2017-03-01T18:51:54Z",
        "closed_at": "2017-03-01T20:05:14Z",
        "merged_at": "2017-03-01T20:05:14Z",
        "body": "The logo as-is is too large, it won't even fit on my screen!\r\n\r\nI made a smaller version for use in the README.rst, because GitHub has neutered some useful features and doesn't care: https://github.com/github/markup/issues/295\r\n\r\nNOTE: the image path is to my fork. Once merged, the path should be changed to refer to the main repo.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2017-02-28T23:11:35Z",
        "closed_at": "2017-03-02T14:41:18Z",
        "merged_at": "2017-03-02T14:41:18Z",
        "body": "Looks like a duplicate copy of this exception was added at some point in a previous merge from master. Preferably hold off on merging this until #3897 is merged to avoid rebasing those commits again.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 96,
        "deletions": 23,
        "changed_files": 5,
        "created_at": "2017-02-28T21:59:09Z",
        "closed_at": "2017-03-02T14:40:58Z",
        "merged_at": "2017-03-02T14:40:58Z",
        "body": "This PR supersedes #3338 with the branch brought up to date, as well as a few minor changes, including logic tweaks based on updates to `super_len` since the original PR.\r\n\r\nThis will forcibly prevent the transmission of headers that include both Content-Length and Transfer-Encoding, as well as simplify redundant code we use for both `prepare_content_length` and `prepare_body`. All the credit here goes to @davidsoncasey, the original creator of this PR.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2017-02-26T18:36:43Z",
        "closed_at": "2017-02-27T16:25:10Z",
        "merged_at": "2017-02-27T16:25:10Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 15,
        "changed_files": 2,
        "created_at": "2017-02-22T18:37:11Z",
        "closed_at": "2017-02-25T15:05:40Z",
        "merged_at": "2017-02-25T15:05:40Z",
        "body": "This is a resubmit of #3871 against the 3.0.0 branch.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 175,
        "deletions": 3,
        "changed_files": 4,
        "created_at": "2017-02-22T04:21:30Z",
        "closed_at": "2017-02-27T08:56:44Z",
        "merged_at": "2017-02-27T08:56:44Z",
        "body": "Added simple cache over `urllib.proxy_bypass` to remedy #2988. Holds on to entries for a minute. Once it reaches its max size, will evict the first entry that is the oldest.\r\n\r\nAdded tests over the structure, did not add a test that `should_bypass_proxies` invokes the cache.\r\n\r\nThis is my first pull request; please let me know if I've overlooked something.\r\n\r\nAdditionally, when I check out master, run `make coverage` in pipenv, the test named 'TestRequests.test_proxy_error' fails. This is still the only failing test when I use my branch. The error is `ConnectionError: ('Connection aborted.', BadStatusLine(\"''\",))`. Is there some additional setup I need to do to run the test suite?",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 24,
        "deletions": 19,
        "changed_files": 6,
        "created_at": "2017-02-22T00:13:03Z",
        "closed_at": "2017-05-17T20:18:49Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2017-02-14T16:27:56Z",
        "closed_at": "2017-02-21T19:04:25Z",
        "merged_at": "2017-02-21T19:04:25Z",
        "body": "Just need to clean up a few variable names.",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 11,
        "changed_files": 2,
        "created_at": "2017-02-13T18:46:05Z",
        "closed_at": "2017-02-23T16:09:59Z",
        "merged_at": null,
        "body": "This is an idea for updating the `resolve_redirects` loop.  \r\n\r\nThe existing code was hard to untangle as variables get overwritten midway through the loop (`resp` switches between the previous and the next, which can be easy to miss).  It manages the `hist` by omitting the first request, appending the previous request, then shuffling some stuff around in a cleanup during the `send` method.\r\n\r\nIn this approach, populating the `hist` is moved down the loop so the current request is topmost on the stack.   The cleanup function is then simplified to just popping it off.\r\n\r\nThis passes all tests, but causes a slight undocumented API change -- the value of `request.history` changes, requiring a slightly different cleanup.  The only code that calls `resolve_redirects` is within `Session.send`, but I don't know if this would break any hooks.\r\n\r\nanyways, I think this makes the block more straightforward as the \"cleanup\" function in `send` is simplified and the context of `resp` when appending the history doesn't change as much.  another approach I thought of was using inline comments or variable name changes to clearly note which is the \"previous_request\" in that loop.",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 2,
        "changed_files": 4,
        "created_at": "2017-02-11T20:12:31Z",
        "closed_at": "2017-02-12T09:58:09Z",
        "merged_at": "2017-02-12T09:58:09Z",
        "body": "This allows for chaining method calls in cases where we want to raise for bad codes but use the response otherwise,\r\ne.g. `requests.get(URL).raise_for_status().json()['value']`",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 75,
        "deletions": 18,
        "changed_files": 4,
        "created_at": "2017-02-10T20:20:19Z",
        "closed_at": "2017-02-10T21:47:33Z",
        "merged_at": null,
        "body": "This is offered as an alternate/addition to my other PR, https://github.com/kennethreitz/requests/pull/3846\r\n\r\nSpecifically the code is in this commit: https://github.com/jvanasco/requests/commit/5e9371854176164db9ce5fee5ceb39b58f4035b2\r\n\r\nThis passes current tests, but it's a bit of a change so I'm offering it separately.\r\n\r\nThe existing redirect code was incredibly confusing, because objects were being overwritten mid-loop, select items had to be removed, and then everything needed to be switched back again.\r\n\r\nThis approach does a major reorganization of the logic, but I think for the better:\r\n\r\n# SessionRedirectMixin.resolve_redirects\r\n\r\nThe `hist` tracker makes more sense.\r\n\r\n* `hist` is started off with the original response. \r\n* after the redirect response is created, it is updated with the \"current\" history\r\n* `hist` is then updated with the new response\r\n\r\n# Session.send\r\n\r\nBecause the `Request.history` was carefully constructed within the loop context, the history had to then be shuffled around and response updated.  The above change makes that unnecessary, and instead `r ` is just popped off and used as-is.\r\n\r\nI think this makes the code easier to read and maintain, and it removes that weird shuffle at the end.  It's a bit of a change though, and might break the API in a way that is currently untested.\r\n\r\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 91,
        "deletions": 15,
        "changed_files": 3,
        "created_at": "2017-02-10T17:49:26Z",
        "closed_at": "2017-02-10T21:50:11Z",
        "merged_at": "2017-02-10T21:50:11Z",
        "body": "Add the ability to add 'no_proxy' and a value to the 'proxies'\r\ndictionary argument.\r\n\r\nhttps://github.com/kennethreitz/requests/issues/2817\r\n\r\nCloses gh-2817",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1168,
        "deletions": 429,
        "changed_files": 30,
        "created_at": "2017-02-10T17:23:04Z",
        "closed_at": "2018-11-13T12:55:45Z",
        "merged_at": null,
        "body": "# v3.0.0 of Requests\r\n\r\nThis is a long-polling pull request for the next breaking-change version of Requests \u2014\u00a0version 3.0.0.\r\n\r\nAny feature requests should be added as comments here \u2014\u00a0this is the time to get anything into Requests, if there's any time at at all. \r\n\r\n**Expected landing date**: *this year*. \r\n\r\n## Upcoming changes\r\n\r\n- Remove the HTTPProxyAuth class in favor of supporting proxy auth via the proxies parameter.\r\n- Relax how Requests strips bodies from redirects. 3.0.0 only supports body removal on 301/302 POST redirects and all 303 redirects.\r\n- Remove support for non-string/bytes parameters in _basic_auth_str.\r\n- Prevent Session.merge_environment from erroneously setting the verify parameter to None instead of True.\r\n- Streaming responses with Response.iter_lines or Response.iter_content now requires an encoding to be set if one isn't provided by the server.\r\n- Raise exception if multiple locations are returned during a redirect.\r\n- Update ConnectionPool connections when TLS/SSL settings change.\r\n- Remove simplejson import and only use standard json module.\r\n- Strip surrounding whitespace from urls.\r\n- MissingSchema and InvalidSchema renamed to MissingScheme and InvalidScheme respectively.\r\n- Change merge order for environment settings to avoid excluding Session-level settings.\r\n- Encode redirect URIs as latin-1 before performing redirects in Python 3 to avoid mangling during the requoting process.\r\n- Remove the __bool__ and __nonzero__ methods from a Response object.\r\n- This has been a planned feature for over a year. The behaviour is surprising to most people and breaks most of the assumptions that people have about Response objects. This resolves issue #2002\r\n- Skip over empty chunks in iterators. Empty chunks could prematurely signal the end of a request body's transmission, skipping them allows all of the data through. See #2631 for more details.\r\n- Remove the req argument from Session.resolve_redirects method.\r\n- Rename the resp argument from Session.resolve_redirects to response.\r\n- New PreparedRequest.send method. Now, you can Request().prepare().send().\r\n- All porcelain API functions (e.g. requests.get, etc) now accept an optional session parameter. If provided, the session given will be used for the request, in place of one being created for you.\r\n- URLs are now automatically stripped of leading/trailing whitespace.\r\n\r\n## What's left\r\n\r\n- Pluggable redirect handler (#3846)\r\n- Anything Kenneth thinks of. \r\n- Urllib3 v2 update",
        "comments": 12
    },
    {
        "merged": true,
        "additions": 22,
        "deletions": 14,
        "changed_files": 5,
        "created_at": "2017-02-10T10:56:00Z",
        "closed_at": "2017-02-10T12:19:01Z",
        "merged_at": "2017-02-10T12:19:01Z",
        "body": "Removed out-of-date advice for installing `py.test` with `requirements.txt`",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-02-06T16:31:22Z",
        "closed_at": "2017-02-07T16:04:25Z",
        "merged_at": "2017-02-07T16:04:25Z",
        "body": "There is code that already check that a guy raising (at least) his right arm does not get big-headed (a.k.a uppercased). Just add the same for the other, poor guy complaining about an error.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 70,
        "deletions": 11,
        "changed_files": 4,
        "created_at": "2017-02-02T01:52:21Z",
        "closed_at": "2017-02-10T21:46:14Z",
        "merged_at": "2017-02-10T21:46:14Z",
        "body": "This is the first attempt at a PR to address my proposal #3837 to support pluggable redirect handling.  Feedback is welcome.\r\n\r\nThis does not break existing tests and adds a new test to for handling malformed 200+location responses using a custom session mixin.\r\n\r\nI've been testing it for a day and it seems to be fine.\r\n\r\nThank you for simply considering this, and even more thanks for all the suggestions and advice in the related thread.  It has been a long week of little sleep trying to pin down some issues.  ",
        "comments": 14
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-01-31T03:04:22Z",
        "closed_at": "2017-01-31T08:54:28Z",
        "merged_at": "2017-01-31T08:54:28Z",
        "body": "Branch name was meant to be 'Happy New Year' but apparently typing the word 'Year' isn't my strongest skill. ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 43,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2017-01-26T21:10:55Z",
        "closed_at": "2017-01-29T08:15:36Z",
        "merged_at": "2017-01-29T08:15:36Z",
        "body": "Resolves: #3772",
        "comments": 12
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 4,
        "changed_files": 3,
        "created_at": "2017-01-24T23:13:07Z",
        "closed_at": "2017-01-25T01:58:00Z",
        "merged_at": "2017-01-25T01:58:00Z",
        "body": "This fixes the issue that was encountered this morning during the 2.13.0 release.\r\n\r\nThe source specified in the original Pipfile was for an incorrect pypi endpoint. This didn't matter until pipenv 2.6 was released, specifically [cb22a12](https://github.com/kennethreitz/pipenv/commit/cb22a129eae8c8e800e603c38bf1fe04d420fbde), which started using the provided `source` value.\r\n\r\n@kennethreitz I used `pipenv lock` with pipenv 3.0.0 to generate the new lock file which I'm assuming is what we want here.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-01-14T04:13:04Z",
        "closed_at": "2017-01-14T10:01:54Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 15,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2017-01-13T20:51:40Z",
        "closed_at": "2017-01-16T20:30:14Z",
        "merged_at": null,
        "body": "See issue #3213",
        "comments": 11
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-01-10T05:17:34Z",
        "closed_at": "2017-01-10T08:31:59Z",
        "merged_at": "2017-01-10T08:31:59Z",
        "body": "The previous summary gave the impression that requests-oauthlib only supports\r\nOAuth 1.\r\n\r\nThis updates makes it clear that it also supports OAuth 2, and links directly to the\r\nuse case specific authentication flow guides.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-01-09T03:45:58Z",
        "closed_at": "2017-02-10T17:11:56Z",
        "merged_at": null,
        "body": "It's can be useful for set not default cookies attributes values, for example \"domain\" or \"discard\".",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 1,
        "changed_files": 6,
        "created_at": "2017-01-08T22:41:06Z",
        "closed_at": "2017-01-09T04:13:04Z",
        "merged_at": "2017-01-09T04:13:04Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2016-12-29T03:24:28Z",
        "closed_at": "2016-12-29T09:41:24Z",
        "merged_at": "2016-12-29T09:41:24Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 28,
        "deletions": 17,
        "changed_files": 3,
        "created_at": "2016-12-23T17:21:43Z",
        "closed_at": "2017-01-19T09:19:00Z",
        "merged_at": "2017-01-19T09:19:00Z",
        "body": "Changes based on comment from previous Pull Request: https://github.com/kennethreitz/requests/pull/3787\r\n\r\nFix for issue: https://github.com/kennethreitz/requests/issues/3780\r\n",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 139,
        "deletions": 17,
        "changed_files": 7,
        "created_at": "2016-12-22T23:07:33Z",
        "closed_at": "2016-12-23T13:52:43Z",
        "merged_at": null,
        "body": "Fix for issue: https://github.com/kennethreitz/requests/issues/3780\r\n\r\nLazily loading `idna`. This CR includes utilities to:\r\n* lazily load idna package\r\n* And, delete module from sys.modules after use\r\n\r\nChanges looks to work fine for me. Now, None of the reference to `idna` is getting used directly. GC will release the memory when required.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-12-21T06:10:53Z",
        "closed_at": "2016-12-21T15:59:35Z",
        "merged_at": "2016-12-21T15:59:35Z",
        "body": "",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 9,
        "changed_files": 3,
        "created_at": "2016-12-16T22:26:37Z",
        "closed_at": "2016-12-17T14:23:33Z",
        "merged_at": "2016-12-17T14:23:33Z",
        "body": "Minor tweak for 3.0.0 to cross off #2003 by removing the HTTPProxyAuth class in favor of the `proxies` param.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 112,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-12-12T17:35:13Z",
        "closed_at": "2016-12-14T09:41:11Z",
        "merged_at": "2016-12-14T09:41:11Z",
        "body": "#1979 is still opened as \"unresolved\" but it looks like a patch (#2253) was merged to address it in 2014. There wasn't a testing framework at the time, so no tests were included to verify things actually worked. I haven't been able to concoct a end-to-end test with httpbin for this, but the individual pieces work as intended. I can work on devising a socket test if needed.",
        "comments": 9
    },
    {
        "merged": false,
        "additions": 8,
        "deletions": 32,
        "changed_files": 5,
        "created_at": "2016-12-09T19:27:16Z",
        "closed_at": "2016-12-09T21:16:30Z",
        "merged_at": null,
        "body": "This is more of a TODO reminder. Given the upcoming work for urllib3 2.0, which I'm assuming will be used in a Requests 3.0.0, this won't work. We don't need to remove this immediately, but I'll leave this here for when we're sure 2.0 is happening.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 25,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-12-09T19:23:35Z",
        "closed_at": "2016-12-10T13:57:44Z",
        "merged_at": "2016-12-10T13:57:44Z",
        "body": "Catching up the 3.0-HISTORY.rst file for the most of 2016's changes.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 27,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2016-12-08T22:01:52Z",
        "closed_at": "2016-12-09T08:45:14Z",
        "merged_at": "2016-12-09T08:45:14Z",
        "body": "This addresses #3753, I'll open a PR for 3.0.0 removing this when we merge master.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 93,
        "deletions": 44,
        "changed_files": 3,
        "created_at": "2016-12-08T18:23:36Z",
        "closed_at": "2016-12-12T15:54:17Z",
        "merged_at": "2016-12-12T15:54:17Z",
        "body": "This patch is an attempt to address #2590 by relaxing the way Requests handles redirects. \r\n\r\nTaking a look at how we\u2019re handling stripping bodies, I modified the conditional to avoid an overly complicated check. The only requests we want to strip bodies off of are ones that have been modified from the redirect. That means the method will have already been changed to GET in `rebuild_method` and we can perform a uniform stripping for only GET requests. Personally, I'd like to have `rebuild_method` return a value, either a boolean or the new method, and use that as the parameter for the check. Then move the code inside the conditional into it's own function. This will help a bit with the overall size of `resolve_redirects`.\r\n\r\nI also removed the 302 catch-all which was put in place in #1704 when RFC 2616 was still the standard. The previous mandates for 302 aren\u2019t included in [RFC 7231 6.4.3](https://tools.ietf.org/html/rfc7231#section-6.4.3) and don\u2019t appear to be reproducible in Chrome or Firefox with any tools supporting PUT, PATCH, or DELETE. (Note: if there\u2019s a repro for this that I\u2019m missing please let me know and I\u2019ll gladly revert this. I\u2019m just going off of the information available.)\r\n\r\nThe \"test all methods\" tests may be a bit overboard, I added them primarily for my own assurance to make sure I wasn't missing edge cases. I can remove those if they're deemed unnecessary.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 37,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2016-12-08T04:21:45Z",
        "closed_at": "2016-12-08T09:05:13Z",
        "merged_at": "2016-12-08T09:05:13Z",
        "body": "These are a few tests from #3338 which is slated for Proposed/3.0.0. #3066 is the issue #3338 was originally opened to fix, but has since been resolved on master with #3082 and #3535. Adding these tests will allow us to confirm #3066 is indeed resolved and help prevent regressions until 3.0.0 is released.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 68,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2016-12-02T19:31:54Z",
        "closed_at": "2017-02-10T17:11:37Z",
        "merged_at": null,
        "body": "This is really quite unexciting: #2431 had a tentative +1 from @Lukasa, pending a rebase and retargeting against 3.0.0, but it\u2019s been sat unloved for nearly eight months. \ud83d\ude22 \r\n\r\nThis patch does the required rebase and targets the 3.0.0 branch.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 69,
        "deletions": 15,
        "changed_files": 2,
        "created_at": "2016-11-30T21:22:10Z",
        "closed_at": "2016-12-01T10:45:25Z",
        "merged_at": "2016-12-01T10:45:25Z",
        "body": "This reverts commit 34af72c87d79bd8852e8564c050dd7711c6a08d6.\r\n\r\nThis commit was added by @tiran to try to avoid the IDNA-encoding logic that we added in v2.12.0. I believe that the *other* workarounds we merged for that are sufficient, and this change broke docker-py and probably broke others.\r\n\r\n@tiran, can you confirm that your code continues to function with this change reverted? I'd like to be able to merge this and ship a v2.12.3 if at all possible.\r\n\r\nResolves #3735.",
        "comments": 27
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2016-11-23T21:26:30Z",
        "closed_at": "2016-11-24T13:35:37Z",
        "merged_at": "2016-11-24T13:35:37Z",
        "body": "Fix #3698.\r\n\r\nThis fixes also a traceback in https://github.com/galaxyproject/bioblend/blob/master/bioblend/galaxy/client.py#L135 where the `text` attribute of an empty `requests.Response()` object is used:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/users/ga002/soranzon/software/galaxyproject_bioblend/tests/TestGalaxyInstance.py\", line 37, in test_get_retry\r\n    self.gi.libraries.get_libraries()\r\n  File \"/usr/users/ga002/soranzon/software/galaxyproject_bioblend/bioblend/galaxy/libraries/__init__.py\", line 218, in get_libraries\r\n    libraries = self._get(deleted=deleted)\r\n  File \"/usr/users/ga002/soranzon/software/galaxyproject_bioblend/bioblend/galaxy/client.py\", line 135, in _get\r\n    raise ConnectionError(msg, body=r.text,\r\n  File \"/usr/users/ga002/soranzon/software/galaxyproject_bioblend/.tox/py27/local/lib/python2.7/site-packages/requests/models.py\", line 796, in text\r\n    if not self.content:\r\n  File \"/usr/users/ga002/soranzon/software/galaxyproject_bioblend/.tox/py27/local/lib/python2.7/site-packages/requests/models.py\", line 772, in content\r\n    self._content = bytes().join(self.iter_content(CONTENT_CHUNK_SIZE)) or bytes()\r\n  File \"/usr/users/ga002/soranzon/software/galaxyproject_bioblend/.tox/py27/local/lib/python2.7/site-packages/requests/models.py\", line 705, in generate\r\n    chunk = self.raw.read(chunk_size)\r\nAttributeError: 'NoneType' object has no attribute 'read'\r\n```",
        "comments": 17
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2016-11-23T03:48:05Z",
        "closed_at": "2016-11-23T10:17:32Z",
        "merged_at": "2016-11-23T10:17:32Z",
        "body": "Minor example update and rewording in response to the continued discussion after merging #3704. @afeld, if you're inclined to comment, does this change still address your original concerns?",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2016-11-21T17:05:12Z",
        "closed_at": "2016-11-21T19:13:56Z",
        "merged_at": "2016-11-21T19:13:56Z",
        "body": "Requests treats all URLs starting with the string 'http' as HTTP URLs.\r\nPreparation with IDNA breaks non-standard URIs like http+unix. Requests\r\nnow prepares only URLs with prefix http:// and https://.\r\n\r\nSigned-off-by: Christian Heimes <christian@python.org>",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 37,
        "deletions": 4,
        "changed_files": 3,
        "created_at": "2016-11-20T03:03:26Z",
        "closed_at": "2016-11-20T07:45:36Z",
        "merged_at": null,
        "body": "The function sjson in the Response class will return a json object in string form. Unless provided arguments, it will return a pretty printed string, when printed is human readable. You can look at the docs for the json module's dumps object to know which arguments to send to the sjson function for custom output. ",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2016-11-17T06:40:03Z",
        "closed_at": "2016-11-17T08:23:57Z",
        "merged_at": "2016-11-17T08:23:57Z",
        "body": "The interpreter snippet at the top of the readme.rst is the first snippet of code that users will see for using requests. I think an import statement should be shown at the top of the code snippet, so a novice or even intermediate python user will know to import the module first before attempting to use it. It makes the snippet more complete. I've seen other github projects include the import statement in snippets like the one in the readme. I changed the doc/index.rst file for consistency, since they are the same code snippet.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2016-11-16T17:23:30Z",
        "closed_at": "2016-11-16T18:32:59Z",
        "merged_at": "2016-11-16T18:32:59Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 52,
        "deletions": 4,
        "changed_files": 4,
        "created_at": "2016-11-16T13:24:32Z",
        "closed_at": "2016-11-25T13:18:01Z",
        "merged_at": "2016-11-25T13:18:01Z",
        "body": "This addresses #3687 allowing URLs that are already idna encoded to pass through while everything else is still properly encoded.",
        "comments": 17
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2016-11-16T03:32:19Z",
        "closed_at": "2016-11-16T08:39:06Z",
        "merged_at": "2016-11-16T08:39:06Z",
        "body": "Fixed readme typo - 'site' should be 'domain'",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-11-16T03:05:08Z",
        "closed_at": "2016-11-16T08:38:33Z",
        "merged_at": "2016-11-16T08:38:33Z",
        "body": "Make consistent with quickstart doc.\r\n\r\n_If_ true, this would be better:\r\n\r\n:param allow_redirects: (optional) Boolean. Whether redirects will be followed. Defaults to False for HEAD requests, True for all other methods.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 29,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2016-11-12T09:02:26Z",
        "closed_at": "2016-11-21T19:27:39Z",
        "merged_at": "2016-11-21T19:27:39Z",
        "body": "Fixed the issue with unicode characters in basic http auth",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-11-10T21:29:14Z",
        "closed_at": "2016-11-10T23:18:16Z",
        "merged_at": "2016-11-10T23:18:16Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2016-11-02T22:24:13Z",
        "closed_at": "2016-11-03T10:03:59Z",
        "merged_at": null,
        "body": "referring to #2979 ...\r\n\r\nthis is answered that this can be done with **kwargs, which is true. But wouldn't that would go for **post** too ?\r\nIt would make consistent use of parameters possible if **put** and **patch** would support the _json_ parameter also, so then there is no need for additional logic to distinguish between the different methods, take for example:\r\n\r\n```python\r\n   ...\r\n   self.client = requests.Session()  \r\n   ...\r\n   request_args = {}\r\n   if method == 'get':\r\n        request_args['params'] = params\r\n   elif hasattr(endpoint, \"data\") and endpoint.data:\r\n       request_args['json'] = endpoint.data\r\n   ....\r\n   func = getattr(self.client, method)\r\n   response = func(url, stream=stream, headers=headers, **request_args)\r\n   ...\r\n\r\n```\r\npost, put and patch can all be handled the same this way.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2016-11-02T21:18:18Z",
        "closed_at": "2016-11-03T10:06:53Z",
        "merged_at": "2016-11-03T10:06:53Z",
        "body": "Right now the `cookiejar_from_dict` path provided to autofunction in api.rst is incorrect. It happens to work though because Sphinx is smart enough to correct the source url for us. This will make the display string consistent with the correct path.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 168,
        "deletions": 6,
        "changed_files": 7,
        "created_at": "2016-10-29T00:18:10Z",
        "closed_at": "2016-11-03T10:31:04Z",
        "merged_at": "2016-11-03T10:31:04Z",
        "body": "This addresses the issue (#3079) of Requests hanging when a POST with a file-like body encounters a temporary redirect. This currently has the unmerged tests from #3536, so I'll need to remove those if we reach a point where we're ready to merge this.\n\nThis approach has a couple of things that I'm not especially happy with but couldn't come up with a nicer alternative. I've added a few outstanding questions below.\n\n1.) I feel like `body_position` should probably be `_body_position`, but we need to use it in the `Session` module. Making it a private var would require an additional getter method for `PreparedRequest` to expose the data to `Session`, but I wanted to run that by before adding more  code. It just seems problematic to provide any encouragement to manually set `body_position` since it will lead to fairly unintuitive behaviour.\n\n2.) As I noted in the comment [here](https://github.com/nateprewitt/requests/commit/b84d71461e238b123a39ce91a48a99e3eb03717c#commitcomment-19619276), this still allows for the possibility that a request with a file-like object, that has tell but no seek, to hang. I feel like we should raise an `IOError` if we can't rewind, at least allowing the user to manually recreate the body and POST it to the new URL. Does that seem reasonable?\n",
        "comments": 9
    },
    {
        "merged": false,
        "additions": 50,
        "deletions": 25,
        "changed_files": 3,
        "created_at": "2016-10-25T16:13:09Z",
        "closed_at": "2016-11-15T09:45:32Z",
        "merged_at": null,
        "body": "In a previous PR, the SSL options are updated on the main pool manager in `get_connection()` but not when the selected pool manager is a proxy pool manager.  This PR fixes that.  \n\nIn addition, I renamed the `_pool_kw_lock` because it's used in  `get_connection()` to create a _critical section_ for both updating the selected pool manager _connection_pool_kw_  and calling `connection_from_url()` without being preempted.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2016-10-23T16:07:44Z",
        "closed_at": "2016-10-25T08:56:53Z",
        "merged_at": "2016-10-25T08:56:53Z",
        "body": "If the `trust_env` flag is set on a session and `verify` is `True`\nor `None`, the environment is checked for `CURL_CA_BUNDLE` and\n`REQUESTS_CA_BUNDLE`. Before this patch, if neither existed,\n`verify` would always be set to `None` rather than `True` when it\nwas originally `True`.\n\nI found this while working on a patch for https://github.com/kennethreitz/requests/issues/3633.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 18,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2016-10-18T17:18:25Z",
        "closed_at": "2016-10-27T19:53:18Z",
        "merged_at": "2016-10-27T19:53:18Z",
        "body": "This is a minor fix in the same vein as #3591. This function calls `update` on the CookieJar which only exists on `RequestsCookieJar` not the standard library `cookielib.CookieJar`. While this function will now be somewhat trivial, this will ensure it maintains backwards compatibility. It may be worth discussing removal in the future.\n\nI have a test as well @Lukasa but it seems a bit overkill. I can include it if you'd like though.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 21,
        "deletions": 9,
        "changed_files": 2,
        "created_at": "2016-10-17T15:14:38Z",
        "closed_at": "2016-10-21T07:20:37Z",
        "merged_at": "2016-10-21T07:20:37Z",
        "body": "",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2016-10-14T10:08:31Z",
        "closed_at": "2016-10-14T16:38:17Z",
        "merged_at": "2016-10-14T16:38:17Z",
        "body": "Extra work that spun out of #3620.\n\nWe've had it as our policy that we only ship tagged releases of our vendored modules for a while now. This makefile update consolidates that by ensuring that the makefile will only ever use the latest tag for updates.\n\nFor the moment this is probably a bit naive, because if any of our dependencies tagged backport releases we'd be totally screwed. Right now they don't, and I think we'll notice if they start doing it, so we should be safe.\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-10-14T09:59:08Z",
        "closed_at": "2016-10-14T16:38:33Z",
        "merged_at": "2016-10-14T16:38:33Z",
        "body": "Spotted this while working on #3620.\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 9580,
        "deletions": 4,
        "changed_files": 15,
        "created_at": "2016-10-14T09:56:36Z",
        "closed_at": "2016-10-21T12:09:04Z",
        "merged_at": "2016-10-21T12:09:04Z",
        "body": "Fixes #3616. This adds support for IDNA 2008 by vendoring the idna module, with the kind permission of @kjd.\n\nFor those keeping track, changes like this are another reason that Requests should stay out of the stdlib. ;) See also: [CPython issue 17305](https://bugs.python.org/issue17305).\n",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2016-10-13T12:28:59Z",
        "closed_at": "2016-10-13T14:08:10Z",
        "merged_at": "2016-10-13T14:08:10Z",
        "body": "Congratulations @jeremycline!\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 18,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-10-07T20:24:10Z",
        "closed_at": "2016-10-12T10:11:30Z",
        "merged_at": "2016-10-12T10:11:30Z",
        "body": "This PR simply adds the documentation for custom method verbs that people may need or wish to use, such as in #3611\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 10,
        "changed_files": 1,
        "created_at": "2016-09-30T03:20:09Z",
        "closed_at": "2016-09-30T12:17:17Z",
        "merged_at": "2016-09-30T12:17:17Z",
        "body": "This exception catching is far too aggressive in my opinion. A lot of code could run in this and could throw AttributeError for any number of reasons. It's actually not clear to me what error it's trying to catch. It made it quite difficult for me to debug this problem: https://github.com/shazow/urllib3/pull/990\n\nThis PR removes it altogether since as far as I can see it is not needed in normal operation and can only serve to mask errors.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2016-09-29T03:50:11Z",
        "closed_at": "2016-09-29T07:09:22Z",
        "merged_at": "2016-09-29T07:09:22Z",
        "body": "Fixes dependency on internet connection for test added in PR #3598 for Issue #3597 \n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-09-26T20:21:20Z",
        "closed_at": "2016-09-27T07:06:27Z",
        "merged_at": "2016-09-27T07:06:27Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 51,
        "deletions": 24,
        "changed_files": 8,
        "created_at": "2016-09-26T05:31:21Z",
        "closed_at": "2016-09-28T07:56:38Z",
        "merged_at": "2016-09-28T07:56:38Z",
        "body": "When resolving the request full URL, the Host cookie is used to override the URL's host, in Python 3 this causes a mix of str and bytestring objects when the Host cookie is set to a bytestring. Patch checks that ParsedResult is str type and host is non-str type before attempting to decode bytestring to str.\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 27,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2016-09-23T15:51:56Z",
        "closed_at": "2016-11-10T13:50:06Z",
        "merged_at": null,
        "body": "Right now you can provide a dictionary to the `cookies` param almost everywhere in Requests and it will be converted into a RequestsCookieJar (aka \"just work\"). The one place this isn't happening is with Session, which will accept a dictionary without complaint but then fail when you try to send a PreparedRequest. \n\nI discussed wanting to make this part of the API a bit more predictable with @Lukasa and this was a suggested fix for the problem. I did fair amount of testing outside of the included test and I don't believe this will adversely affect functionality. The one case I found is where someone is providing a CookieJar-like object that doesn't inherit from `cookielib.CookieJar`, and doesn't have an `__iter__` method. This seems like an unlikely case and wasn't _really_ supported before, so I wouldn't consider this breaking.\n",
        "comments": 10
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 9,
        "changed_files": 1,
        "created_at": "2016-09-20T16:24:26Z",
        "closed_at": "2016-09-21T09:41:00Z",
        "merged_at": "2016-09-21T09:41:00Z",
        "body": "Merging change from #3576 into the proposed/3.0.0 branch as per @sigmavirus24's request.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 35,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2016-09-19T17:33:08Z",
        "closed_at": "2016-09-23T09:32:52Z",
        "merged_at": "2016-09-23T09:32:52Z",
        "body": "This should solve the issue in #3579. `merge_cookies` performs the same `update` call inside of a try/except block which will fallback to the same logic that [`update`](https://github.com/kennethreitz/requests/blob/master/requests/cookies.py#L347-L353) itself implements for non-`RequestsCookieJar`-like objects.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2016-09-16T16:23:45Z",
        "closed_at": "2016-09-20T14:48:40Z",
        "merged_at": "2016-09-20T14:48:40Z",
        "body": "`test_response_reason_unicode_fallback` is currently failing in Python 2. The original proposed fix in #3557 unfortunately didn't address the underlying issue.\n\nWhile this patch should fix the test now, it may be worth taking a brief moment to discuss how we envision the original PR #3554 working. Currently an error retrieved from an `except` clause can't be cast as `str`, `unicode`, written to a file, or easily decoded in Python 2. It prints to the console fine, but that's about it. This seems like a semi-serious issue for making this exception usable. I need to run a few more tests this evening or tomorrow, so we can sit on this for the weekend unless someone has some obvious insight I'm missing.\n",
        "comments": 9
    },
    {
        "merged": false,
        "additions": 27,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-09-15T16:15:41Z",
        "closed_at": "2016-11-17T01:25:45Z",
        "merged_at": null,
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 30,
        "deletions": 8,
        "changed_files": 3,
        "created_at": "2016-09-15T02:58:02Z",
        "closed_at": "2016-09-16T10:36:03Z",
        "merged_at": "2016-09-16T10:36:03Z",
        "body": "Resolves the issues called out in #3359 and #3481 when `Response.iter_content(decode_unicode=True)` would return bytes instead of unicode. This is a breaking change as it raises an exception if `Response.encoding` is not set before invoking this function.\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-09-14T20:58:57Z",
        "closed_at": "2016-09-15T06:34:28Z",
        "merged_at": null,
        "body": "Fixes #3104 (or the weird mutant version of it that happens if you use eventlet).\n\nWhen eventlet monkey-patches ssl, the resulting `socket.read` calls throw an instance of the same class (`SSLError`) with a different message (`'timed out'` instead of `'read operation timed out'`). This causes the SSLError to not get swallowed by urllib3 or requests.\n\nPlease let me know if you'd prefer the issue to be fixed in another way, happy to adjust--this was just the clearest place to fix it.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 32,
        "deletions": 8,
        "changed_files": 5,
        "created_at": "2016-09-08T18:45:28Z",
        "closed_at": "2016-11-16T13:29:51Z",
        "merged_at": "2016-11-16T13:29:51Z",
        "body": "This is a **DO NOT MERGE** until we bring urllib3 1.17 into the Requests `proposed/3.0.0` branch, which should likely happen before 3.0.0 gets out the door.\n\nThis is the final step for the work in shazow/urllib3#949 and addresses the issues originally raised in shazow/urllib3#723 and #2833.\n",
        "comments": 12
    },
    {
        "merged": false,
        "additions": 90,
        "deletions": 15,
        "changed_files": 3,
        "created_at": "2016-09-08T00:47:43Z",
        "closed_at": "2017-02-10T17:21:29Z",
        "merged_at": null,
        "body": "Add the ability to add 'no_proxy' and a value to the 'proxies'\ndictionary argument.\n\nhttps://github.com/kennethreitz/requests/issues/2817\nCloses gh-2817\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2016-09-05T18:51:18Z",
        "closed_at": "2016-09-05T23:15:06Z",
        "merged_at": "2016-09-05T23:15:06Z",
        "body": "This implements the proposed solution to #3538 by falling back from Unicode to ISO-8859-1 for raw reason decoding.\n\nThis is a relatively trivial fix, and I wasn't sure if you wanted to waste bandwidth fixing, @mitsuhiko. I had a brief chat with @Lukasa who said to toss this up, but I'll gladly drop it in favor of #3538, if you had plans to update.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 12,
        "changed_files": 2,
        "created_at": "2016-08-29T16:22:24Z",
        "closed_at": "2016-09-22T12:49:57Z",
        "merged_at": "2016-09-22T12:49:57Z",
        "body": "# Background\n\nSo while working on #3535 I noticed that `prepare_content_length` will be fairly redundant after the patch is merged. I was going to push the abbreviated version of `prepare_content_length` into #3535 but found some inconsistencies in how we're currently handling Content-Length.\n\nSo here's a quick rundown of what I've found, and what it seems like _should_ happen.\n- #957 addressed #223 and added Content-Length to _everything_.\n- #1142 amended this to NOT send Content-Length with GET/HEAD requests (Issue #1051)\n- #2329 addressed the issue of not being able to override Content-Length with a custom header (Issue #2329)\n\nFrom this, I'd expect:\n- Content-Length to be set on all requests that are not using a HEAD/GET method.\n- If a Content-Length header exists, that it remains untouched when sending a request.\n# Next Steps\n\nCurrently, setting a body on a request will override the custom Content-Length header. The test implemented in #2329 doesn't test the code path with a body. I've added that test and the required logic to make it succeed. However, the solution attached here is not my preferred approach, rather the closest to the old functionality of prepare_content_length.\n\n_Ideally_, I think that any call to `prepare_content_length` will do just that, set the Content-Length. That way if someone updates the body on a PreparedRequest, they can use `prepare_content_length` without having to delete a header, or recreate the object. This approach would require moving `if self.headers.get('Content-Length') is None` up to `prepare_body` and `prepare_auth` to run the overwrite check there.\n\nThis has the issue of causing latent errors though, if someone decides to use `prepare_content_length` elsewhere without the existence check. So if we're concerned about that being a possibility, then I think `prepare_content_length` should instead have an `overwrite` param which will bypass the [check](https://github.com/kennethreitz/requests/compare/master...nateprewitt:new_prepare_content_length#diff-afd5aad80649cdfae687bee05242c8faR472) to see if the header exists.\n# \n\nThis PR is two tangentially related fixes (abbreviating prepare_content_length post #3535 and fixing inconsistencies in how we handle Content-Lengths). This SHOULD NOT be merged and probably doesn't need to even be addressed until after #3535 is merged.\n",
        "comments": 9
    },
    {
        "merged": false,
        "additions": 472,
        "deletions": 354,
        "changed_files": 11,
        "created_at": "2016-08-27T11:31:58Z",
        "closed_at": "2017-02-10T17:12:43Z",
        "merged_at": null,
        "body": null,
        "comments": 3
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-08-26T07:47:12Z",
        "closed_at": "2016-08-26T13:16:54Z",
        "merged_at": "2016-08-26T13:16:54Z",
        "body": "Learning python and Requests it was not immediately clear that many arguments can also be made persistent using the Sessions class.\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-08-25T23:10:33Z",
        "closed_at": "2016-09-06T08:33:02Z",
        "merged_at": null,
        "body": "HTTP status lines are latin1 and not utf-8\n\n>    The TEXT rule is only used for descriptive field contents and values\n>    that are not intended to be interpreted by the message parser. Words\n>    of *TEXT MAY contain characters from character sets other than ISO-\n>    8859-1 only when encoded according to the rules of RFC 2047\n\nTo quote the RFC. Nobody implements RFC 2047 so this can be disregarded.\n\n<!-- Reviewable:start -->\n\n---\n\nThis change is [<img src=\"https://reviewable.io/review_button.svg\" height=\"34\" align=\"absmiddle\" alt=\"Reviewable\"/>](https://reviewable.io/reviews/kennethreitz/requests/3538)\n\n<!-- Reviewable:end -->\n",
        "comments": 11
    },
    {
        "merged": false,
        "additions": 17,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2016-08-24T20:15:21Z",
        "closed_at": "2016-11-03T15:36:57Z",
        "merged_at": null,
        "body": "https://github.com/kennethreitz/requests/issues/3079\n\nThis is a test case that depends on httpbin 0.5.0 to show the bug.\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 45,
        "deletions": 6,
        "changed_files": 2,
        "created_at": "2016-08-24T18:04:53Z",
        "closed_at": "2016-09-14T07:10:28Z",
        "merged_at": "2016-09-14T07:10:28Z",
        "body": "This is a follow up on @jseabold's work in #3339. These last minor changes should fix the issues with return values of `seek` between Python 2 and Python 3.\n",
        "comments": 10
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2016-08-23T03:03:39Z",
        "closed_at": "2016-08-23T11:54:35Z",
        "merged_at": "2016-08-23T11:54:35Z",
        "body": "Fixed the missing lines pointed out in #3526 to hopefully squash #3518 once and for all.\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 75,
        "deletions": 4,
        "changed_files": 4,
        "created_at": "2016-08-21T21:16:57Z",
        "closed_at": "2016-08-21T22:21:13Z",
        "merged_at": null,
        "body": "I'm fairly new to open source contributions, so any feedback is appreciated. This PR\n1) Addresses issue #3518 by iterating over ALL_PROXY last. \n2) Elaborates some of the most commonly used response headers into their corresponding Python equivalents for convenience, namely r.date() and r.last_modified() return datetime objects and r.content_length() and r.age() return ints when possible, None otherwise\n3) Added corresponding tests for the above \n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 2,
        "changed_files": 3,
        "created_at": "2016-08-21T16:59:04Z",
        "closed_at": "2016-08-21T22:17:31Z",
        "merged_at": "2016-08-21T22:17:31Z",
        "body": "Addresses bug called out in issue #3518.\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 2,
        "changed_files": 3,
        "created_at": "2016-08-17T18:33:32Z",
        "closed_at": "2016-08-17T21:30:27Z",
        "merged_at": "2016-08-17T21:30:27Z",
        "body": "As discussed in #2228, I added a short note to the quick start and the advanced section about Requests' standard usage of timeouts as this can be unexpected.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-08-15T09:08:00Z",
        "closed_at": "2016-08-17T20:01:58Z",
        "merged_at": "2016-08-17T20:01:58Z",
        "body": "@kennethreitz, this is all we need from a boring administrative perspective. If you merge this PR, you only need to do three things to release:\n1. Update the version number to 2.11.1.\n2. Put the date you do this in the changelog instead of the XX.\n3. Push the release.\n\nIt'd be good to get this release out this week: it should put the nastiest bugs of 2.11 behind us and get people back to working again. =)\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 45,
        "deletions": 57,
        "changed_files": 6,
        "created_at": "2016-08-14T20:08:58Z",
        "closed_at": "2016-08-15T17:52:56Z",
        "merged_at": "2016-08-15T17:52:56Z",
        "body": "Various doc updates for clarity. Some of these may not match @kennethreitz's aesthetic sensibilities, which may require an inversion of the proposed change. I was mainly trying to make things consistent, input on preferences would be greatly appreciated.\n\nSome notes:\n- I think at least the faq.rst changes _need_ to be merged because there is still live documentation stating that Requests supports 3.1 and 3.2. I can open a separate PR if we want those changes quicker.\n- What was ScraperWiki, is now found at quickcode.io and appears to either be a paid or account-walled service. Wayback Machine is showing the site as a free service when the documentation was created, so I'm not sure if Kenneth still wants this included. At the very least, the URL should be updated.\n- ~~Does Requests support pypy 2.2 officially? faq.rst says yes, but it's other versions were wrong.~~\n- While I realize it's common to use `class.method` as a pattern when describing code, I felt like `r.json` is ambiguous when referenced next to `r.text`. Calling exactly `r.json` won't function as described in the provided `ValueError` example. Explicitly defining the call as `r.json()` reduces the chance of misinterpretation.\n- api.rst has a pared down set of Exceptions and classes. I assume this is to keep extraneous information from bloating the page to a point of being unhelpful. I do think it may be worth including `BaseAdapter` for easy reference since anyone looking into a custom _non-HTTP_ Transport Adapter will likely need to start there.\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2016-08-13T02:43:30Z",
        "closed_at": "2016-08-13T08:42:25Z",
        "merged_at": "2016-08-13T08:42:25Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2016-08-12T15:42:08Z",
        "closed_at": "2016-08-18T08:28:20Z",
        "merged_at": "2016-08-18T08:28:20Z",
        "body": "This is minor, but when testing `resolve_redirects` I encountered an `AttributeError` when passing a non-urllib3 Response. This is because the method unconditionally calls [`close`](https://github.com/kennethreitz/requests/blob/master/requests/models.py#L864) on the Response which in turn calls `release_conn` on the `Response.raw` attribute.\n\nIf the desire for requests is to maintain support for non-urllib3 objects in custom adapters, I think this would be a simple and useful addition. If urllib3 is going to be a de facto pattern for Responses though, this is probably just unnecessary code bloat.\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 44,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2016-08-10T15:50:44Z",
        "closed_at": "2016-08-12T11:24:36Z",
        "merged_at": "2016-08-12T11:24:36Z",
        "body": "This will remove additional headers (`Content-Type` and `Transfer-Encoding`) from non-temporary/non-permanent redirects in `resolve_redirects` to address #3490.\n\nThis functionality isn't currently being tested but I'm happy to add a test or two for it if desired.\n",
        "comments": 13
    },
    {
        "merged": true,
        "additions": 46,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-08-09T18:17:19Z",
        "closed_at": "2016-11-10T17:26:47Z",
        "merged_at": "2016-11-10T17:26:47Z",
        "body": "This is a continuation of @keyan's work in #2757 and addresses issue #1558 regarding pickling Request objects (specifically `PreparedRequest` objects in this PR).\r\n\r\nThese tests ensure that a standard `PreparedRequest`, a `PreparedRequest` with a file object as the body, and a `PreparedRequest` with hooks defined outside of the `locals` scope will all pickle properly.\r\n\r\nThis also works for data passed to the `json` parameter and I can add my test for that as well if it's deemed helpful.\r\n\r\nHooks defined inside of a method (such as in the [original test](https://github.com/kennethreitz/requests/pull/2757/files#diff-56c2d754173a4a158ce8f445834c8fe8R843) by @keyan) will fail because you can't pickle local objects. Is this a use case that needs to be handled?",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 767,
        "deletions": 102,
        "changed_files": 12,
        "created_at": "2016-08-08T12:39:59Z",
        "closed_at": "2016-08-08T15:05:02Z",
        "merged_at": "2016-08-08T15:05:02Z",
        "body": "@kennethreitz, this is all we need from a boring administrative perspective. If you merge this PR, you only need to do three things to release:\n1. Update the version number to 2.11.\n2. Put the date you do this in the changelog instead of the XX.\n3. Push the release.\n\n@sigmavirus24 I'm inclined to want to let all currently open PRs remain open rather than try to rush merge any: they can always wait for a 2.11.1 or 2.12 without any risk.\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 53,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2016-07-30T20:51:17Z",
        "closed_at": "2017-02-10T21:51:13Z",
        "merged_at": null,
        "body": "This will add in the option to persist cookie policies on requests when the session and request cookie jars are merged. Currently any custom cookie policies on the session are not sent as noted in #3416.\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-07-30T12:18:14Z",
        "closed_at": "2016-07-30T17:18:14Z",
        "merged_at": "2016-07-30T17:18:14Z",
        "body": "urllib3 closes the underlying connection when we call\nurllib3.Response.close but does not release it back to the connection\npool. This can cause issues when users have a blocking connection pool\nconfigured and connections are not readily returned to the pool.\n\nSince the underlying connection is closed, we should be able to safely\nreturn the connection to the connection pool, so to fix this issue we\nmerely need to not return after closing the response.\n\nCloses gh-3461\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 114,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2016-07-27T04:06:28Z",
        "closed_at": "2016-07-27T13:47:42Z",
        "merged_at": null,
        "body": "# Description\n\nA logging mechanism to display important information regarding all requests and responses sent through the `requests` api.\n# Why is this necessary?\n\nAt the company I work for we've been using this [logging mechanism](https://github.com/openstack/opencafe/blob/master/cafe/plugins/http/cafe/engine/http/client.py#L29) for a very long time and have had great success with it for testing numerous APIs. The level of logging provides the user with information they would normally have to dig for, and also provides a ready made log from which to draw relevant information. This is especially important for testing as it provides testers with sufficient logs to assess what is wrong, if a request should fail.\n\nThis information is even valuable for API developers as they can get immediate, easy to see, feedback on what their API is doing and returning.\n# Try it for yourself!:\n## Code:\n\n``` python\nimport logging;root=logging.getLogger();root.addHandler(logging.StreamHandler());root.setLevel(0);\nimport requests\nrequests.post('https://jsonplaceholder.typicode.com/posts', data=\"\"\"{\"id\": 101, \"title\": \"foo\", \"body\": \"bar\", \"userId\": 1}\"\"\", headers={'content-type': 'application/json'})\n```\n## Logging output:\n\n```\n(<requests.sessions.Session object at 0x111000a90>,) {'data': '{\"id\": 101, \"title\": \"foo\", \"body\": \"bar\", \"userId\": 1}', 'url': 'https://jsonplaceholder.typicode.com/posts', 'method': 'post', 'headers': {'content-type': 'application/json'}, 'json': None}\nStarting new HTTPS connection (1): jsonplaceholder.typicode.com\n\"POST /posts HTTP/1.1\" 201 65\n\n------------\nREQUEST SENT\n------------\nrequest method..: POST\nrequest url.....: https://jsonplaceholder.typicode.com/posts\nrequest params..:\nrequest headers.: {'Content-Length': '55', 'Connection': 'keep-alive', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'User-Agent': 'python-requests/2.10.0', 'content-type': 'application/json'}\nrequest body....: {\"id\": 101, \"title\": \"foo\", \"body\": \"bar\", \"userId\": 1}\n\n\n-----------------\nRESPONSE RECEIVED\n-----------------\nresponse status..: <Response [201]>\nresponse time....: 0.7399938106536865\nresponse headers.: {'CF-RAY': '2c8d2175a6d20108-DFW', 'X-Content-Type-Options': 'nosniff', 'Etag': 'W/\"41-1twMC34dpcMvmO2NLu+Kkg\"', 'Pragma': 'no-cache', 'Server': 'cloudflare-nginx', 'Cache-Control': 'no-cache', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '65', 'Set-Cookie': '__cfduid=dadf01d51aae9ede807ecf3e77439a3d51469591463; expires=Thu, 27-Jul-17 03:51:03 GMT; path=/; domain=.typicode.com; HttpOnly', 'X-Powered-By': 'Express', 'Via': '1.1 vegur', 'Vary': 'Origin, X-HTTP-Method-Override, Accept-Encoding', 'Date': 'Wed, 27 Jul 2016 03:51:03 GMT', 'Access-Control-Allow-Credentials': 'true', 'Expires': '-1', 'Connection': 'keep-alive'}\nresponse body....: b'{\\n  \"id\": 101,\\n  \"title\": \"foo\",\\n  \"body\": \"bar\",\\n  \"userId\": 1\\n}'\n-------------------------------------------------------------------------------\n```\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-07-26T17:40:58Z",
        "closed_at": "2016-07-26T20:16:38Z",
        "merged_at": "2016-07-26T20:16:38Z",
        "body": "This fixes the failing test I brought up [here](https://github.com/kennethreitz/requests/pull/3417#issuecomment-233136908). 4dfe7a4 removed the `req` param from `resolve_redirects` in favor of calling `response.request` in the method. The test wasn't updated though, so the request param is being assigned to `stream` which should be a boolean. This is causing the `test_requests_are_updated_each_time` test to fail.\n\nEdit: Sorry, I overlooked that this was addressed in 4dfe7a4 but accidentally reverted in 18b26d2.\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 7,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-07-22T22:27:38Z",
        "closed_at": "2016-08-04T17:21:49Z",
        "merged_at": null,
        "body": "",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 130,
        "deletions": 108,
        "changed_files": 22,
        "created_at": "2016-07-20T16:48:01Z",
        "closed_at": "2016-07-20T22:38:39Z",
        "merged_at": "2016-07-20T22:38:39Z",
        "body": "This is adding in mostly cosmetic fixes to docstrings, including some sphinx additions. I think these will help catch docstring style choices that are determined by looking at the function above or below where you're adding your new one.\n\nThis is part two of two for #3427.\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 44,
        "deletions": 38,
        "changed_files": 8,
        "created_at": "2016-07-20T16:08:10Z",
        "closed_at": "2016-07-20T17:33:12Z",
        "merged_at": null,
        "body": "This spawned off of [an article](https://hynek.me/articles/hasattr/) @Lukasa brought up in another PR. These changes should fix the pitfalls with using `hasattr` by converting their logic to use `getattr` instead.\n",
        "comments": 10
    },
    {
        "merged": true,
        "additions": 38,
        "deletions": 4,
        "changed_files": 4,
        "created_at": "2016-07-15T05:42:45Z",
        "closed_at": "2016-08-22T16:49:36Z",
        "merged_at": "2016-08-22T16:49:36Z",
        "body": "Addresses issue raised in #2939 with a fix for multiple Location headers in response. This currently breaks on `test_requests_are_updated_each_time` because the [`RedirectSession`](https://github.com/kennethreitz/requests/blob/proposed/3.0.0/tests/test_requests.py#L1564) populates it's `raw` attribute with `StringIO` rather than a urllib3 `HTTPResponse`. I can convert the `_build_raw` method to fix the test, if this looks like a workable solution.\n",
        "comments": 18
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2016-07-15T03:57:01Z",
        "closed_at": "2016-07-15T07:07:44Z",
        "merged_at": "2016-07-15T07:07:44Z",
        "body": "I was writing up a new test and found this comment block. Looks like it was commented out as part of a cleanup effort, but never removed. Test functionality is fulfilled by [this test](https://github.com/kennethreitz/requests/blob/master/tests/test_requests.py#L196).\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2016-07-14T15:49:18Z",
        "closed_at": "2016-07-14T16:59:51Z",
        "merged_at": "2016-07-14T16:59:51Z",
        "body": "Just reading through the source and found this dupe import - is it intentional? After running the tests locally before and after nothing fails... but there is some extra output as the test runs.\n\nBefore:\n\n```\nmake test\n# This runs all of the tests. To run an individual test, run py.test with\n# the -k flag, like \"py.test -k test_path_is_not_double_encoded\"\npy.test tests\n======================================= test session starts =======================================\nplatform darwin -- Python 2.7.11, pytest-2.8.7, py-1.4.31, pluggy-0.3.1\nrootdir: /Users/harrisonjackson/Zapier/requests, inifile:\nplugins: cov-2.2.1, httpbin-0.2.0, mock-0.11.0\ncollected 357 items\n\ntests/test_hooks.py ...\ntests/test_lowlevel.py .........\ntests/test_requests.py ................................................................................................................................X.........127.0.0.1 - - [14/Jul/2016 09:42:31] \"GET /stream/4 HTTP/1.1\" 200 1080\nX...................................................\ntests/test_structures.py ....................\ntests/test_testserver.py ...........\ntests/test_utils.py ............................................................................................................................\n\n============================= 355 passed, 2 xpassed in 42.56 seconds ==============================\n```\n\nAfter:\n\n```\nmake test\n# This runs all of the tests. To run an individual test, run py.test with\n# the -k flag, like \"py.test -k test_path_is_not_double_encoded\"\npy.test tests\n======================================= test session starts =======================================\nplatform darwin -- Python 2.7.11, pytest-2.8.7, py-1.4.31, pluggy-0.3.1\nrootdir: /Users/harrisonjackson/Zapier/requests, inifile:\nplugins: cov-2.2.1, httpbin-0.2.0, mock-0.11.0\ncollected 357 items\n\ntests/test_hooks.py ...\ntests/test_lowlevel.py .........\ntests/test_requests.py ...................127.0.0.1 - - [14/Jul/2016 09:44:19] \"GET /get HTTP/1.1\" 200 197\n................................................127.0.0.1 - - [14/Jul/2016 09:44:21] \"GET /gzip HTTP/1.1\" 200 205\n...127.0.0.1 - - [14/Jul/2016 09:44:21] \"GET /get?f%C3%B8%C3%B8=f%C3%B8%C3%B8 HTTP/1.1\" 200 370\n..........................................................X.........127.0.0.1 - - [14/Jul/2016 09:44:21] \"GET /stream/4 HTTP/1.1\" 200 1080\nX...................................................\ntests/test_structures.py ....................\ntests/test_testserver.py ...........\ntests/test_utils.py ............................................................................................................................\n\n============================= 355 passed, 2 xpassed in 41.34 seconds ==============================\n```\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-07-14T02:40:39Z",
        "closed_at": "2016-07-14T07:57:49Z",
        "merged_at": "2016-07-14T07:57:49Z",
        "body": "I think, should such an amendment.\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 30,
        "deletions": 7,
        "changed_files": 2,
        "created_at": "2016-07-07T15:13:22Z",
        "closed_at": "2016-07-07T16:20:03Z",
        "merged_at": "2016-07-07T16:20:03Z",
        "body": "Currently a non-string/bytes value will cause `pat.match(value)` to raise a TypeError from `re`. I'm proposing catching this exception and raising it as a more descriptive `InvalidHeader` instead, so that it's clear we're intending this to happen.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2016-07-06T21:15:46Z",
        "closed_at": "2016-07-07T14:56:08Z",
        "merged_at": "2016-07-07T14:56:08Z",
        "body": "These are a couple of minor doc tweaks to document the decision to enforce strings in header values. Since requests previously operated with non-string header values, I figured it was best to make note that an exception will now be thrown in the event of a non-string value.\n\nThere may be some formatting and wording changes needed, this iteration is mainly to get the conversation going.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2016-07-05T08:54:17Z",
        "closed_at": "2016-07-05T14:01:19Z",
        "merged_at": "2016-07-05T14:01:19Z",
        "body": "Currently this code raises UnicodeDecodeError:\n\n`requests.get('http://www.voice.fi//lampaan-kiveksia-ja-coca-cola-hulluutta-5-asiaa-joita-et-tiennyt-islannista-122015?utm_source=feed&utm_medium=feed&utm_content=article_link&utm_campaign=feed').ok`\n\nHere is their status:\n`HTTP/1.1 404 Komponenttia ei l\u00f6ydy`\n\nThis pull request allow module to handle URLs like this correctly\n",
        "comments": 18
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 9,
        "changed_files": 3,
        "created_at": "2016-07-01T23:42:41Z",
        "closed_at": "2016-07-02T07:33:31Z",
        "merged_at": "2016-07-02T07:33:31Z",
        "body": "@Lukasa @sigmavirus24 \n\nI tried running the tests on the proposed/3.0.0 branch, and found that they did not run. So I changed a couple of variable names to fix the obvious errors. If you prefer InvalidSchema and MissingSchema I can change those back, I changed the imports to match the names of the exceptions as they were defined.\n\nAfter these changes, there is still one failing test. I'll try to take a look and see if I can debug it. But this was low hanging fruit.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-07-01T20:18:53Z",
        "closed_at": "2016-07-02T18:10:20Z",
        "merged_at": "2016-07-02T18:10:20Z",
        "body": "Sorry to be bombarding you guys with PRs. This one is pretty minor but explains what I would say was non-obvious behaviour of the function before PR #3368 and PR #3365.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2016-07-01T03:55:18Z",
        "closed_at": "2016-07-02T20:56:20Z",
        "merged_at": "2016-07-02T20:56:20Z",
        "body": "This fixes the issue discussed in #3369 but may not be the best way. It adds a certain amount of additional complexity to iter_slices that may be better solved by using a try/except. If we throw an exception requiring an int for slice_length, we could pass `chunk_size or len(self._content)` [here](https://github.com/kennethreitz/requests/blob/master/requests/models.py#L691) and solve the issue that way as well.\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 75,
        "deletions": 7,
        "changed_files": 5,
        "created_at": "2016-06-29T17:57:41Z",
        "closed_at": "2016-07-02T19:32:17Z",
        "merged_at": "2016-07-02T19:32:17Z",
        "body": "Addresses issue raised in #2947.\n\nThis likely needs some tweaking. I added the check in `adapters.py` because it was the lowest level I could find header modification being done before sending. I'm not sure it actually needs to be this low though since it doesn't seem easily reachable with a non-`PreparedRequest` object.\n\nAlternatively, we could move the check to the [`prepare_headers`](https://github.com/kennethreitz/requests/blob/master/requests/models.py#L406) method in `PreparedRequest`.\n\nI also ignored `Accept` headers in the check because I the requirements in [RFC7230](https://tools.ietf.org/html/rfc7230#page-24) seems a bit vague.\n\n> This specification deprecates such line folding except within the message/http media type\n>    (Section 8.3.1).  A sender MUST NOT generate a message that includes line folding (i.e., that has any    field-value that contains a match to the obs-fold rule) unless the message is intended for packaging\n>    within the message/http media type.\n\nThis may be a poor interpretation on my part though.\n",
        "comments": 30
    },
    {
        "merged": true,
        "additions": 16,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2016-06-27T22:55:25Z",
        "closed_at": "2016-06-28T07:33:29Z",
        "merged_at": "2016-06-28T07:33:29Z",
        "body": "This should raise a type error if a non-integer chunk_size is passed. I'm assuming we're not concerned about a chunk_size of type long, but that may be wrong. Resolves issue #3364\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 19,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2016-06-24T13:31:31Z",
        "closed_at": "2016-06-28T19:22:00Z",
        "merged_at": "2016-06-28T19:22:00Z",
        "body": "\u2026behavior. Resolves #3359 \n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 45,
        "deletions": 16,
        "changed_files": 1,
        "created_at": "2016-06-23T04:25:28Z",
        "closed_at": "2016-06-23T06:06:56Z",
        "merged_at": null,
        "body": "This can be considered a request in the form of a PR because it was easier to make the code change than explain it. \n\nI have multiple places where i am passing around method, url, json etc before it makes it to the requests level. Now these can all be bundled up into a single request object which is much easier to pass around, but then i have to manually call\n\nprep = session.prepare_request(req)\nsettings = session.merge_environment_settings(....) \nsettings['timeout'] = timeout\nsession.send(prep, **settings)\n\nNow it's not super hard, but it's something that happens by default doing request() and it's certainly not intuitive. If we add a send_request() which does exactly the same as request() just on an existing request object it makes it much easier to correctly use Request objects.\n\nNote: If you like the idea but not the implementation and have something equivalent - please just do it your way. I don't care if this particular PR gets accepted or not if the idea gets up. I proposed this against 3.0 thinking it was going to be a more breaking change, but it seems pretty easy if you'd prefer i propose against master.\n\nThanks\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 19,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2016-06-16T20:00:58Z",
        "closed_at": "2016-08-24T18:02:00Z",
        "merged_at": null,
        "body": "Avoids having the (potentially large) object in memory twice.\n",
        "comments": 11
    },
    {
        "merged": false,
        "additions": 97,
        "deletions": 29,
        "changed_files": 5,
        "created_at": "2016-06-16T16:38:33Z",
        "closed_at": "2017-03-01T17:25:30Z",
        "merged_at": null,
        "body": "PR for proposed/3.0 with refactoring of `prepare_body` method. For discussion see #3184.\n",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2016-06-09T01:21:28Z",
        "closed_at": "2016-06-09T06:57:44Z",
        "merged_at": "2016-06-09T06:57:44Z",
        "body": "After looking through the code line, `requests.exceptions.HTTPError`s are only raised by `raise_for_status` but the docs made it seem like that error could happen through other means. This PR makes the docs explicit.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-06-08T15:26:13Z",
        "closed_at": "2016-06-08T16:44:33Z",
        "merged_at": "2016-06-08T16:44:33Z",
        "body": "Resolves #3096.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 56,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2016-06-06T14:41:02Z",
        "closed_at": "2016-06-17T13:00:05Z",
        "merged_at": "2016-06-17T13:00:05Z",
        "body": "",
        "comments": 10
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-06-06T02:09:25Z",
        "closed_at": "2016-08-08T12:04:22Z",
        "merged_at": null,
        "body": "",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-06-05T06:52:05Z",
        "closed_at": "2016-06-05T07:54:53Z",
        "merged_at": null,
        "body": "re #3238\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-06-01T16:01:06Z",
        "closed_at": "2016-06-01T18:08:39Z",
        "merged_at": "2016-06-01T18:08:39Z",
        "body": "Fixes #3250\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-05-29T18:57:33Z",
        "closed_at": "2016-06-21T02:17:24Z",
        "merged_at": "2016-06-21T02:17:24Z",
        "body": "This is only a minor improvement on the great work of https://github.com/kennethreitz/requests/pull/2859 that permits to run tests on hosts without Internet connection without failures.\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 5,
        "changed_files": 4,
        "created_at": "2016-05-29T11:48:56Z",
        "closed_at": "2016-05-29T13:09:48Z",
        "merged_at": null,
        "body": "As per their email \u2018Changes to project subdomains\u2019:\n\n> Starting today, Read the Docs will start hosting projects from subdomains on the domain readthedocs.io, instead of on readthedocs.org. This change addresses some security concerns around site cookies while hosting user generated data on the same domain as our dashboard.\n\nTest Plan: Manually visited all the links I\u2019ve modified.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-05-23T20:51:04Z",
        "closed_at": "2016-05-24T18:23:16Z",
        "merged_at": "2016-05-24T18:23:16Z",
        "body": "BaseAdapter should document the mandatory interfaces for implementing your own adapter from scratch for a different HTTP library. Currently requests requires all the parameters from HTTPAdapter implementation of send to be defined so copying them and relevant documentation over to the base adapter. Also adding relevant parts of documentation on what close is to the base class\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 24,
        "deletions": 6,
        "changed_files": 3,
        "created_at": "2016-05-16T21:41:53Z",
        "closed_at": "2017-02-10T17:18:50Z",
        "merged_at": null,
        "body": "As discussed on issue #2645, I added a success attribute to\nrequests.codes. Now, Response.ok checks if the response's status code\nis listed on requests.codes.success.\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 25,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2016-05-16T06:50:12Z",
        "closed_at": "2016-05-16T12:47:33Z",
        "merged_at": "2016-05-16T12:47:33Z",
        "body": "For ipv4 addresses no_proxy is not being honored. \n\n[This line ](https://github.com/kennethreitz/requests/blob/master/requests/utils.py#L539) checks for `cidr notation` but `plain ip` notation is not considered, due to which the request is always routed to proxy server. This results in error ReadTimeoutError\n\nSample `proxy` configuration\n\n```\nno_proxy=192.168.1.1,192.168.1.3,*.example.com\nhttp_proxy=http://192.168.1.100:8080\nhttps_proxy=http://192.168.1.100:8080\n```\n\n> When request is made to `192.168.1.1`, the request should not be made to proxy server, without this fix it is being made to proxy server `192.168.1.100`\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 52,
        "deletions": 6,
        "changed_files": 2,
        "created_at": "2016-05-14T00:46:52Z",
        "closed_at": "2016-05-17T15:45:12Z",
        "merged_at": "2016-05-17T15:45:12Z",
        "body": "So that failing tests don't cause the server thread to hang\nindefinitely, waiting for connections that will never come.\n\nRationale for suppressing error/traceback from interrupted\n_accept_connection in testserver.Server:\nhttps://gist.github.com/brettdh/b6e741227b2297f19d2118077f14dfa5\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-05-12T09:58:34Z",
        "closed_at": "2016-05-12T13:11:19Z",
        "merged_at": "2016-05-12T13:11:19Z",
        "body": "Looks like this crept in. It shouldn't break anything, it's in a multiline string, but still, let's get rid of it.\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 115,
        "deletions": 18,
        "changed_files": 8,
        "created_at": "2016-05-11T13:09:02Z",
        "closed_at": "2016-05-17T15:42:32Z",
        "merged_at": "2016-05-17T15:42:32Z",
        "body": "Closes #3183.\n",
        "comments": 14
    },
    {
        "merged": false,
        "additions": 97,
        "deletions": 29,
        "changed_files": 5,
        "created_at": "2016-05-11T04:01:14Z",
        "closed_at": "2017-02-10T17:18:18Z",
        "merged_at": null,
        "body": "@Lukasa Here's an alternative fix to #3066 (discussed in PR #3181), where I refactored `PreparedRequest.prepare_body` and `PreparedRequest.prepare_content_length` so that `prepare_content_length` is always called.\n\nMy only question is in the case when the body is a stream (which it is in the case that brought up this issue) that the current position will always be 0 when the length is calculated. Previously, in cases where `prepare_auth` was not called, the content length was being calculated with `super_len`, now it would be calculated using `self.headers['Content-Length'] = builtin_str(max(0, end_pos - curr_pos))`. As far as I can tell, this will give the same result (as long as the current position is 0), and this is how it's been computed in cases where authorization is being used. But I'm curious if you have thoughts about this.\n",
        "comments": 26
    },
    {
        "merged": false,
        "additions": 25,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2016-05-06T21:46:07Z",
        "closed_at": "2016-05-24T01:42:27Z",
        "merged_at": null,
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2016-05-05T03:17:47Z",
        "closed_at": "2016-05-06T12:59:01Z",
        "merged_at": "2016-05-06T12:59:01Z",
        "body": "[`self.content`](https://github.com/kennethreitz/requests/blob/master/requests/models.py#L728) could be `None`, so `len(self.content)` may raise `TypeError: object of type 'NoneType' has no len()`\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2016-05-05T00:26:23Z",
        "closed_at": "2016-05-22T16:02:09Z",
        "merged_at": "2016-05-22T16:02:09Z",
        "body": "Implements #3177.\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 0,
        "changed_files": 0,
        "created_at": "2016-05-04T17:01:34Z",
        "closed_at": "2016-11-15T09:47:36Z",
        "merged_at": null,
        "body": "In some cases the redirect is done to a different host.\nwhen the {\"Host\": \"www.example.com\"} is set in the headers and the request is redirected to another host, let's say www.another-example.com, the next request will be sent to a new URLwith a wrong Host header.\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 23,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-05-03T07:08:00Z",
        "closed_at": "2016-05-05T17:18:28Z",
        "merged_at": "2016-05-05T17:18:28Z",
        "body": "Resolves #3172.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-05-02T21:08:34Z",
        "closed_at": "2016-05-03T07:44:42Z",
        "merged_at": "2016-05-03T07:44:42Z",
        "body": "Just adding a quick note to inform users that it's not enough to point to a directory with the certificates but the directory needs to be \"indexed\". It took me some time to figure this out ... this simple note might save time to others in the future :).\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 77,
        "deletions": 33,
        "changed_files": 3,
        "created_at": "2016-04-21T20:47:49Z",
        "closed_at": "2016-09-29T20:30:31Z",
        "merged_at": "2016-09-29T20:30:31Z",
        "body": "This is not particularly polished yet, and depends on the as-yet unreleased\nurllib3 version 1.16. Still, I'd greatly appreciate some early feedback on how\n(in)sane this approach is. \n\nWith the addition of https://github.com/shazow/urllib3/pull/830 requests\nshould update the connection_pool_kw on the PoolManager so that new\nConnectionPools get created when TLS/SSL settings change. This ensures\nthat users can update the CA certificates used to verify servers as well\nas the client certificate and key it uses to authenticate with servers.\n\nThis fixes issue #2863\n\n---\n\nCloses #2863 \n",
        "comments": 13
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2016-04-18T09:10:17Z",
        "closed_at": "2016-04-18T13:42:50Z",
        "merged_at": null,
        "body": "Though #2149 is marked as closed, I had to do this because 1) I can't just give up requests and 2) I can't change the non-standard URLs I'm using. So I did a little hack. Now it goes like this:\n\n```\n>>> from urllib.parse import quote\n>>> requests.models.DEFAULT_QUOTE_VIA = quote\n>>> requests.models.DEFAULT_SAFE = '/?$=%'\n>>> r = requests.get('http://reddit.com/', params={'$foo': 'bar baz'})\n>>> r.url\n'https://www.reddit.com/?$foo=bar%20baz'\n```\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2016-04-16T09:59:53Z",
        "closed_at": "2016-04-17T17:26:25Z",
        "merged_at": "2016-04-17T17:26:25Z",
        "body": "Sentence contains reference to version 1.0.0.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 23,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2016-04-14T16:15:41Z",
        "closed_at": "2016-04-29T21:47:35Z",
        "merged_at": "2016-04-29T21:47:35Z",
        "body": "This will preserve order of request headers when passed to request method as `OrderedDict`.\n\nCloses #3038.\n",
        "comments": 13
    },
    {
        "merged": true,
        "additions": 16,
        "deletions": 2,
        "changed_files": 3,
        "created_at": "2016-04-13T16:25:31Z",
        "closed_at": "2016-04-15T12:50:06Z",
        "merged_at": "2016-04-15T12:50:06Z",
        "body": "Based on the explanation of the bug in #3090 this PR closes any pooled connections for any active ProxyManager object associated with the session.\n",
        "comments": 9
    },
    {
        "merged": false,
        "additions": 41,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2016-04-13T03:44:27Z",
        "closed_at": "2016-04-13T07:23:19Z",
        "merged_at": null,
        "body": "help things easy\n",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 46,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2016-04-08T17:28:11Z",
        "closed_at": "2016-04-11T12:38:50Z",
        "merged_at": "2016-04-11T12:38:50Z",
        "body": "An object with read / seek / tell but without __iter__ triggers a code path in requests which causes the stream to seek to the start instead of the position it was when it was passed into the data of the request. The faulty code is in models.py in the function prepare_content_length where it seeks to the start of the stream.\n\nThe tests fail currently because this is a test to expose the bug.\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-04-08T07:25:52Z",
        "closed_at": "2016-04-10T20:49:27Z",
        "merged_at": "2016-04-10T20:49:27Z",
        "body": "The 421 Misdirect Request status code was originally added in [RFC 7540](https://tools.ietf.org/html/rfc7540#section-11.7), and is going to be actively used in [RFC 7838](https://www.rfc-editor.org/rfc/rfc7838.txt). This adds it to our status code registry.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 66,
        "deletions": 17,
        "changed_files": 2,
        "created_at": "2016-03-18T04:23:45Z",
        "closed_at": "2016-03-20T18:46:00Z",
        "merged_at": "2016-03-20T18:46:00Z",
        "body": "I only moved the code into a function, there was no actual change to the code. I added a few tests to ensure we're doing things correctly.\n\nThe real point of me doing this is to make it easier to bring back `strict_mode` functionality. For you requests youngsters in the crowd, `strict_mode` followed the spec for redirects meaning the method wouldn't change to a GET. The current code follows the browser convention of changing the method to a GET when doing a 302 redirect. However, lots of servers want you to follow the standards (the nerve!) so I'd like to override the logic. Now that the method changing logic is in `rebuild_method`, I can simply override that function instead of overriding the entire `resolve_redirects` function as suggested by kennethreitz/requests#1325\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2016-03-17T19:47:29Z",
        "closed_at": "2016-04-06T19:01:25Z",
        "merged_at": "2016-04-06T19:01:25Z",
        "body": "This one aims to address https://github.com/kennethreitz/requests/issues/3050\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 8,
        "changed_files": 2,
        "created_at": "2016-03-16T14:55:30Z",
        "closed_at": "2016-03-16T16:00:24Z",
        "merged_at": null,
        "body": "Pull Request derived from the discussion on issue https://github.com/kennethreitz/requests/issues/3052\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 22,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-03-13T11:03:49Z",
        "closed_at": "2016-04-06T19:04:16Z",
        "merged_at": "2016-04-06T19:04:16Z",
        "body": "",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 79,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-03-13T10:09:05Z",
        "closed_at": "2016-04-06T19:06:36Z",
        "merged_at": "2016-04-06T19:06:36Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 8,
        "deletions": 17,
        "changed_files": 3,
        "created_at": "2016-03-09T15:28:46Z",
        "closed_at": "2016-03-09T18:11:26Z",
        "merged_at": null,
        "body": "Since `and` condition is there, `verify is not True` will be always false.\n",
        "comments": 11
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-03-09T05:02:18Z",
        "closed_at": "2016-03-09T08:59:44Z",
        "merged_at": "2016-03-09T08:59:44Z",
        "body": "`requests.codes` is a class (`LookupDict`), not a function.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 24,
        "deletions": 2,
        "changed_files": 3,
        "created_at": "2016-03-07T08:33:52Z",
        "closed_at": "2016-03-11T13:30:53Z",
        "merged_at": "2016-03-11T13:30:53Z",
        "body": "Resolves #3035.\n\nI'm not actually sure that this approach is the right one: I'm inclined to say that, when an exception is hit from `tell()`, that we may want to assume we don't know the length at all (return length 0) and use chunked-transfer encoding. That's a particularly good idea in this case, as frequently stdin has an unknown length altogether.\n\nThoughts on that point @sigmavirus24 and @jkbrzt?\n",
        "comments": 11
    },
    {
        "merged": false,
        "additions": 30,
        "deletions": 4,
        "changed_files": 3,
        "created_at": "2016-03-06T21:50:37Z",
        "closed_at": "2016-03-09T21:31:41Z",
        "merged_at": null,
        "body": "RFC2616 specifies that header values and reason phrases are encoded in in ISO-8859-1 or RFC2047 (MIME for text). RFC7230, which obsoletes RC2616, recommends treating non-ASCII header values as 'opaque data'.\n\nIn the case of the Reason Phrase, however, we should try to decode it as described due to its possible/encouraged localization and due to its purpose for display to the user; treating it as 'opaque data' is not useful and prevents its intended use.\n\nNote that several production servers, including Apache Tomcat, send responses conforming to RFC2616. Servers that respond only in US-ASCII are unaffected by this change. This _only_ regresses (by introducing possible encoding errors) for servers that send responses conforming to neither RFC, which I believe are either uncommon or non-existent.\n\nFixes kennethreitz/requests#3009\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 38,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2016-03-05T00:01:21Z",
        "closed_at": "2016-03-06T18:07:59Z",
        "merged_at": "2016-03-06T18:07:59Z",
        "body": "I've overwritten the `__contains__` method of `RequestsCookieJar` as discussed in the issue. It looks to be working as expected and tests pass, but this is my first contribution to this project so I could be missing something.\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-03-03T22:20:14Z",
        "closed_at": "2016-03-04T19:57:56Z",
        "merged_at": null,
        "body": "# Context\n\nIn here:\n\nhttps://github.com/kennethreitz/requests/blob/v2.7.0/requests/models.py#L464-L466\n\nThe content type is only set if the there isn't one already set. I feel this shouldn't be the case.\n\nAs we can see here:  https://github.com/kennethreitz/requests/blob/master/requests/packages/urllib3/filepost.py#L92\n\nThe content type string has a boundary generated by this method. This is specific to the body being encoded. Without this boundary and content type, the data being posted is no longer considered `Multipart Form Data`, which is the whole point of specifying `files=` in the post method.\n\nEven raising an exception would be better than silently skipping setting the content type.\n",
        "comments": 15
    },
    {
        "merged": true,
        "additions": 206,
        "deletions": 24,
        "changed_files": 2,
        "created_at": "2016-02-19T09:44:23Z",
        "closed_at": "2016-04-06T19:05:13Z",
        "merged_at": "2016-04-06T19:05:13Z",
        "body": "More unit tests for `utils` module. Also there is small cleanup for this module - removed unused imports & variable.\nLines coverage increased from 46% to 75%, but I'd like to ask about some functions, which are not used in `requests` at all (e.g `dict_to_sequence`, `from_key_val_list`, etc). Is there some plan for them? I wanted to write unit tests for it, but I'm not sure, may be they are staged to be deleted and it is not reasonable to cover them with unit tests.\n\nBR\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2016-02-18T17:28:38Z",
        "closed_at": "2016-02-19T01:49:15Z",
        "merged_at": null,
        "body": "Addresses Issue #3022.\n\nAlso added the JetBrains IDE settings folder, `.idea/`, to `.gitignore`.\n",
        "comments": 9
    },
    {
        "merged": false,
        "additions": 472,
        "deletions": 430,
        "changed_files": 14,
        "created_at": "2016-02-17T23:45:37Z",
        "closed_at": "2016-02-18T06:54:01Z",
        "merged_at": null,
        "body": "My attempt to fix [the issue I reported](https://github.com/kennethreitz/requests/issues/3017). Feel free to comment my changes, especially if you don't agree with them.\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 15,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2016-02-17T23:14:54Z",
        "closed_at": "2016-02-18T06:54:36Z",
        "merged_at": null,
        "body": "My attempt to fix [the issue I reported](https://github.com/kennethreitz/requests/issues/3017). Feel free to comment my changes, especially if you don't agree with them.\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1084,
        "deletions": 1,
        "changed_files": 10,
        "created_at": "2016-02-14T20:26:41Z",
        "closed_at": "2016-04-06T19:08:02Z",
        "merged_at": null,
        "body": "```\n>>> r = requests.get('http://httpbin.org/ip')\n\n>>> print r.request.dump()\nREQUESTS/2.9.1 GET http://httpbin.org/ip\nConnection: keep-alive\nAccept-Encoding: gzip, deflate\nAccept: */*\nUser-Agent: python-requests/2.9.1\n```\n",
        "comments": 63
    },
    {
        "merged": false,
        "additions": 7,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2016-02-11T18:30:48Z",
        "closed_at": "2016-04-06T18:56:17Z",
        "merged_at": null,
        "body": "",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 32,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-02-09T23:05:14Z",
        "closed_at": "2016-02-10T20:26:21Z",
        "merged_at": null,
        "body": "This feature is aimed at making debugging/following HTTP traffic easier on a developer. Many times in the past, I would send Requests' traffic through Burp proxy in order to have a visual representation of my HTTP traffic. With this pull request, a developer can simply call pprint() on their HTTP requests to see a Burp-like view of the traffic.\n\nExample usage:\n\n```\nimport requests\n\nr = requests.get(\"http://www.praetorian.com\")\nr.request.pprint()\nr.pprint(body=False)\n```\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 361,
        "deletions": 333,
        "changed_files": 6,
        "created_at": "2016-02-05T13:01:41Z",
        "closed_at": "2016-02-05T20:54:25Z",
        "merged_at": "2016-02-05T20:54:25Z",
        "body": "Hello, I want to propose some tests changes again :)\n\nWhat is done:\n1. All tests are moved to`tests` module.\n2. All tests related to `requests.utils` are separated in `tests.test_utils` module.\n3. Fixtures `httpbin` and `httpbin_secure` were slightly refactored and moved to `tests.conftest` module.\n4. `ThreadPool` was removed, because it was not used.\n5. All compatibility code was moved to `tests.compat`.\n6. More parametrization was added.\n\nI want to ask you if I'm going in the right way or not. Also I noticed, that `requests.utils` has ~45% coverage by unit tests, so, would you mind if I'll add more unit tests i this PR? If everything is ok\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 100,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-02-03T14:59:15Z",
        "closed_at": "2017-02-10T17:19:47Z",
        "merged_at": null,
        "body": "As mentioned in https://github.com/kennethreitz/requests/issues/2988, we might leverage the LRU cache to speed up the `proxy_bypass`, which might cause unexpected delay.\n",
        "comments": 18
    },
    {
        "merged": true,
        "additions": 172,
        "deletions": 161,
        "changed_files": 7,
        "created_at": "2016-02-02T13:04:14Z",
        "closed_at": "2016-02-03T08:26:27Z",
        "merged_at": "2016-02-03T08:26:27Z",
        "body": "Hello, I'd like to propose some refactorings for current test suite. First of all it is more about testing convenience, to make development process easier.\n\nCurrent changes:\n- Changed test running to setup.py. It allows to use some tuning on dependencies during test runs\n- Updated classifiers list. All tests run fine on Python 2.6 and PyPy. And almost all on Jython. I think it will not be a problem to deal with 2 failing tests, but will see.\n- Added config file for coverage. But I'm not sure about omitting \"_/packages/_\".\n- Added tox.ini to run tests against different Python versions locally.\n- Removed `unittest` from tests. It is not required for `py.test`. Also I've removed `_multiprocess_can_split_` because it is only related to `nose`.\n- Added some of py.test parametrization.\n- Replaced `assert False` with `pytest.fail`.\n- Fixed typo and added some minor improvements.\n\nSome thoughts and questions:\n- Coverage report shows, that code [here](https://github.com/kennethreitz/requests/compare/master...Stranger6667:tests-refactoring?expand=1#diff-56c2d754173a4a158ce8f445834c8fe8R616) is not executed. So, is there problem in hooks execution?\n- Split test module to some logically separated files. Current file is kind of huge. May be it will be better to have test suite in multiply files?\n- Python 3.2. Basically all tests pass on Python 3.2 / PyPy3 (based on Python 3.2). But `httpbin` dependency is not compatible with this Python version. But `requests` seems to be compatible. Any plans to keep compatibility with Python 3.2? May be rewrite some tests for Python 3.2 or something?\n- Jython. Most things are OK on Jython. Only 2 tests are failing - `TestRequests.test_pyopenssl_redirect` and `TestMorselToCookieExpires.test_expires_valid_str`. I don't know detail yet, but I hope, that it won't be a problem to fix it. Is it reasonable to run test suite against Jython? \n- Travis CI. I saw some CI-related lines in `Makefile`, but I don't see any info about in docs. Can you help me here? Also I can add some Travis CI config to run all configurations on it (including Jython)\n- Public coverage report. May I add some `codecov/coveralls` integration? Will it be helpful?\n\nIt is not a complete lists and I'll be glad to hear what do you think about it. Also I'll be happy to write more tests here :)\nThanks!\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-01-29T23:41:23Z",
        "closed_at": "2016-01-30T02:59:04Z",
        "merged_at": "2016-01-30T02:59:04Z",
        "body": "The argument description says `max_retries` can be an int, or a `urllib3.util.Retry` object. However, the type declared in the doc restricts it to int only. Passing a Retry object causes a warning in PyCharm code inspection.\n\nThe behaviour described for `max_retries` is accurate: HTTPAdapter passes `max_retries` to `Retry.from_int()`, which just returns the input if `max_retries` is a Retry object.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-01-27T11:57:13Z",
        "closed_at": "2016-01-27T16:19:27Z",
        "merged_at": "2016-01-27T16:19:27Z",
        "body": "We don't support them!\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2016-01-22T03:48:40Z",
        "closed_at": "2016-01-22T07:12:01Z",
        "merged_at": "2016-01-22T07:12:01Z",
        "body": "`httplib` was renamed in Python 3.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 26,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2016-01-20T00:53:26Z",
        "closed_at": "2016-01-21T23:01:58Z",
        "merged_at": "2016-01-21T23:01:58Z",
        "body": "I'm using requests to fetch data from websites that I don't maintain, and sometimes websites have broken cyclic redirects, but still return useful responses.  So I would like to grab the last cut off response, similar to the browser.\n\nThe problem is that `TooManyRedirects` doesn't throw the ending response state for me to inspect, so this PR adds that.\n",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 315,
        "deletions": 173,
        "changed_files": 19,
        "created_at": "2016-01-14T18:02:38Z",
        "closed_at": "2016-01-21T19:58:26Z",
        "merged_at": null,
        "body": "I just rebased the proposed 3.0.0 to current master near 2.9.1 to further help with socks support there also :)\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 22,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-01-04T16:39:11Z",
        "closed_at": "2016-01-30T03:08:26Z",
        "merged_at": "2016-01-30T03:08:26Z",
        "body": "A use case for this is mocking.\n\nIf you have a function that wrap a call like `requests.post('http://my_url', auth=HTTPBasicAuth(user, password))` and mock requests.post in your tests, calling `assert_called_once_with('http://my_url', auth=HTTPBasicAuth(user, password))` will fail.\n\nImplementing equality functions solves this use case.\n",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 268,
        "deletions": 46,
        "changed_files": 13,
        "created_at": "2015-12-30T10:46:50Z",
        "closed_at": "2016-04-29T22:03:04Z",
        "merged_at": "2016-04-29T22:03:04Z",
        "body": "This pull request _finally_ adds SOCKS proxy support to the Requests module, pretty much four years _to the day_ since we were first asked (in #324 for those who want to follow it).\n\nThis pull request relies on a pull request I have opened against urllib3, so we can't land it until urllib3 1.14.1 is released containing that code. However, once that's done this PR should be ready to rock.\n\nI'm setting this up for the 2.10.0 milestone as I see no reason to wait for 3.0.0 for SOCKS support.\n\nResolves #324, #723, #1147, #1982, #2156, #2425, and #2562.\n",
        "comments": 27
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2015-12-21T16:57:08Z",
        "closed_at": "2015-12-21T18:49:52Z",
        "merged_at": "2015-12-21T18:49:52Z",
        "body": "This closes #2062 by clarifying in the docs which auth\nheader takes precedence:\n1st auth=\n2nd .netrc\n3rd headers=\n\nThis precedence order is already tested in test_requests.py,\nin the test_basicauth_with_netrc method. Perhaps we should\nadd further tests for non-basic auth schemes.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 28,
        "deletions": 2,
        "changed_files": 3,
        "created_at": "2015-12-18T09:56:33Z",
        "closed_at": "2015-12-21T14:51:21Z",
        "merged_at": "2015-12-21T14:51:21Z",
        "body": "This release is scheduled for Monday. I'm aiming to set this up now so that it's an easy release to push on Monday.\n\n@shazow, what are the odds that we can get a urllib3 patch release 1.13.1 containing the fix for shazow/urllib3#761 by Monday? I'd owe you lots of :custard: if we could get it! :heart:\n",
        "comments": 16
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2015-12-18T09:23:48Z",
        "closed_at": "2015-12-19T17:34:34Z",
        "merged_at": "2015-12-19T17:34:34Z",
        "body": "Spotted this on my local machine running tests on Python 3. Annoyingly, we didn't see this on the CI rig because the Jenkins box doesn't have a netrc file, so it never gets that far in the function.\n\nHowever, tests preparing bytes URLs fail here on Python 3 because the splitter is the wrong type. This change ensures that we use the appropriate type.\n\nFeels like this is safe for 2.9.1.\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2015-12-15T16:10:53Z",
        "closed_at": "2015-12-15T17:22:06Z",
        "merged_at": null,
        "body": "distutils brokes when we use tuple based meta values\ncanonic way is define classifiers as list not a tuple\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 2,
        "changed_files": 3,
        "created_at": "2015-12-11T18:48:38Z",
        "closed_at": "2015-12-11T22:13:53Z",
        "merged_at": "2015-12-11T22:13:53Z",
        "body": "Specified the default argument for params that have a default in the docstring\nso that the default is easier to see from the code. Modified the docstring in\napi.py to match the docstring in sessions.py.\n",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 20,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2015-12-07T04:10:39Z",
        "closed_at": "2016-04-06T19:13:48Z",
        "merged_at": null,
        "body": "Use existing method `to_native_string()` as a check.\n\nThis is a first attempt to resolve https://github.com/kennethreitz/requests/issues/2638, so marking this PR as [DRAFT]. I'd appreciate feedback on this. \n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2015-12-05T16:21:42Z",
        "closed_at": "2015-12-06T04:48:52Z",
        "merged_at": "2015-12-06T04:48:52Z",
        "body": "Some malfunctioning HTTP servers may return a qop directive with no token, as\nopposed to correctly omitting the qop directive completely. For example:\n\n```\nheader: WWW-Authenticate: Digest realm=\"foobar_api_auth\", qop=\"\",\n        nonce=\"a12059eaaad0b86ece8f62f04cbafed6\", algorithm=\"MD5\",\n        stale=\"false\"\n```\n\nPrior to this patch, requests would respond with a 'None' Authorization header.\nWhile the server is certainly incorrect, this patch updates requests to be\nmore tolerant to this kind of shenaniganry. If we receive an empty string for\nthe value of the qop attribute, or some tokens that are not recognized (that\nis, not 'auth' or 'auth-int'), we instead treat that as if the qop attribute\nwas simply not provided.\n\nCloses #2916\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 912,
        "changed_files": 10,
        "created_at": "2015-12-04T08:22:53Z",
        "closed_at": "2016-01-15T23:35:03Z",
        "merged_at": "2016-01-15T23:35:03Z",
        "body": "Feedback is welcome! :grinning: \n## Before with @kennethreitz's sphinx theme\n\n![before_kr_sphinx_theme](https://cloud.githubusercontent.com/assets/954858/11584924/f6321290-9a1c-11e5-890c-11a20cf3ff8d.png)\n## After with alabaster sphinx theme\n\n![alabaster_theme_for_requests](https://cloud.githubusercontent.com/assets/954858/11672701/a4a17548-9dc7-11e5-8038-d2ca698b8aa9.png)\n",
        "comments": 20
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2015-11-26T22:15:14Z",
        "closed_at": "2017-02-10T17:44:57Z",
        "merged_at": null,
        "body": "A proposed fix for issue #2899.\n",
        "comments": 21
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2015-11-25T01:02:47Z",
        "closed_at": "2015-11-25T02:44:51Z",
        "merged_at": "2015-11-25T02:44:51Z",
        "body": "Remove duplicate word.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 258,
        "deletions": 0,
        "changed_files": 4,
        "created_at": "2015-11-24T23:20:45Z",
        "closed_at": "2016-04-11T20:29:02Z",
        "merged_at": "2016-04-11T20:29:02Z",
        "body": "Fixes #2866.\n### What is this?\n\nThis is an implementation of a basic socket server that is able to run concurrently with the main thread. This might be useful for testing our 'Transfer-Encoding: chunked' functionality as pytest-httpbin isn't able to handle this kind of encoding.\n### How does it work?\n\nYou provide the Server constructor with a handler that will be called once the socket server is listening. This handler will be able to accept clients and send and receive any info it wants to. The main thread will be able to query the server by creating a normal socket. \n### Syntax proposed\n\nI think that using a Context-Manager is a great way of making it easy to use the Server. \n\n``` python\nwith Server(handler) as host, port:\n    sock = socket.socket()\n    sock.connect((host, port))\n   ...\n```\n### Doubts\n- urllib3 tries to use a IPv6 socket and falls back to IPv4 when it can't. Should I try doing the same thing?\n- I made a new directory for dummyserver, but don't know whether that was the right thing to do.\n- I am not sure whether I'm testing my code properly. Code is being tested in very different ways in `test_requests.py`\n### Roadmap\n- Handle exceptions in Server.\n- Add features such as `basic_response_handler` in urllib3's implementation.\n- Implement more tests\n- Implement 'Transfer-Encoding: chunked' tests using the dummy server.\n\nIs this a good idea? Or should I stop doing this right now?\n",
        "comments": 44
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2015-11-23T19:55:37Z",
        "closed_at": "2015-12-02T14:35:41Z",
        "merged_at": "2015-12-02T14:35:41Z",
        "body": "Fixes #2215 \n\nThis is the first time I contribute to the project so I am not sure at all I put that code where it belongs. I know I have to add tests for this, but wanted to show you this beforehand.\n\nDid I do this right?\n\nThank you\n",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 57,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2015-11-20T11:30:20Z",
        "closed_at": "2015-11-20T14:14:59Z",
        "merged_at": "2015-11-20T14:14:59Z",
        "body": "It's beginning to get frustrating to have to keep dealing with questions on this issue tracker. Let's see if we can dissuade them.\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 24,
        "deletions": 22,
        "changed_files": 1,
        "created_at": "2015-11-12T21:19:12Z",
        "closed_at": "2015-11-12T23:05:17Z",
        "merged_at": null,
        "body": "`Response.text` is a pure function, seems pointless doing the same conversions in repeated calls. \n\nCached\n\n```\nIn [4]: %timeit any(word in resp.text for word in words)\nThe slowest run took 6.20 times longer than the fastest. This could mean that an intermediate result is being cached \n100000 loops, best of 3: 17.4 \u00b5s per loop\n```\n\nNot cached\n\n```\nIn [5]: %timeit any(word in resp.text_old for word in words)                                                                            \n10000 loops, best of 3: 64.4 \u00b5s per loop\n```\n\n`len(words) == 3` in these examples, in a real world use case it could be much longer.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 24,
        "deletions": 9,
        "changed_files": 2,
        "created_at": "2015-11-11T03:22:53Z",
        "closed_at": "2015-11-11T07:52:47Z",
        "merged_at": "2015-11-11T07:52:47Z",
        "body": "See #2872\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2015-11-10T11:40:58Z",
        "closed_at": "2015-11-10T13:21:01Z",
        "merged_at": "2015-11-10T13:21:01Z",
        "body": "Flat is better than nested. Instead of nesting `if` statements, check for the opposite early in the loop and `continue` if the opposite is the case.\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2015-11-05T18:55:57Z",
        "closed_at": "2015-11-07T17:50:50Z",
        "merged_at": "2015-11-07T17:50:50Z",
        "body": "Turns out we broke chunked uploads in 8f591682e6a901baf0cc8a0393b5930252f0318a. I discovered this while investigating #2215.\n\nWhile we were here, I added a test that would at least have caught errors as egregious as this one.\n",
        "comments": 12
    },
    {
        "merged": true,
        "additions": 141,
        "deletions": 137,
        "changed_files": 2,
        "created_at": "2015-11-05T13:48:32Z",
        "closed_at": "2015-11-05T15:37:22Z",
        "merged_at": "2015-11-05T15:37:22Z",
        "body": "Resolves #2184, and should allow us to move back to Travis for our testing.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 16,
        "deletions": 2,
        "changed_files": 3,
        "created_at": "2015-11-05T13:22:14Z",
        "closed_at": "2015-11-07T21:39:41Z",
        "merged_at": "2015-11-07T21:39:41Z",
        "body": "Resolves #2659.\n\nThis would have to go in 2.9.0.\n\nOnce again, our test suite isn't really in a place that lets us effectively test this.\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 71,
        "deletions": 10,
        "changed_files": 2,
        "created_at": "2015-10-21T08:24:30Z",
        "closed_at": "2016-04-15T21:38:50Z",
        "merged_at": "2016-04-15T21:38:50Z",
        "body": "Resolves #2836.\n\nThis actually requires a slightly tricky re-ordering here: the proxies work needs to happen separately to make sure keys set to `None` DTRT.\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 18,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2015-10-19T23:02:35Z",
        "closed_at": "2015-10-21T08:24:44Z",
        "merged_at": null,
        "body": "session.verify is currently ignored. Didn't have time for a unit test, but this is one solution.\n",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 52,
        "deletions": 7,
        "changed_files": 4,
        "created_at": "2015-10-16T18:39:49Z",
        "closed_at": "2015-10-17T21:15:13Z",
        "merged_at": null,
        "body": "This is pretty hard to reproduce, but I have seen truncated responses in the presence of connection resets that are silently ignored by requests.\n\nThis link describes how the vagaries of TCP and socket API may return an error or 0 (end-of-file) when the stars align just right:\n  http://blog.netherlabs.nl/articles/2009/01/18/the-ultimate-so_linger-page-or-why-is-my-tcp-not-reliable\n\nThis patch checks that the number of bytes read matches the declared Content-Length (when declared). I'm not an HTTP expert, so I may be missing something, but I hope this is useful. This also only covers the urllib3 code path.\n",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 66,
        "deletions": 4,
        "changed_files": 5,
        "created_at": "2015-10-14T12:24:27Z",
        "closed_at": "2015-10-24T14:37:16Z",
        "merged_at": "2015-10-24T14:37:16Z",
        "body": "Resolves #2725.\n\n@sigmavirus24 I'm wondering if we should add a warning to `super_len` for whenever we decide on the length of the file using `os.fstat`, if the file has not been opened in binary mode. It should be easy enough to do. Thoughts?\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 4,
        "changed_files": 3,
        "created_at": "2015-10-12T09:49:35Z",
        "closed_at": "2015-10-12T14:50:53Z",
        "merged_at": "2015-10-12T14:50:53Z",
        "body": "Resolves #2818.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2015-10-08T13:54:23Z",
        "closed_at": "2015-10-08T15:13:08Z",
        "merged_at": "2015-10-08T15:13:08Z",
        "body": "Resolves #2813.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1391,
        "deletions": 801,
        "changed_files": 1,
        "created_at": "2015-10-08T07:12:37Z",
        "closed_at": "2015-10-08T16:12:09Z",
        "merged_at": "2015-10-08T16:12:09Z",
        "body": "This brings it up-to-date with the certifi 2015.9.6.2 release, specifically the `weak.pem` bundle that still contains the 1024-bit root certificates. This is really as aggressive as I'm happy to be with requests at this time.\n\nResolves #2809.\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 123,
        "deletions": 67,
        "changed_files": 12,
        "created_at": "2015-10-05T14:39:54Z",
        "closed_at": "2015-10-05T16:21:40Z",
        "merged_at": "2015-10-05T16:21:40Z",
        "body": "This contains the final remaining chunks of work for 2.8.0: updated changelog and updated urllib3. When we merge this we'll be in code-freeze until we release.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 7,
        "changed_files": 2,
        "created_at": "2015-10-02T23:02:42Z",
        "closed_at": "2015-10-03T17:33:57Z",
        "merged_at": "2015-10-03T17:33:57Z",
        "body": "Fixes #2799 \n",
        "comments": 11
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2015-09-28T02:51:36Z",
        "closed_at": "2015-09-30T13:29:27Z",
        "merged_at": "2015-09-30T13:29:27Z",
        "body": "I don't have the time to dedicate to this any longer unfortunately.\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 23,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2015-09-23T16:45:57Z",
        "closed_at": "2015-10-01T07:26:01Z",
        "merged_at": null,
        "body": "Whenever chunked request was made (using generators) read timeout value was ignored because socket timeout was not set.\n\nThis can be a problem when system default timeout is very long because blocks process waiting for response for a period of time that cannot be controlled.\n\nChanges:\n- `HTTPAdapter.send()` now sets read timeout on `low_conn.sock` socket when request body is chunked.\n- socket.error, socket.timeout are explicitely translated to urllib3 exceptions using `conn._raise_timeout`\n  as expected with non-chunked request bodies to be later translated to `requests` exceptions with existing code.\n- test added for timeouts on chunked-message body requests\n\nAdditional notes:\n- due to convention to use httbin in requests tests and no posibility\n  to tests POST timeouts with `delay/:n` endpoint (method not allowed)\n  test for this bug uses GET with chunked message-body. This is OK\n  because RFC-2616 does not explicitely say that message-body is\n  forbidden in GET requests. And also it works\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2015-09-21T18:09:10Z",
        "closed_at": "2016-01-30T03:29:55Z",
        "merged_at": null,
        "body": "",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2015-09-13T10:36:42Z",
        "closed_at": "2015-09-13T12:26:05Z",
        "merged_at": "2015-09-13T12:26:05Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 13,
        "changed_files": 1,
        "created_at": "2015-09-13T00:42:11Z",
        "closed_at": "2015-09-13T05:05:34Z",
        "merged_at": "2015-09-13T05:05:34Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 22,
        "deletions": 22,
        "changed_files": 1,
        "created_at": "2015-09-11T17:56:06Z",
        "closed_at": "2015-09-11T19:22:13Z",
        "merged_at": "2015-09-11T19:22:13Z",
        "body": "When reading the SSL Cert Verification documentation and working on directing requests to use a system's local CA store I never noticed the CA Certificates documentation as it is at the tail end of the Advanced page.  I suggest it would be better to have the CA Certificates documentation immediately follow the documentation regarding SSL Cert Verification.\n\nNo content change, just a relocation of existing verbiage.\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2015-09-11T04:42:27Z",
        "closed_at": "2015-09-11T06:15:28Z",
        "merged_at": null,
        "body": "Since a context manager is defined for session, i thought it would be better (and more pythonic) to use it. All the tests passed. Let me know what you guys think\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2015-09-10T20:26:51Z",
        "closed_at": "2015-09-10T22:01:59Z",
        "merged_at": null,
        "body": "Small suggestion as this was something I heard in Raymond Hettinger's talk at PyCon 2015\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2015-09-08T09:19:51Z",
        "closed_at": "2015-10-05T14:27:53Z",
        "merged_at": "2015-10-05T14:27:53Z",
        "body": "Now 'json' parameter will be used to prepare body only if the 'data'\nparameter is not present\n",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2015-09-05T10:08:59Z",
        "closed_at": "2015-09-05T21:01:39Z",
        "merged_at": "2015-09-05T21:01:39Z",
        "body": "Minor nitpick: The quote in http://www.python-requests.org/en/latest/user/quickstart/#response-headers is currently not formatted properly. This PR fixes this.\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 58,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2015-09-05T06:33:55Z",
        "closed_at": "2016-04-06T19:15:38Z",
        "merged_at": null,
        "body": "Trying to address #1558 by first creating a failing test, but I'm not sure when `PreparedRequest`s fail to be pickleable. Pulling early to see if anyone has suggestions on how to re-create the issue, also maybe these tests are useful on their own as well.\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 62,
        "deletions": 9,
        "changed_files": 3,
        "created_at": "2015-09-01T08:35:36Z",
        "closed_at": "2016-04-15T21:39:18Z",
        "merged_at": "2016-04-15T21:39:18Z",
        "body": "Resolves #2653.\n\nFollows on from #2655: please read the discussion there for more information.\n",
        "comments": 13
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2015-08-31T09:26:44Z",
        "closed_at": "2015-09-01T01:34:11Z",
        "merged_at": "2015-09-01T01:34:11Z",
        "body": "Just a little bit of extra example documentation.\n\nResolves #2652.\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2015-08-29T02:19:45Z",
        "closed_at": "2015-08-29T12:21:07Z",
        "merged_at": "2015-08-29T12:21:07Z",
        "body": "Fixes #2750 \n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2015-08-25T20:10:24Z",
        "closed_at": "2015-08-26T00:38:04Z",
        "merged_at": "2015-08-26T00:38:04Z",
        "body": "Fixes #2744 \n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2015-08-25T01:47:46Z",
        "closed_at": "2015-08-25T07:27:20Z",
        "merged_at": "2015-08-25T07:27:20Z",
        "body": "On Python 2.6, there's no `OrderedDict` in the `collections` module.\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2015-08-24T23:29:58Z",
        "closed_at": "2015-08-25T01:44:45Z",
        "merged_at": "2015-08-25T01:44:45Z",
        "body": "If `requests.api.request()` uses `requests.sessions.Session.request()` to get it's work done then the data arg description should match between the two.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 42,
        "deletions": 13,
        "changed_files": 5,
        "created_at": "2015-08-24T21:17:16Z",
        "closed_at": "2015-09-06T03:02:41Z",
        "merged_at": "2015-09-06T03:02:41Z",
        "body": "This change allows the proxy dict to be have entries of the form\n`{'<scheme>://<hostname>': '<proxy>'}`.  Host-specific proxies will be used in\npreference to the scheme-specific proxies (i.e., proxy dict entries with keys\nlike 'http' or 'https').\n\nFixes #2722\n",
        "comments": 24
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 6,
        "changed_files": 3,
        "created_at": "2015-08-15T10:11:50Z",
        "closed_at": "2015-08-15T13:24:20Z",
        "merged_at": "2015-08-15T13:24:20Z",
        "body": "This fixes three links (from docstrings) to the [<`timeouts`>](http://docs.python-requests.org/en/latest/user/advanced/#timeouts) section by using `:ref:` instead of linking to `.html` files (which are only available when building docs locally, but not in the published docs on RTD).\n\nFixes #2698\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2015-08-14T14:37:04Z",
        "closed_at": "2015-08-14T19:30:00Z",
        "merged_at": "2015-08-14T19:30:00Z",
        "body": "As suggested in #2686, I added a snippet about `requests.post(json=...)` to [Quickstart#More complicated POST requests](http://docs.python-requests.org/en/latest/user/quickstart/#more-complicated-post-requests).\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2015-08-13T19:05:23Z",
        "closed_at": "2015-10-05T14:28:49Z",
        "merged_at": "2015-10-05T14:28:49Z",
        "body": "Resolves #2720.\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 66,
        "deletions": 11,
        "changed_files": 4,
        "created_at": "2015-08-08T03:16:16Z",
        "closed_at": "2017-02-10T17:21:45Z",
        "merged_at": null,
        "body": "This ensures that we follow RFC 6265 Section 4.1.2.3 appropriately. If a\ncookie is returned without a domain attribute, we do not want to send it\nto subdomains.\n\nCloses #2576 \n\n---\n\nNeeds:\n- [ ] Tests\n- [ ] Documenting this breaking change\n- [ ] Porting to requests-toolbelt for early adopters\n- [ ] Backport to master for a 2.x release\n",
        "comments": 14
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2015-08-07T23:01:27Z",
        "closed_at": "2015-08-08T01:18:21Z",
        "merged_at": "2015-08-08T01:18:21Z",
        "body": "This adds a paragraph to the **session docs** that clarifies the fact that **method-level parameters are not persisted across requests**, even when a session is being used (fixes #2488).\n\nAs an example I used cookies, and included a pointer to the [Cookie utility functions](http://docs.python-requests.org/en/latest/api/#cookies). In order to be able to link to that section I added some section labels in `docs/api.rst` (prefixed with `api-`, because otherwise there would be label collisions).\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 21,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2015-08-07T19:07:15Z",
        "closed_at": "2015-08-07T20:41:21Z",
        "merged_at": "2015-08-07T20:41:21Z",
        "body": "This adds some documentation on how to use sessions as **context managers** (fixes #2580). I also added a brief mention of **connection pooling** and its performance benefits.\n\nI still got one question though: Is instantiating [`Session`](https://github.com/kennethreitz/requests/blob/9b067db19e20226dcb3aa407605d30942d085050/requests/sessions.py#L267) directly the proper API to document? I noticed that there's also a [`session()` factory function](https://github.com/kennethreitz/requests/blob/9b067db19e20226dcb3aa407605d30942d085050/requests/sessions.py#L674-L677) that explicitly mentions context management in its docstring. But I then saw this in the [API changes section](http://www.python-requests.org/en/latest/api/?highlight=backwards%20compatibility#api-changes):\n\n> The `Session` API has changed. Sessions objects no longer take parameters. `Session` is also now capitalized, but it can still be instantiated with a lowercase `session` for backwards compatibility.\n\nSo I therefore used `Session()` in the examples, and I'm assuming that factory function is only there for backwards compatibility. Should I update its docstring with something like `Alias for backwards compatibility`?\n\nLet me know how you'd like it documented, and I'll update my PR accordingly.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2015-08-04T21:50:38Z",
        "closed_at": "2015-08-15T15:39:46Z",
        "merged_at": "2015-08-15T15:39:46Z",
        "body": "Fix a bug introduced by https://github.com/kennethreitz/requests/pull/1921\n\nBug: the ordered dictionary (the default `dict_class`) is accidentally converted back to normal dictionary.\n",
        "comments": 13
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 9,
        "changed_files": 1,
        "created_at": "2015-07-28T01:07:29Z",
        "closed_at": "2015-07-28T02:34:36Z",
        "merged_at": null,
        "body": "for services that require Authorization in the header, all redirect calls to a different domain would result in a 403-Forbidden.  Authorization should be preserved just as Authentication is.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2015-07-18T22:50:57Z",
        "closed_at": "2015-07-19T09:57:01Z",
        "merged_at": "2015-07-19T09:57:01Z",
        "body": "The special `[]` notation at the end of the field name is not necessary to get a field to appear with multiple values in the query string.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 590,
        "deletions": 144,
        "changed_files": 18,
        "created_at": "2015-07-18T15:45:52Z",
        "closed_at": "2015-10-05T14:09:41Z",
        "merged_at": "2015-10-05T14:09:41Z",
        "body": "Includes\n- #2674 \n- #2567 \n- #2523 \n- #2706\n- Bump for urllib3\n\nReminder to look at http://ci.kennethreitz.org/job/requests-pr/ for build status\n",
        "comments": 15
    },
    {
        "merged": false,
        "additions": 23,
        "deletions": 2,
        "changed_files": 3,
        "created_at": "2015-07-17T10:46:30Z",
        "closed_at": "2015-07-18T15:26:20Z",
        "merged_at": null,
        "body": "Fixes https://github.com/kennethreitz/requests/issues/2675\n",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2015-07-17T08:33:52Z",
        "closed_at": "2015-10-05T14:09:46Z",
        "merged_at": "2015-10-05T14:09:46Z",
        "body": "Partially resolves #1572: \"urllib3 exceptions passing through requests\nAPI\". #1572 \n\nInspired from @Lukasa's previous 2605be11d82d42438ac7c3993810c955bde74cef.\n\nThis is my first PR to requests library; feel free to give me feedback. I generally have a fast response time. Also, available on IRC and Twitter (@ArcTanSusan).\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2015-07-15T22:31:06Z",
        "closed_at": "2015-07-16T01:51:07Z",
        "merged_at": "2015-07-16T01:51:07Z",
        "body": "Previously this section prefaced an example with:\n\n```\nFor example, we didn't specify our content-type\n```\n\nBut, the actual example set a custom user-agent header on the request. This\nchanges it to say \"user-agent\" instead which matches the given example.\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2015-07-15T16:34:07Z",
        "closed_at": "2015-07-18T15:48:26Z",
        "merged_at": null,
        "body": "InsensitiveDict.**repr** does not order the members, which on\nPython 3 causes TestCaseInsensitiveDict.test_repr to fail.\n\nFixes issue #2668\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 18,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2015-07-13T12:35:19Z",
        "closed_at": "2015-07-14T06:57:58Z",
        "merged_at": "2015-07-14T06:57:58Z",
        "body": "This adds extra tstes for `requests.structures.CaseInsensitiveDict`\n- Test for NotImplemented in `__eq__`\n- Adds test for `copy()`\n- Adds test for `__repr__()`\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2015-07-10T08:14:54Z",
        "closed_at": "2015-07-13T21:01:31Z",
        "merged_at": null,
        "body": "Referring to #1926\nMaybe I am wrong, but my understanding was that header fields must be latin-1 encoded.\nThis is awlays true for Basic Authentication headers, since base64 encoded strings consist of plain ascii.  \nI would think however that `<username>:<password>` may contain special characters, as long as client and server assume the same encoding (for example utf8).\n\nThis code currently encodes the credentials:\n\n``` py\ndef _basic_auth_str(username, password):\n    \"\"\"Returns a Basic Auth string.\"\"\"\n\n    authstr = 'Basic ' + to_native_string(\n        b64encode(('%s:%s' % (username, password)).encode('latin1')).strip()\n    )\n\n    return authstr\n```\n\nbut could be changed to encode the base64 header string instead:\n\n``` py\n        ...\n        b64encode(('%s:%s' % (username, password))).encode('latin1').strip()\n```\n",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2015-07-03T16:04:53Z",
        "closed_at": "2015-07-04T20:19:37Z",
        "merged_at": "2015-07-04T20:19:37Z",
        "body": "So `_get_conn` doesn't use a urllib3 `Timeout` object, it only takes a float. It also only does stuff if `block` is `True`. Given that by default we use `block=False`, it won't do anything, so let's not use it. However, if someone changes that with a global constant they may want to be able to change this too, so let's make it a named constant.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2015-06-29T02:18:17Z",
        "closed_at": "2015-06-29T07:24:21Z",
        "merged_at": "2015-06-29T07:24:21Z",
        "body": "If the netrc file exists but cannot be parsed or read, get_netrc_auth\nsilently fails.\n\nAdd a new argument `ignore_errors` which when set to False will cause\nany parse/permission errors to be raised to the caller.  The default\nvalue is True, which means the default behavior is unchanged.\n\nFixes #2654\n\nChange-Id: I7436aaaf593178673ab84fd9e7ab4bcb0e3fe75e\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 20,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2015-06-28T15:58:44Z",
        "closed_at": "2015-09-01T08:32:21Z",
        "merged_at": null,
        "body": "Resolves #2653.\n\nThis is one of those annoying changes that's almost impossible to test because of the sheer complexity of our redirect handling code. This also doesn't make it any simpler, sadly.\n\nAs to what version we merge this into, I proposed it against the master branch. I don't think it belongs in 3.0.0 (`resolve_redirects` isn't really part of our public API), but it could definitely break people's stuff. Next minor release feels appropriate, but I'd like to hear what you think @sigmavirus24.\n",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 141,
        "deletions": 7,
        "changed_files": 2,
        "created_at": "2015-06-15T02:41:51Z",
        "closed_at": "2015-06-15T09:21:23Z",
        "merged_at": null,
        "body": "Use an object pool, making api.py support for keepalive\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2015-06-13T07:11:39Z",
        "closed_at": "2015-06-13T13:54:40Z",
        "merged_at": "2015-06-13T13:54:40Z",
        "body": "Resolves #2636\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2015-06-05T06:05:45Z",
        "closed_at": "2015-06-21T14:22:55Z",
        "merged_at": "2015-06-21T14:22:55Z",
        "body": "Empty chunk in request body could prematurely signal end of chunked\ntransmission. As a result, the terminating zero-size chunk sent by\n'requests' can be interpretted as bad request by the recepient. I\nhave used the same logic used by httplib to handle such cases.\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2015-06-05T04:39:31Z",
        "closed_at": "2016-01-30T03:49:28Z",
        "merged_at": null,
        "body": "This change allows the existing test script (test_requests.py) to be invoked via the standard setuptools test command. It also declares pytest as a test_dependency, so that it is installed on a test run, if not available.\n",
        "comments": 14
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 7,
        "changed_files": 3,
        "created_at": "2015-05-28T17:09:51Z",
        "closed_at": "2015-07-18T15:43:50Z",
        "merged_at": "2015-07-18T15:43:50Z",
        "body": "This fixes #2613. I believe that this technically constitutes a backward-incompatible API change, so I've proposed this against 3.0.0. Let me know if you disagree @sigmavirus24 (the other option is really that this is a bugfix), and I'll propose against master.\n",
        "comments": 11
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2015-05-25T21:10:37Z",
        "closed_at": "2015-05-26T19:56:18Z",
        "merged_at": null,
        "body": "IDE auto-complete error.  \n\nedit:  edited to be a bit more pythonic\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2015-05-24T14:01:17Z",
        "closed_at": "2015-05-25T17:15:57Z",
        "merged_at": "2015-05-25T17:15:57Z",
        "body": "\u2026 (issue #2593)\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 8,
        "changed_files": 2,
        "created_at": "2015-05-21T00:26:12Z",
        "closed_at": "2015-05-21T08:16:24Z",
        "merged_at": "2015-05-21T08:16:24Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2015-05-14T10:45:17Z",
        "closed_at": "2015-05-15T15:14:56Z",
        "merged_at": null,
        "body": "Example:\n\nhere are Set-Cookie list:\n\n``` python\nsclst = ['dwac_bcIBMiaagZmkYaaadeYtg11eVR=j9jHdmPjUhgDOhyH9f89X4lQgehEmflVyeA%3D|dw-only|||CNY|false|Asia%2FShanghai|true; Path=/',\n 'sid=j9jHdmPjUhgDOhyH9f89X4lQgehEmflVyeA; Path=/',\n 'geoLocation=CN; Path=/',\n 'dwpersonalization_fae107a9dd0fc32ed99532ec1977f31f=bc8sEiaagZqRsaaadk8XoNTL8h20150506; Expires=Sun, 14-Jun-2015 10:37:07 GMT; Path=/',\n 'dwanonymous_fae107a9dd0fc32ed99532ec1977f31f=abjpA8kng31LjPp8ZEERDT4XVg; Version=1; Comment=\"Demandware anonymous cookie for site Sites-abercrombie_cn-Site\"; Max-Age=15552000; Expires=Tue, 10-Nov-2015 10:37:07 GMT; Path=/',\n 'myStore=91156; Path=/',\n 'AF_PREF=en_CN; Path=/',\n 'dwsid=MiHJy3KYZKDcN0lZg4HS1zSpj1VV4s_tFu39ar0KXNpAx9aX8X2LlvZQ9m5fOOknb6QXtmmukHcOjmivYf31hg==; path=/; HttpOnly']\n```\n\n``` python\n    for sc in sclst:\n        C = Cookie.SimpleCookie(sc)\n        for morsel in C.values():\n            cookie = requests.cookies.morsel_to_cookie(morsel)\n            cookiejar.set_cookie(cookie)\n```\n\nThen, exception occured\n\n``` shell\n  File \"/Library/Python/2.7/site-packages/requests/cookies.py\", line 402, in morsel_to_cookie\n    expires = time.time() + morsel['max-age']\nTypeError: unsupported operand type(s) for +: 'float' and 'str'\n```\n\nAs Cookie.SimpleCookie is in STL, should `morsel_to_cookie` check the type of `max-age`? On the other hand, if **max-age** can not be converted to float, it's illegal obviously.\n",
        "comments": 10
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2015-05-13T06:08:49Z",
        "closed_at": "2015-05-14T22:32:19Z",
        "merged_at": "2015-05-14T22:32:19Z",
        "body": "As discussed in the comments for ab84f9be5740d4649d734e73b84f17f85e52ffc9, this code block is necessary thanks to our shiny `json` parameter.\n\nAs a temporary workaround, this reinstates the code Kenneth hates so much so that the builds start working again. @kennethreitz feel free to replace this with something else longer term if you still hate it. :grin:\n",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2015-05-12T23:22:24Z",
        "closed_at": "2015-05-13T06:16:44Z",
        "merged_at": "2015-05-13T06:16:44Z",
        "body": "see shazow/urllib3#618\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2015-05-04T00:34:20Z",
        "closed_at": "2015-05-04T02:18:37Z",
        "merged_at": "2015-05-04T02:18:37Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 8,
        "changed_files": 2,
        "created_at": "2015-05-03T19:24:01Z",
        "closed_at": "2015-05-04T13:05:36Z",
        "merged_at": "2015-05-04T13:05:36Z",
        "body": "Many people expect to be able to say:\n\n```\nresponse = make_request(url)\n\nif response:\n    body = response.content\n```\n\nWhere the first part should test for whether or not response is None.\nInstead, the **bool** and **nonzero** methods return response.ok, so if\nthe response is actually a 4xx or 5xx response, then the user would\nexpect to get the body of the response.\n\nBy removing these methods, we restore the functionality that most users\nexpect.\n\nCloses #2002 \n\n---\n\n**Note** this is development for 3.0.0\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2015-05-01T04:01:51Z",
        "closed_at": "2015-05-01T05:59:46Z",
        "merged_at": "2015-05-01T05:59:46Z",
        "body": "I opened issue #2581, and since it is such a small change, I just went ahead and opened the pull request immediately.\n\nThis makes the docstring for `requests.get` clearer so when someone does `help(requests.get)` they can see that `params` is an optional kwarg that can be used to attach query string parameters to a GET request.  I think this change makes it symmetric with `requests.post` which specifically mentions `data` and `json` for body and json parameters.  As I mentioned in #2581, query string parameters are as relevant to GET requests as json and body parameters are to POST requests, so this change makes a lot of sense in that respect. \n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 56,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2015-04-25T00:29:09Z",
        "closed_at": "2015-04-25T21:46:31Z",
        "merged_at": "2015-04-25T21:46:31Z",
        "body": "Closes #2569\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 39,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2015-04-24T10:05:43Z",
        "closed_at": "2015-10-05T14:09:46Z",
        "merged_at": "2015-10-05T14:09:46Z",
        "body": "Alternative to #2375, on the risk of being naive...\n",
        "comments": 63
    },
    {
        "merged": true,
        "additions": 172,
        "deletions": 169,
        "changed_files": 11,
        "created_at": "2015-04-22T13:19:47Z",
        "closed_at": "2015-04-22T22:12:26Z",
        "merged_at": "2015-04-22T22:12:26Z",
        "body": "I'll probably update the history and such in this branch too.\n\n/cc @aanand\n",
        "comments": 22
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2015-04-21T01:14:53Z",
        "closed_at": "2015-04-21T05:59:55Z",
        "merged_at": "2015-04-21T05:59:55Z",
        "body": "Do not require that hooks be passed as an empty list to\nPreparedRequest.prepare. In the event hooks is None in prepare or\nprepare_hooks, use an empty list as a default.\n\nRelated to #2552\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 27,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2015-04-13T15:40:17Z",
        "closed_at": "2015-04-17T12:44:38Z",
        "merged_at": "2015-04-17T12:44:38Z",
        "body": "Beginnings of work to have a list of recommended third-party (fourth-party?) packages.\n\n@sigmavirus24 @kennethreitz feel free to push on top of this branch to add other things if you want.\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2015-04-10T21:27:24Z",
        "closed_at": "2015-04-11T02:59:13Z",
        "merged_at": "2015-04-11T02:59:13Z",
        "body": "",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2015-04-10T18:41:20Z",
        "closed_at": "2015-04-14T18:03:08Z",
        "merged_at": "2015-04-14T18:03:08Z",
        "body": "PyCon's weird.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2015-04-06T18:10:05Z",
        "closed_at": "2015-04-06T22:29:17Z",
        "merged_at": "2015-04-06T22:29:17Z",
        "body": "I've done the documentation changes suggested in #2532.\n\nI also documented a way to work around this in the docstring, but I'm not sure if it'd be good to do so. (As it may lead to hacked-together solutions) Then again, other solutions like creating a brand new `Request` might lead to worse problems. (e.g.: loss of data)\n\n@sigmavirus24, what do you think?\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2015-04-06T14:02:45Z",
        "closed_at": "2015-04-06T21:54:22Z",
        "merged_at": "2015-04-06T21:54:22Z",
        "body": "Closes #2530\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 19,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2015-04-06T02:29:14Z",
        "closed_at": "2015-04-06T11:15:55Z",
        "merged_at": "2015-04-06T11:15:55Z",
        "body": "When a PreparedRequests's cookie jar is not a RequestsCookieJar instance, it\nwill not have a \"copy\" method. By adding _copy_cookie_jar we can reliably copy\ncookie jars so that we have an actual copy instead of the same instance on\ndifferent prepared requests.\n\nThis also updates the RequestsCookieJar.update logic to create copies of\ncookies from the other jar.\n\nCloses #2527\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2015-04-06T01:57:05Z",
        "closed_at": "2015-04-06T11:19:15Z",
        "merged_at": "2015-04-06T11:19:15Z",
        "body": "When other libraries or tools add items to the meta_path, we need to preempt\nsome of their import hooks to be sure modules can be properly found. This also\nprevents problems importing built-in modules on Python 2 where it will first\nattempt to import something like:\n\n```\nrequests.packages.chardet.sys\n```\n\nBy placing our VendorAlias first, the above will fail and then it will fall\nback to trying to import sys directly instead.\n\nCloses #2465\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 58,
        "deletions": 27,
        "changed_files": 2,
        "created_at": "2015-04-02T13:36:09Z",
        "closed_at": "2015-10-05T14:09:45Z",
        "merged_at": "2015-10-05T14:09:45Z",
        "body": "The existing code counts the number of 401 responses in the num_401_calls\nauthenticator attribute. This is in place so as to ensure the necessary auth\nheader is sent, while avoiding infinite 401 loops (issue #547).\n\nThis commit makes num_401_calls an instance of threading.local() (previously\nan integer), using num_401_calls.value as the counter.\n\nIt ensures that concurrent authentication requests get each their own counter\nand behave as expected (otherwise every other concurrent request would have\nits authentication fail).\n",
        "comments": 12
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2015-03-25T17:20:49Z",
        "closed_at": "2015-03-27T12:49:29Z",
        "merged_at": "2015-03-27T12:49:29Z",
        "body": "@sigmavirus24 I though it could be improved a bit. Tell me what you think.\n",
        "comments": 11
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2015-03-24T13:16:12Z",
        "closed_at": "2015-04-02T18:41:52Z",
        "merged_at": null,
        "body": "`simplejson` segfaults for me ([details](https://github.com/simplejson/simplejson/issues/114)) and it looks like it's not maintained. It should only be used as a last resort.\n",
        "comments": 15
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2015-03-23T05:03:25Z",
        "closed_at": "2015-03-23T06:18:48Z",
        "merged_at": "2015-03-23T06:18:48Z",
        "body": "Python2.7, str(err) was throwing a TypeError as it doesn't override the 'toString' method **str**.\n\nWrapped offending block in a quick try block, catching only TypeError exceptions.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2015-03-21T16:27:44Z",
        "closed_at": "2015-03-22T19:51:17Z",
        "merged_at": "2015-03-22T19:51:17Z",
        "body": "Resolves #2511.\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2015-03-18T21:32:41Z",
        "closed_at": "2015-07-18T15:44:31Z",
        "merged_at": "2015-07-18T15:44:31Z",
        "body": "Once we merge in the new urllib3, this will update the docs to reflect the new best way to handle chunked transfer encoding.\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 12,
        "changed_files": 2,
        "created_at": "2015-03-18T11:33:15Z",
        "closed_at": "2015-04-16T05:57:56Z",
        "merged_at": "2015-04-16T05:57:56Z",
        "body": "Fix for https://github.com/kennethreitz/requests/issues/2503\nIt is still a bit inconsistent but as mentioned in the issue, but it otherwise will break the current public api. \n\nThis makes it possible for non urllib3 adapters to accept extra arguments.\n",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 106,
        "deletions": 36,
        "changed_files": 3,
        "created_at": "2015-03-17T20:08:19Z",
        "closed_at": "2015-03-27T11:03:41Z",
        "merged_at": "2015-03-27T11:03:41Z",
        "body": "In the wake of CVE-2015-2296 we should take another look at our policy for patching, releasing and publicising security vulnerabilities like this one.\n\nAlthough we did a great job of responding quickly and pushing out a new release, we can definitely improve. I've received feedback from a couple of places that wanted to point out ways we could improve, and I'd like to solicit public feedback from anyone who has an interest to ensure that we're doing the best we possibly can with this sort of thing.\n\nThe goal here is for me to write up a document that explains, step-by-step, our policy with security issues. This will be posted publicly and we'll use it as a reference for any future events.\n\nBelow is the list of points people have raised:\n- We probably shouldn't announce these vulnerabilities on weekends. Several people have products and projects that require them to evaluate vulnerabilities as soon as they become aware of them, and forcing those people to work on weekends does not engender positive feelings towards us.\n- We released and announced before we had a CVE number. This might not have been the best thing for us to do, particularly as it will have made it a bit more difficult for people to keep track of what was going on.\n\nIf you have any other suggestions, please post them below.\n\nI'm going to ping some specific interested parties to ensure they see this: @sigmavirus24 @dstufft @eriol @ralphbean\n",
        "comments": 14
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2015-03-15T06:47:28Z",
        "closed_at": "2015-03-15T11:50:47Z",
        "merged_at": null,
        "body": "I believe this is the more correct grammar?\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2015-03-14T20:02:40Z",
        "closed_at": "2015-03-15T18:39:54Z",
        "merged_at": "2015-03-15T18:39:54Z",
        "body": "Closes #2418\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 24,
        "deletions": 8,
        "changed_files": 2,
        "created_at": "2015-03-12T12:56:10Z",
        "closed_at": "2015-03-14T11:19:12Z",
        "merged_at": "2015-03-14T11:19:12Z",
        "body": "Fixes: #2483\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2015-03-12T02:02:12Z",
        "closed_at": "2015-03-14T11:20:33Z",
        "merged_at": "2015-03-14T11:20:33Z",
        "body": "This works around a bug in the way setuptools' `test` command works when initially run.\n\nCloses #2462\n",
        "comments": 17
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2015-03-12T01:55:12Z",
        "closed_at": "2015-03-12T06:50:33Z",
        "merged_at": "2015-03-12T06:50:33Z",
        "body": "Importing from urllib3's top-level location causes the namespace to be\nurllib3.util.retry.Retry instead of\nrequests.packages.urllib3.util.retry.Retry. Without this fix, an using\nrequests with an un-vendored version of urllib3 will break when urllib3's\nretry handling kicks in.\n\nCloses shazow/urllib3#567\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 16,
        "deletions": 1,
        "changed_files": 3,
        "created_at": "2015-03-11T12:58:46Z",
        "closed_at": "2015-03-11T14:25:05Z",
        "merged_at": null,
        "body": "There is error (`UnicodeDecodeError: 'ascii' codec can't decode...`) when use unicode string as http verb in instance Request.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 30,
        "deletions": 15,
        "changed_files": 4,
        "created_at": "2015-03-11T00:34:50Z",
        "closed_at": "2015-03-11T14:52:11Z",
        "merged_at": "2015-03-11T14:52:11Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2015-03-06T18:50:20Z",
        "closed_at": "2015-03-07T09:09:01Z",
        "merged_at": null,
        "body": "Calling r.iter_lines() multiple times doesn't lose pending data between\ncalls to this method.\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2015-03-04T17:13:10Z",
        "closed_at": "2015-03-14T12:43:18Z",
        "merged_at": "2015-03-14T12:43:17Z",
        "body": "I've worked on the idea discussed in #2468 regarding avoiding duplicating the file data when creating a Request with files input that is str/bytes/bytearray and not a stream. The code currently creates a BytesIO or StringIO stream using the str/bytes/bytearray as initial input. This is then read out with fp.read() when creating a RequestField. The problem with this is that BytesIO and StringIO creates a copy of the input. Thus, if you have created a 100 MB file in memory using a bytearray which is used to create a Request, three identical copies is produced:\n_(1)_ The original bytearray, _(2)_ The BytesIO/StringIO object, which has its own copy, and _(3)_ The copy that is read out with fp.read() and stored in the RequestField object.\n\nIf we instead of creating BytesIO/StringIO objects just pass the str/bytes/bytearray on to RequestField, we avoid making the two duplicates of the data. This yields a **30-40% performance improvement** for files larger than 5 MB when creating a Request. The end result is, as far as I've been able to tell, the same.\n\nI have created a GIST with my code for checking that the proposed change yield the same body as the old. It also has the code for evaluating performance and the results of the three ways I've compared the performance differences. https://gist.github.com/scholer/57fced2b63d1bb3130eb\n\nThe tests in test_requests.py completes without failure on python 2.6 and 3.4. I don't believe any new tests are required, but let me know.\n\n**Question:** Is this really relevant? Why would you ever build a large file in memory? Large files are always read from disk or handled as some other stream.\nAnswer: Some cloud storage services, e.g. Amazon AWS, relies on adding a \"prefix\" and \"suffix\" to the file content, which includes e.g. upload authorization tokens. You can build the file data using e.g. a BytesIO stream or a bytearray. The bytearray can be used through a memoryview, which supports Python's buffer protocol. This means that the file data can be inserted directly into the bytearray without extra memory overhead.\n\n```\nfp.readinto(mv[offset:offset+length])\n```\n\nTo my knowledge, it is not easy to read the content of one stream directly into another. For instance, appending a BytesIO with filecontent using  fp.readinto(bytestream) # will fail since bytestream does not support the buffer interface\n\nNote: Although my tests says that the final body is the same with the new code as the old, I would still recommend that someone with more experience takes a look at this to make sure that it does not have any adverse effects.\n\nThanks.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2015-03-03T03:07:04Z",
        "closed_at": "2015-03-03T20:01:31Z",
        "merged_at": "2015-03-03T20:01:31Z",
        "body": "When creating a Request with files argument, the \"fp\" part of a file entry can currently be either (a) a str, (b) a bytes, or (c) any other object that has a .read() method that returns data. For str or bytes,  StringIO or ByteIO wrapper-objects are created.\nWhen building data in-memory, a bytearray is often more convenient and memory efficient compared to immutable bytes.\n\nThis simple change allows models.RequestEncodingMixin._encode_files method to use bytearray as fp in addition to the currently supported bytes and str input. This means that users do not have to worry about creating a ByteIO object. \n\nI've seen requests users creating bytes-objects from bytearrays before passing it to requests. This, of course, doubles the memory consumption and is completely unnecessary. Yes, the correct approach from the user's side would be to create a ByteIO object (instead of bytes). But not all users seem to be aware of this. Letting requests take bytearrays means that it would \"just work\", when the user passes these to requests, and thus avoids the potential pitfall where a user just says \"requests chokes on bytearrays, so convert to str.\" (Actual comment from pyzotero, a principal python client module to consume Zotero's REST API).\n\nI'm not sure if this simple change requires it's own test, but I've added one just in case. It also tests for bytes objects, which was not covered by the existing test, test_can_send_nonstring_objects_with_files. Perhaps I should just expand test_can_send_nonstring_objects_with_files to also cover bytes and bytearray? It currently only covers str (which are, of course, also bytes in python 2).\n\nThe test suite currently does fail in TestMorselToCookieExpires.test_expires_valid_str; however this is unrelated to this change and was also failing before, in commit 461b740d.\n\nCompatability: bytearray and the byte literal (used in the test) are both available in python 2.6 and forward.\n\nLet me know if there is anything else that you would need in order to accept this pull request.\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 21,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2015-02-28T16:53:27Z",
        "closed_at": "2015-03-04T13:49:12Z",
        "merged_at": "2015-03-04T13:49:12Z",
        "body": "Closes #2465 \nCloses #2470 \n\n/cc @dstufft Let me know if I should send this to pip as well\n",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2015-02-20T18:25:58Z",
        "closed_at": "2015-02-21T10:20:57Z",
        "merged_at": "2015-02-21T10:20:57Z",
        "body": "as explained in https://github.com/kennethreitz/requests/issues/1155#issuecomment-53229867.\n\nmotivation:\n\nrequests uses a dict for response headers. In a given response, the same header may appear multiple times with different values, but dicts of course allow each key to map to only one value. requests [handles this intelligently](https://github.com/kennethreitz/requests/issues/1155#issuecomment-53229867), but users will not expect this given it's not documented in any of these places:\n- http://docs.python-requests.org/en/latest/user/quickstart/#response-headers\n- http://docs.python-requests.org/en/latest/api/?highlight=headers#requests.request\n- http://docs.python-requests.org/en/latest/api/#requests.Response.headers\n\n(Also, they may (likely) be unfamiliar with this part of http://tools.ietf.org/html/rfc7230#section-3.2, while only actually being familiar with werkzeug and other libraries that use a multidict instead to handle repeated headers.)\n\nI think there's a perfect spot to document this behavior (right after the docs explain how the dict is already special in that it's case-insensitive), and given that #1155 will probably be closed, I figured it's a good time to document this and increase users' future understanding.\n\nThanks for the great work on requests.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2015-02-19T19:14:06Z",
        "closed_at": "2015-02-20T02:01:55Z",
        "merged_at": "2015-02-20T02:01:55Z",
        "body": "The SVG badges served by [Shields](http://shields.io) are friendlier to retina displays and have a standardized design.\n\n![Shields Comparison](https://cloud.githubusercontent.com/assets/2434728/6273906/0fc39ff8-b828-11e4-95e8-b7b5f80ef9e9.png)\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 79,
        "deletions": 11,
        "changed_files": 5,
        "created_at": "2015-02-11T18:23:53Z",
        "closed_at": "2015-02-23T22:01:06Z",
        "merged_at": "2015-02-23T22:01:06Z",
        "body": "This is the release tagged at 85dfc16817df1e3604c238ad5d64f3b229e0598b\n",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2015-02-08T14:52:56Z",
        "closed_at": "2016-01-30T03:53:32Z",
        "merged_at": null,
        "body": "It's a common case when one sends multipart request with json meta data. Currently, it is not clear that `json` argument is silently omitted. The same happens when both `data` and `json` are provided.\n",
        "comments": 9
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2015-02-04T22:22:16Z",
        "closed_at": "2015-02-05T04:27:33Z",
        "merged_at": null,
        "body": "Setting verify to False differs from verify=None in being explicitly set,\nand therefore the warning being undesirable.\n\nSee this for the a proposed alternative that involves importing\nimplementation details of Requests onto the application:\n https://github.com/kennethreitz/requests/issues/2214#issuecomment-72941896\n\nThis fix avoids deep imports and pulling the knowledge of internals of\nRequests into the application.\n\nFixes #2214\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2015-02-04T02:17:49Z",
        "closed_at": "2015-02-04T07:01:10Z",
        "merged_at": "2015-02-04T07:01:10Z",
        "body": "As mentioned here https://github.com/kennethreitz/requests/pull/2436 , one of the tests seemed like it was hanging.   In fact, the test was just (correctly) waiting to hit its timeout value.  We now give it a shorter timeout value to accelerate the testing process. \n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2015-02-03T09:21:06Z",
        "closed_at": "2015-02-03T10:34:07Z",
        "merged_at": "2015-02-03T10:34:07Z",
        "body": "Update docs  - how to pass a list of values in a query\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2015-02-03T02:28:37Z",
        "closed_at": "2015-02-03T06:50:11Z",
        "merged_at": "2015-02-03T06:50:11Z",
        "body": "http://fooobarbangbazbing.httpbin.org does not seem to be an unknown domain anymore.  I've also split up this unit test into two tests since they test slightly different things. \n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 18,
        "changed_files": 1,
        "created_at": "2015-02-02T17:12:59Z",
        "closed_at": "2015-04-02T18:44:13Z",
        "merged_at": null,
        "body": "This commit resolves #2433 by using os.read() on self.raw.fileno()\nin all cases, and removes the use fo the self.raw.stream() iterator\nwhich would block rather than returning short reads.\n",
        "comments": 8
    },
    {
        "merged": false,
        "additions": 58,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2015-01-31T03:29:19Z",
        "closed_at": "2016-12-02T20:09:32Z",
        "merged_at": null,
        "body": "I ran into this problem today where my data would randomly have additional null strings from iter_lines.  I added a test to show the issue, then fixed it.\n\nThe only weirdness might be when no data comes back, how should iter_lines behave?  Should there be a single yield of a null string, or should it just return without yielding anything?  This edit performs the latter.\n",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 52,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2015-01-28T14:16:25Z",
        "closed_at": "2015-03-04T22:20:33Z",
        "merged_at": "2015-03-04T22:20:33Z",
        "body": "We were missing instructions to report security vulnerabilities,\nand all of the documentation referred to Kenneth as the only\nsource of support. We were also missing a link to StackOverflow.\n",
        "comments": 12
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2015-01-27T12:53:10Z",
        "closed_at": "2015-01-27T18:22:35Z",
        "merged_at": null,
        "body": "Moved \"Custom Headers\" part after \"More complicated POST requests\" and before \"POST a Multipart-Encoded File\" in quickstart doc for adding headers is mentioned in the last one.\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2015-01-26T00:13:59Z",
        "closed_at": "2015-04-06T15:19:15Z",
        "merged_at": "2015-04-06T15:19:15Z",
        "body": "...ounter http redirections.\n\nhttps://github.com/kennethreitz/requests/issues/2426\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2015-01-23T03:54:12Z",
        "closed_at": "2015-01-23T07:19:39Z",
        "merged_at": "2015-01-23T07:19:39Z",
        "body": "There exists a problem (maybe a bug?) in pip when using a locale like `LC_ALL=C` (which is commonly used by CI environments and system configuration tools such as Puppet), where the PKG-INFO file is decoded using ascii, raising a UnicodeDecodeError when PKG-INFO contains non-ASCII characters (such as the n-dash removed by this commit):\n\n```\nDownloading/unpacking requests from https://pypi.python.org/packages/source/r/requests/requests-2.5.1.tar.gz\n  Downloading requests-2.5.1.tar.gz (443Kb): 443Kb downloaded\n  Running setup.py egg_info for package requests\n\nException:\nTraceback (most recent call last):\n  File \"/usr/lib/python3/dist-packages/pip/basecommand.py\", line 104, in main\n    status = self.run(options, args)\n  File \"/usr/lib/python3/dist-packages/pip/commands/install.py\", line 245, in run\n    requirement_set.prepare_files(finder, force_root_egg_info=self.bundle, bundle=self.bundle)\n  File \"/usr/lib/python3/dist-packages/pip/req.py\", line 1014, in prepare_files\n    req_to_install.assert_source_matches_version()\n  File \"/usr/lib/python3/dist-packages/pip/req.py\", line 359, in assert_source_matches_version\n    version = self.installed_version\n  File \"/usr/lib/python3/dist-packages/pip/req.py\", line 351, in installed_version\n    return self.pkg_info()['version']\n  File \"/usr/lib/python3/dist-packages/pip/req.py\", line 318, in pkg_info\n    data = self.egg_info_data('PKG-INFO')\n  File \"/usr/lib/python3/dist-packages/pip/req.py\", line 261, in egg_info_data\n    data = fp.read()\n  File \"/usr/lib/python3.2/encodings/ascii.py\", line 26, in decode\n    return codecs.ascii_decode(input, self.errors)[0]\nUnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 8161: ordinal not in range(128)\n```\n\nThere are some existing issues for pip:\n- pypa/pip#1233\n- pypa/pip#761\n\nOther projects have had the same issue occur; there is some useful discussion in these issues as well:\n- cleder/fastkml#9\n- gabrielfalcao/HTTPretty#108\n- rbarrois/factory_boy#118\n\nI know this isn't really a problem with requests (and should probably be addressed ultimately in pip), but I think replacing this character in HISTORY would be a pain-free and pragmatic way to help developers and system administrators, especially given the inactivity on the pip bug reports.\n\nMany thanks!\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2015-01-20T00:51:27Z",
        "closed_at": "2015-01-27T18:22:53Z",
        "merged_at": "2015-01-27T18:22:53Z",
        "body": "Since we only allow for \"auth\" qop-value, hardcode it\n\nFixes #2408\n\nI want to add tests but I'm not sure a good way to write them. =(\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 30,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2015-01-19T03:54:01Z",
        "closed_at": "2015-01-27T18:23:18Z",
        "merged_at": "2015-01-27T18:23:18Z",
        "body": "Instead of only checking one or another type of string-like object that we\naccept, let's be able to check both.\n\nFixes #2411\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 52,
        "changed_files": 1,
        "created_at": "2015-01-19T03:17:36Z",
        "closed_at": "2015-01-27T18:24:25Z",
        "merged_at": "2015-01-27T18:24:25Z",
        "body": "A tiny refactor I noticed while looking into a separate bug.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 3,
        "created_at": "2015-01-01T03:36:18Z",
        "closed_at": "2015-01-01T08:28:11Z",
        "merged_at": "2015-01-01T08:28:11Z",
        "body": ":tada: :tada:\nHappy new year! Thanks for this awesome library :)\n:tada: :tada:\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 28,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2014-12-27T02:06:03Z",
        "closed_at": "2015-01-27T18:24:34Z",
        "merged_at": "2015-01-27T18:24:34Z",
        "body": "Fixes #2356\n\nTODO\n- [x] Add test\n",
        "comments": 9
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-12-22T23:19:34Z",
        "closed_at": "2015-06-05T12:33:56Z",
        "merged_at": null,
        "body": "Empty chunk in request body could prematurely signal end of chunked\ntransmission. As a result, the terminating zero-size chunk sent by\n'requests' can be interpretted as bad request by the recepient. I\nhave used the same logic used by httplib to handle such cases.\nPlease review this and comment.\n",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2014-12-16T08:04:53Z",
        "closed_at": "2014-12-16T09:19:50Z",
        "merged_at": "2014-12-16T09:19:50Z",
        "body": "Because `raise_for_status` only raises `HTTPError`, I think it's better to catch `HTTPError` which is a subclass of `RequestException`. Please review this.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-12-15T06:37:31Z",
        "closed_at": "2014-12-15T07:59:47Z",
        "merged_at": "2014-12-15T07:59:47Z",
        "body": "I just fixed a minor typo: \"throws\" is misspelled as \"thows\".\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 1,
        "changed_files": 3,
        "created_at": "2014-12-12T15:16:43Z",
        "closed_at": "2014-12-13T19:49:04Z",
        "merged_at": "2014-12-13T19:49:04Z",
        "body": "A cherrypy uploaded file behave like a regular file, except that its name attribute is an int and passing it directly to requests fails because of that\n\n(not sure if i should add myself to AUTHORS for this?)\n",
        "comments": 13
    },
    {
        "merged": true,
        "additions": 93,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-12-09T02:58:42Z",
        "closed_at": "2015-01-09T20:38:31Z",
        "merged_at": "2015-01-09T20:38:31Z",
        "body": "Fedora and Debian have both recently added symlinks to their distributions of requests so people can do `from requests.packages import urllib3` but they seem to still rewrite our import statements. So the following situation is possible:\n- User registers adapter for custom scheme\n- User does the following:\n  \n  ``` python\n  from requests.packages.urllib3 import poolmanager\n  \n  poolmanager.pool_classes_by_scheme['glance+https'] = HTTPSConectionPool\n  ```\n- When they do `s.get('glance+https://...')` they see a `KeyError` because the urllib3 we're using in requests is not the one they've imported (according to `sys.modules`).\n\nPip works around this with the copied machinery. The tests seem to work just fine for me. I still need to test this with our vendored packages removed and urllib3/chardet installed separately.\n\n/cc @dstufft @eriolv @ralphbean \n",
        "comments": 39
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-12-08T20:34:47Z",
        "closed_at": "2014-12-08T23:46:08Z",
        "merged_at": "2014-12-08T23:46:08Z",
        "body": "The existing link to Twitter streaming API is broken in the Requests documentation. Updated the link with the working URL.\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 29,
        "deletions": 16,
        "changed_files": 2,
        "created_at": "2014-12-04T00:33:48Z",
        "closed_at": "2014-12-04T02:57:41Z",
        "merged_at": null,
        "body": " Fixes #2336\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2014-12-01T22:25:44Z",
        "closed_at": "2014-12-03T04:46:10Z",
        "merged_at": "2014-12-03T04:46:10Z",
        "body": "There are still some that we cannot force to work offline but this improves a lot of things.\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 108,
        "deletions": 3,
        "changed_files": 4,
        "created_at": "2014-11-25T00:18:28Z",
        "closed_at": "2014-11-25T02:09:42Z",
        "merged_at": null,
        "body": "This adds support for unix domain sockets by using a slightly modified version of the unix domain socket adapter from the [docker-py](https://github.com/docker/docker-py) project:\n\nhttps://github.com/docker/docker-py/blob/master/docker/unixconn/unixconn.py\n\nThe modifications are to make the adapter more usable in a greater variety of contexts by getting rid of the context of a `base_url` for the adapter and inventing a URL syntax that allows embedding the socket path into the URL. Basically the socket name goes in the netloc (host) part of the URL, but it's URL-encoded so that slashes become `%2F`'s so that the slashes don't interfere with separating the netloc and path parts of the URLs. This was roughly inspired by URL syntaxes that are mentioned in the following comments:\n- http://daniel.haxx.se/blog/2008/04/14/http-over-unix-domain-sockets/\n- http://lists.w3.org/Archives/Public/uri/2008Oct/0000.html\n\nSo for example if I had a server listening on `/tmp/profilesvc.sock`:\n\n```\n$ gunicorn --paste development.ini --log-config development.ini --bind unix:/tmp/profilesvc.sock\n...\n2014-11-24 16:14:54,943 INFO  [MainThread][gunicorn.error.info][glogging.py +213] Listening at: \nunix:/tmp/profilesvc.sock (95775)\n...\n```\n\nI can access it as follows:\n\n``` python\nimport requests\n\nresp = requests.get('http+unix://%2Ftmp%2Fprofilesvc.sock/status/pid')\n```\n\nIn case you're curious about the motivation for adding unix domain socket support, it was inspired by:\n\nhttps://github.com/jakubroztocil/httpie/issues/209\n\nCc: @shin-, @jakubroztocil, @monsanto, @np, @nuxlli, @matrixise, @remmelt\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-11-24T01:54:56Z",
        "closed_at": "2014-11-30T19:11:52Z",
        "merged_at": "2014-11-30T19:11:52Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 39,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2014-11-21T12:15:25Z",
        "closed_at": "2014-11-25T03:06:12Z",
        "merged_at": null,
        "body": "Basic Usage:\n\n``` python\nimport requests\nr = requests.Session()\np =  {'http':['proxy1.com:81', 'proxy2:82', 'proxy2:82'], 'https': 'proxy4.com'}\nr.proxies = p\n\nprint r.get('http://ya.ru')\nprint r.get('http://google.com')\n\nprint requests.get('http://ya.ru', proxies=p)\n\nprint r.get('https://www.google.ru')\nprint requests.get('https://www.google.ru')\n```\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2014-11-18T04:18:55Z",
        "closed_at": "2014-11-30T19:12:43Z",
        "merged_at": "2014-11-30T19:12:43Z",
        "body": "RecentlyUsedContainers are threadsafe so they require a lock and as such\ncannot be serialized with pickle directly. To handle it, we need to\nconvert it to a dictionary first and then back when deserializing.\n\nFixes #2345\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 13,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2014-11-17T10:42:33Z",
        "closed_at": "2014-11-30T19:12:04Z",
        "merged_at": "2014-11-30T19:12:04Z",
        "body": "so sections can be linked from other projects using Intersphinx\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2014-11-16T00:59:29Z",
        "closed_at": "2014-12-17T04:49:50Z",
        "merged_at": "2014-12-17T04:49:50Z",
        "body": "Addresses the LocationParseError but not the DecodeError from kennethreitz#1572. When running\ntest_requests.py, I got an error in test_session_pickling which resulted in a TypeError. I'm not sure of the reason for the TypeError but I have commented out that test.\n",
        "comments": 12
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2014-11-12T14:58:25Z",
        "closed_at": "2014-11-12T17:34:48Z",
        "merged_at": "2014-11-12T17:34:48Z",
        "body": "This is related to https://github.com/kennethreitz/requests/issues/2329\n\nJust implemented @Lukasa's solution and added test.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-11-07T15:27:05Z",
        "closed_at": "2014-11-12T17:34:14Z",
        "merged_at": "2014-11-12T17:34:14Z",
        "body": "This is related to #1882 and #1685. By calling close on the session, we\nclear the PoolManager operated by the Session and close all sockets.\n\nFixes #1882\nPartially-fixes #1685\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-11-07T08:22:25Z",
        "closed_at": "2014-11-07T14:12:24Z",
        "merged_at": "2014-11-07T14:12:24Z",
        "body": "This change passes `strict=True` to urllib3, and thus to httplib.\n\nAs per the documentation:\n\n> the optional parameter strict (which defaults to a false value) causes BadStatusLine to be raised if the status line can\u2019t be parsed as a valid HTTP/1.0 or 1.1 status line.\n\nMerging this would mean that requests is now actively limiting itself to HTTP/1.0+, excluding HTTP/0.9 (who the hell cares?). This is _already_ requests behaviour on Python 3, it simply brings it into consistency in Python 2.\n\nNote that, despite the fact that requests already sort of does this, this change is arguably breaking.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2014-11-01T02:20:16Z",
        "closed_at": "2014-11-01T14:04:09Z",
        "merged_at": "2014-11-01T14:04:09Z",
        "body": "Fixes #2316\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2014-10-27T00:28:03Z",
        "closed_at": "2014-11-12T17:36:03Z",
        "merged_at": "2014-11-12T17:36:03Z",
        "body": "After a long discussion in IRC and on several issues, the developers of\nrequests have decided to remove specific functions from requests.utils\nin version 3.0.0. To give users ample time to prepare for this, we've\nadded DeprecationWarnings long in advance. See also the planning of this\nin issue #2266.\n\nMy only concern with this is that these DeprecationWarnings are on by default\nin Python 2.6 and off everywhere else. Should we disable them for 2.6? It's a\nnot insignificant portion of our user base that may be affected by this.\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2014-10-26T19:46:54Z",
        "closed_at": "2014-11-12T17:35:24Z",
        "merged_at": "2014-11-12T17:35:24Z",
        "body": "Update HISTORY to note this. The change was made in urllib3 and not picked up here. \n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2014-10-25T15:06:09Z",
        "closed_at": "2014-10-27T00:32:46Z",
        "merged_at": "2014-10-27T00:32:46Z",
        "body": "Test was failing in case of undefined `hooks` in prepare_hooks()\n",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 15,
        "deletions": 13,
        "changed_files": 3,
        "created_at": "2014-10-25T11:57:53Z",
        "closed_at": "2014-10-25T14:11:26Z",
        "merged_at": null,
        "body": "Ran into #1979. I think it's reasonable to try the digest request again every time we encounter a 3xx. Also changed the state variable `num_401_calls` to a boolean `do_401`, since it's just used to see if we should try again and decrementing it on 3xx would be misleading. I assumed it would be safe to rename it since it looks like it's supposed to be hidden (not declared in constructor). I also assume that existing max redirects handler will still work. Regression test also still due.\n\nOh, this also fixes a previously failing test... I haven't looked into that one very deeply though.\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2014-10-24T12:54:24Z",
        "closed_at": "2014-10-24T15:03:06Z",
        "merged_at": null,
        "body": "This was causing one of the tests to fail.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-10-24T03:49:55Z",
        "closed_at": "2014-11-07T20:18:41Z",
        "merged_at": "2014-11-07T20:18:41Z",
        "body": "It'd be easily possible to run out of memory from a long running process and session that does a lot of redirects. This is also potentially able to be abused if some information was known about how a service operated. Relatively unlikely, but it's a detail that users shouldn't have to think about. We can enforce something better.\n\nAnd caching more than 10,000 redirects, in my opinion, is unreasonable. I'm open to a different value. Both more and less conservative.\n",
        "comments": 17
    },
    {
        "merged": false,
        "additions": 18,
        "deletions": 18,
        "changed_files": 5,
        "created_at": "2014-10-24T03:25:42Z",
        "closed_at": "2014-10-27T01:07:27Z",
        "merged_at": null,
        "body": "Fixing some minor issues found with pylint.  I've done them in separate commits in case you don't want all ofg the fixes.  Feel free to squash if necessary.\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2014-10-22T01:21:26Z",
        "closed_at": "2014-10-25T18:33:52Z",
        "merged_at": "2014-10-25T18:33:52Z",
        "body": "Initial description is in Issue #2292 however, I shall elaborate.\n\nIt is often necessary to iterate over something other than conventional newlines, where such characters are a part of the data, for example.  This is a small functionality requiring a proportionally small change in the code.  Wrapping `iter_content()` in a custom iterator outside of the Requests library requires significantly more code, which is why I'm proposing this change.  The effect on the performance is negligible.  \n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 6,
        "changed_files": 2,
        "created_at": "2014-10-19T08:39:50Z",
        "closed_at": "2014-10-19T09:42:28Z",
        "merged_at": "2014-10-19T09:42:28Z",
        "body": "Updated gratipay widget iframe in both sidebarintro.html and sidebarlogo.html . \n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2014-10-10T02:07:26Z",
        "closed_at": "2014-10-12T14:55:34Z",
        "merged_at": "2014-10-12T14:55:34Z",
        "body": "Closes #2269\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-10-09T02:28:13Z",
        "closed_at": "2014-10-10T18:30:18Z",
        "merged_at": "2014-10-10T18:30:18Z",
        "body": "Fixed #2250 with #2271 \n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2014-10-05T23:56:27Z",
        "closed_at": "2014-10-06T09:40:03Z",
        "merged_at": "2014-10-06T09:40:03Z",
        "body": "Address @kevinburke's concerns\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2014-10-05T23:30:52Z",
        "closed_at": "2014-10-06T09:39:54Z",
        "merged_at": "2014-10-06T09:39:54Z",
        "body": "on Python 2 `u'\u00e9'.decode('utf8')` fails with UnicodeEncodeError, but only AttributeError is caught.\n\nThis only calls decode on known bytes objects.\n\nincludes a test that succeeds on 2.4.1 and fails on 2.4.2\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2014-10-05T04:04:57Z",
        "closed_at": "2014-10-05T08:05:29Z",
        "merged_at": "2014-10-05T08:05:29Z",
        "body": "We do not allow the user to set the timeout value on the Session any longer so\nthis is extraneous\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 14,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2014-10-03T18:48:43Z",
        "closed_at": "2014-11-12T17:36:20Z",
        "merged_at": null,
        "body": "Hello.\nI made some fixes to `get_unicode_from_response` fixing #2205.\nIt now tries every encodings from meta tags by calling `get_encodings_from_content`.\nBecause encoding charset is case-insensitive by RFC 2616, encoding charset is appended to `tried_encodings` in lower case.\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 38,
        "deletions": 10,
        "changed_files": 4,
        "created_at": "2014-09-30T15:59:29Z",
        "closed_at": "2014-10-05T16:46:09Z",
        "merged_at": "2014-10-05T16:46:09Z",
        "body": "Closes #2025\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-09-27T18:19:36Z",
        "closed_at": "2014-11-01T14:04:29Z",
        "merged_at": "2014-11-01T14:04:29Z",
        "body": "This solves the following scenario:\n(1) 401 (Digest authentication begins)\n(2) 302 (Authenticated, response redirects to another endpoint)\n(3) 401 (New endpoint also requires authentication)\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 8,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2014-09-27T17:42:35Z",
        "closed_at": "2014-09-27T19:20:15Z",
        "merged_at": null,
        "body": "it's my solution of #2251\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 18,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2014-09-25T19:50:35Z",
        "closed_at": "2014-10-05T17:19:14Z",
        "merged_at": "2014-10-05T17:19:14Z",
        "body": "We have to pass urllib3 the url without the authentication information,\nelse it will be parsed by httplib as a netloc and included in the request line\nand Host header\n",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2014-09-23T02:08:53Z",
        "closed_at": "2014-09-23T06:25:26Z",
        "merged_at": "2014-09-23T06:25:26Z",
        "body": "The history attribute contains responses, not requests.\n\nThanks to Yang Yang for reporting this to me via email\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-09-23T02:04:04Z",
        "closed_at": "2014-09-25T02:57:38Z",
        "merged_at": "2014-09-25T02:57:38Z",
        "body": "This prevents a case where we make a request to URL A, which 301s to B which\nwould then 301 back to A. Alternatively, for less simple schemes, this will\nalso prevent us from getting stuck in a loop, e.g., it will prevent the\nfollowing from causing an endless loop:\n\n```\n    A -> B -> C -> D -> E -> F --\n    ^                             \\\n    |                             /\n    ---<------------<----------<-\n```\n\nFixes #2231.\n\nI tested this by cloning httpbin and hard coding a permanent redirect loop from `/relative-redirect/1` to `/relative-redirect/2` so that we could trigger this. This pull request fixes it.\n",
        "comments": 16
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2014-09-22T16:10:24Z",
        "closed_at": "2014-10-05T16:48:40Z",
        "merged_at": "2014-10-05T16:48:40Z",
        "body": "In response to issue #2240, add a check to see if the content was \"consumed\"\n",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 6,
        "changed_files": 3,
        "created_at": "2014-09-20T20:47:05Z",
        "closed_at": "2014-10-02T16:20:05Z",
        "merged_at": "2014-10-02T16:20:05Z",
        "body": "Hi there folks.\n\nCurrently `prepare_url` will call `unicode` or `str` on the url arg depending on the python version. This works fine for most cases, but the one case it trips up on is bytestrings on python 3.x as the string representation of these is `\"b'http://httpbin.org'\"`. Eventually this will surface as an `InvalidSchema` exception.\n\nI find this to be completely unexpected, and I'd imagine it's not something that's been done intentionally.\n\nTechnically this a breaking change. The possibility of passing non-strings to `prepare_url` is undocumented and untested, but regardless it may be better to go about fixing this in a different way, that's your call.\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2014-09-20T20:02:07Z",
        "closed_at": "2014-09-20T22:12:38Z",
        "merged_at": "2014-09-20T22:12:38Z",
        "body": "Invoke seems to be an old, unneeded dependency\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 28,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2014-09-16T09:39:48Z",
        "closed_at": "2014-09-18T01:06:54Z",
        "merged_at": "2014-09-18T01:06:54Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2014-09-12T15:14:15Z",
        "closed_at": "2014-09-12T16:54:40Z",
        "merged_at": "2014-09-12T16:54:40Z",
        "body": "I've meant to add this to #2222, which has been merged already.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2014-09-12T01:15:37Z",
        "closed_at": "2014-09-12T14:16:11Z",
        "merged_at": "2014-09-12T14:16:11Z",
        "body": "In b149be5d `PreparedRequest` was made to skip `parse_url` for e.g.\n`$HOST:$PORT`, which results in `MissingSchema` not being raised for\n`localhost:3128`.\n",
        "comments": 13
    },
    {
        "merged": false,
        "additions": 29,
        "deletions": 10,
        "changed_files": 3,
        "created_at": "2014-09-11T23:13:48Z",
        "closed_at": "2014-09-12T06:19:58Z",
        "merged_at": null,
        "body": "`prepend_scheme_if_needed` is used for the proxy, but failed to do so properly for `host:port`.\n\nThis PR addresses the first occasion in the docs I've stumbled upon, fixes the implementation and adds tests.\n\n(This is derived from https://github.com/kennethreitz/requests/pull/2219.)\n\nIf this seems OK, the documentation at https://github.com/kennethreitz/requests/blame/master/docs/api.rst#L238-249 needs to get removed/addressed also.\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-09-11T21:58:28Z",
        "closed_at": "2014-09-12T01:55:48Z",
        "merged_at": null,
        "body": "`prepend_scheme_if_needed` is used to add `http` if necessary.\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 128,
        "deletions": 31,
        "changed_files": 10,
        "created_at": "2014-09-10T19:17:41Z",
        "closed_at": "2014-12-01T19:45:27Z",
        "merged_at": "2014-12-01T19:45:27Z",
        "body": "Currently our documentation tells user that by creating a custom `HTTPAdapter` they can pass `max_retries=n` and that will apply to connection and read retries. This is a lie at the moment (and has been probably since 2.4.0 was released with the new version of urllib3 that added the `Retry` class).\n\nIn order to preserve backwards compatibility (and have passing tests) I remember upgrading the logic [here](https://github.com/kennethreitz/requests/blob/master/requests/adapters.py#L361) to pass `read=False` because some where we expected a plain `ReadTimeout` exception we were now getting a `MaxRetryError`. This, however, means that we have broken what we promised in the documentation (and what was likely present in even 2.3.0).\n\nAt the moment we do not support passing a `Retry` instance from `urllib3`. I'd like to propose the following changes:\n- In `requests.adapters`, `DEFAULT_RETRIES` becomes a sentinel object, e.g., `DEFAULT_RETRIES = object()`.\n- In `HTTPAdatper.__init__`, we check for the sentinel object and if so set `self.max_retries` to `Retry(0, read=False)`. Otherwise, we do `self.max_retries = Retry.from_int(max_retries)`\n\nThis should fix preserve the default existing behaviour that specifying `read=False` preserved but also allow users to do one of two things:\n1. Import `Retry` from urllib3, construct their own `Retry` instance and then pass it as `max_retries`\n2. Specify a number for both connection and read retries.\n\nDoes this sound like a fair proposal?\n\n**Edit** I forgot to mention that @txtsd brought this to our attention in IRC. They get the credit for reporting this. Thank you @txtsd \n",
        "comments": 30
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2014-09-07T17:03:09Z",
        "closed_at": "2014-09-09T14:24:24Z",
        "merged_at": "2014-09-09T14:24:24Z",
        "body": "@Lukasa wrote the fix in #2207 \n\nWith this, the expected behaviour is restored (a `TooManyRedirects` error);\n\n``` pycon\n>>> import requests\n>>> r = requests.get('http://www.dx.com/p/-268479')\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"./requests/api.py\", line 59, in get\n    return request('get', url, **kwargs)\n  File \"./requests/api.py\", line 48, in request\n    return session.request(method=method, url=url, **kwargs)\n  File \"./requests/sessions.py\", line 451, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"./requests/sessions.py\", line 583, in send\n    history = [resp for resp in gen] if allow_redirects else []\n  File \"./requests/sessions.py\", line 583, in <listcomp>\n    history = [resp for resp in gen] if allow_redirects else []\n  File \"./requests/sessions.py\", line 111, in resolve_redirects\n    raise TooManyRedirects('Exceeded %s redirects.' % self.max_redirects)\nrequests.exceptions.TooManyRedirects: Exceeded 30 redirects.\n```\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 16,
        "deletions": 4,
        "changed_files": 3,
        "created_at": "2014-09-07T14:25:36Z",
        "closed_at": "2015-04-05T16:03:15Z",
        "merged_at": null,
        "body": "When doing a request with stream=False, to an endpoint that responds with a streaming/chunked response, the download time of the response body is not included in the Response.elapsed timedelta.\n\nThis pull request adds a test for this that currently fails.\n\nIn Requests 2.2 the behaviour was different, and this test passes. If the current behaviour is the intended, I guess one could just modify the test in this pull request to reflect the expected behaviour.\n",
        "comments": 17
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-09-06T23:12:58Z",
        "closed_at": "2014-09-07T05:41:49Z",
        "merged_at": null,
        "body": "In my use of Requests, [I noticed at some point](https://stackoverflow.com/questions/11588458/how-to-handle-encodings-using-python-requests-library) that text that was encoded as cp1252 was coming back as ISO-8859-1. While in many cases, that's a fine fallback encoding, cp1252 is a superset of ISO-8859-1, making it right even more often. \n\nWalking through the scenarios, just to make sure I'm not missing something:\n1. Text is encoded as cp1252, but is misidentified as ISO-8859-1. Result: Characters from the cp1252 superset will be mojibake.\n2. Text is encoded as cp1252 and is identified as cp1252. Result: All good.\n3. Text is encoded as ISO-8859-1, but is misidentified as cp1252. Result: All good. Superset in cp1252 encoding won't cause a problem.\n4. Text is encoded as ISO-8859-1 and is identified as ISO-8859-1. Result: All good.\n\nSo, I think this can only do good, but encodings have never been my friend, and I'd be only slightly surprised if I missed something. \n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 19,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2014-09-04T18:41:19Z",
        "closed_at": "2014-09-05T15:11:57Z",
        "merged_at": "2014-09-05T15:11:57Z",
        "body": "As discussed in #2124.\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2014-09-03T07:42:02Z",
        "closed_at": "2014-09-04T18:41:46Z",
        "merged_at": "2014-09-04T18:41:46Z",
        "body": "This is a fix for #2196 where if you tried running setup.py with some LANG it would throws an exception when reading HISTORY with non-ascii characters.\n\nTry it with\n\n```\nLANG=C python setup.py\n```\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-09-01T05:30:06Z",
        "closed_at": "2014-09-03T09:30:05Z",
        "merged_at": null,
        "body": "Replaces em dash in HISTORY.rst with ascii dash. \n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2014-08-29T21:39:35Z",
        "closed_at": "2014-09-04T18:36:56Z",
        "merged_at": "2014-09-04T18:36:56Z",
        "body": "Fixes #1995 \n",
        "comments": 15
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2014-08-29T20:16:54Z",
        "closed_at": "2014-09-04T18:39:41Z",
        "merged_at": "2014-09-04T18:39:41Z",
        "body": "Fixes #2192 \n",
        "comments": 15
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-08-29T19:07:09Z",
        "closed_at": "2014-09-04T18:39:23Z",
        "merged_at": "2014-09-04T18:39:23Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 28,
        "deletions": 34,
        "changed_files": 7,
        "created_at": "2014-08-29T18:36:44Z",
        "closed_at": "2014-09-04T18:39:12Z",
        "merged_at": "2014-09-04T18:39:12Z",
        "body": "Adds better documentation of `timeout` behavior\n- \"How long to wait for the server to send data before giving up, as a float, or a (connect timeout, read timeout) tuple.\" was as short as I could get to accurately describe the behavior.\n- Sphinx puts the description of timeouts on the line below the parameter name, but this is not true for other parameters. I'm curious why this is but I can't see any differences.\n- We don't use the `stream` parameter anywhere in the `adapters.send` method, so I removed the \"Behavior\" section that described the behavior of requests incorrectly. May also want to remove the parameter description from the documentation, or state that it's not actually used anywhere.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 100,
        "deletions": 24,
        "changed_files": 8,
        "created_at": "2014-08-25T20:47:33Z",
        "closed_at": "2014-08-26T19:10:51Z",
        "merged_at": "2014-08-26T19:10:51Z",
        "body": "This includes fixes for openssl running with Pypy, so SSL connections can be\nmade if ndg-httpsclient, pyopenssl and pyasn1 are installed.\n\nsee also:\n- https://github.com/shazow/urllib3/issues/449\n- https://github.com/pypa/pip/issues/1988\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 28,
        "deletions": 24,
        "changed_files": 1,
        "created_at": "2014-08-23T20:52:48Z",
        "closed_at": "2014-08-26T19:44:51Z",
        "merged_at": "2014-08-26T19:44:51Z",
        "body": "See also #2129 \n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 130,
        "deletions": 13,
        "changed_files": 6,
        "created_at": "2014-08-23T19:39:43Z",
        "closed_at": "2014-08-26T19:13:30Z",
        "merged_at": "2014-08-26T19:13:30Z",
        "body": "Modifies the timeout interface to also accept a tuple (connect, read) which\nwould be used to set individual connect and read timeouts for Requests. Adds\nAdvanced documentation explaining the interface and providing guidance for\ntimeout values.\n",
        "comments": 11
    },
    {
        "merged": false,
        "additions": 14,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2014-08-23T19:23:01Z",
        "closed_at": "2014-08-23T21:19:04Z",
        "merged_at": null,
        "body": "Please don't merge this, I'm trying to track down behavior issues in CPython + Pypy\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-08-23T17:06:15Z",
        "closed_at": "2014-08-26T19:15:28Z",
        "merged_at": "2014-08-26T19:15:28Z",
        "body": "If you put your Virtualenv in the same folder as Requests (as I\nusually do), py.test will pick up any test_\\* files inside the\nvirtualenv and attempt to run them too, leading to the following error:\nhttps://gist.github.com/kevinburke/1aa2b07e01de3a7daa15\n\nInstead specify the test file we would like to run in the Makefile.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2014-08-22T08:45:23Z",
        "closed_at": "2014-08-22T10:47:35Z",
        "merged_at": "2014-08-22T10:47:35Z",
        "body": "Concerning #2169, i get a problem with automatic keep alive.\n@sigmavirus24 has commented this saying that was in documentation but can have been lost.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2014-08-21T18:27:35Z",
        "closed_at": "2014-08-22T13:04:50Z",
        "merged_at": "2014-08-22T13:04:50Z",
        "body": "Fix sentence case requests by sigmavirus24 here: https://github.com/kennethreitz/requests/pull/2168\nAdded myself to authors.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 16,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2014-08-18T02:19:45Z",
        "closed_at": "2014-08-21T17:43:23Z",
        "merged_at": "2014-08-21T17:43:23Z",
        "body": "Addresses the issue brought up here:\nhttps://github.com/kennethreitz/requests/issues/1929\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 21,
        "deletions": 1,
        "changed_files": 3,
        "created_at": "2014-08-07T03:32:45Z",
        "closed_at": "2014-08-07T11:15:58Z",
        "merged_at": null,
        "body": "requests detect page's charset/encoding from responsed http headers, but many servers won't set it in headers.\n\nIn this case, requests will set the charset/encoding to the default 'ISO-8859-1', and result in decoded error, many Chinese developers get lose and complain.\n\nFor example:\n\n```\nprint requests.get('http://www.126.com/').text\n```\n\nThis commit will detect charset/encoding from http headers, if no, from http body, for most situations, everything goes well now.\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2014-08-01T08:45:00Z",
        "closed_at": "2014-08-01T11:19:35Z",
        "merged_at": null,
        "body": "This is the one which shows up first in Google search results and looks odd with broken sidebar below the logo.\n![requests-docs-broken](https://cloud.githubusercontent.com/assets/769447/3776643/f362af58-1957-11e4-94ce-93806eca40b0.png)\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 19,
        "changed_files": 3,
        "created_at": "2014-07-30T03:32:34Z",
        "closed_at": "2014-08-02T01:33:56Z",
        "merged_at": "2014-08-02T01:33:56Z",
        "body": "urllib3 changed and now catches all of the exceptions in `iter_content` that requests was working around. This patch addresses those changes so that the proper exceptions are being caught and rethrown.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2014-07-24T21:03:03Z",
        "closed_at": "2014-07-27T13:59:08Z",
        "merged_at": "2014-07-27T13:59:08Z",
        "body": "My first PR for Requests, so I probably did something terribly wrong.\n\nCloses #2144.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2014-07-22T16:38:13Z",
        "closed_at": "2014-07-22T20:20:37Z",
        "merged_at": "2014-07-22T20:20:37Z",
        "body": "Removed an unnecessary \"to\" in the \"What are \"hostname doesn't match\" errors?\" section.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 818,
        "deletions": 544,
        "changed_files": 21,
        "created_at": "2014-07-21T18:46:08Z",
        "closed_at": "2014-07-22T20:21:05Z",
        "merged_at": "2014-07-22T20:21:05Z",
        "body": "It seems urllib3 changed the timeout logic such that, we now have a failing test (`test_stream_timeout`). We now receive a `MaxRetryError` instead of a `TimeoutError` from urllib3. Either we have to adjust or this is a bug that needs to be fixed in urllib3.\n\nThoughts @shazow @lukasa?\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 19,
        "deletions": 19,
        "changed_files": 2,
        "created_at": "2014-07-18T16:51:21Z",
        "closed_at": "2014-07-18T20:17:43Z",
        "merged_at": "2014-07-18T20:17:43Z",
        "body": "Half of documentation use print() & half the print command.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 30,
        "deletions": 30,
        "changed_files": 1,
        "created_at": "2014-07-18T08:01:47Z",
        "closed_at": "2014-07-22T06:57:25Z",
        "merged_at": "2014-07-22T06:57:25Z",
        "body": "- Linkify github usernames\n- Remove usernames that do not exist\n\nChange-Id: Ib88b70a3010e915b3570ae5062c8cb416c9a6462\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 38,
        "deletions": 14,
        "changed_files": 2,
        "created_at": "2014-07-18T08:01:16Z",
        "closed_at": "2014-07-18T09:59:48Z",
        "merged_at": "2014-07-18T09:59:48Z",
        "body": "Wrapping lines at around 80 chars.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 7,
        "changed_files": 4,
        "created_at": "2014-07-18T06:23:02Z",
        "closed_at": "2014-07-18T07:24:27Z",
        "merged_at": "2014-07-18T07:24:27Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-07-16T06:22:04Z",
        "closed_at": "2014-07-16T12:14:36Z",
        "merged_at": "2014-07-16T12:14:36Z",
        "body": "See http://pydanny.com/\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2014-07-16T01:54:35Z",
        "closed_at": "2014-07-16T05:36:40Z",
        "merged_at": "2014-07-16T05:36:40Z",
        "body": "A few instances of the directives were malformed and did not\nresult in hyperlinks in the generated HTML.\n\nChange-Id: I94d93de928ee4ff24a48797baf2ac77598a20704\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 8,
        "changed_files": 2,
        "created_at": "2014-07-15T09:31:05Z",
        "closed_at": "2014-07-15T10:40:28Z",
        "merged_at": "2014-07-15T10:40:28Z",
        "body": "- Add the Timeout exception in API doc so it gets hyperlinked properly from quickstart\n- Restructure the redirection and history section so it's a bit easier to read\n- Couple of other minor tidy-ups\n\nNote: the documentation build does not work on my machine, so I have not tested this fully.\n",
        "comments": 9
    },
    {
        "merged": false,
        "additions": 24,
        "deletions": 19,
        "changed_files": 1,
        "created_at": "2014-07-15T01:59:33Z",
        "closed_at": "2014-08-22T13:12:08Z",
        "merged_at": null,
        "body": "By having trust environment lookup in request() applications using\nprepared requests don't get access to this functionality. Having this in\nsend() is a more logical place as we are dealing with default\ncommunication parameters.\n\nCloses #1436\n",
        "comments": 21
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 7,
        "changed_files": 2,
        "created_at": "2014-07-10T20:51:52Z",
        "closed_at": "2014-07-11T17:30:07Z",
        "merged_at": "2014-07-11T17:30:07Z",
        "body": "Resolves #2123.\n\nThis represents one possible approach to certifi: always take it if it's present. This is probably not the most secure approach, however. If we wanted to be more intelligent we could embed the version number of certifi that requests contains and use the most up-to-date version. If you're interested in doing that let me know and I'll add it as an enhancement.\n\nNote also that this adds certifi as a hard dependency. I'd be equally happy to not install it in the install process but take it if it's there.\n",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2014-07-02T15:26:36Z",
        "closed_at": "2014-07-03T13:35:55Z",
        "merged_at": "2014-07-03T13:35:55Z",
        "body": "Closes #2092\n",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-06-23T03:40:50Z",
        "closed_at": "2014-06-23T07:24:46Z",
        "merged_at": null,
        "body": "\"assert cookie.expires == 1\" is changed to \"assert cookie.expires is not None\" at line 1166.\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2014-06-21T00:33:50Z",
        "closed_at": "2014-06-23T19:10:42Z",
        "merged_at": null,
        "body": "Currently requests.head() behaves differently (doesn't follow redirects) than requests.request('HEAD', ...)\n\nThis is, I believe, undesirable behaviour, and also disagrees with the documentation (http://docs.python-requests.org/en/latest/user/quickstart/#redirection-and-history).\n\nThis also addresses the problem described in kennethreitz/grequests#45\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2014-06-18T05:35:20Z",
        "closed_at": "2014-06-18T15:30:26Z",
        "merged_at": null,
        "body": "sorry. this is for testing\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-06-15T07:10:14Z",
        "closed_at": "2014-06-15T08:19:34Z",
        "merged_at": "2014-06-15T08:19:34Z",
        "body": "Remove french blog post which is now a deadlink.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2014-06-12T12:34:08Z",
        "closed_at": "2014-06-12T18:42:42Z",
        "merged_at": "2014-06-12T18:42:42Z",
        "body": "When web clients like Firefox get a redirect they will not go after the old version any more even if you type it into the address bar.\nThis patch makes the requests framework work in the same way.\nThis helps performance when creating a request proxy that delegates to other servers based on URL.\nThis patch has me going from 245 requests per second to 470 requests per second against a server returning 308 response codes.\n\n-- example server\nhttps://gist.github.com/ericfrederich/a004862e1da1fb6916ef\n-- example client\nhttps://gist.github.com/ericfrederich/e1225e2d07e3ee923b27\n-- example server output of 301 vs 302 redireects\nhttps://gist.github.com/ericfrederich/b77bd4852a3cf9b968f0\n",
        "comments": 22
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 6,
        "changed_files": 3,
        "created_at": "2014-06-10T20:33:18Z",
        "closed_at": "2014-06-12T04:19:45Z",
        "merged_at": "2014-06-12T04:19:44Z",
        "body": "308 is also a redirect.  It is the permanent version of 307\n",
        "comments": 8
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-06-10T15:22:32Z",
        "closed_at": "2014-06-10T16:25:08Z",
        "merged_at": null,
        "body": "Translated some important message to Chinese.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 61,
        "deletions": 43,
        "changed_files": 1,
        "created_at": "2014-06-10T13:11:22Z",
        "closed_at": "2014-06-10T16:02:21Z",
        "merged_at": "2014-06-10T16:02:21Z",
        "body": "A number of PEP-8 related cleanups. Also removing unused imports and unused variables.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 13,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2014-06-08T09:22:45Z",
        "closed_at": "2014-06-09T14:53:23Z",
        "merged_at": "2014-06-09T14:53:23Z",
        "body": "Observe:\n\n``` python\n>>> import requests\n>>> requests.__version__\n'2.3.0'\n>>> r = requests.Request('GET', 'http://www.google.com/', auth=('user', 'pass'))\n>>> p = r.prepare()\n>>> p.headers['Authorization']\nu'Basic dXNlcjpwYXNz'\n```\n\nThis is wrong: all header keys and values should be native strings. Easily fixed though. =)\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2014-06-07T08:56:07Z",
        "closed_at": "2014-06-08T14:44:26Z",
        "merged_at": "2014-06-08T14:44:26Z",
        "body": "As a companion to #2086, this updates all the other references to RFC 2616 in our codebase and documentation to their new locations. Gonna let @sigmavirus24 review this rather than merge it myself (which I'd normally do) just so he can sanity-check.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-05-28T01:31:31Z",
        "closed_at": "2014-05-29T14:39:42Z",
        "merged_at": "2014-05-29T14:39:42Z",
        "body": "Fixes #2071\n\nThis provides consistent behaviour across Python 2 & 3.\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2014-05-26T15:41:47Z",
        "closed_at": "2014-05-27T15:11:21Z",
        "merged_at": "2014-05-27T15:11:21Z",
        "body": "In response to #2066. Weirdly, we weren't initialising the `.request` property in the constructor. Nothing terrible there, but we need to do it to get it documented, so let's do it.\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2014-05-26T10:50:31Z",
        "closed_at": "2014-05-26T12:37:07Z",
        "merged_at": null,
        "body": "In the case of a bulk delete operation, it would be useful to have a \"data\" parameter to send the ids of objects to delete.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 16,
        "deletions": 6,
        "changed_files": 2,
        "created_at": "2014-05-25T23:00:11Z",
        "closed_at": "2014-05-27T15:24:47Z",
        "merged_at": "2014-05-27T15:24:47Z",
        "body": "The FAQ says that requests is compatible with Python 3.2. However, I could not execute the tests using that Python version. This PR fixes this and updated the FAQ to match.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-05-25T22:57:50Z",
        "closed_at": "2014-05-27T15:25:54Z",
        "merged_at": "2014-05-27T15:25:54Z",
        "body": "We officially support Python 2.6 to 3.3, but simplejson does not\nsupport Python 3.1 or 3.2:\n\n  https://github.com/simplejson/simplejson/issues/66\n\nImporting simplejson on Python 3.2 results in a SyntaxError because\nsimplejson uses the u'...' syntax (the syntax was not supported in\nPython 3.0 to 3.2).\n\nSupport for loading simplejson instead of the stdlib json module was\nadded by #710:\n\n  https://github.com/kennethreitz/requests/pull/710\n\nNo mention was made of the lack of support for Python 3.2, but it was\nmentioned that simplejson can be faster than the stdlib json module.\n",
        "comments": 10
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 23,
        "changed_files": 1,
        "created_at": "2014-05-23T15:54:58Z",
        "closed_at": "2014-05-27T15:28:11Z",
        "merged_at": "2014-05-27T15:28:11Z",
        "body": "It's undocumented, unused and basically uninteresting. It looks like it was added in error in this commit https://github.com/kennethreitz/requests/commit/ef8563ab36c6b52834ee9c35f6f75a424cd9ceef. Or at least the interesting bit was factored out into `super_len`.\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-05-22T13:17:43Z",
        "closed_at": "2014-05-27T17:09:43Z",
        "merged_at": null,
        "body": "Proposed solution to #2057\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 75,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2014-05-18T01:32:07Z",
        "closed_at": "2014-05-18T09:23:58Z",
        "merged_at": null,
        "body": "Added instructions and sample code for using requests over the Tor network.\n\nSample code shows how to verify a successful connection and how to connect to a hidden service.  Example sites are https://check.torproject.org/ and http://ic6au7wa3f6naxjq.onion/ (www.gnupg.org).\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 34,
        "deletions": 16,
        "changed_files": 2,
        "created_at": "2014-05-17T22:42:52Z",
        "closed_at": "2014-06-23T19:11:13Z",
        "merged_at": "2014-06-23T19:11:13Z",
        "body": "Basically identical to @sigmavirus24's suggested code - thanks for that pointer. Just added docstring.\n\nThere aren't tests for particular Adapter implementations, and I've not added any at this stage.\nI have tested it with the following (which achieves what I want):\n\n```\nclass SourceAddressAdapter(requests.adapters.HTTPAdapter):\n    \"\"\"\n    A Requests HTTP adapter to add source address specification for proxies\n    \"\"\"\n    def __init__(self, *o, **k):\n        self.source_address = k.pop('source_address', None)\n        super(SourceAddressAdapter, self).__init__(*o, **k)\n\n    def proxy_manager_for(self, proxy):\n        conn_params = {}\n        if self.source_address is not None:\n            conn_params['source_address'] = (self.source_address, 0)\n\n        if not proxy in self.proxy_manager:\n            proxy_headers = self.proxy_headers(proxy)\n            self.proxy_manager[proxy] = requests.adapters.proxy_from_url(\n                proxy,\n                proxy_headers=proxy_headers,\n                num_pools=self._pool_connections,\n                maxsize=self._pool_maxsize,\n                block=self._pool_block,\n                **conn_params)\n\n        return self.proxy_manager[proxy]\n```\n",
        "comments": 14
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-05-16T18:11:06Z",
        "closed_at": "2014-05-16T21:05:41Z",
        "merged_at": "2014-05-16T21:05:41Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-05-13T08:12:37Z",
        "closed_at": "2014-05-13T10:31:24Z",
        "merged_at": "2014-05-13T10:31:24Z",
        "body": "\"Sesssion\" -> \"Session\"\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-05-12T19:27:53Z",
        "closed_at": "2014-05-16T14:37:32Z",
        "merged_at": "2014-05-16T14:37:32Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2014-05-02T16:52:03Z",
        "closed_at": "2014-05-02T19:09:21Z",
        "merged_at": "2014-05-02T19:09:21Z",
        "body": "There's not a lot of good reason to actually call out easy_install at all. Anyone who prefers it already knows it exists and everyone else should be directed unambiguously towards pip.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-04-29T17:52:26Z",
        "closed_at": "2014-05-02T19:09:39Z",
        "merged_at": "2014-05-02T19:09:39Z",
        "body": "I'm using Python 3.4. I get this error from `import requests`:\n\n```\nTraceback (most recent call last):\n  File \"devwiki.py\", line 4, in <module>\n    import requests\n  File \"/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/requests-2.3.0-py3.4.egg/requests/__init__.py\", line 58, in <module>\n    from . import utils\n  File \"/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/requests-2.3.0-py3.4.egg/requests/utils.py\", line 25, in <module>\n    from .compat import parse_http_list as _parse_list_header\n  File \"/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/requests-2.3.0-py3.4.egg/requests/compat.py\", line 7, in <module>\n    from .packages import chardet\n  File \"/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/requests-2.3.0-py3.4.egg/requests/packages/__init__.py\", line 3, in <module>\n    from . import urllib3\n  File \"/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/requests-2.3.0-py3.4.egg/requests/packages/urllib3/__init__.py\", line 16, in <module>\n    from .connectionpool import (\n  File \"/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/requests-2.3.0-py3.4.egg/requests/packages/urllib3/connectionpool.py\", line 36, in <module>\n    from .connection import (\n  File \"/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/requests-2.3.0-py3.4.egg/requests/packages/urllib3/connection.py\", line 43, in <module>\n    from .util import (\nImportError: No module named 'requests.packages.urllib3.util'\n```\n",
        "comments": 9
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-04-26T21:12:48Z",
        "closed_at": "2014-05-12T18:57:10Z",
        "merged_at": null,
        "body": "This is meant to be used when triaging bugs, without requiring deep knowledge\nabout the internals from reporters.\n",
        "comments": 11
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2014-04-26T12:10:01Z",
        "closed_at": "2014-04-28T21:49:28Z",
        "merged_at": "2014-04-28T21:49:28Z",
        "body": "This should resolve the problems raised in #2018.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 738,
        "deletions": 678,
        "changed_files": 12,
        "created_at": "2014-04-24T18:49:17Z",
        "closed_at": "2014-04-26T03:04:54Z",
        "merged_at": "2014-04-26T03:04:54Z",
        "body": "Hi,\n\nThe update enables https request on the google app engine dev server (see https://github.com/shazow/urllib3/issues/356 and https://github.com/kennethreitz/requests/issues/1961).\n\nThanks,\nAlex\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 10,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2014-04-22T22:46:44Z",
        "closed_at": "2014-04-23T06:24:30Z",
        "merged_at": null,
        "body": "After this change:\n  In [1]: from requests import Request\n\n  In [2]: eval(repr(Request('GET', 'http://x.org')))\n  Out[2]: Request(method='GET', url='http://x.org')\n\n  In [3]: eval(repr(Request('GET', 'http://x.org', auth=('hello', 'world'))))\n  Out[3]: Request(method='GET', url='http://x.org', auth=('hello', 'world'))\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2014-04-18T16:30:32Z",
        "closed_at": "2014-04-21T16:25:01Z",
        "merged_at": "2014-04-21T16:25:01Z",
        "body": "As @kennethreitz and I discussed at PyCon, this is a first pass at a rewrite of part of the Philosophy section of the docs, attempting to explain Requests' slightly unusual management style. I'd like some feedback.\n\nSome ideas:\n- should @shazow be mentioned? I felt like he should but I wasn't sure how best to explain the relationship.\n- is there anything major that I've missed?\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 487,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2014-04-16T15:14:41Z",
        "closed_at": "2014-04-16T19:37:29Z",
        "merged_at": "2014-04-16T19:37:29Z",
        "body": "SVG version of Requests logo for users, which have not Palatino-Roman fonts and so on.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 707,
        "deletions": 515,
        "changed_files": 1,
        "created_at": "2014-04-12T18:21:34Z",
        "closed_at": "2014-04-16T14:56:44Z",
        "merged_at": "2014-04-16T14:56:44Z",
        "body": "Some users may not have Palatino-Roman font, but in curves form they can use logo.\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-04-10T03:11:30Z",
        "closed_at": "2014-04-10T05:46:05Z",
        "merged_at": "2014-04-10T05:46:05Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 13,
        "changed_files": 2,
        "created_at": "2014-04-05T13:40:47Z",
        "closed_at": "2014-04-05T15:35:16Z",
        "merged_at": null,
        "body": "so that newbies don't run them in the REPL, I've seen it happen :smile: \n",
        "comments": 15
    },
    {
        "merged": false,
        "additions": 767,
        "deletions": 219,
        "changed_files": 28,
        "created_at": "2014-04-05T04:08:12Z",
        "closed_at": "2014-04-05T07:33:55Z",
        "merged_at": null,
        "body": "Changed requests/docs/user/advanced.rst after the 1st section in that doc:\n\nRemove a Value From a Dict Parameter\n\nIt's a distinct section from the rest of the neighboring text.\n\nEDIT:  OK, I'm just learning about commits, and I did the edit on that doc in the browser, and now it's going to the wrong branch.  Just to be clear, I don't have anything else to commit/change other than the doc issue I cited above.  Sorry for the confusion. What's the best way to fix any problems this has caused?\n\nEDIT2:  I figured out what happened and will submit it the right (I think) way this time.  Sorry again for any confusion as I'm just starting to learn how this works.  The submit seemed to go through on the other, so this pull can be disregarded in lieu of the other I made just now.\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 10,
        "changed_files": 1,
        "created_at": "2014-04-05T03:58:22Z",
        "closed_at": "2014-04-08T14:19:40Z",
        "merged_at": "2014-04-08T14:19:40Z",
        "body": "crate.io is gone, so a different mirror should be used as an example. Also, the list of PyPI mirrors should be mentioned.\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 20,
        "deletions": 2,
        "changed_files": 3,
        "created_at": "2014-04-03T16:18:22Z",
        "closed_at": "2014-04-03T22:09:32Z",
        "merged_at": null,
        "body": "When resolving redirects, all methods except HEAD were being converted to GET to mimic browser behavior.\n\nThis change maintains the DELETE method when resolving 302 redirects.\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2014-04-03T00:05:43Z",
        "closed_at": "2014-04-03T05:51:07Z",
        "merged_at": "2014-04-03T05:51:07Z",
        "body": "Just a doc change. If anyone thinks they deserve separate items let me know. /cc @dstufft\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 227,
        "deletions": 76,
        "changed_files": 8,
        "created_at": "2014-03-28T23:42:34Z",
        "closed_at": "2014-03-31T14:29:30Z",
        "merged_at": "2014-03-31T14:29:30Z",
        "body": "I noticed this version of urllib3 was attempting to use RC4 as the cipher, and SSL connections using pyOpenSSL would fail to servers that did not support RC4. Update to v1.8 version of urllib3 to get the new cipher settings pushed in https://github.com/shazow/urllib3/commit/2088570a293df42b1623dd74fcff0174d0565af5.\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 109,
        "deletions": 21,
        "changed_files": 3,
        "created_at": "2014-03-28T19:49:10Z",
        "closed_at": "2014-08-22T13:12:40Z",
        "merged_at": null,
        "body": "The current `Request.links` property has a few problems: it assumes there will only be a single link for a given relation type, and that each link has only a single relation type (see [RFC 5988](http://tools.ietf.org/html/rfc5988)); and the `utils.parse_header_links()` function it relies on does not properly parse inputs containing commas or semicolons within quoted strings. However, since I'm not sure of the proper way to fix either function without breaking backwards compatibility, I've instead created `Requests.links_multi` and `utils.parse_header_links_full`, if only to solicit feedback on the logic itself; the factoring can be changed in any way the maintainers prefer.\n\nSpecifically, `parse_header_links_full` returns a list of the new `Link` `namedtuple`s with `uri` and `attrs` attributes. Internally, it delegates to a new `tokenize` function, which splits a string into a list of tokens (identifiers, \"specials\", and quoted strings) according to the rules in [RFC 2616](http://tools.ietf.org/html/rfc2616#section-2.2), which makes the parsing itself quite straightforward with some application of `itertools`. In addition, `parse_header_links` is reimplemented in terms of this, to at least properly handle quoted delimiters.\n\n`Request.links_multi`, in turn, returns a `CaseInsensitiveDict` keyed on the relation type (`Request.links` has been updated to do this as well), whose values are a list of all the links with that relation type. If a link has multiple relation types (e.g. `rel=\"foo bar\"`), it will be added to the lists for each relation type.\n",
        "comments": 12
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-03-26T13:13:26Z",
        "closed_at": "2014-03-26T15:34:36Z",
        "merged_at": "2014-03-26T15:34:36Z",
        "body": "It used to be None but a recent PR changed that before my last one was merged\n\nFixes #1975 \n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2014-03-22T20:45:36Z",
        "closed_at": "2014-05-12T19:08:31Z",
        "merged_at": "2014-05-12T19:08:31Z",
        "body": "Logging headers for debugging purposes is often necessary, and the currently logging the headers would be using **repr** which would log the implementation detail of headers, caseinsensitivedict. Adding str to case insensitive dict makes the headers of the response object more log friendly, by logging only the request itself and not implementation details.\n",
        "comments": 9
    },
    {
        "merged": false,
        "additions": 123,
        "deletions": 104,
        "changed_files": 2,
        "created_at": "2014-03-16T14:28:24Z",
        "closed_at": "2014-05-12T18:59:59Z",
        "merged_at": null,
        "body": "This is almost entirely moving code around: the new method is\nmost of the code that used to be the loop body of `resolve_redirects`.\n",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 361,
        "deletions": 224,
        "changed_files": 11,
        "created_at": "2014-03-15T19:53:41Z",
        "closed_at": "2014-03-16T04:11:20Z",
        "merged_at": null,
        "body": "This commit fixes various violations of PEP 8. Most of the changes are shortening of lines longer than 79 characters. Compatibility to PEP 8 was checked using Flake-8 and the vim plugin (vim-flake8). Violations because of 'modules being imported and not used'  were left as it is. These are mostly 'unfixable'. \n",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 65,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2014-03-15T17:42:11Z",
        "closed_at": "2014-03-24T15:44:14Z",
        "merged_at": "2014-03-24T15:44:14Z",
        "body": "The original request was never being properly overriden in resolve_redirects.\nAs such being having a POST request respond with a 303 would generate a GET\nrequest. If the GET request encountered another redirect to something like a\n307, then it would use the original request and generate another POST request.\n\nThere are two parts to this fix:\n- The fix itself\n- The test infrastructure to ensure it does not regress because HTTPBin is\n  insufficient\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2014-03-15T16:35:33Z",
        "closed_at": "2014-03-24T15:45:06Z",
        "merged_at": "2014-03-24T15:45:06Z",
        "body": "",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 28,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2014-03-14T08:37:24Z",
        "closed_at": "2014-03-31T14:30:36Z",
        "merged_at": "2014-03-31T14:30:36Z",
        "body": "I have wrote this:\nr = requests.post(url, data=post_data, timeout=10)\nThen I found the data param does not support tuple type, but it should do.\nSo I add one line in the requests/models.py to fix this problem and add some unittest to it.\n",
        "comments": 15
    },
    {
        "merged": true,
        "additions": 102,
        "deletions": 24,
        "changed_files": 3,
        "created_at": "2014-03-12T19:26:15Z",
        "closed_at": "2014-03-23T14:51:48Z",
        "merged_at": "2014-03-23T14:51:48Z",
        "body": "This pull request falls into three commits.\n\nThe first is a refactoring of the `get_environ_proxies` method to make it possible to evaluate whether a given URL is in the NO_PROXY list.\n\nThe second is a refactoring of the `resolve_redirects` method to move rebuilding the `Authorization` header to its own method.\n\nBoth of these commits are intended to set the stage for the third, which is a new method that re-evaluates proxy configuration on a redirect, and re-evaluates proxy authorization as well.\n\nI don't want this merged yet, but it's a pretty sizeable change and I'd like to get eyes on it as early as possible. The key problem right now is that I don't have tests, though it should be possible for me to test this fairly easily. I'll want to add tests before we merge this.\n\n@sigmavirus24, do you mind taking a look?\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2014-03-12T18:36:34Z",
        "closed_at": "2014-03-12T20:18:58Z",
        "merged_at": "2014-03-12T20:18:58Z",
        "body": "I received [this issue](https://github.com/ionrock/cachecontrol/issues/16) in CacheControl where a pickled response throws an error because there is no raw attribute on the response object. The `__setstate__` function should set this explicitly to an empty `urllib3.response.HTTPResponse`.\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 22,
        "deletions": 3,
        "changed_files": 4,
        "created_at": "2014-03-10T19:46:26Z",
        "closed_at": "2014-03-12T20:59:05Z",
        "merged_at": null,
        "body": "This PR adds support for SSL CommonName and fingerprint verification provided by urllib3.\n\nIn contrast to https://github.com/kennethreitz/requests/pull/1606 it is minimally invasive and does not require new API parameters. Instead, it allows \"verify\" to be a dictionary with extra parameters.\n",
        "comments": 13
    },
    {
        "merged": true,
        "additions": 50,
        "deletions": 9,
        "changed_files": 3,
        "created_at": "2014-03-10T07:24:49Z",
        "closed_at": "2014-05-12T20:50:33Z",
        "merged_at": "2014-05-12T20:50:33Z",
        "body": "This is my proposal which fixes #1939 completely.\n\n@sigmavirus24 missed one possible exception in #1940 (ChunkedEncodingError) and didn't handle RuntimeError correctly (because this means that the content is already consumed).\n\nThis also addresses the issue that a decoding error is already thrown in Adapter.send by moving the content reading part at the end of Session.send.\n",
        "comments": 37
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2014-03-10T05:55:50Z",
        "closed_at": "2014-03-10T11:21:52Z",
        "merged_at": null,
        "body": "When work with a pool proxy,It doesn't close connection when except errors.Then request get block forever.\nI don't want add timeout arg for every request.So I opened this pull request.\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2014-03-05T03:08:13Z",
        "closed_at": "2014-03-11T13:19:35Z",
        "merged_at": null,
        "body": "This fixes #1939 and part of @zackw's rehaul of redirection.\n\nTo better test this, I'd like to add Betamax as a test dependency. Also, as a separate PR I plan to kill the usage of `RuntimeError` in `Response#content`. That's awful and the community consensus is that nothing should ever raise that. \n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 32,
        "deletions": 7,
        "changed_files": 2,
        "created_at": "2014-03-04T21:38:30Z",
        "closed_at": "2014-05-12T19:04:35Z",
        "merged_at": "2014-05-12T19:04:35Z",
        "body": "This PR adds basic documentation for the decode_unicode parameter to iter_content (and implicitly for iter_lines). It also ensures the now-documented behavior is correct and consistent, specifically by honoring the parameter in all cases and not just in some (previously only apparent by reading the source).\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2014-02-28T16:11:18Z",
        "closed_at": "2014-03-03T18:14:37Z",
        "merged_at": "2014-03-03T18:14:37Z",
        "body": "Fixes Issue #1803\n",
        "comments": 17
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 17,
        "changed_files": 1,
        "created_at": "2014-02-28T14:29:58Z",
        "closed_at": "2014-03-02T09:34:55Z",
        "merged_at": "2014-03-02T09:34:55Z",
        "body": "- Charade is gone, long live Chardet.\n- cacert.pem is now taken wholesale from Mozilla so we need to display that\n  itis licensed under the MPL2.0\n\nCloses #1933 \n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 173,
        "deletions": 127,
        "changed_files": 1,
        "created_at": "2014-02-26T00:34:55Z",
        "closed_at": "2014-03-12T20:36:16Z",
        "merged_at": null,
        "body": "Sorry for dropping off the face of the earth for a while, folks.  After reading the reaction to my previous pull request, I realized that the bugfixes I want to get in will be easier, cleaner, and make more sense in context if I make the big API change _first_.  So this is the proposed big API change.  It is not fully baked -- if nothing else, it needs tests -- but I'd like to get your opinion on the idea first.\n- Session.send now offers a new mode, `iter_redirects=True`, in which\n  it returns an iterator over redirects _instead of_ the first response.\n  In this mode, the first request does not actually fire until you call\n  next() on the iterator the first time.  Unlike the legacy\n  Session.resolve_redirects, the first response is included in the\n  generated sequence.\n- Session.resolve_redirects is preserved and works as it always has, but\n  is now clearly documented as not the API you want.  (The docstring for\n  Session.send itself probably needs some improvement as well.)  Its\n  calling convention has been slightly polished: the request argument is\n  now optional (defaults to `resp.redirect`), it will accept arbitrary\n  kwargs to be passed to the adapter, and it defaults the same set of kwargs\n  from session settings as `send` itself does.\n- The `allow_redirects=False` mode of `Session.send` also still works just\n  as it always has.  If both allow_redirects=False and iter_redirects=True\n  are specified, allow_redirects=False wins.\n- SessionRedirectMixin has been replaced by a RedirectIterator class\n  which is not a parent of Session.\n- Response.history is now always a list.\n",
        "comments": 18
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 10,
        "changed_files": 2,
        "created_at": "2014-02-18T14:27:19Z",
        "closed_at": "2014-05-12T19:05:56Z",
        "merged_at": "2014-05-12T19:05:56Z",
        "body": "See #1622.\n",
        "comments": 10
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2014-02-14T22:15:56Z",
        "closed_at": "2014-03-03T18:13:13Z",
        "merged_at": "2014-03-03T18:13:13Z",
        "body": "- Regardless of whether they are on the session or not\n- Fixes #1920\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 122,
        "deletions": 21,
        "changed_files": 3,
        "created_at": "2014-02-13T23:15:34Z",
        "closed_at": "2014-02-26T00:50:42Z",
        "merged_at": null,
        "body": "This pull request contains the subset of #1913 which (IMNSHO) consists entirely of bugfixes, with no question about backward compatibility or what the best behavior should be.\n- `Session.resolve_redirects` no longer crashes, when responses are\n  being loaded in `stream=True` mode, if `Response.iter_content`\n  is used to consume the entire stream before advancing the generator.\n- `Response.history` is now always a list, not a tuple.\n- Each response in a chain of redirects now has a filled-out history\n  property, consisting of all responses up to but not including itself.\n\nAnd I didn't bother mentioning it in HISTORY.rst, but `Session.send` doesn't create the redirection resolution generator anymore if it's not going to use it, and `resolve_redirects` doesn't extract cookies anymore that `send` has already extracted, both of which should make things ever so slightly more efficient.\n\nSome of the new tests are pretty grody, and raise the question of whether the response-modification hook should really be _allowed_ to modify history, but there's specific code in `send` to support them, so  this seems to have been a desired feature...\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 36,
        "deletions": 13,
        "changed_files": 5,
        "created_at": "2014-02-13T19:31:51Z",
        "closed_at": "2014-02-13T21:03:37Z",
        "merged_at": "2014-02-13T21:03:37Z",
        "body": "Here's a fresh pull request containing only the new `.is_redirect` property for Response objects.\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-02-13T08:49:54Z",
        "closed_at": "2014-03-12T20:37:27Z",
        "merged_at": "2014-03-12T20:37:27Z",
        "body": "urllib3 doesn't support \"compress\" anyway...\n",
        "comments": 15
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2014-02-12T22:58:35Z",
        "closed_at": "2014-02-13T19:26:54Z",
        "merged_at": null,
        "body": "Putting an exception (or another type) as the first argument\nto an Exception is confusing and makes it so that a caller's\n\"e.message\" returns an Exception type rather than a string.\n\nWe spent quite a long time on this bug today -- a fix would be\nmuch appreciated. Thanks!\n\n--Robin\n",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 297,
        "deletions": 167,
        "changed_files": 7,
        "created_at": "2014-02-11T20:33:32Z",
        "closed_at": "2014-03-12T20:59:23Z",
        "merged_at": null,
        "body": "I'd like to propose a bunch of bugfixes and API improvements to redirection resolution, particularly when it's being done manually (i.e. `allow_redirects=False` on the initial `send()`).  These are all motivated by problems I encountered while trying to chase redirects for every single URL in the Alexa top million, which, as you might imagine, contains an awful lot of misconfiguredness (up to and including IMAP and SMTP servers on ports 80 and 443!)\n\nThe most significant change is the new `Session.resolve_one_redirect` method, which does what it says - it resolves _one_ redirect.  This turns out to be substantially more convenient for applications that need to do complicated processing on each redirect as it happens, than the existing `Session.resolve_redirects` generator.  It goes along with `Response.is_redirect`, a new property that is the canonical home for the \"is this a redirect\" predicate.\n\nThe second most significant change is that each response in a redirection chain now has an accurate `.history` property, containing all responses up to but not including itself.  As a side effect, I anti-resolved issue #1898 - `.history` is now always a _list_.\n\nThe third most significant change is that `resolve_one_redirect` and `resolve_redirects` do not need to be passed a bunch of arguments that were already passed to the initial `send`; concretely, all of `send`'s kwargs are cached on the `PreparedRequest` and reused thereafter.\n\nEverything else is bugfixes, generally in the service of greater robustness against Weird Shit coming off the network.\n",
        "comments": 24
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-02-11T17:16:33Z",
        "closed_at": "2014-02-13T12:53:36Z",
        "merged_at": null,
        "body": "Real fix for #1898\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 32,
        "deletions": 6,
        "changed_files": 2,
        "created_at": "2014-02-07T14:50:28Z",
        "closed_at": "2014-02-08T13:35:06Z",
        "merged_at": null,
        "body": "If pyopenssl is available and you give an empty ca_certs to urllib3,\nit will use the default CA of the current platform.\n\nNot ready for merging as this feature requires a bleeding edge version of urllib3 (https://github.com/shazow/urllib3/commit/5c25a73dfb48e4260c44e19e3a50fb5d46832c52)\n\nI post this PR now, to discuss about its implementation and testing improvements.\nAbout testing we could run the project with tox and iterate among different versions of python and with or without dependencies of urllib3.contrib.pyopenssl.\n\n```\npyOpenSSL\nndg-httpsclient\npyasn1\n```\n\nthx\n",
        "comments": 20
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-02-05T17:31:31Z",
        "closed_at": "2014-02-05T18:32:16Z",
        "merged_at": "2014-02-05T18:32:16Z",
        "body": "Made `.status_code` and `.reason` consistent with one another, adding some examples. Addresses #1225.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 6,
        "changed_files": 2,
        "created_at": "2014-02-03T13:45:16Z",
        "closed_at": "2014-02-07T02:32:41Z",
        "merged_at": "2014-02-07T02:32:41Z",
        "body": "Logging has been removed long ago, the import and `log` object are dead code to be pruned with a vengeance.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2014-02-03T13:40:24Z",
        "closed_at": "2014-02-04T08:53:53Z",
        "merged_at": "2014-02-04T08:53:53Z",
        "body": "",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-02-03T12:01:10Z",
        "closed_at": "2014-02-11T16:55:21Z",
        "merged_at": "2014-02-11T16:55:21Z",
        "body": "A JSON response that has no encoding specified will be decoded with a detected UTF codec (compliant with the JSON RFC), but if that fails, we guessed wrong and need to fall back to charade character detection (via `self.text`). Kenneth removed this functionality (by accident?) in 1451ba0c6d395c41f86da35036fa361c3a41bc90, this reinstates it again and adds a log warning.\n\nFixes #1674\n",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-02-02T16:09:22Z",
        "closed_at": "2014-02-11T16:56:32Z",
        "merged_at": null,
        "body": "An empty history was represented by an empty list whereas a non-empty history was a tuple.\nNow the type of .history is always a tuple, so it does not break code such as `req.history + (req,)`.\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 25,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2014-02-02T09:18:43Z",
        "closed_at": "2014-02-11T16:55:33Z",
        "merged_at": "2014-02-11T16:55:33Z",
        "body": "Adds a section to Request's advanced usage guide on what Server Name\nIndication is, its purpose, and how to enable it on Python2.\n",
        "comments": 11
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2014-01-30T13:26:25Z",
        "closed_at": "2014-01-30T17:25:23Z",
        "merged_at": null,
        "body": "This would make simple usages simpler:\n\n``` python\nresult = requests.get(\"http://api.server.com/path\").raise_for_status().json()\n```\n",
        "comments": 10
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2014-01-29T19:23:36Z",
        "closed_at": "2014-01-30T17:23:57Z",
        "merged_at": "2014-01-30T17:23:57Z",
        "body": "Apparently RPM doesn't like us having the full license text in the 'license' section, as in #1878. Seems innocuous to change this, because realistically who the hell cares?\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2014-01-29T19:15:37Z",
        "closed_at": "2014-01-31T17:19:53Z",
        "merged_at": "2014-01-31T17:19:53Z",
        "body": "This should be a fix for #1885.\n\n@sigmavirus24, can you give me some code review? =)\n",
        "comments": 21
    },
    {
        "merged": true,
        "additions": 16,
        "deletions": 9,
        "changed_files": 2,
        "created_at": "2014-01-29T02:16:48Z",
        "closed_at": "2014-02-11T16:58:23Z",
        "merged_at": "2014-02-11T16:58:23Z",
        "body": "Pass request objects in `HTTPAdapter`.\n\nFixes #1890\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2014-01-28T17:18:12Z",
        "closed_at": "2014-01-28T20:14:38Z",
        "merged_at": "2014-01-28T20:14:38Z",
        "body": "Fixes #1887\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 34,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2014-01-27T09:52:43Z",
        "closed_at": "2014-01-27T17:38:53Z",
        "merged_at": null,
        "body": "Currently only works for http as ssl module is not yet fully functional.\n\nRan the tests, with some (expectedly) failing on ssl support\n",
        "comments": 17
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-01-25T08:21:26Z",
        "closed_at": "2014-01-25T13:38:39Z",
        "merged_at": "2014-01-25T13:38:39Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 152,
        "deletions": 32,
        "changed_files": 6,
        "created_at": "2014-01-22T19:28:54Z",
        "closed_at": "2014-01-23T18:22:21Z",
        "merged_at": "2014-01-23T18:22:21Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 151,
        "deletions": 31,
        "changed_files": 7,
        "created_at": "2014-01-21T18:14:14Z",
        "closed_at": "2014-01-22T19:31:01Z",
        "merged_at": null,
        "body": "Adds a short discussion of the change to HISTORY.rst\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2014-01-19T04:48:47Z",
        "closed_at": "2014-01-23T18:54:08Z",
        "merged_at": "2014-01-23T18:54:08Z",
        "body": "We can add more info to discuss the inclusion of @lukasa's `SSLAdapter`. Are there any objections to adding this information to requests' documentation?\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2014-01-16T08:39:35Z",
        "closed_at": "2014-01-16T22:16:05Z",
        "merged_at": "2014-01-16T22:16:05Z",
        "body": "From #1493. Provides a way to use the `Response` object as a context manager without adding the conceptual overhead to the `Response` class.\n\nI'm still on the fence about whether we should document this or just make `Response`s context managers, but this seems the least controversial option so lets do this first.\n\nReview: @sigmavirus24, @pepijndevos.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 24,
        "deletions": 12,
        "changed_files": 3,
        "created_at": "2014-01-13T12:39:59Z",
        "closed_at": "2014-01-14T19:56:04Z",
        "merged_at": "2014-01-14T19:56:04Z",
        "body": "As per #1856, fixes the parsing of URI encoded usernames and password. Also fixes a bogus test where the username in the URI was not correctly encoded.\n",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-01-13T01:59:16Z",
        "closed_at": "2014-01-16T12:53:31Z",
        "merged_at": null,
        "body": "Guess content type for posting files, just like what urllib3 does.\n",
        "comments": 27
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2014-01-12T20:28:11Z",
        "closed_at": "2015-12-18T09:18:26Z",
        "merged_at": "2015-12-18T09:18:26Z",
        "body": "Fixes #1859\n\nCredit: @lukasa\n",
        "comments": 12
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 11,
        "changed_files": 3,
        "created_at": "2014-01-11T10:00:52Z",
        "closed_at": "2014-01-13T13:10:10Z",
        "merged_at": null,
        "body": "This _should_ resolve #1856. /cc @sigmavirus24 @t-8ch.\n",
        "comments": 10
    },
    {
        "merged": true,
        "additions": 34,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2014-01-09T05:44:17Z",
        "closed_at": "2014-01-09T19:46:49Z",
        "merged_at": "2014-01-09T19:46:49Z",
        "body": "",
        "comments": 12
    },
    {
        "merged": false,
        "additions": 24,
        "deletions": 5,
        "changed_files": 3,
        "created_at": "2014-01-08T04:33:20Z",
        "closed_at": "2014-01-08T07:54:40Z",
        "merged_at": null,
        "body": "This implements a `send` hook, which is called right before a `Request` object is sent.\n\nMy motivation here is for a profiler I've written that automatically records request timing information (by recording a timestamp before a request is sent, and after), but I think there are probably a lot of other use cases, such as automagically munging request headers or whatnot.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2014-01-07T20:32:39Z",
        "closed_at": "2014-01-07T23:22:24Z",
        "merged_at": "2014-01-07T23:22:24Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 13,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2014-01-07T16:38:29Z",
        "closed_at": "2014-01-08T18:57:09Z",
        "merged_at": "2014-01-08T18:57:09Z",
        "body": "https://github.com/toastdriven/django-haystack/issues/924 has a problem report from a user who appears to be running inside a process which does not have `$HOME` defined and is running under a UID which is either not in /etc/passwd or does not have permission to access it.\n\nThis causes [utils.get_netrc_auth](https://github.com/kennethreitz/requests/blob/v2.1.0/requests/utils.py#L73) to raise an unexpected `KeyError`. The easiest fix would be to simply add that to the except block at the bottom but that's probably too dangerous \u2013 I'd probably handle the `KeyError` right at the source until this can be fixed upstream.\n",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2014-01-07T09:40:58Z",
        "closed_at": "2014-01-08T18:51:08Z",
        "merged_at": "2014-01-08T18:51:08Z",
        "body": "This resolves the sad, sad 2.6.x problems in `proxy_bypass` as reported in #1844 and #1841.\n\nThe nature of this fix is that, fundamentally, we don't care enough to let this call stop us. Assume that if it fails we aren't bypassing the proxy (usually we won't be) and move on with our lives.\n\nI'm only catching the specific exceptions we've seen. I'm open to wrapping this in a generic `except` block if we want to.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 3,
        "created_at": "2014-01-02T22:01:41Z",
        "closed_at": "2014-01-08T18:44:21Z",
        "merged_at": "2014-01-08T18:44:21Z",
        "body": "s/2013/2014\n",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 6,
        "changed_files": 5,
        "created_at": "2013-12-28T08:11:57Z",
        "closed_at": "2014-01-08T18:45:33Z",
        "merged_at": "2014-01-08T18:45:33Z",
        "body": "It may be nice to make builds fail if new documentation generates warnings, to\navoid these sorts of problems slipping in in the future.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 47,
        "deletions": 36,
        "changed_files": 2,
        "created_at": "2013-12-28T07:47:48Z",
        "closed_at": "2014-01-08T18:48:25Z",
        "merged_at": "2014-01-08T18:48:25Z",
        "body": "Also fixes up tense in a few cases, and adds the `intersphinx` extension so we\ncan link to the urllib3 documentation when it is called out.\n\nI should probably write documentation for how to do this somewhere as well...\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-12-27T08:37:25Z",
        "closed_at": "2013-12-27T09:39:03Z",
        "merged_at": null,
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-12-24T10:25:28Z",
        "closed_at": "2014-01-08T18:50:00Z",
        "merged_at": "2014-01-08T18:50:00Z",
        "body": "I was doing hundreds of parallel requests, and kept seeing warnings about dropped connections because the connection pool was full.\n\nSo I increased the connection pool on the adapter, and increased it some more. And then even more. It did not help.\n\nThen I noticed that only my proxy connections where dropped.\nSome investigation revealed that proxy connections use their own pool subclass.\nHowever, this pool is created without respecting the pool size setting.\n\nThis PR simply propagates the pool kwargs to the proxy pool.\nI contemplated adding additional kwargs for the proxy pool size, but this seems uneccecery complexity.\n\nIf there is a use case for using one Session for proxied and direct requests, and the proxies needs a different pool size than the direct connections, I could add that.\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2013-12-20T09:16:45Z",
        "closed_at": "2013-12-20T14:21:04Z",
        "merged_at": "2013-12-20T14:21:04Z",
        "body": "This should help address the concerns raised in #1795.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2013-12-19T09:07:16Z",
        "closed_at": "2013-12-19T20:38:34Z",
        "merged_at": "2013-12-19T20:38:34Z",
        "body": "Re-raise DecodeError in urllib3 for https://github.com/kennethreitz/requests/issues/1815.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4450,
        "deletions": 4438,
        "changed_files": 46,
        "created_at": "2013-12-18T14:47:36Z",
        "closed_at": "2013-12-18T15:52:55Z",
        "merged_at": "2013-12-18T15:52:55Z",
        "body": "Fixes #1800\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2013-12-18T04:55:25Z",
        "closed_at": "2013-12-18T15:56:30Z",
        "merged_at": "2013-12-18T15:56:30Z",
        "body": "Sure cookies are persisted to the session, but those new cookies are not added\nto the next prepared request. We need to update that new request's CookieJar\nwith the new cookies.\n\n/cc @teleyinex\nThis allows me to fetch the URL you specified quite quickly.\n\nTODO:\n- [ ] Find a way to reliably test this. Perhaps introduce [Betamax](https://github.com/sigmavirus24/betamax) to make this test reproducible.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 108,
        "deletions": 10,
        "changed_files": 3,
        "created_at": "2013-12-18T03:03:21Z",
        "closed_at": "2013-12-19T20:38:52Z",
        "merged_at": "2013-12-19T20:38:52Z",
        "body": "```\nPython 2.7.5+ (default, Sep 19 2013, 13:48:49) \n[GCC 4.8.1] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import requests\n>>> requests.__version__\n'2.1.0'\n>>> r = requests.get('http://google.com')\n>>> r.cookies\n<<class 'requests.cookies.RequestsCookieJar'>[Cookie(version=0, name='NID', value='67=WbyIM1gU91bGQ5Y3SjPHQ8_fqtStHiMWGJQ5n2Bt_PwytcmPii7fV7AELJ95cqfSmhAHSJCtFm0bBDZJJoTzQHGGQvk6PT8h78PrwWi96r0K7R9N0KsNCZkkrgJW94dV', port=None, port_specified=False, domain='.google.ru', domain_specified=True, domain_initial_dot=True, path='/', path_specified=True, secure=False, expires=1403146705, discard=False, comment=None, comment_url=None, rest={'HttpOnly': None}, rfc2109=False), Cookie(version=0, name='PREF', value='ID=7c3265d2706e8bea:FF=0:NW=1:TM=1387335505:LM=1387335505:S=LsdqbwGuUdHENT0m', port=None, port_specified=False, domain='.google.ru', domain_specified=True, domain_initial_dot=True, path='/', path_specified=True, secure=False, expires=1450407505, discard=False, comment=None, comment_url=None, rest={}, rfc2109=False)]>\n>>> dict(r.cookies)\n{'PREF': 'ID=7c3265d2706e8bea:FF=0:NW=1:TM=1387335505:LM=1387335505:S=LsdqbwGuUdHENT0m', 'NID': '67=WbyIM1gU91bGQ5Y3SjPHQ8_fqtStHiMWGJQ5n2Bt_PwytcmPii7fV7AELJ95cqfSmhAHSJCtFm0bBDZJJoTzQHGGQvk6PT8h78PrwWi96r0K7R9N0KsNCZkkrgJW94dV'}\n>>> r.cookies.items()\n[('NID', '67=WbyIM1gU91bGQ5Y3SjPHQ8_fqtStHiMWGJQ5n2Bt_PwytcmPii7fV7AELJ95cqfSmhAHSJCtFm0bBDZJJoTzQHGGQvk6PT8h78PrwWi96r0K7R9N0KsNCZkkrgJW94dV'), ('PREF', 'ID=7c3265d2706e8bea:FF=0:NW=1:TM=1387335505:LM=1387335505:S=LsdqbwGuUdHENT0m')]\n>>> r.cookies.iteritems()\n<generator object iteritems at 0x1940dc0>\n>>> list(r.cookies.iteritems())\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/home/kpp/build/trng_social/venv/lib/python2.7/_abcoll.py\", line 387, in iteritems\n    yield (key, self[key])\n  File \"/home/kpp/build/trng_social/venv/local/lib/python2.7/site-packages/requests/cookies.py\", line 267, in __getitem__\n    return self._find_no_duplicates(name)\n  File \"/home/kpp/build/trng_social/venv/local/lib/python2.7/site-packages/requests/cookies.py\", line 322, in _find_no_duplicates\n    raise KeyError('name=%r, domain=%r, path=%r' % (name, domain, path))\nKeyError: \"name=Cookie(version=0, name='NID', value='67=WbyIM1gU91bGQ5Y3SjPHQ8_fqtStHiMWGJQ5n2Bt_PwytcmPii7fV7AELJ95cqfSmhAHSJCtFm0bBDZJJoTzQHGGQvk6PT8h78PrwWi96r0K7R9N0KsNCZkkrgJW94dV', port=None, port_specified=False, domain='.google.ru', domain_specified=True, domain_initial_dot=True, path='/', path_specified=True, secure=False, expires=1403146705, discard=False, comment=None, comment_url=None, rest={'HttpOnly': None}, rfc2109=False), domain=None, path=None\"\n```\n\nBecause of this one can't for example build `OrderedDict` from `RequestCookieJar`.\n",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 78,
        "deletions": 9,
        "changed_files": 3,
        "created_at": "2013-12-16T05:41:53Z",
        "closed_at": "2013-12-16T14:08:23Z",
        "merged_at": null,
        "body": "When a HTTP response doesn't contain the content that I expect, most times I find that the simplest debugging information I want is the actual HTTP content that was sent over the wire. Instead of having to construct all of this manually I thought it would be nice to add this information as a convenience `as_http()` request.\n\nExample:\n\n``` python\n>>> r = requests.get('https://api.twilio.com/2010-04-01.json')\n>>> print r.as_http()\nHTTP/1.1 200 OK\ncontent-length: 109\nx-powered-by: AT-5000\nconnection: close\netag:\ndate: Mon, 16 Dec 2013 05:39:55 GMT\nx-shenanigans: none\naccess-control-allow-origin: https://www.twilio.com\ncontent-type: application/json\n\n{\"name\":\"2010-04-01\",\"uri\":\"\\/2010-04-01.json\",\"subresource_uris\":{\"accounts\":\"\\/2010-04-01\\/Accounts.json\"}}\n```\n\nThis PR also passes through version information as an attribute on the `Response` object, and adds tests for this method.\n\nI asked about this in IRC last week, didn't get much feedback, figured it wouldn't be too hard to just write it up and submit a PR.\n",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 138,
        "deletions": 14,
        "changed_files": 8,
        "created_at": "2013-12-16T04:10:00Z",
        "closed_at": "2014-08-23T21:22:02Z",
        "merged_at": null,
        "body": "Per discussion with @sigmavirus24 in IRC, this PR kills the Timeout class and adds support for connect timeouts via a simple tuple interface: \n\n``` python\nr = requests.get('https://api.twilio.com', timeout=(3.05, 27))\n```\n\nSometimes you try to connect to a dead host (this happens to us all the time, because of AWS) and you would like to fail fairly quickly in this case; the request has no chance of succeeding. However, once the connection succeeds, you'd like to give the server a fairly long time to process the request and return a response. \n\nThe attached tests and documentation have more information. Hope this is okay!\n",
        "comments": 36
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2013-12-14T20:11:04Z",
        "closed_at": "2013-12-15T04:20:07Z",
        "merged_at": null,
        "body": "",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 11,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2013-12-14T03:50:35Z",
        "closed_at": "2013-12-14T20:11:51Z",
        "merged_at": null,
        "body": "When there's no encoding in the headers and it has to be autodetected from the\ncontents using charade, the Response object should expose the confidence value\nso the user can decide whether the value of Response.text should be trusted or\nnot.\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2013-12-13T00:26:27Z",
        "closed_at": "2013-12-14T04:29:58Z",
        "merged_at": null,
        "body": "Fixed issue https://github.com/kennethreitz/requests/issues/1777 by adding unpickle support to the HTTPAdapter.  \n\nWhile unpickleing, the class will now set `proxy_manager` to an empty dictionary.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2013-12-12T19:04:51Z",
        "closed_at": "2014-01-08T18:53:42Z",
        "merged_at": "2014-01-08T18:53:42Z",
        "body": "@Lukasa if you'd like to add tests for this you can. I'm not exactly certain if we already had tests for pickling objects and didn't have the time to check right now. I'll check when I get home though (unless you've already added tests).\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2013-12-11T05:01:57Z",
        "closed_at": "2013-12-11T06:58:29Z",
        "merged_at": null,
        "body": "...enSSL\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2013-12-06T19:46:03Z",
        "closed_at": "2013-12-07T05:55:44Z",
        "merged_at": null,
        "body": "make the version reusable too.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2013-12-05T06:41:57Z",
        "closed_at": "2013-12-05T19:44:06Z",
        "merged_at": "2013-12-05T19:44:06Z",
        "body": "This is not exciting change, but will help for people who wants to change name of user agent alone. Also name can be unicode.\n",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 22,
        "deletions": 12,
        "changed_files": 4,
        "created_at": "2013-12-04T12:46:50Z",
        "closed_at": "2013-12-05T22:26:58Z",
        "merged_at": "2013-12-05T22:26:58Z",
        "body": "This is just @gazpachoking's PR #1729 in a mergable state and with the PR feedback that @Lukasa left on it.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2013-12-03T15:19:22Z",
        "closed_at": "2013-12-04T01:02:25Z",
        "merged_at": "2013-12-04T01:02:25Z",
        "body": "- Hopefully people will read this before making changes to vendored libraries\n\nHopefully this will prevent PRs like: #1773\n",
        "comments": 15
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2013-12-03T12:44:55Z",
        "closed_at": "2013-12-03T14:10:19Z",
        "merged_at": null,
        "body": "Fix issue @tardyp reported on #239\n\nWe have not been able to reproduce on a simple testcase. We can only make it happen on our complex environment; involving buildbot, twisted and txrequests.\n\nThis fix no longer exhibits the issue. Please, give us a feedback whether this solutions is correct.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 83,
        "deletions": 22,
        "changed_files": 3,
        "created_at": "2013-12-03T02:56:53Z",
        "closed_at": "2013-12-06T15:38:12Z",
        "merged_at": "2013-12-06T15:38:12Z",
        "body": "Fix a pep8 error. Prior to fixing this, I implemented some tests to cover the code I was fixing. This should help prevent regression issues.\n",
        "comments": 16
    },
    {
        "merged": true,
        "additions": 106,
        "deletions": 5,
        "changed_files": 3,
        "created_at": "2013-12-02T21:55:18Z",
        "closed_at": "2013-12-05T22:40:44Z",
        "merged_at": "2013-12-05T22:40:44Z",
        "body": "Hello,\n\nDuring OpenStack implementation we found out that it is not possible to use IP ranges in no_proxy environment variable. We needed to exclude whole range of IP addresses (172.28.1.0/24), not only domain names or particular IP addresses.\n\nNow it is possible to specify no_proxy like\n\n```\nno_proxy=127.0.0.1,192.168.0.0/24\n```\n\nand request to http://192.168.0.20:5000/ won't go through http proxy.\n\nI added tests for no_proxy function as well.\n\nKamil\n",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2013-12-01T11:34:25Z",
        "closed_at": "2013-12-04T01:36:00Z",
        "merged_at": "2013-12-04T01:36:00Z",
        "body": "Fixes #1767.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2013-11-29T08:38:09Z",
        "closed_at": "2013-12-04T01:33:59Z",
        "merged_at": "2013-12-04T01:33:59Z",
        "body": "Resolves #1765.\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-11-29T06:45:00Z",
        "closed_at": "2013-11-29T16:47:12Z",
        "merged_at": null,
        "body": "Based on RFC2617 (http://tools.ietf.org/html/rfc2617), the value of\n'qop-options' directive should be quoted with double quotes:\n\n```\nqop-options\n     This directive is optional, but is made so only for backward\n     compatibility with RFC 2069 [6]; it SHOULD be used by all\n     implementations compliant with this version of the Digest\n     scheme. If present, it is a quoted string of one or more\n     tokens indicating the \"quality of protection\" values supported by\n     the server.  The value \"auth\" indicates authentication; the\n     value \"auth-int\" indicates authentication with\n     integrity protection; see the\n```\n\ncurl comamnd-line tool also appends these quotes. You can see this\nby `curl -v --digest --user user:passwd http://example.com/digest-auth`.\nUnfortunately, some minor server-side implementations seem to be sensitive\non this difference.\n",
        "comments": 10
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2013-11-28T18:36:29Z",
        "closed_at": "2013-12-04T01:35:02Z",
        "merged_at": "2013-12-04T01:35:02Z",
        "body": "There are a few nasty bugs that we've fixed since the last release, including the broken SNI support. It'd be good to get another release out. I think a few things have changed dramatically enough that this is probably a minor release (e.g. takes us to 2.1.0). Thoughts? /cc @kennethreitz @sigmavirus24\n\nStill to do:\n- [ ] Merge outstanding PRs (definitely ~~#1713, #1657, #1768, and #1766~~; maybe #1729, #1628 and #1743 depending on how @kennethreitz feels).\n- [ ] Update changelog to match those PRs.\n\nIf nothing else Runscope could do with this release, so it'd be nice to be in good shape.\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-11-27T02:42:29Z",
        "closed_at": "2013-11-27T17:23:40Z",
        "merged_at": "2013-11-27T17:23:40Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2013-11-25T14:26:36Z",
        "closed_at": "2013-11-25T19:40:10Z",
        "merged_at": "2013-11-25T19:40:10Z",
        "body": "When using Digest Authentication, the client resends the same request\nafter the server responds with the 401 \"Unauthorized\". However, when\ndoing streaming uploads, it gets stuck because the body data (a\nfile-like object) is already consumed at the initial request.\n\nThe patch fixes this by rewinding the file-like object before\nresending the request.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2013-11-24T11:20:20Z",
        "closed_at": "2013-11-25T19:40:00Z",
        "merged_at": "2013-11-25T19:40:00Z",
        "body": "See the discussion on issue #1704.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 6,
        "changed_files": 2,
        "created_at": "2013-11-19T11:01:25Z",
        "closed_at": "2013-11-20T09:05:15Z",
        "merged_at": "2013-11-20T09:05:15Z",
        "body": "#1746\n\nModified adapters not to lowercase the whole url.\nBecause `urlparse` automatically makes scheme lowercase, `scheme.lower()` is unnecessary.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-11-18T21:35:38Z",
        "closed_at": "2013-11-20T08:58:21Z",
        "merged_at": "2013-11-20T08:58:21Z",
        "body": "Code:\n\n``` python\nimport requests\nresp = requests.get('http://www.servanegaxotte.com') \n# or khvigra.ru, nastersrl.ru, spcentre2000.ru etc.\n```\n\nRaised exception:\n\n```\n  File \"C:\\Python27\\lib\\cookielib.py\", line 1645, in extract_cookies\n    self.set_cookie(cookie)\n  File \"C:\\Python27\\lib\\site-packages\\requests\\cookies.py\", line 270, in set_cookie\n    if cookie.value.startswith('\"') and cookie.value.endswith('\"'):\nAttributeError: 'NoneType' object has no attribute 'startswith'\n```\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 100,
        "deletions": 17,
        "changed_files": 7,
        "created_at": "2013-11-18T08:54:49Z",
        "closed_at": "2013-12-05T22:29:56Z",
        "merged_at": null,
        "body": "Support separate connect timeouts in Requests by allowing you to write something like\n\n``` python\nimport requests.structures.Timeout\nt = Timeout(connect=3, read=7)\nrequests.get('https://api.twilio.com', timeout=t)\n```\n\nAdds tests, docs and some new exceptions for this functionality.\n\nPlease note, this kills the current `stream` based branching of timeouts. The `timeout` value applies only to the amount of time between bytes sent by the server. So, if a read timeout is set to 20 seconds and the server streams one byte every 15 seconds, the read timeout will never get hit. This means long streaming downloads are ok and won't hit the read timeout even if it's specified.\n\nIt is perfectly valid to set a read timeout on a streaming request - if the request doesn't start streaming in 15 seconds, then raise an error. With the current master, this is impossible.\n",
        "comments": 11
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2013-11-18T02:39:07Z",
        "closed_at": "2013-11-20T09:02:38Z",
        "merged_at": "2013-11-20T09:02:38Z",
        "body": "Hooray makefiles :)\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2013-11-15T14:22:03Z",
        "closed_at": "2013-11-15T18:51:47Z",
        "merged_at": "2013-11-15T18:51:47Z",
        "body": "[issue 1545](https://github.com/kennethreitz/requests/issues/1545), setup code coverage.\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 1,
        "changed_files": 3,
        "created_at": "2013-11-15T10:16:41Z",
        "closed_at": "2013-11-15T14:24:16Z",
        "merged_at": null,
        "body": "[issue 1545](https://github.com/kennethreitz/requests/issues/1545), setup code coverage.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 1,
        "changed_files": 3,
        "created_at": "2013-11-13T19:11:29Z",
        "closed_at": "2013-11-15T09:33:38Z",
        "merged_at": "2013-11-15T09:33:38Z",
        "body": "Let's get ourselves green on [this list](http://pythonwheels.com/). We're pure python, so this should be totally trivial for us. I'll try to provide a PR tonight.\n",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 44,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2013-11-09T22:49:23Z",
        "closed_at": "2013-11-20T09:01:26Z",
        "merged_at": "2013-11-20T09:01:26Z",
        "body": "Includes a basic test. More could be add to confirm known attributes\nthat could cause problems.\n\nThis should fix #1367.\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2013-11-08T08:47:55Z",
        "closed_at": "2013-11-08T10:08:26Z",
        "merged_at": null,
        "body": "lowercase cookie names when check badargs\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 21,
        "deletions": 12,
        "changed_files": 4,
        "created_at": "2013-11-07T02:59:28Z",
        "closed_at": "2013-12-04T12:44:25Z",
        "merged_at": null,
        "body": "This is how I think things should be fixed if we are okay with adding the cookiejar to `PreparedRequest`s. What do you guys think?\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 153,
        "deletions": 107,
        "changed_files": 8,
        "created_at": "2013-11-04T18:57:04Z",
        "closed_at": "2013-11-04T21:55:58Z",
        "merged_at": "2013-11-04T21:55:58Z",
        "body": "... and use the opportunity to add myself to `AUTHORS.rst`\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2013-11-04T09:37:00Z",
        "closed_at": "2013-11-04T21:58:12Z",
        "merged_at": "2013-11-04T21:58:12Z",
        "body": "I'm unsure that using unicode to `method` is expectable behavior or not.\nbut this pull request will fix #1723\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 18,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2013-10-30T20:33:27Z",
        "closed_at": "2013-11-15T09:33:03Z",
        "merged_at": "2013-11-15T09:33:03Z",
        "body": "Requests supports adding other URL schemes by mounting an adapter for them. For\nschemes that have unfamiliar URLs, requests currently prevents the request from ever reaching the adapter, making it impossible to extend requests with sometimes convenient extensions. This change allows requests to detect this and gives the adapter author the full ability to shoot themselves firmly in the foot.\n\nNOTE: This is to be compatible with the previous work I did to add a file URL scheme to Requests (which is now available here: https://github.com/jvantuyl/requests-file). I've since added a data URL scheme implementation (available https://github.com/jvantuyl/requests-data).\n",
        "comments": 17
    },
    {
        "merged": true,
        "additions": 35,
        "deletions": 5,
        "changed_files": 3,
        "created_at": "2013-10-29T14:49:12Z",
        "closed_at": "2013-12-04T01:33:33Z",
        "merged_at": "2013-12-04T01:33:33Z",
        "body": "I think i missed the point that cookies can be Dict or CookieJar.\nThis fix will work for MozillaCookieJar.\n",
        "comments": 25
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2013-10-29T09:29:42Z",
        "closed_at": "2013-10-30T17:17:26Z",
        "merged_at": "2013-10-30T17:17:26Z",
        "body": "Requests supports adding other URL schemes by mounting an adapter for them.  For\nschemes that have unfamiliar URLs, requests currently prevents the request from ever reaching the adapter, making it impossible to extend requests with sometimes convenient extensions.  This change allows requests to detect this and gives the adapter author the full ability to shoot themselves firmly in the foot.\n\nNOTE:  This is to be compatible with the previous work I did to add a file URL scheme to Requests (which is now available here: https://github.com/jvantuyl/requests-file).  I've since added a data URL scheme implementation (available https://github.com/jvantuyl/requests-data).\n",
        "comments": 24
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2013-10-26T23:43:11Z",
        "closed_at": "2013-10-28T17:31:59Z",
        "merged_at": "2013-10-28T17:31:59Z",
        "body": "otherwise python3.4 warns\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 161,
        "deletions": 182,
        "changed_files": 1,
        "created_at": "2013-10-26T10:43:14Z",
        "closed_at": "2013-10-28T17:32:09Z",
        "merged_at": "2013-10-28T17:32:09Z",
        "body": "Also fixed the test `test_prepared_from_session` which always return true but I believe the test means to check to equality of the two values.\n\nFought hard to not modify some test strings to introduce some classical music humor.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 22,
        "deletions": 17,
        "changed_files": 1,
        "created_at": "2013-10-26T09:20:13Z",
        "closed_at": "2013-10-28T17:32:21Z",
        "merged_at": "2013-10-28T17:32:21Z",
        "body": "Because i thought it will not be merged, i checkout-ed auth.py in my another pull request.\nAs for that pull request is merged, my previous fix of auth.py to add 'MD5-sess' is deleted in master branch.\nhttps://github.com/kennethreitz/requests/commit/3501ea463432400c77479dddedab3b7af967b618\n(it's original commit)\nSorry for my mistake and sorry for confusing :(\nThis is pull request restoring previous fixes.\nthanks.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 30,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2013-10-24T20:24:11Z",
        "closed_at": "2013-10-28T17:34:07Z",
        "merged_at": "2013-10-28T17:34:07Z",
        "body": "In response to some of the discussion in #1698. Looking for review from @sigmavirus24. =)\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2013-10-22T20:51:27Z",
        "closed_at": "2013-10-24T11:10:14Z",
        "merged_at": "2013-10-24T11:10:14Z",
        "body": "First contribution, half expecting to see that I screwed something up. Thanks a lot @Lukasa for your assistance in IRC.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2013-10-20T17:33:01Z",
        "closed_at": "2013-10-21T08:31:50Z",
        "merged_at": "2013-10-21T08:31:50Z",
        "body": "We keep seeing issues on the tracker and on StackOverflow where people are using `r.raw.read` to get the streamed content. The docs don't ever explicitly say they shouldn't do this so I added an addendum to recommend that they instead use `iter_content` instead. A recipe for saving that content to a file is also provided.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-10-20T07:48:29Z",
        "closed_at": "2013-10-24T14:35:40Z",
        "merged_at": "2013-10-24T14:35:40Z",
        "body": "Just a short bit that suggests a possible fix to the problem\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2013-10-18T17:35:07Z",
        "closed_at": "2013-10-24T14:38:52Z",
        "merged_at": "2013-10-24T14:38:52Z",
        "body": "This resolves #1688.\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2013-10-17T16:38:46Z",
        "closed_at": "2013-10-18T08:06:35Z",
        "merged_at": null,
        "body": "#### Problem\n\nWhen making a POST request with the `files` argument, one should not specify the `'content-type'` header. This is because internally, requests forms the content-type header with a boundary string matching that used in the body; if this boundary string is not present in the header then there will be a server-side error. However, if the user does supply a content-type header, then although requests still forms the correct header internally, it silently drops it in favor of the user-supplied header, which it knows to be invalid, because the user has no way of knowing the boundary string that requests will send in the body.\n#### Example\n\n``` python\nfrom test_requests import httpbin\nimport requests\nurl = httpbin('post')\nwith open('requirements.txt') as f:\n    resp = requests.post(url, files={'some': f},\n                         headers={'content-type': 'multipart/form-data'})\n    resp.raise_for_status()\n\n# requests.exceptions.HTTPError: 500 Server Error: INTERNAL SERVER ERROR\n```\n#### Proposed fix\n\nThis PR raises an exception if the user attempts to supply a value for the `'content-type'` header when making a POST request with the `files` argument.\n\nThe example above now results in a client-side `ValueError`:\n\n``` python\n# ValueError: 'content-type' should not be specified in headers dict when using the `files` argument.\n```\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2013-10-17T05:28:15Z",
        "closed_at": "2013-10-17T06:33:49Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 33,
        "deletions": 20,
        "changed_files": 1,
        "created_at": "2013-10-13T08:59:50Z",
        "closed_at": "2013-12-05T22:36:10Z",
        "merged_at": "2013-12-05T22:36:10Z",
        "body": "Following #1642, I think we should treat urllib3's pooled connections better when we manage them ourselves. This PR provides the following extra functionality:\n- Clean up connections when we hit problems during chunked upload, rather than leaking them.\n- Return connections to the pool when a chunked upload is successful, rather than leaking it.\n\nThe diff is a little unclear, so let me clarify: I wrapped most of the chunked code in a `try` block, then added a catch-everything exception handler that will attempt to close the connection if we hit it. Otherwise, we'll return the presumably-fine connection to the pool.\n\nI'd like some code review on this. @sigmavirus24, can you confirm this is doing what I think it is, and can you give me some suggestions for how best to test it? @shazow, if you have time, can you confirm that I'm obeying the semantics of the urllib3 connection pool? (e.g. should I check if we get a `Connection: close` header on the response?\n",
        "comments": 11
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2013-10-12T20:06:22Z",
        "closed_at": "2013-10-12T21:15:30Z",
        "merged_at": "2013-10-12T21:15:30Z",
        "body": "Following discussion on #1665. =)\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 13,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2013-10-09T16:04:35Z",
        "closed_at": "2013-11-06T19:19:31Z",
        "merged_at": "2013-11-06T19:19:31Z",
        "body": "TODO:\n- [ ] Add test to ensure this doesn't regress\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 36,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2013-10-08T00:23:48Z",
        "closed_at": "2013-12-04T01:33:42Z",
        "merged_at": "2013-12-04T01:33:42Z",
        "body": "Fixes #1655 \n\nTODO:\n- [ ] ~~Add tests for `merge_hooks`~~\n- [x] Add tests to ensure that Session hooks can be overridden by request hooks.\n- [x] Fix logic so that there is no API braking change. Currently `merge_hooks` changes the behaviour of how hooks behave.\n",
        "comments": 17
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2013-10-07T19:24:19Z",
        "closed_at": "2013-10-07T20:45:11Z",
        "merged_at": "2013-10-07T20:45:11Z",
        "body": "The Twitter API is no longer used in the example.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 4,
        "created_at": "2013-10-05T04:01:57Z",
        "closed_at": "2013-10-05T17:02:46Z",
        "merged_at": "2013-10-05T17:02:46Z",
        "body": "Remove or replacing old codes with more modern idioms\n1. Deprecated `BaseException`\n2. `while 1:`\n3. updated to `print()` function\n",
        "comments": 15
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-10-04T13:00:53Z",
        "closed_at": "2013-10-04T19:42:11Z",
        "merged_at": null,
        "body": "this commit fixes #1648\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-10-04T01:22:41Z",
        "closed_at": "2013-10-04T08:55:19Z",
        "merged_at": "2013-10-04T08:55:19Z",
        "body": "- Improve wording of sentence describing proxy environment\n  variable setting.\n- Mention that proxy URLs must include the scheme.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-10-02T15:19:04Z",
        "closed_at": "2013-10-07T23:19:50Z",
        "merged_at": "2013-10-07T23:19:50Z",
        "body": "Just a small fix :)\n",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2013-10-01T00:09:08Z",
        "closed_at": "2013-10-07T23:21:16Z",
        "merged_at": "2013-10-07T23:21:16Z",
        "body": "- Each file in the `files` argument can now be a 4-tuple, instead of\n  just a file, 2-tuple, or 3-tuple. If it is, the last value in the\n  tuple is a dictionary of extra headers.\n- See [#1639](https://github.com/kennethreitz/requests/issues/1639) and [StackOverflow](http://stackoverflow.com/questions/19104924/how-to-add-per-file-custom-header-to-multipart-upload-with-requests/19105672#19105672) for more details.\n",
        "comments": 12
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2013-09-28T16:03:42Z",
        "closed_at": "2013-10-07T23:21:29Z",
        "merged_at": "2013-10-07T23:21:29Z",
        "body": "This resolves the problem from #1633.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2013-09-28T14:50:19Z",
        "closed_at": "2013-10-07T23:23:18Z",
        "merged_at": "2013-10-07T23:23:18Z",
        "body": "This should resolve the problem from #1631.\n\n@atomontage, can you try testing with this version of Requests to confirm that it resolves your problem?\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 4,
        "changed_files": 5,
        "created_at": "2013-09-28T14:50:12Z",
        "closed_at": "2013-10-07T23:22:49Z",
        "merged_at": "2013-10-07T23:22:49Z",
        "body": "I've added logic for adding cookies to the Session cookie jar in `Session.request`.\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-09-26T09:45:06Z",
        "closed_at": "2013-09-26T19:01:25Z",
        "merged_at": null,
        "body": "see #1622\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 28,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2013-09-26T09:44:58Z",
        "closed_at": "2013-12-05T22:39:12Z",
        "merged_at": null,
        "body": "If you manually specify HTTP Host header, any redirect to host different from specified will result in TooManyRedirects exception. \n\nExample:\n\n```\n>>> import requests\n>>> requests.get('http://reddit.com', headers={\"Host\": \"reddit.com\"})\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"requests/api.py\", line 55, in get\n    return request('get', url, **kwargs)\n  File \"requests/api.py\", line 44, in request\n    return session.request(method=method, url=url, **kwargs)\n  File \"requests/sessions.py\", line 357, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"requests/sessions.py\", line 480, in send\n    history = [resp for resp in gen] if allow_redirects else []\n  File \"requests/sessions.py\", line 82, in resolve_redirects\n    raise TooManyRedirects('Exceeded %s redirects.' % self.max_redirects)\nrequests.exceptions.TooManyRedirects: Exceeded 30 redirects.\n```\n\nAfter receiving first 301 response, requests library makes a request for url specified in it's \"Location\" field (in the example above it was http://www.reddit.com/), but it also preserves all headers set by user, so you end up having header \"Host: reddit.com\" while host is now **www**.reddit.com. Server checks \"host\" header and responds with 301 again. And now we're in a loop.\n\nI'd be glad to add tests for this fix, but httpbin does not support subdomains.\n",
        "comments": 26
    },
    {
        "merged": true,
        "additions": 22,
        "deletions": 17,
        "changed_files": 1,
        "created_at": "2013-09-26T06:46:26Z",
        "closed_at": "2013-10-07T23:22:50Z",
        "merged_at": "2013-10-07T23:22:50Z",
        "body": "See https://github.com/kennethreitz/requests/issues/1623\nI've added md5-sess algorithm referencing 'http://en.wikipedia.org/wiki/Digest_access_authentication'\nAny criticism is welcome :)\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2013-09-25T14:33:23Z",
        "closed_at": "2013-09-25T15:34:22Z",
        "merged_at": null,
        "body": "It adds the kbutton to clone requests repository into Koding easily. You can find the details in http://kbutton.org\n\nThank you so much! :)\ngithub: @f\ntwitter: @fkadev\nFatih Kadir Akin\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 7,
        "deletions": 4,
        "changed_files": 3,
        "created_at": "2013-09-21T12:41:51Z",
        "closed_at": "2013-09-24T17:40:52Z",
        "merged_at": null,
        "body": "",
        "comments": 8
    },
    {
        "merged": false,
        "additions": 994,
        "deletions": 148,
        "changed_files": 10,
        "created_at": "2013-09-20T18:18:14Z",
        "closed_at": "2013-09-20T20:05:17Z",
        "merged_at": null,
        "body": "urllib3 recently added support for https proxies (https://github.com/shazow/urllib3/pull/170). This has been a blocking issue for our us of the requests library.\n\nAll tests pass, and no backwards incompatible changes are noted in the urllib3 docs.\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2013-09-20T15:19:51Z",
        "closed_at": "2013-09-24T17:44:28Z",
        "merged_at": null,
        "body": "\"TypeError: 'long' does not have the buffer interface\" fixed for multi-part file encoding.\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 19,
        "deletions": 5,
        "changed_files": 3,
        "created_at": "2013-09-17T06:42:27Z",
        "closed_at": "2013-09-24T17:44:02Z",
        "merged_at": null,
        "body": "This allows the user to control SSL CommonName verification.\nFor example,\n\n``` python\nrequests.get('https://github.com/', assert_hostname='foo')\n```\n\nWill fail with an requests.exceptions.SSLError\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2013-09-14T03:33:08Z",
        "closed_at": "2013-09-24T17:46:16Z",
        "merged_at": "2013-09-24T17:46:16Z",
        "body": "In Digest Access Authentication there are two possible values (four if you count the not-present and both cases) for authentication. We were narrowly handling one of the four cases. Now we handle two.\n\nFixes #1601.\n\nAs for logic: I reordered the branches because if `qop is None` then we can not call `split` on it. So if we handle that case first, we shouldn't hit any exceptions. :)\n\nI think I'll also be sending a PR to handle the `auth-int` `qop` value for DigestAuth. Is there a reason we never did do it?\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 4,
        "changed_files": 3,
        "created_at": "2013-09-12T06:35:39Z",
        "closed_at": "2013-09-12T09:29:16Z",
        "merged_at": "2013-09-12T09:29:16Z",
        "body": "Difference between `r.raw` and `r.iter_content` not clearly described in all places where `r.raw` mentioned. This is very dangerous, because difference not only in calling format. I purpose leave `r.raw` only when we are talking about sockets or encoded data.\n",
        "comments": 8
    },
    {
        "merged": false,
        "additions": 12,
        "deletions": 10,
        "changed_files": 2,
        "created_at": "2013-09-10T19:46:09Z",
        "closed_at": "2013-09-10T20:52:30Z",
        "merged_at": null,
        "body": "HTML pages which declared their charset encoding only in their content\nhad the wrong encoding applied because the content was never checked.\n\nCurrently only the request headers are checked for the charset\nencoding, if absent the apparent_encoding heuristic is applied. But\nthe W3.org doc says one should check the header first for a charset\ndeclaration, then if that's absent check the meta tags in the content\nfor a charset encoding declaration. It also says if no charset\nencoding declaration is found one should assume UTF-8, not ISO-8859-1\n(a bad recommendation from the early days of the web).\n\nThis patch does the following:\n- Removes the default ISO-8859-1 from get_encoding_from_headers(),\n  it's wrong for 2 reasons, 1) get_encoding_from_headers() should\n  return None if no encoding was found in the header, otherwise how\n  can you tell it was absent in the headers? 2) It's the wrong default\n  for the contemporary web. Also because get_encoding_from_headers()\n  always returned an encoding any subsequent logic failed to execute.\n- The Request text property now does a 4 stage check for encoding in\n  this priority order:\n  \n  1) encoding declared in the headers\n  2) encoding declared in the content (selects the highest priority\n     encoding if more than one encoding is declared in the content)\n  3) apply apparent_encoding hueristic (includes BOM)\n  4) if none of the above default to UTF-8\n",
        "comments": 15
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-09-10T12:22:37Z",
        "closed_at": "2013-09-10T13:43:04Z",
        "merged_at": "2013-09-10T13:43:04Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-09-09T12:29:57Z",
        "closed_at": "2013-09-24T17:45:46Z",
        "merged_at": "2013-09-24T17:45:46Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2013-09-07T02:28:00Z",
        "closed_at": "2013-09-08T15:05:00Z",
        "merged_at": "2013-09-08T15:05:00Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2013-09-04T16:01:07Z",
        "closed_at": "2013-09-05T06:44:28Z",
        "merged_at": "2013-09-05T06:44:28Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 49,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2013-09-03T23:21:51Z",
        "closed_at": "2013-09-04T02:42:43Z",
        "merged_at": "2013-09-04T02:42:43Z",
        "body": "`get_encodings_from_content()` can now detect HTML in-document content\nencoding declarations in the following formats:\n- HTML5\n- HTML4\n- XHTML 1.x served with text/html MIME type\n- XHTML 1.x served as XML\n\nRef: http://www.w3.org/International/questions/qa-html-encoding-declarations\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-09-01T17:12:19Z",
        "closed_at": "2013-09-24T17:39:09Z",
        "merged_at": "2013-09-24T17:39:09Z",
        "body": "Pointed out by @dstufft in #1560.\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2013-08-30T20:17:16Z",
        "closed_at": "2013-08-31T01:30:19Z",
        "merged_at": null,
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-08-23T11:38:57Z",
        "closed_at": "2013-08-24T00:23:58Z",
        "merged_at": "2013-08-24T00:23:57Z",
        "body": "As mentioned in #1551, we could do with being a little more lenient here. A space isn't a valid URL character anyway, so just yank them all out and everything should be fine.\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-08-20T12:36:15Z",
        "closed_at": "2013-08-20T15:07:04Z",
        "merged_at": null,
        "body": "... Location header pointing to itself (try it against http://google.com/robots.txt to test it)\n",
        "comments": 11
    },
    {
        "merged": true,
        "additions": 44,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2013-08-19T12:29:57Z",
        "closed_at": "2013-09-24T17:45:11Z",
        "merged_at": "2013-09-24T17:45:11Z",
        "body": "This contains all of the current fixes merged into the 2.0 branch in changelog form. I'll keep updating this as new changes get merged.\n\n_Note_: This uses [this link](https://github.com/kennethreitz/requests/compare/v1.2.3...2.0) as the source of changes. I'll keep consulting it as we work on 2.0.\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-08-18T18:59:09Z",
        "closed_at": "2013-08-18T20:03:17Z",
        "merged_at": null,
        "body": "Or u can use **kwargs\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-08-18T01:06:39Z",
        "closed_at": "2013-08-18T06:26:59Z",
        "merged_at": "2013-08-18T06:26:59Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2013-08-17T06:29:06Z",
        "closed_at": "2013-08-21T18:46:28Z",
        "merged_at": "2013-08-21T18:46:28Z",
        "body": "This should resolve #1462.\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-08-17T06:18:11Z",
        "closed_at": "2013-08-21T18:25:20Z",
        "merged_at": "2013-08-21T18:25:20Z",
        "body": "This should resolve #1532. Let me know if you'd rather we multiply-inherit from `IOError` and `RuntimeError`.\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-08-12T22:26:47Z",
        "closed_at": "2013-08-13T05:44:32Z",
        "merged_at": null,
        "body": "... keys into binary byte strings and cause the CaseInsensitiveDict to fail to find existing keys, such as content-type\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2013-08-12T14:32:50Z",
        "closed_at": "2013-08-21T18:28:23Z",
        "merged_at": "2013-08-21T18:28:23Z",
        "body": "Fixes #1525 against branch 2.0\n- Raises a ValueError for an unsupported hook event\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2013-08-03T18:26:22Z",
        "closed_at": "2013-08-06T15:43:45Z",
        "merged_at": "2013-08-06T15:43:45Z",
        "body": "This should resolve #1504.\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 177,
        "deletions": 53,
        "changed_files": 6,
        "created_at": "2013-08-03T12:02:13Z",
        "closed_at": "2013-08-14T20:41:08Z",
        "merged_at": "2013-08-14T20:41:08Z",
        "body": "",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2013-08-02T11:31:59Z",
        "closed_at": "2013-08-02T16:48:33Z",
        "merged_at": "2013-08-02T16:48:33Z",
        "body": "Should resolve #1510. While improving exceptions for 2.0 we may as well get as much as possible done.\n\nFor your ease, this PR is already against the 2.0 branch, so it should be an easy merge. =)\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 154,
        "deletions": 46,
        "changed_files": 6,
        "created_at": "2013-08-01T19:52:16Z",
        "closed_at": "2013-08-03T12:02:56Z",
        "merged_at": null,
        "body": "HTTPS proxy support finally made it into urllib3 (https://github.com/shazow/urllib3/pull/170), this is a patch for requests to support it.\n",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 143,
        "deletions": 42,
        "changed_files": 3,
        "created_at": "2013-08-01T18:22:57Z",
        "closed_at": "2013-08-01T19:54:19Z",
        "merged_at": null,
        "body": "Includes the truly awesome proxy support! =D\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 328,
        "deletions": 98,
        "changed_files": 14,
        "created_at": "2013-08-01T01:27:28Z",
        "closed_at": "2013-09-24T17:45:21Z",
        "merged_at": null,
        "body": "TODO:\n- [ ] Pull in latest urllib3 before releasing.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2013-07-31T07:30:35Z",
        "closed_at": "2013-08-01T01:36:08Z",
        "merged_at": "2013-08-01T01:36:07Z",
        "body": "This is already mentioned at line 357...\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 98,
        "deletions": 48,
        "changed_files": 3,
        "created_at": "2013-07-31T04:51:20Z",
        "closed_at": "2013-08-01T01:21:28Z",
        "merged_at": "2013-08-01T01:21:28Z",
        "body": "Attempt to address #1445. All tests pass.\n\nNote that I think it could likely make sense to change `Session.update_request` to be an internal method, since `Session.prepare_request` is really the only public use I can think of having use in practice.\n",
        "comments": 14
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2013-07-30T17:22:20Z",
        "closed_at": "2013-08-01T01:22:03Z",
        "merged_at": "2013-08-01T01:22:03Z",
        "body": "This should resolve #1502.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2013-07-29T20:39:42Z",
        "closed_at": "2013-09-24T17:48:07Z",
        "merged_at": "2013-09-24T17:48:07Z",
        "body": "In passing I managed to produce a situation where I would get an error when this check fails. When this gets called on line 391:\n\n``` python\n391            # Multi-part file uploads.\n392            if files:\n393                (body, content_type) = self._encode_files(files, data)\n```\n\nWhich would result in:\n`TypeError: 'NoneType' object is not iterable`\n\nThis patch fixes that return.\n",
        "comments": 24
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-07-29T13:15:40Z",
        "closed_at": "2013-08-01T01:22:59Z",
        "merged_at": "2013-08-01T01:22:59Z",
        "body": "Fixes #1499\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 22,
        "deletions": 13,
        "changed_files": 4,
        "created_at": "2013-07-29T08:32:49Z",
        "closed_at": "2013-08-01T01:23:43Z",
        "merged_at": "2013-08-01T01:23:43Z",
        "body": "This fixes a bug in urllib3 that caused the Host header to be set incorrectly when a proxy is used together with a nonstandard port number.\n\nFor example, when going to http://example.com:8000/ through a proxy, the Host header was set to 'example.com' instead of 'example.com:8000' which totally breaks Requests in such a case.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 16,
        "deletions": 4,
        "changed_files": 3,
        "created_at": "2013-07-28T06:43:35Z",
        "closed_at": "2013-08-01T01:23:14Z",
        "merged_at": "2013-08-01T01:23:14Z",
        "body": "This should improve the user experience from #1397.\n\n@sigmavirus24, @kennethreitz: I'm not really happy with the nested try...except blocks here. Suggestions for a better style? Nothing leaps out at me.\n",
        "comments": 15
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 17,
        "changed_files": 2,
        "created_at": "2013-07-28T06:17:58Z",
        "closed_at": "2013-08-01T01:28:35Z",
        "merged_at": null,
        "body": "This is for 2.0, and is in response to @t-8ch's suggestion that proxies should have explicit schemes instead of guessing (which is stupid).\n\n@sigmavirus24, @kennethreitz: I'm not entirely happy with the validation code being here: let me know if you have a better idea for where it should go.\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2013-07-25T18:11:26Z",
        "closed_at": "2013-07-28T06:04:34Z",
        "merged_at": "2013-07-28T06:04:34Z",
        "body": "Should resolve the problem from #1492.\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2013-07-24T10:53:20Z",
        "closed_at": "2013-07-24T12:07:57Z",
        "merged_at": null,
        "body": "Suggested solution for #1488\n\nAllows for code such as:\n\n``` python\n#!/usr/bin/env python\nimport requests\nimport cookielib\nc = cookielib.LWPCookieJar(filename=\"test.cookies\")\ns = requests.Session(cookiejar=c)\nr = s.get(\"http://www.reprap.no/\")\nc.save()\n```\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 34,
        "changed_files": 1,
        "created_at": "2013-07-24T07:44:41Z",
        "closed_at": "2013-08-01T01:23:35Z",
        "merged_at": "2013-08-01T01:23:35Z",
        "body": "Partial solution to #1485\n\nOnly fixes the uses of httpbin.org; there are still a couple of test cases referencing example.com\n\nI'm not sure if this solution is too much of a hack...\n",
        "comments": 10
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2013-07-23T08:02:27Z",
        "closed_at": "2013-07-23T12:21:30Z",
        "merged_at": null,
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2013-07-23T06:18:03Z",
        "closed_at": "2013-07-23T12:23:11Z",
        "merged_at": "2013-07-23T12:23:11Z",
        "body": "Test cases can be run against a local httpbin server defined by\nthe `HTTPBIN_URL` environment variable, but it causes tests to\nfail if the given URL does not end with a slash.\n\nEnsure that the URL always ends with a slash.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2013-07-23T01:56:03Z",
        "closed_at": "2013-07-23T12:23:35Z",
        "merged_at": "2013-07-23T12:23:35Z",
        "body": "When sending a request via `Session.send()` the proxies must be\nexplicitly given with the `proxies` argument.  This is not done\nin the test cases, which means that they fail when run on a system\nthat is behind a proxy.\n\nAdd the `proxies` argument in the calls to `Session.send()` in test\ncases.\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 18,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2013-07-22T00:17:21Z",
        "closed_at": "2013-07-22T06:04:31Z",
        "merged_at": "2013-07-22T06:04:31Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-07-21T18:48:25Z",
        "closed_at": "2013-07-27T01:16:00Z",
        "merged_at": "2013-07-27T01:16:00Z",
        "body": "I really think it is only needed for `PreparedRequest` objects, but I could see a desire to implement it on `Request` objects too.\n\nThe reasoning is simple. Currently, we have duplicated code to make copies of `PreparedRequests` to preserve the history of the requests sent and be able to make new ones. We could not only reduce duplication, but also ensure (via tests) that the library won't break in weird ways because of this in the future. It would be a dead-simple method to write, and would be very useful and probably even more useful to authentication handler authors.\n",
        "comments": 11
    },
    {
        "merged": false,
        "additions": 306,
        "deletions": 106,
        "changed_files": 12,
        "created_at": "2013-07-20T17:04:19Z",
        "closed_at": "2013-09-24T17:48:38Z",
        "merged_at": null,
        "body": "This PR is a work in progress. It addresses some problems we've got with Exceptions. Currently it contains two fixes:\n- Resolves the misspelling of 'scheme', reimplementing the fix proposed in #1187.\n- Attempts to provide a fix of #1294.\n\nThis second part is of particular interest. I want to know what @sigmavirus24 thinks of this possible fix.\n",
        "comments": 14
    },
    {
        "merged": false,
        "additions": 28,
        "deletions": 8,
        "changed_files": 3,
        "created_at": "2013-07-19T20:46:23Z",
        "closed_at": "2013-08-01T01:33:56Z",
        "merged_at": null,
        "body": "On 401's the cookies received aren't sent back to the server. Fixes: #1336\n\nAlso this will rely on some changes in HTTPBin for testing. I'm going to start a pull over there too.\n",
        "comments": 18
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 9,
        "changed_files": 3,
        "created_at": "2013-07-19T09:14:59Z",
        "closed_at": "2013-07-19T11:12:29Z",
        "merged_at": "2013-07-19T11:12:29Z",
        "body": "fix doc\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2013-07-19T08:32:39Z",
        "closed_at": "2013-07-19T13:45:18Z",
        "merged_at": "2013-07-19T13:45:18Z",
        "body": "The documentation does not make it clear that when the credentials\nfrom netrc are used, Requests authenticates with HTTP Basic Auth.\n\nI just spent ages trying to figure out why it wasn't working, and\nit was because although the credentials in the netrc were correct,\nthe server actually required HTTP Digest Auth.\n\nAdd a section in the authentication documentation to make it clear\nthat HTTP Basic Auth is used.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-07-13T07:57:23Z",
        "closed_at": "2013-07-15T13:21:31Z",
        "merged_at": "2013-07-15T13:21:31Z",
        "body": "Changed the \"im_used\" informational status code for the value given by IANA (226)\n\nSee RFC 3229 at http://tools.ietf.org/html/rfc3229#section-10.4.1 and HTTP status codes at http://www.iana.org/assignments/http-status-codes/http-status-codes.xhtml\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 19,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2013-07-09T21:11:37Z",
        "closed_at": "2013-07-13T15:46:27Z",
        "merged_at": null,
        "body": "This is a prototype solution for https://github.com/kennethreitz/requests/issues/1450 .\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-07-04T09:41:43Z",
        "closed_at": "2013-07-15T13:22:41Z",
        "merged_at": "2013-07-15T13:22:41Z",
        "body": "As pointed out by @lukesneeringer in #1395, the kwargs in the non-urllib3 branch of the `iter_content` code are urllib3 specific. This PR will finish the split I originally made in #1425.\n\n/cc @sigmavirus24 and @lukesneeringer who have both done work that has been rendered unnecessary (though not useless) by this change.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2013-07-01T19:08:17Z",
        "closed_at": "2013-07-15T13:54:01Z",
        "merged_at": "2013-07-15T13:54:01Z",
        "body": "Reading the spec, seems to me that quote-enclosed values should be returned unclosed. My interpretation is that the quotes are not part of the value, but they are considered 'punctuation'.\n\nI'm not confident I'm reading the spec right, and I don't have a big knowledge of the many actual server implementations out there (for example: does anyone actually send cookies with `Version=\"1\"`?), so feel free to prove me wrong.\n",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 30,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2013-06-27T21:24:25Z",
        "closed_at": "2013-07-15T13:22:54Z",
        "merged_at": "2013-07-15T13:22:54Z",
        "body": "This fixes issue #1438.\n\n.netrc is still going to be used by default if it's available (that's the intended behavior based on #446), but now any explicit settings (whether they're set on the session or passed to request()) will take precedence.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-06-27T11:38:09Z",
        "closed_at": "2013-06-27T18:18:56Z",
        "merged_at": "2013-06-27T18:18:56Z",
        "body": "405 is returned if POST request is performed to http://httpbin.org/stream/20\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2013-06-22T14:05:03Z",
        "closed_at": "2013-06-24T07:48:48Z",
        "merged_at": "2013-06-24T07:48:48Z",
        "body": "Warn about including `cacerts.pem`.\n\n@andrewgross: This is my idea about better placement. Do you think this wording of the warning would have been helpful?\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2013-06-20T22:49:01Z",
        "closed_at": "2013-06-24T07:49:08Z",
        "merged_at": null,
        "body": "Adding a note about modifying setup.py for a package that embeds requests so that SSL will still work.  Hopefully this avoid several hours of pain for someone else in the future.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 50,
        "deletions": 6,
        "changed_files": 3,
        "created_at": "2013-06-18T17:26:37Z",
        "closed_at": "2013-06-21T09:23:11Z",
        "merged_at": "2013-06-21T09:23:11Z",
        "body": "In shazow/urllib3#186 I proposed to add a `.stream()` generator to the urllib3 response object. This avoids some of the nasty problems with the `.read()` method on that object (apparent zero-sized reads when there's still data, all sorts of stuff). It's also a much more natural way to stream data.\n\nThis PR would update urllib3 to include that PR, and updates our streaming methods to use it where possible.\n\n@michaelhelmick: Do you want to try this branch with your twitter issue? Use one-byte chunk sizes.\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 47,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2013-06-13T05:27:34Z",
        "closed_at": "2013-06-15T05:50:05Z",
        "merged_at": null,
        "body": "Unfortunately according to wc3 (http://www.w3.org/DesignIssues/Axioms.html#matrix) matrix parameters to http requests has been unsupported since 2001. The company I work for recently tried integrating a REST interface with third party software and their REST request required HTTP matrix parameters. Which up until this morning I had never heard of. I have added a quick patch into requests to support this.\n\nInformation on how matrix parameters are used and created is found at this link:\nhttp://www.w3.org/DesignIssues/MatrixURIs.html\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2013-06-12T22:58:10Z",
        "closed_at": "2013-06-15T05:50:45Z",
        "merged_at": "2013-06-15T05:50:45Z",
        "body": "Sphinx has a neat cross-referencing feature where if you include the tilde\ncharacter in front of a :py: class, it'll link to the full object but provide\nonly the last part of class name in the text. For more info see\nhttp://sphinx-doc.org/domains.html#cross-referencing-syntax\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-06-09T15:16:37Z",
        "closed_at": "2013-06-12T18:12:18Z",
        "merged_at": "2013-06-12T18:12:18Z",
        "body": "I was reading the \"advanced\" section of the docs and noticed a typo, so I sent you a pull request!\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 52,
        "deletions": 6,
        "changed_files": 7,
        "created_at": "2013-06-08T08:24:17Z",
        "closed_at": "2013-06-08T10:13:34Z",
        "merged_at": "2013-06-08T10:13:34Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2013-06-06T16:47:13Z",
        "closed_at": "2013-06-08T10:14:32Z",
        "merged_at": "2013-06-08T10:14:32Z",
        "body": "eg. view yahoo.com will return:\n\n```\nSet-Cookie  B=9a3jpi98r1dd8&b=3&s=fb; expires=Sun, 07-Jun-2015 16:15:36 GMT; path=/; domain=.yahoo.com\n```\n\nexpires is str time, but cookielib.Cookie.expires only int\npy code:\n\n```\n    str_cookie = \"B=9a3jpi98r1dd8&b=3&s=fb; expires=Sun, 07-Jun-2015 16:15:36 GMT; path=/; domain=.yahoo.com\"\n    C = Cookie.SimpleCookie(str_cookie)\n    for morsel in C.values():\n        cookie = requests.cookies.morsel_to_cookie(morsel)\n        print cookie\n```\n\n1.raise TypeError:\nTypeError: create_cookie() got unexpected keyword arguments: ['path_specified', 'domain_specified', 'port_specified', 'domain_initial_dot']\n\nso we should remove these param from morsel_to_cookie(morsel):create_cookie(....)\n\n2.where  repair 1 after, will raise:\n  File \"/usr/lib/python2.7/cookielib.py\", line 739, in **init**\n    if expires is not None: expires = int(expires)\nValueError: invalid literal for int() with base 10: 'Sun, 07-Jun-2015 16:15:36 GMT'\n",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2013-06-06T11:16:03Z",
        "closed_at": "2013-06-06T16:50:03Z",
        "merged_at": null,
        "body": "morsel_to_cookie(mosel) method raise TypeError: create_cookie() got unexpected keyword arguments: ['path_specified', 'domain_specified', 'port_specified', 'domain_initial_dot'].\n\nso we should remove these param from create_cookie(...)\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 26,
        "deletions": 7,
        "changed_files": 3,
        "created_at": "2013-06-03T12:43:15Z",
        "closed_at": "2013-06-08T08:04:20Z",
        "merged_at": null,
        "body": "There are some use-cases where SSL certificate verification is required, but without validating the CN (it is the host name of the server in HTTPS).\n\nThis patch introduces the dont_verify_host flag, which disables host verification, only if it is set to True. A value of None (the default) or False will keep the enabled host verification.\n",
        "comments": 9
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2013-06-01T22:01:00Z",
        "closed_at": "2013-06-02T05:43:16Z",
        "merged_at": null,
        "body": "fixes https://github.com/kennethreitz/requests/issues/1402\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 16,
        "deletions": 17,
        "changed_files": 3,
        "created_at": "2013-06-01T01:32:02Z",
        "closed_at": "2013-06-08T10:20:19Z",
        "merged_at": "2013-06-08T10:20:19Z",
        "body": "I ran into a problem earlier today when trying to debug an issue with migrating some code from urllib2 to requests. To compare the requests being made, I fired up my trusty web debugging proxy (Charles), but the requests from requests (ahem) weren't being sent through the proxy.\n\nAfter digging around in the code, I noticed that requests was only checking the OS environment variables for proxy settings, not the extra OS-specific locations handled by urllib2's ProxyHandler (the System Configuration framework on OS X and the Windows registry). Since the requests code appeared to be duplicating some functionality already in urllib, I made a quick patch to use the standard library functions instead.\n\nIt works as expected on Python 2 and 3 using OS X; since it's using urllib under the hood I assume it's safe, but I'll test on Windows/Linux when I'm having less of a nightmare day. However, I'm unsure how to write a test that covers this, since it depends on the current environment's configuration. Any advice would be appreciated!\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-05-29T09:58:00Z",
        "closed_at": "2013-06-08T10:16:21Z",
        "merged_at": "2013-06-08T10:16:21Z",
        "body": "rephrase misleading info about `raise_for_status`\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 33,
        "deletions": 5,
        "changed_files": 3,
        "created_at": "2013-05-24T15:27:59Z",
        "closed_at": "2013-06-08T10:17:38Z",
        "merged_at": "2013-06-08T10:17:38Z",
        "body": "The URL specification (RFC 2396) recommends that resilient platforms support upper-case letters in scheme specifiers.\n\nAt the moment `requests.sessions.Session.get_adapter(self,url)` and `requests.adapters.HTTPAdapter.cert_verify(self,conn,url,verify,cert)` do a `url.startswith()` that match against 'http' and/or 'https' (lower case only), not admitting for the possibility of an upper-case or mixed-case scheme in the url being examined.\n\nIn these cases, can we do a url.lower.startswith() instead of simply url.startswith() to allow for mixed case schemes and still be able to effectively match against 'http' and 'https'?\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2013-05-23T15:23:12Z",
        "closed_at": "2013-06-08T10:16:33Z",
        "merged_at": "2013-06-08T10:16:33Z",
        "body": "Only switch to chunked if we don't know the length of a file like object. This fixes the case of trying to transfer a 0-length file - chunked upload was being forced. Services like S3 that disallow chunked upload will fail.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2013-05-21T17:51:54Z",
        "closed_at": "2013-05-21T21:25:50Z",
        "merged_at": "2013-05-21T21:25:49Z",
        "body": "`invoke test` fails sometimes due to #1374\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-05-21T17:50:14Z",
        "closed_at": "2013-05-21T21:33:26Z",
        "merged_at": "2013-05-21T21:33:26Z",
        "body": "See https://github.com/kennethreitz/requests/issues/1358\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2013-05-21T08:52:21Z",
        "closed_at": "2013-05-21T13:19:48Z",
        "merged_at": "2013-05-21T13:19:48Z",
        "body": "`filepost.encode_multipart_formdata` says all fieldnames should be unicode and currently that is not the case - https://github.com/shazow/urllib3/blob/master/urllib3/filepost.py#L55 - since requests encodes to bytes here - https://github.com/kennethreitz/requests/blob/master/requests/models.py#L108.\n\nDiscovered after plenty of fun in https://github.com/requests/requests-oauthlib/pull/43. This should fix https://github.com/kennethreitz/requests/issues/1371.\n\nTested in 2.6, 2.7 and 3.3.\n\ncc @Lukasa, @michaelhelmick, @sigmavirus24\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 25,
        "deletions": 7,
        "changed_files": 3,
        "created_at": "2013-05-16T15:56:53Z",
        "closed_at": "2013-05-17T06:23:04Z",
        "merged_at": "2013-05-17T06:23:04Z",
        "body": "- Replaced usage of `urlparse` in `PreparedRequest.prepare_url` with `urllib3` equivalent.\n- Modified IDNA encoding section so that it only encodes the host portion of the URL\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-05-16T11:05:44Z",
        "closed_at": "2013-05-20T20:04:08Z",
        "merged_at": "2013-05-20T20:04:08Z",
        "body": "If we don't, stupid servers that don't do it themselves can hurt us badly.\n\nResolves #1360.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2013-05-11T22:24:27Z",
        "closed_at": "2013-05-20T20:05:02Z",
        "merged_at": "2013-05-20T20:05:02Z",
        "body": "Adding an argument to the adapter for passing a block argument to the connection pool.\n\nThis allows for blocking when using threading to prevent the pool from creating more connections that the max-size allows.\n\nSpecifically was seeing the following warnings were shown when using threads to download files without the block=True:\n\n```\nWARNING:requests.packages.urllib3.connectionpool:HttpConnectionPool is full, discarding connection: www.example.com\n```\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-05-09T03:31:01Z",
        "closed_at": "2013-05-09T08:03:49Z",
        "merged_at": "2013-05-09T08:03:49Z",
        "body": "This nipped me in the bud with github3.py+github-cli. Previously, the `CaseInsensitiveDict` behaved like a `defaultdict` that returned None when the key wasn't there. Now the CID behaves like a regular dict and raises a `KeyError`. To dodge this on our attribute, we should use `.get` to avoid a `KeyError`.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2013-05-07T02:49:27Z",
        "closed_at": "2013-05-07T17:01:33Z",
        "merged_at": "2013-05-07T17:01:33Z",
        "body": "Just adding a link to the documentation at python-requests.org\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2013-05-07T00:40:33Z",
        "closed_at": "2013-05-07T02:41:48Z",
        "merged_at": null,
        "body": "Just adding a link to the documentation at readthedocs.org\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 345,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2013-05-06T03:46:05Z",
        "closed_at": "2013-05-07T17:01:01Z",
        "merged_at": null,
        "body": "I've added classes that I've made to have requests on their own thread with variables and methods that allow the main thread to monitor their status.\n\nThis is my first attempt at contributing to anything like this.\nI tried to keep it simple. I hope you like it.\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 32,
        "deletions": 1,
        "changed_files": 3,
        "created_at": "2013-05-05T02:59:22Z",
        "closed_at": "2013-05-06T17:50:22Z",
        "merged_at": null,
        "body": "A reminder...\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2013-05-04T00:06:36Z",
        "closed_at": "2013-05-04T20:11:46Z",
        "merged_at": "2013-05-04T20:11:46Z",
        "body": "SNI support will be enabled for python2 if ndg-httpsclient and pyopenssl are available.\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 20,
        "deletions": 1,
        "changed_files": 3,
        "created_at": "2013-05-02T22:09:10Z",
        "closed_at": "2013-05-04T20:12:18Z",
        "merged_at": null,
        "body": "Adding support for this underappreciated method.\n\nReference: http://tools.ietf.org/html/rfc2616#section-9.8\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 47,
        "deletions": 45,
        "changed_files": 3,
        "created_at": "2013-05-02T17:03:42Z",
        "closed_at": "2013-05-21T02:14:55Z",
        "merged_at": "2013-05-21T02:14:55Z",
        "body": "This refactors the `merge_kwargs` function for sessions to (hopefully) be clearer, and fix some bugs with it. It fixes #1321, as well as fixing an issue where arguments other than headers were being improperly merged case insensitively.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-05-02T15:17:06Z",
        "closed_at": "2013-05-07T17:01:18Z",
        "merged_at": "2013-05-07T17:01:18Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 227,
        "deletions": 28,
        "changed_files": 4,
        "created_at": "2013-04-30T20:05:30Z",
        "closed_at": "2013-05-01T17:27:58Z",
        "merged_at": "2013-05-01T17:27:58Z",
        "body": "Fixes #649 and #1329 by making Session.headers a CaseInsensitiveDict,\nand fixing the implementation of CID. Credit for the brilliant idea\nto map `lowercased_key -> (cased_key, mapped_value)` goes to\n@gazpachoking, thanks a bunch.\n\nChanges from original implementation of CaseInsensitiveDict:\n1.  CID is rewritten as a subclass of `collections.MutableMapping`.\n2.  CID remembers the case of the last-set key, but `__setitem__`\n   and `__delitem__` will handle keys without respect to case.\n3.  CID returns the key case as remembered for the `keys`, `items`,\n   and `__iter__` methods.\n4.  Query operations (`__getitem__` and `__contains__`) are done in\n   a case-insensitive manner: `cid['foo']` and `cid['FOO']` will\n   return the same value.\n5.  The constructor as well as `update` and `__eq__` have undefined\n   behavior when given multiple keys that have the same `lower()`.\n6.  The new method `lower_items` is like `iteritems`, but keys are\n   all lowercased.\n7.  CID raises `KeyError` for `__getitem__` as normal dicts do. The\n   old implementation returned `None`\n8.  The `__repr__` now makes it obvious that it's not a normal dict.\n\nSee PR #1333 for the discussions that lead up to this implementation\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 43,
        "deletions": 16,
        "changed_files": 3,
        "created_at": "2013-04-30T19:56:33Z",
        "closed_at": "2013-08-01T01:28:54Z",
        "merged_at": null,
        "body": "_Note_: This PR follows a discussion on IRC. The logs can be found [here](https://botbot.me/freenode/python-requests/msg/2942059/).\n### Summary\n\nThis fixes a problem that @https://github.com/va1en0k _would_ have had in #1335 if the current Case-Insensitive Dict didn't behave so weirdly (see #1333 for progress on that).\n\nRight now, Requests unconditionally encodes all header values as bytes on all Python versions. Kenneth and I are (tentatively) in agreement that header values should actually be native strings on all platforms. This pull request introduces code that explicitly encodes or decodes string objects to satisfy that requirement.\n### Notes\n\nFirstly, **this is a breaking API change on Python 3**. On Python 2 the behaviour will be the same unless the user has changed `sys.defaultencoding`, and if they have they deserve what's coming to them. On Python 3, all header keys on `PreparedRequest`s will go from being bytes to unicode objects, and so anyone who has correctly programmed to this interface will have to change their code.\n\nSecondly, this code currently uses ASCII as the codec in both directions. I think this is OK for now. I'm pretty sure that header values should actually be Latin-1, but I can understand if we want to keep the current behaviour in place. I'm open to feedback here.\n",
        "comments": 27
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 14,
        "changed_files": 1,
        "created_at": "2013-04-30T14:17:58Z",
        "closed_at": "2013-05-01T17:28:18Z",
        "merged_at": "2013-05-01T17:28:18Z",
        "body": "- 'Cookies' and 'Encodings' sections were not built because the\n  reference to the functions was wrong.\n- 'Exceptions' section had a wrong anchor link ('module-requests', same\n  one as the main heading).\n- Remove 'decode_gzip' function, which is no longer present.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2013-04-29T21:05:06Z",
        "closed_at": "2013-06-08T10:18:25Z",
        "merged_at": "2013-06-08T10:18:25Z",
        "body": "I had a case where the Location header had a URL with the scheme in uppercase, which caused an InvalidSchema exception.\n",
        "comments": 12
    },
    {
        "merged": false,
        "additions": 227,
        "deletions": 28,
        "changed_files": 4,
        "created_at": "2013-04-28T06:46:30Z",
        "closed_at": "2013-04-30T20:07:27Z",
        "merged_at": null,
        "body": "Fixes #649, ~~#1321,~~ and #1329. Don't merge yet, I want to get\nsome opinions about this implementation.\n\nThere are a few things I'd like input on. I completely rewrote `CaseInsensitiveDict` because it was hard to read. Instead of subclassing `dict`, this just implements the `collections.MutableMapping` interface, storing the data in an internal dict (._store). The result is far more obvious and readable.\n1. The [old version](https://github.com/kennethreitz/requests/blob/40a060cf579a7f0996c92eed578148e526d9416f/requests/structures.py#L64-L66) returns None for nonexistent keys instead of raising KeyError. Do we actually need this behavior? My version doesn't do this, but it would be fairly trivial to add.\n2. ~~Do we want header names to be titlecased? This stores keys and returns them in lowercase.~~\n\nPlease let me know if I can improve this at all.\n\nEDIT: Doesn't fix 1321\n",
        "comments": 19
    },
    {
        "merged": true,
        "additions": 31,
        "deletions": 19,
        "changed_files": 9,
        "created_at": "2013-04-27T21:34:40Z",
        "closed_at": "2013-04-28T23:58:09Z",
        "merged_at": "2013-04-28T23:58:09Z",
        "body": "This update includes two fixes:\n- https://github.com/shazow/urllib3/issues/149\n- https://github.com/shazow/urllib3/issues/174\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 24,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2013-04-26T02:40:38Z",
        "closed_at": "2013-04-26T07:02:28Z",
        "merged_at": "2013-04-26T07:02:28Z",
        "body": "Fix for #1324, make any subclass of `cookielib.CookieJar` work as `session.cookies`\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 49,
        "deletions": 6,
        "changed_files": 3,
        "created_at": "2013-04-25T10:01:49Z",
        "closed_at": "2013-05-15T16:43:58Z",
        "merged_at": "2013-05-15T16:43:58Z",
        "body": "As suggested in [this comment](https://github.com/kennethreitz/requests/issues/1320#issuecomment-16992832), I used an OrderedDict. All tests pass on Python 2.6 - 3.3 (provided #1326 is merged for 3.2).\n",
        "comments": 15
    },
    {
        "merged": false,
        "additions": 14,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2013-04-25T07:55:25Z",
        "closed_at": "2013-04-28T23:59:12Z",
        "merged_at": null,
        "body": "A test introduced in #1279 used the `u''` literal which is not present on Python 3.2 which made unit tests fail.\n\nThis PR fixes the bug and introduces a rudimentary \"tox.ini\" which makes local tests with multiple Python versions trivial:\n\n```\n$ pip install tox\n$ cd requests-sources/\n$ tox\nGLOB sdist-make: setup.py\npy26 inst-nodeps: .tox/dist/requests-1.2.0.zip\npy26 runtests: commands[0]\n.........................................\nRan 41 tests in 24.071s\nOK\npy27 inst-nodeps: .tox/dist/requests-1.2.0.zip\npy27 runtests: commands[0]\n.........................................\nRan 41 tests in 23.269s\nOK\npy32 inst-nodeps: .tox/dist/requests-1.2.0.zip\npy32 runtests: commands[0]\n.........................................\nRan 41 tests in 21.836s\nOK\npy33 inst-nodeps: .tox/dist/requests-1.2.0.zip\npy33 runtests: commands[0]\n.........................................\nRan 41 tests in 22.674s\nOK\n________________ summary ________________\n  py26: commands succeeded\n  py27: commands succeeded\n  py32: commands succeeded\n  py33: commands succeeded\n  congratulations :)\n```\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 27,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2013-04-24T18:49:22Z",
        "closed_at": "2013-04-25T08:30:44Z",
        "merged_at": null,
        "body": "So it turns out the documentation here has been wrong the whole time! Who knew?\n\nThis PR follows #1320, and selects the best matching prefix from the dict in a _really stupid_ way. The _right_ way to do this would be to use a trie, but I thought we probably didn't want the cost of a new structure, especially as it's unlikely a user will mount a large number of adapters to any one session.\n\nLet me know if you think that's a bad idea, and I'll whip up a quick trie and add it to this PR.\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 23,
        "deletions": 7,
        "changed_files": 3,
        "created_at": "2013-04-24T12:47:13Z",
        "closed_at": "2013-05-21T02:14:55Z",
        "merged_at": null,
        "body": "While request headers can be removed by setting them to `None`:\n\n```\n>>> r = requests.get('http://github.com', headers={'Accept-Encoding': None})\n>>> 'Accept-Encoding' in r.request.headers\nFalse\n```\n\nthe following code gives an `KeyError` instead of doing the same job:\n\n```\n>>> # Remove preset header\n>>> r = requests.get('http://github.com', headers={'accept-encoding': None})\nTraceback (most recent call last):\n  (...)\n  File \"..\\requests\\sessions.py\", line 313, in request\n    headers = merge_kwargs(headers, self.headers)\n  File \"..\\requests\\sessions.py\", line 76, in merge_kwargs\n    del kwargs[k]\n  File \"..\\requests\\packages\\urllib3\\packages\\ordered_dict.py\", line 59, in __delitem__\n    dict_delitem(self, key)\nKeyError: 'accept-encoding'\n```\n\nWith this patch the key to remove can be specified case-insensitively.\n\n```\n>>> r = requests.get('http://github.com', headers={'accept-encoding': None})\n>>> 'Accept-Encoding' in r.request.headers\nFalse\n```\n",
        "comments": 12
    },
    {
        "merged": false,
        "additions": 676,
        "deletions": 42,
        "changed_files": 5,
        "created_at": "2013-04-19T18:50:57Z",
        "closed_at": "2013-05-11T19:33:13Z",
        "merged_at": null,
        "body": "As discussed in [Add MultiDict Support](https://github.com/kennethreitz/requests/issues/1155), this enables `OrderedMultiDict` support in requests by adding the `OrderedMultiDict` and `MultiDict` structures and using them to marshall the `params=`, `data=`, and `files=` keyword arguments.\n",
        "comments": 26
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 10,
        "changed_files": 2,
        "created_at": "2013-04-19T06:38:16Z",
        "closed_at": "2013-06-08T10:53:16Z",
        "merged_at": "2013-06-08T10:53:16Z",
        "body": "Updated #1275\n\nExample:\n\n``` python\nimport requests\n\nresp = requests.get(\"http://httpbin.org/redirect/4\")\nfor r in resp.history:\n    print(\"url: {} request.url: {}\".format(r.url, r.request.url))\n```\n\nOutput:\n\n```\nurl: http://httpbin.org/redirect/4 request.url: http://httpbin.org/redirect/4\nurl: http://httpbin.org/redirect/3 request.url: http://httpbin.org/get\nurl: http://httpbin.org/redirect/2 request.url: http://httpbin.org/get\nurl: http://httpbin.org/redirect/1 request.url: http://httpbin.org/get\n```\n\nDesired:\n\n```\nurl: http://httpbin.org/redirect/4 request.url: http://httpbin.org/redirect/4\nurl: http://httpbin.org/redirect/3 request.url: http://httpbin.org/redirect/3\n...\n```\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-04-18T23:59:45Z",
        "closed_at": "2013-05-01T17:29:41Z",
        "merged_at": "2013-05-01T17:29:40Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-04-13T16:32:50Z",
        "closed_at": "2013-04-13T19:02:29Z",
        "merged_at": "2013-04-13T19:02:29Z",
        "body": "For some reason it was only change the method when a POST was being made. This\nis almost certainly my fault.\n\nFixes #1303\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-04-13T04:28:07Z",
        "closed_at": "2013-04-13T19:03:48Z",
        "merged_at": null,
        "body": "[Errno 185090050] _ssl.c:340: error:0B084002:x509 certificate routines:X509_load\n_cert_crl_file:system lib\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2013-04-12T23:44:40Z",
        "closed_at": "2013-04-13T19:05:13Z",
        "merged_at": "2013-04-13T19:05:13Z",
        "body": "Currently, to bump the number of `max_retries`, you need to reach into the `HTTPAdapter` instance & manipulate `HTTPAdapter.max_retries`. The other pool options are passed, with sane defaults, to the constructor so it makes sense this should be configurable in the same breath.\n\nPasses all tests & updated documentation. Should be 100% backward-compatible, since it's a new parameter that's not being passed anywhere else & is being default to the same constant as before.\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-04-11T14:09:03Z",
        "closed_at": "2013-04-11T16:04:07Z",
        "merged_at": "2013-04-11T16:04:07Z",
        "body": "Which is likely what you meant, eh?\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 31,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2013-04-11T03:51:56Z",
        "closed_at": "2013-04-13T19:24:21Z",
        "merged_at": "2013-04-13T19:24:21Z",
        "body": "I don't know how you feel about adding the dependency of `requests_oauthlib` in the documentation, but Twitter API v1.1 Streaming now requires OAuth Authentication rather than XAuth. I believe v1 is being blacked out sometime at the beginning of May.\n\n(And yeah, I edited this fron the GitHub website... **judge** me :smile:)\n",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2013-04-10T15:20:30Z",
        "closed_at": "2013-04-14T03:25:47Z",
        "merged_at": "2013-04-14T03:25:47Z",
        "body": "- Documented the logging, requested in #1297\n- Added build directory and *.egg to .gitignore\n- Added sphinx as setup requirement in order to be able to build documentation with `pyhton setup.py build_sphinx`\n\nmodified:   .gitignore\nmodified:   docs/api.rst\nmodified:   setup.py\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 62,
        "deletions": 72,
        "changed_files": 5,
        "created_at": "2013-04-10T06:13:18Z",
        "closed_at": "2013-04-14T03:27:47Z",
        "merged_at": "2013-04-14T03:27:47Z",
        "body": "This will fix #1249. Additionally, the urllib3 upgrade offers a reasonable way to deal with #465, see [this comment](https://github.com/kennethreitz/requests/issues/465#issuecomment-15106811).\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-04-08T16:02:49Z",
        "closed_at": "2013-04-08T18:01:37Z",
        "merged_at": "2013-04-08T18:01:37Z",
        "body": "It took me a while to figure out that this error was coming from the newest version of Requests rather than somewhere in Django. This updates the documentation to be more control-F friendly. \n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-04-06T15:33:15Z",
        "closed_at": "2013-04-07T00:27:23Z",
        "merged_at": "2013-04-07T00:27:23Z",
        "body": "Technically missing a netloc isn't the same as missing a scheme even if it is more convenient the other way. :-P\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 11,
        "changed_files": 2,
        "created_at": "2013-04-05T02:19:15Z",
        "closed_at": "2013-04-05T03:22:38Z",
        "merged_at": "2013-04-05T03:22:38Z",
        "body": "This changes sessions to update their cookiejar directly from the headers rather than the cookiejar attached to responses. This way cookies that the server marks as expired are removed from the session cookiejar.\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 71,
        "deletions": 25,
        "changed_files": 3,
        "created_at": "2013-04-03T19:33:14Z",
        "closed_at": "2013-04-16T19:53:11Z",
        "merged_at": null,
        "body": "Over the last few months there have been multiple issues raised about problems with string encodings. At best Requests is being inconsistent (#1250), and at worst perfectly valid combinations of input are failing (#1279).\n\nI think it's time for Requests to enforce a very consistent behaviour when it comes to string encodings. We need to establish what format the data will be in when we pass it to urllib3, and where we're going to transform it. We need to be consistent so that when users inevitably encounter errors, we can make it very clear what they should have passed in.\n\n@shazow has said that urllib3 wants the following input: bytes in the body, and native strings everywhere else. This defines our interface to urllib3.\n\nTo keep in sync with the above, we need to do the following things.\n- On Python 2, any unicode strings anywhere on a `PreparedRequest` other than the body should be encoded as UTF-8. The body should also be encoded as UTF-8 if it is a unicode string (unlikely, but unless we can guarantee it won't be we should do the right thing).\n- On Python 3, any bytestrings in a PreparedRequest should be decoded to unicode strings. Because we cannot make any intelligent guess, we will use Python's (stupid, stupid, _stupid_) locale-based decoding. This will almost-certainly throw exceptions if an incorrect encoding has been used, alerting the user.\n\nThoughts?\n",
        "comments": 14
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-04-02T13:26:22Z",
        "closed_at": "2013-04-02T18:42:58Z",
        "merged_at": null,
        "body": ".... This time with proper whitespaces.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 37,
        "deletions": 7,
        "changed_files": 2,
        "created_at": "2013-04-02T13:23:09Z",
        "closed_at": "2013-04-04T01:04:40Z",
        "merged_at": "2013-04-04T01:04:40Z",
        "body": "I'll close #1280 after you merge this by hand. I forgot to include it in the commit message.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 28,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2013-04-01T22:53:38Z",
        "closed_at": "2013-04-16T19:55:58Z",
        "merged_at": "2013-04-16T19:55:58Z",
        "body": "When attempting to post a file along with some other data including a unicode string (demonstrated in the added test case) I was running into the following error:\n\nUnicodeEncodeError: 'ascii' codec can't encode character u'\\xeb' in position 0: ordinal not in range(128)\n\nI traced the issue back to `_encode_files` where `compat.builtin_str`, in my case `str`, was being applied to the unicode string causing the above error. I changed it to use `compat.str` which seems to have resolved the issue.\n\n``` bash\n> python --version\nPython 2.7.2\n```\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-04-01T18:47:39Z",
        "closed_at": "2013-04-02T04:36:49Z",
        "merged_at": "2013-04-02T04:36:49Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 5,
        "changed_files": 4,
        "created_at": "2013-04-01T15:03:21Z",
        "closed_at": "2013-04-02T04:36:39Z",
        "merged_at": "2013-04-02T04:36:39Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-04-01T06:20:50Z",
        "closed_at": "2013-04-02T03:42:23Z",
        "merged_at": "2013-04-02T03:42:23Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 9,
        "changed_files": 2,
        "created_at": "2013-03-31T10:42:56Z",
        "closed_at": "2013-04-19T06:32:31Z",
        "merged_at": null,
        "body": "Example:\n\n``` python\nimport requests\n\nresp = requests.get(\"http://httpbin.org/redirect/4\")\nfor r in resp.history:\n    print(\"url: {} request.url: {}\".format(r.url, r.request.url))\n```\n\nOutput:\n\n```\nurl: http://httpbin.org/redirect/4 request.url: http://httpbin.org/redirect/4\nurl: http://httpbin.org/redirect/3 request.url: http://httpbin.org/get\nurl: http://httpbin.org/redirect/2 request.url: http://httpbin.org/get\nurl: http://httpbin.org/redirect/1 request.url: http://httpbin.org/get\n```\n\nSimplest solution is to copy `prepared_request` for each redirect. Also `prepared_request` can be created inside the while loop (maybe it's better?).\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 10,
        "deletions": 1,
        "changed_files": 3,
        "created_at": "2013-03-30T00:06:40Z",
        "closed_at": "2013-05-01T17:31:56Z",
        "merged_at": null,
        "body": "...for the most recent request.\n\nThis pertains to issue at https://github.com/kennethreitz/requests/issues/1271\n",
        "comments": 13
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-03-29T13:10:31Z",
        "closed_at": "2013-03-31T05:20:02Z",
        "merged_at": "2013-03-31T05:20:02Z",
        "body": "This patch is to ensure the **proper serialization** with, like, the standard module _pickle_.\n\nSee  [Issue #1269](https://github.com/kennethreitz/requests/issues/1269) for specific potential error it may produce.\n\nThanks for reviewing ;)\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 248,
        "deletions": 16,
        "changed_files": 4,
        "created_at": "2013-03-28T12:53:24Z",
        "closed_at": "2013-03-31T05:27:59Z",
        "merged_at": "2013-03-31T05:27:59Z",
        "body": "Contains a workaround (fingerprint, random hostname verification) and a solution (pyOpenSSL) for SNI on python 2.\n\nIntended to be included in 1.2 (#1267)\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 84,
        "deletions": 8,
        "changed_files": 4,
        "created_at": "2013-03-28T03:49:17Z",
        "closed_at": "2013-03-31T05:21:52Z",
        "merged_at": "2013-03-31T05:21:52Z",
        "body": "This fixes a few issues once and for all and I updated the HISTORY for the 1.2 release to include all the big changes.\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-03-22T00:57:54Z",
        "closed_at": "2013-03-22T04:06:23Z",
        "merged_at": "2013-03-22T04:06:23Z",
        "body": "- When credentials are included in a URL they are extracted and passed\n  to the server using HTTP Basic Auth.\n\nI've tested this by hand and it works.  I'm not quite sure how I\nshould test this in `test_requests.py`.  I would normally mock this\nkind of thing, since I don't have a persistent service that requires\ncredentials running to use from a test, which seems to be the existing\npattern.  I'm reluctant to add a dependency on a mocking library and\njump through all those hoops if that technique is not already used.\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 76,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2013-03-16T17:28:43Z",
        "closed_at": "2013-03-21T15:39:02Z",
        "merged_at": null,
        "body": "this is a proposal/proof of concept. by no means is it expected to be merged.\n\nit provides a FuturesSession which returns concurrent.futures.Future objects to calls in place of requests.Response. this provides a near seamless async requests api.\n\nan example:\n\n```\nsession = FuturesSession()\nfuture = session.get('http://www.foo.com/bar/')\n... do other stuff ...\n# wait for response or return immediately if it's already back\nresponse = future.result()\n... continue as normal ...\n```\n\nas currently implemented it requires no external dependancies and uses the python3 futures, tested with python 3.3.0. if desired support could be added to 2.x releases by either using the backport of futures or without dependancies using methods similar to https://github.com/ross/python-asynchttp.\n\nfeedback solicited. \n## best,\n\n-rm\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 30,
        "deletions": 2,
        "changed_files": 3,
        "created_at": "2013-03-11T18:15:41Z",
        "closed_at": "2013-03-12T14:37:55Z",
        "merged_at": "2013-03-12T14:37:55Z",
        "body": "This is for issue #1088\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-03-11T08:56:27Z",
        "closed_at": "2013-04-14T03:28:43Z",
        "merged_at": "2013-04-14T03:28:43Z",
        "body": "Hi,\n\nI've encountered this error:\n\n```\nFile \"/sites/.ro-api/api/local/lib/python2.7/site-packages/requests/api.py\", line 87, in post\n  return request('post', url, data=data, **kwargs)\nFile \"/sites/.ro-api/api/local/lib/python2.7/site-packages/requests/api.py\", line 44, in request\n  return session.request(method=method, url=url, **kwargs)\nFile \"/sites/.ro-api/api/local/lib/python2.7/site-packages/requests/sessions.py\", line 279, in request\n  resp = self.send(prep, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies) \nFile \"/sites/.ro-api/api/local/lib/python2.7/site-packages/requests/sessions.py\", line 374, in send \n  r = adapter.send(request, **kwargs)\nFile \"/sites/.ro-api/api/local/lib/python2.7/site-packages/requests/adapters.py\", line 219, in send\n  r = self.build_response(request, resp)\nFile \"/sites/.ro-api/api/local/lib/python2.7/site-packages/requests/adapters.py\", line 113, in build_response \n  response = dispatch_hook('response', req.hooks, response)\nFile \"/sites/.ro-api/api/local/lib/python2.7/site-packages/requests/hooks.py\", line 39, in dispatch_hook\n  _hook_data = hook(hook_data)\nFile \"/sites/.ro-api/api/local/lib/python2.7/site-packages/requests/auth.py\", line 155, in handle_401\n  r.request.headers['Authorization'] = self.build_digest_header(r.request.method, r.request.url)\nFile \"/sites/.ro-api/api/local/lib/python2.7/site-packages/requests/auth.py\", line 69, in build_digest_header\n  nonce = self.chal['nonce']\nKeyError: 'nonce'\n```\n\nWhile investigating i found that the site was sending me the following string:\n`\"WWW-Authenticate: digest nonce=\"***********************\", qop=\"auth\", realm=\"***************\", algorithm=\"md5\", opaque=\"*******************=\"\"`\nThe parsed key in this case was: \"digest nonce\" and not \"nonce\", thus, the error above.\n\nSo I've modified the s_auth in requests/auth.py (line 154) string to replace \"Digest \" or \"digest \" with '' using re module and re.sub function. I've tested the feature and it works.\n\nRegards,\nOvidiu Negrut\n",
        "comments": 15
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2013-03-09T11:13:26Z",
        "closed_at": "2013-03-20T10:37:25Z",
        "merged_at": "2013-03-20T10:37:25Z",
        "body": "A fix for issue #1228.\n\nI have a nagging feeling, that there'd be a better way to do this, but here goes.\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 20,
        "changed_files": 1,
        "created_at": "2013-03-08T10:21:50Z",
        "closed_at": "2013-03-08T19:51:42Z",
        "merged_at": "2013-03-08T19:51:42Z",
        "body": "It was reverted in b14584f36eca344ed5033d1d2f5a59490fadca56 but again merged in c0d4b23cea430ba1dce407f4325d9362c55d577c\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 71,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2013-03-02T07:24:43Z",
        "closed_at": "2013-03-02T20:58:49Z",
        "merged_at": "2013-03-02T20:58:49Z",
        "body": "Hopefully this helps with issues like #1196. I know when 1.0 first dropped I went straight to the docs looking for this and I was surprised it didn't exist.\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-03-02T04:40:08Z",
        "closed_at": "2013-03-02T20:59:10Z",
        "merged_at": "2013-03-02T20:59:10Z",
        "body": "Fixed typo.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-03-01T19:23:51Z",
        "closed_at": "2013-03-02T20:59:41Z",
        "merged_at": "2013-03-02T20:59:41Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 18,
        "deletions": 5,
        "changed_files": 4,
        "created_at": "2013-03-01T09:01:52Z",
        "closed_at": "2013-03-04T22:54:32Z",
        "merged_at": "2013-03-04T22:54:32Z",
        "body": "Just a little refactoring, but it seems nicer to me to be able to pass\nthe response when constructing the `HTTPError` instance instead of\nconstructing it and then changing the member variable.\n",
        "comments": 10
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2013-03-01T09:00:24Z",
        "closed_at": "2013-03-02T21:00:48Z",
        "merged_at": "2013-03-02T21:00:48Z",
        "body": "One typo and a couple of auto-completions, I guess.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2013-02-28T19:36:00Z",
        "closed_at": "2013-03-04T22:52:31Z",
        "merged_at": "2013-03-04T22:52:31Z",
        "body": "As noted in #1088, sessions cannot be pickled currently. I ran into this when implementing some multiprocessing functionality for a project. \n\nHere, I'm just checking for `__attrs__` prior to trying to iterate over it. It does occur to me that if `__attrs__` is removed permanently, maybe the `__getstate__` method should just be stubbed out to preserve pickling functionality.\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 32,
        "deletions": 5,
        "changed_files": 5,
        "created_at": "2013-02-27T16:04:34Z",
        "closed_at": "2013-03-02T21:02:27Z",
        "merged_at": "2013-03-02T21:02:27Z",
        "body": "Related ticket: #1208\n\nThis pull request adds support for `max_retries` as an argument to `requests.request`. I think that since we already support `timeout` as a top-level argument then it makes sense to support `max_retries` too. \n\nI've added a unit test, but this is a very difficult thing to test for. I can't see any easy way to simulate an unreliable connection.\n\nPlease let me know what you think.\n",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-02-25T00:21:02Z",
        "closed_at": "2013-02-25T09:02:43Z",
        "merged_at": null,
        "body": "Checked it out, couldn't see pycon as a syntax highlighter (not trying to be a smart ass either :sparkles:)\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 132,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2013-02-23T03:25:32Z",
        "closed_at": "2013-02-25T10:33:06Z",
        "merged_at": null,
        "body": "This pull request adds printable names for status codes, as both the `requests.status_codes.name` dictionary, and accessible directly from a Response object as `Response.status_name`.\n\nI think it's quite a useful thing to have, say for printing out a name to go with a given status code (especially in the event of a failure.\n\nAnd uses cases:\n\n``` python\n>>> import requests\n\n>>> r = requests.get('https://github.com/timeline.json')\n>>> r.status_code\n200\n>>> r.status_name\n'OK'\n\n>>> r = requests.get('https://github.com/timene.js')\n>>> r.status_code\n404\n>>> r.status_name\n'Not Found'\n>>> r  # I also added the status_name to __repr__'s output, so the below is easier to understand at a glance\n<Response [404: Not Found]>\n\n>>> requests.status_codes.name[200]\n'OK'\n\n>>> requests.status_codes.name[203]\n'Non-Authoritative Info'\n\n>>> requests.status_codes.name[405]\n'Method Not Allowed'\n```\n\nWe may even want to add a `requests.status_codes.description` dict later on, having something like a one sentence description of what the code means. Maybe even create a Status class, with the members `code`, `name`, and `description`, accessible as `Response.status`, so you'd do something like this instead:\n\n``` python\n>>> r = requests.get('https://github.com/timene.js')\n>>> r.status.code\n404\n>>> r.status.name\n'Not Found'\n```\n\nThanks for the awesome library. I dunno how I ever lived without Requests :smile: \n",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2013-02-22T00:39:45Z",
        "closed_at": "2013-02-25T10:31:01Z",
        "merged_at": "2013-02-25T10:31:01Z",
        "body": "Should resolve #1207.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2013-02-20T13:59:50Z",
        "closed_at": "2013-02-25T10:31:21Z",
        "merged_at": "2013-02-25T10:31:21Z",
        "body": "Closes #1203\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 9,
        "changed_files": 3,
        "created_at": "2013-02-16T06:00:17Z",
        "closed_at": "2013-02-20T06:50:10Z",
        "merged_at": "2013-02-20T06:50:10Z",
        "body": "Cookies from a session were overwriting cookies explicitly defined in a request with that session. A couple minor changes as well:\n- Implement RequestsCookieJar.copy\n- Use RequestsCookieJar.update when merging cookiejars in a couple places\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2013-02-15T16:39:13Z",
        "closed_at": "2013-02-19T13:40:15Z",
        "merged_at": "2013-02-19T13:40:15Z",
        "body": "Issue #1192 tried to force users to provide a scheme for proxy urls.\nAs this would break backwards compability change the docs instead.\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2013-02-15T00:47:49Z",
        "closed_at": "2013-02-15T04:52:04Z",
        "merged_at": null,
        "body": "How about this?\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2013-02-14T06:07:44Z",
        "closed_at": "2013-02-15T06:42:50Z",
        "merged_at": "2013-02-15T06:42:50Z",
        "body": "This would allow cookies from external CookieJars, or other RequestsCookieJars to be merged in with a RequestsCookieJar while preserving all domain and other cookie info.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-02-14T04:23:44Z",
        "closed_at": "2013-02-20T07:10:45Z",
        "merged_at": "2013-02-20T07:10:45Z",
        "body": "In #1188 @brandon-rhodes pointed out that we throw some uninformative exceptions when problems arise in urllib3. This would catch the exception and wrap it in a Requests exception, then rethrow it with its original traceback.\n\nI'm on the fence about whether we should do one of the following:\n1. Create a new Requests exception for this case (`requests.exceptions.TransportError`?)\n2. Import urllib3's exceptions into `requests.exceptions` and export them as our own? (Not great)\n\nOpinions welcome (@sigmavirus24?)\n",
        "comments": 10
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2013-02-14T03:49:45Z",
        "closed_at": "2013-02-25T10:31:40Z",
        "merged_at": null,
        "body": ":warning: **CAUTION**:  Breaking change. We may not want to take this. :warning:\n\nThis is in relation to #1182. Currently we guess what scheme to use on proxies if that scheme is not provided. This _usually_ works, but sometimes fails in unexpected ways. This would require users to be explicit about what scheme they want to use to contact the proxy.\n\nThis **will** break some users' code, without question. I am open to leaving the current behaviour in place, as it's not wrong, just a bit odd.\n",
        "comments": 9
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-02-14T03:34:10Z",
        "closed_at": "2013-02-17T22:56:41Z",
        "merged_at": null,
        "body": "Fixes #1189 as confirmed by @Lukasa\n",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 5,
        "changed_files": 4,
        "created_at": "2013-02-14T00:26:08Z",
        "closed_at": "2013-03-02T21:04:01Z",
        "merged_at": "2013-03-02T21:04:01Z",
        "body": "Hooks sometimes have to send requests (e.g. when responding to a 401 during\nauthentication).\n\nAll keyword arguments should be passed along when hooks are dispatched so that\nif a user wanted to use a timeout, stream, specify a cert location with the\nverify flag, etc, their specification can be followed.\n",
        "comments": 20
    },
    {
        "merged": false,
        "additions": 8,
        "deletions": 8,
        "changed_files": 3,
        "created_at": "2013-02-13T20:28:24Z",
        "closed_at": "2013-02-14T01:13:13Z",
        "merged_at": null,
        "body": "MissingSchema -> MissingScheme, InvalidSchema -> InvalidScheme\nsee t-8ch's comment in issue #1182\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2013-02-13T04:05:15Z",
        "closed_at": "2013-02-13T10:13:31Z",
        "merged_at": "2013-02-13T10:13:31Z",
        "body": "Fixes #1183 \n\n/cc @mkomitee\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2013-02-11T22:14:45Z",
        "closed_at": "2013-02-12T08:27:05Z",
        "merged_at": "2013-02-12T08:27:05Z",
        "body": "removed no longer used redirect codes from models\nadded numeric values of redirect codes in comments\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2013-02-11T12:44:21Z",
        "closed_at": "2013-02-12T16:43:02Z",
        "merged_at": "2013-02-12T16:43:02Z",
        "body": "## Problem\n\nPlease see issue #1082.\n## Solution\n\nLet's fix at least Python-2 unicode issues with **header name**,\nbecause its representation as bytes is well defined in HTTP/1.1 spec:\nhttp://tools.ietf.org/html/rfc2616#section-4.2\n\n```\nmessage-header = field-name \":\" [ field-value ]\nfield-name     = token\ntoken          = 1*<any CHAR except CTLs or separators>\nCHAR           = <any US-ASCII character (octets 0 - 127)>\n```\n\nSo header name should always be sent as ascii.\n\nIf user provides header name that can be converted to ascii without errors,\nthen it should be converted, e.g. `u'Content-Type' --> 'Content-Type'`.\n\nOtherwise a helpful error should be raised, indicating that the header name is the reason.\n- Created: `test_unicode_header_name`.\n- Updated: `prepare_headers`.\n",
        "comments": 8
    },
    {
        "merged": false,
        "additions": 10,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-02-10T10:26:22Z",
        "closed_at": "2013-02-10T22:19:27Z",
        "merged_at": null,
        "body": "when using `StringIO` in Python 3 oder using `cStringIO` in Python 2, you will have an object that does not have a `len` AND does not have a `.fileno()`\n\nIn that case, the best method for finding the length of the backing object is to seek to the end. This assumes that the object is seekable, though.\n\nSince we're going to load the whole object into memory anyway, memory consumption should not be increased by the seeking.\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2013-02-09T17:45:04Z",
        "closed_at": "2013-02-10T22:26:18Z",
        "merged_at": null,
        "body": "This is important when posting files/binary data in Python2.\nSince urlsplit will produce unicode parts, the path_url will also be unicode, and thus the sent body will be\u00a0converted to unicode during concatenation by urllib, producing a\u00a0UnicodeDecodeError when sending binary data.\nForcing the path_url to be a native string in Python2 resolves this.\n\nNo test cases yet.\n",
        "comments": 14
    },
    {
        "merged": false,
        "additions": 27,
        "deletions": 14,
        "changed_files": 4,
        "created_at": "2013-02-08T18:36:22Z",
        "closed_at": "2013-02-10T22:01:39Z",
        "merged_at": null,
        "body": "Added \"track_referer\" attribute and \"last_page\" to Session so that the last response's URL can be used as the referer on the next request. The header can still be overwritten globally via Session.headers or on per-request basis.\n",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 29,
        "deletions": 18,
        "changed_files": 1,
        "created_at": "2013-02-08T04:11:02Z",
        "closed_at": "2013-02-10T22:21:13Z",
        "merged_at": "2013-02-10T22:21:13Z",
        "body": "These three (which I'll happily squash if you'd like) should prevent the problem I mentioned [here](https://github.com/kennethreitz/requests/pull/1151#issuecomment-12905796).\n",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 15,
        "deletions": 10,
        "changed_files": 1,
        "created_at": "2013-02-07T20:43:38Z",
        "closed_at": "2013-02-07T22:09:55Z",
        "merged_at": null,
        "body": "okay i was too lazy to clone the repository and do this, but with the in-browser its really quick :)\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 33,
        "deletions": 1,
        "changed_files": 3,
        "created_at": "2013-02-01T20:10:31Z",
        "closed_at": "2013-02-06T21:05:04Z",
        "merged_at": "2013-02-06T21:05:04Z",
        "body": "This is one half of the pair of open problems from #1053. Please code review this before pulling it.\n\nI concluded that, as this is fundamentally an authentication issue, this belongs in our code, not in urllib3. For the moment, I have it set up so that if the authentication is provided in the URL, we simply grab it out. It might be worth turning this into a separate part of the API though. Let me know what you think.\n",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2013-02-01T17:01:29Z",
        "closed_at": "2013-02-10T22:07:08Z",
        "merged_at": "2013-02-10T22:07:08Z",
        "body": "Re: #1159\n",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-01-31T19:25:33Z",
        "closed_at": "2013-02-01T15:30:47Z",
        "merged_at": "2013-02-01T15:30:47Z",
        "body": "This fixes issue #1156.\n\nSigned-off-by: Yehuda Sadeh yehuda@inktank.com\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 12,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2013-01-31T07:18:46Z",
        "closed_at": "2013-01-31T14:32:58Z",
        "merged_at": null,
        "body": "I find myself continuously making a pretty_print type method when dealing with r.json() commands. Figured it may better placed back inside requests.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-01-30T20:22:50Z",
        "closed_at": "2013-01-30T23:54:20Z",
        "merged_at": "2013-01-30T23:54:20Z",
        "body": "Rephrasing a line in the docs, add explicite mention of \"client side certificate\" (for indexing and clarity)\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 49,
        "deletions": 15,
        "changed_files": 2,
        "created_at": "2013-01-30T18:17:08Z",
        "closed_at": "2013-02-05T19:42:51Z",
        "merged_at": "2013-02-05T19:42:51Z",
        "body": "This closes #1133 and allows users to use Session.send with a prepared request. The tests pass, but I just thought of a separate instance where this may not work properly, so don't merge right away.\n",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 642,
        "deletions": 37,
        "changed_files": 1,
        "created_at": "2013-01-29T18:47:07Z",
        "closed_at": "2013-02-10T22:10:16Z",
        "merged_at": null,
        "body": "Updated cacert.pem with latest from http://curl.haxx.se/ca/cacert.pem\n",
        "comments": 10
    },
    {
        "merged": true,
        "additions": 38,
        "deletions": 39,
        "changed_files": 9,
        "created_at": "2013-01-27T01:07:11Z",
        "closed_at": "2013-01-28T03:11:15Z",
        "merged_at": "2013-01-28T03:11:15Z",
        "body": "",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2013-01-26T15:46:41Z",
        "closed_at": "2013-02-10T22:06:38Z",
        "merged_at": "2013-02-10T22:06:38Z",
        "body": "When trying to send unprepared request like\n\n```\nimport requests\n\nrequests.Session().send(requests.Request(url='http://example.com'))\n```\n\none gets rather meaningless error\n\n```\nTraceback (most recent call last):\n  File \"y.py\", line 3, in <module>\n    requests.Session().send(requests.Request(url='http://example.com'))\n  File \"c:\\python\\venvs\\sandbox\\lib\\site-packages\\requests\\sessions.py\", line 374, in send\n    r = adapter.send(request, **kwargs)\n  File \"c:\\python\\venvs\\sandbox\\lib\\site-packages\\requests\\adapters.py\", line 158, in send\n    url = self.request_url(request, proxies)\n  File \"c:\\python\\venvs\\sandbox\\lib\\site-packages\\requests\\adapters.py\", line 148, in request_url\n    url = request.path_url\nAttributeError: 'Request' object has no attribute 'path_url'\n```\n\nIt would be nice to check if the request is prepared before trying to send and inform user what's wrong if the request is not prepared.\n",
        "comments": 24
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2013-01-26T15:23:17Z",
        "closed_at": "2013-01-29T04:52:18Z",
        "merged_at": "2013-01-29T04:52:18Z",
        "body": "Either: \n\n``` python\nr = requests.get('http://bigsite.com/')\n\nfor line in r:\n    # Do stuff.\n```\n\nor:\n\n``` python\nr = requests.get('http://bigsite.com/')\n\nfor chunk in r:\n    # Do stuff.\n```\n\nSee #1141.\n",
        "comments": 16
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 1,
        "changed_files": 3,
        "created_at": "2013-01-25T05:19:16Z",
        "closed_at": "2013-01-26T04:58:20Z",
        "merged_at": "2013-01-26T04:58:20Z",
        "body": "Fix #1051.\n",
        "comments": 10
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2013-01-24T17:49:38Z",
        "closed_at": "2013-01-26T04:58:35Z",
        "merged_at": "2013-01-26T04:58:35Z",
        "body": "I wasn't sure if setting some parameters on cookies was working or not, so I wrote a unit test for it.\n\nThe test passes; turns out I was just using it wrong in my other module.\n",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 12,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2013-01-24T15:34:45Z",
        "closed_at": "2013-01-26T05:03:10Z",
        "merged_at": null,
        "body": "`HTTPDigestAuth.handle_401()` replaces the original response with another by doing `r.connection.send(r.request)`. This ignores the arguments originally passed to `Session.request()` such as `stream`, `proxies`, `timeout`, `verify` and `cert`.\n\n`HTTPDigestAuth` (and other hooks that behave similarly) need a way to perform additional requests in the same context as the original. This could be done by having `request.Session` set the relevant instance attributes in `__init__()` and then doing `resp.session = self` after `self.send()`.\n\nIt's possible that `requests.request()` et al should also pass those arguments to the `Session.__init__()`, not `Session.request()`.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2013-01-24T02:17:33Z",
        "closed_at": "2013-01-28T03:10:16Z",
        "merged_at": "2013-01-28T03:10:16Z",
        "body": "Pretty simple - adds calls to time.time() around send() and a new attribute, Response.time_taken, to tell how long the last request took.\n",
        "comments": 11
    },
    {
        "merged": false,
        "additions": 42,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2013-01-23T10:52:23Z",
        "closed_at": "2013-01-23T13:23:14Z",
        "merged_at": null,
        "body": "...without reading whole response content into machine memory.\n\nIncludes 1 new test case.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 81,
        "deletions": 26,
        "changed_files": 4,
        "created_at": "2013-01-22T22:41:48Z",
        "closed_at": "2013-01-23T01:45:01Z",
        "merged_at": "2013-01-23T01:45:01Z",
        "body": "The urllib3 changeset includes some changes related to issue #1008.\n\nAs this is only an update to the dep, I don't feel that I should add myself to the AUTHORS file. If you disagree, please let me know.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-01-22T22:28:45Z",
        "closed_at": "2013-01-23T01:53:16Z",
        "merged_at": "2013-01-23T01:53:16Z",
        "body": "I swear the tests pass this time ;)\n\nRef: #1126\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2013-01-22T15:39:42Z",
        "closed_at": "2013-01-23T03:43:50Z",
        "merged_at": "2013-01-23T03:43:50Z",
        "body": "While I was testing a digest auth provider I found that the algorithm field was missing at the Authorization Request Header.\n\nFollowing the [RFC](http://pretty-rfc.herokuapp.com/RFC2617#the.authorization.request.header):\n\n> The values of the opaque and algorithm fields must be those supplied in the WWW-Authenticate response header...\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2013-01-21T23:56:28Z",
        "closed_at": "2013-01-26T05:00:33Z",
        "merged_at": "2013-01-26T05:00:33Z",
        "body": "Currently if you try to use digest auth with a bad username and password, you will enter a infinite loop of 401s. I think this is due to the handle_401 method overwriting the current registered hook, which in the context of #1106 is the correct behavior. This means that we can't just count the registered hooks. \n\nI added a counter to the request object, but am not sure if this fits with the way the rest of the library is structured since I am not too familiar with the rest of the codebase. If you have better idea of how this should be implemented, I'd be happy to do it!\n",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2013-01-21T21:17:17Z",
        "closed_at": "2013-01-22T13:09:12Z",
        "merged_at": "2013-01-22T13:09:12Z",
        "body": "Improve the responsiveness of `iter_lines` when called by unsuspecting users. =)\n\nBelatedly changed in response to #989. Obviously, feel free to pick a different number if you think this is no good.\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2013-01-21T20:00:06Z",
        "closed_at": "2013-01-22T14:40:24Z",
        "merged_at": "2013-01-22T14:40:24Z",
        "body": "Resolves #1118.\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2013-01-19T16:51:33Z",
        "closed_at": "2013-01-23T02:48:32Z",
        "merged_at": "2013-01-23T02:48:32Z",
        "body": "The only place it makes sense to call `dispatch_hook` is in the session. Having them performed in the adapter does nothing as is and would be inconsistent across other adapters (ostensibly written by others).\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2013-01-19T12:10:47Z",
        "closed_at": "2013-01-23T02:51:17Z",
        "merged_at": "2013-01-23T02:51:17Z",
        "body": "This should resolve #1113. A test is included, but the test relies on StringIO - if you want to avoid that import, I can remove the test.\n\nAs a side note, the type of the Content-Length header is now always unicode, which feels pretty weird. Should I add in a call to `encode('ascii')`?\n",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 11,
        "changed_files": 2,
        "created_at": "2013-01-18T04:43:26Z",
        "closed_at": "2013-01-18T12:39:41Z",
        "merged_at": "2013-01-18T12:39:41Z",
        "body": "As per #1105, certifi is being end-of-lifed. Requests will use either\nits own vendored bundle, or possibly (when packaged with OS distributions)\nan externally packaged bundle, which can be enabled by patching\nrequests.certs.where().\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 14,
        "deletions": 1,
        "changed_files": 3,
        "created_at": "2013-01-17T23:35:29Z",
        "closed_at": "2013-01-18T03:50:19Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2013-01-17T19:30:34Z",
        "closed_at": "2013-01-18T03:50:55Z",
        "merged_at": "2013-01-18T03:50:55Z",
        "body": "The cookies example in the docs is wrong. This fixes it so it demonstrates correct behaviour, though it is no longer something you can type into your own shell to see. If we need that functionality, we might need to adjust httpbin's behaviour. Let me know if you'd rather do that.\n\nAddresses #1069 (a whole month later).\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2013-01-16T19:13:48Z",
        "closed_at": "2013-01-26T05:02:01Z",
        "merged_at": "2013-01-26T05:02:01Z",
        "body": "As of [commit ef8563a](https://github.com/kennethreitz/requests/commit/ef8563ab36c6b52834ee9c35f6f75a424cd9ceef) the ability to pass a keyword argument like `data=[('key', 'value'), ('key', 'value2')]` was broken because the `is_stream` detection in `PreparedRequest.prepare_body(self, data, files)` fails to look for a list of 2-tuples.\n\nJust in case this is deemed to be an unnecessary change (because the calling code could switch to using a dict), Il'l make note here that this is required in order to pass POST parameters where the key is the same, but values are different. \n\n```\nform_data = [('item', 1), ('item', 2), ('item', 3)]\nresp = requests.post('http://www.example.com', data=form_data)\n```\n",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 7,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2013-01-14T18:05:49Z",
        "closed_at": "2013-01-25T04:37:17Z",
        "merged_at": null,
        "body": "See https://github.com/kennethreitz/requests/pull/965 . However, this no longer appears to be working in Requests 1.1. This pull request is against 1.1.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 27,
        "deletions": 10,
        "changed_files": 3,
        "created_at": "2013-01-12T21:00:08Z",
        "closed_at": "2013-01-24T18:00:25Z",
        "merged_at": "2013-01-24T18:00:24Z",
        "body": ":heart: \n",
        "comments": 16
    },
    {
        "merged": true,
        "additions": 13,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2013-01-11T20:06:37Z",
        "closed_at": "2013-01-22T13:11:14Z",
        "merged_at": "2013-01-22T13:11:14Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-01-11T16:42:28Z",
        "closed_at": "2013-01-22T13:10:19Z",
        "merged_at": "2013-01-22T13:10:19Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2013-01-11T10:28:33Z",
        "closed_at": "2013-01-11T13:46:50Z",
        "merged_at": null,
        "body": "The code assumes that we have only file like objects or strings as body of the request.\nWith this change also\u00a0generators can be set as a body of the request.\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 42,
        "deletions": 36,
        "changed_files": 2,
        "created_at": "2013-01-11T00:15:56Z",
        "closed_at": "2013-01-22T13:10:47Z",
        "merged_at": null,
        "body": "Also, some minor PEP 8 fixes.\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 13,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2013-01-10T05:42:44Z",
        "closed_at": "2013-01-10T07:07:46Z",
        "merged_at": "2013-01-10T07:07:46Z",
        "body": "This GET request spuriously returns a 400\n\n``` python\n>>> import requests\n>>> url = \"http://www.stackoverflow.com\"\n>>> headers ={\"User-agent\": \"Mozilla/5.0\"}\n>>> response = requests.get(url, headers=headers)\n>>> print response.status_code\n400\n```\n\nThis is because ever since a776e7cb3e57e56a2d9974b730e6f5e7776751a4,\n\n``` python\nheaders = merge_kwargs(headers, self.headers)\n```\n\ncauses the LHS to have two keys for user-agent when the user-supplied version is incorrectly capitalized:\n\n``` python\n>>> headers.keys()\n['Accept-Encoding', 'Accept', 'User-Agent', 'User-agent']\n```\n\nA solution is to, instead of using `dict.update`, iterate through each key and update manually using a case-insensitive key lookup. This feels kinda hacky, so please let me know if there is a cleaner way to fix this.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 2,
        "changed_files": 3,
        "created_at": "2013-01-10T03:35:38Z",
        "closed_at": "2013-01-10T07:02:47Z",
        "merged_at": "2013-01-10T07:02:47Z",
        "body": "urllib3 allows for explicit content types to be specified for file data: https://github.com/kennethreitz/requests/blob/master/requests/packages/urllib3/filepost.py#L70\n\nThis patch allows that functionality to be exposed. A test is included.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2013-01-04T21:46:25Z",
        "closed_at": "2013-01-07T18:41:51Z",
        "merged_at": "2013-01-07T18:41:51Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 10,
        "changed_files": 1,
        "created_at": "2013-01-04T21:33:56Z",
        "closed_at": "2013-01-07T18:42:14Z",
        "merged_at": "2013-01-07T18:42:14Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2013-01-02T19:27:27Z",
        "closed_at": "2013-01-07T18:42:30Z",
        "merged_at": "2013-01-07T18:42:30Z",
        "body": "Restore the functionality from here:\nhttps://github.com/kennethreitz/requests/blob/v0.14.2/requests/models.py#L884\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2012-12-31T00:48:47Z",
        "closed_at": "2012-12-31T07:49:44Z",
        "merged_at": "2012-12-31T07:49:44Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 81,
        "deletions": 11,
        "changed_files": 2,
        "created_at": "2012-12-30T17:21:56Z",
        "closed_at": "2013-01-09T22:48:28Z",
        "merged_at": null,
        "body": "CIDR format is usually used in no_proxy environment varilable.\nNow requests modules supports only domain suffix form (.mydomain.example.net) for no_proxy.\nI believe it is useful to support CIDR format in no_proxy.\n\nAfter this commit, we can use no_proxy such as \"no_proxy=127.0.0.0/8,192.168.0.0/16,10.0.0.0/8,.mydomain.example.net\"\n\nThis patch uses 'netaddr' module. I am not sure using a third party module is acceptable in requests module policy.\n\nIn addition, I cannot find unit tests in the repo.\n\nAny feedback will be appreciated.\nThanks,\nAkihiro\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 18,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2012-12-27T13:39:40Z",
        "closed_at": "2012-12-28T15:41:55Z",
        "merged_at": "2012-12-28T15:41:55Z",
        "body": "This resolves #997, sort of.\n\nThere are no tests here, because it felt weird adding tests for this to the tiny, tiny test suite. If you want tests, they're easy to write and I'm happy to do it, just ask. =)\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 19,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2012-12-22T13:37:31Z",
        "closed_at": "2012-12-27T11:24:56Z",
        "merged_at": "2012-12-27T11:24:56Z",
        "body": "This resolves #1056 and #1058.\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 7,
        "changed_files": 2,
        "created_at": "2012-12-20T14:49:40Z",
        "closed_at": "2012-12-20T17:09:24Z",
        "merged_at": "2012-12-20T17:09:24Z",
        "body": "Recently I have been playing with requests (what a fanstastic library) and needed to send potentially large files via PUT requests.  I discovered that passing a file-like objects works just fine here, as it is supported by the underlying httplib layer, so I figured it would be helpful to indicate this in the doc string.  \n\nHope this is helpful -- and accurate :)\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2012-12-19T20:13:02Z",
        "closed_at": "2012-12-22T11:05:51Z",
        "merged_at": "2012-12-22T11:05:51Z",
        "body": "Resolves issue #1046.\n\nI have not tested this, so...yeah.\n",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-12-19T20:06:30Z",
        "closed_at": "2012-12-19T21:12:03Z",
        "merged_at": "2012-12-19T21:12:03Z",
        "body": "Context in https://github.com/requests/requests-oauthlib/pull/4\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2012-12-19T14:03:45Z",
        "closed_at": "2012-12-19T21:12:13Z",
        "merged_at": null,
        "body": "Is there a simpler way to say: \"this pull request solves issue X\"? I hope putting it's number in the title links them together.\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-12-18T14:46:00Z",
        "closed_at": "2012-12-18T18:09:33Z",
        "merged_at": "2012-12-18T18:09:33Z",
        "body": "I can only assume that the only possible thing to close on a session are the\nadapters. As such, I wrote the close method for a session object which closes\nall possible adapters.\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 222,
        "deletions": 249,
        "changed_files": 15,
        "created_at": "2012-12-18T07:59:10Z",
        "closed_at": "2012-12-23T10:32:26Z",
        "merged_at": null,
        "body": "Since a CA bundle started being vendored inside Requests, it always\noverrides the OS bundle. This changes the preference order to be\npackaged certifi, then the OS bundle, then the vendored bundle,\nallowing managed environments to use their system bundles by simply\nomitting a certifi package.\n\nReferences: #557\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 20,
        "changed_files": 4,
        "created_at": "2012-12-18T01:21:33Z",
        "closed_at": "2012-12-18T05:44:56Z",
        "merged_at": "2012-12-18T05:44:56Z",
        "body": "Mostly removed a whole bunch of unused imports.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2012-12-18T01:14:24Z",
        "closed_at": "2012-12-18T05:45:49Z",
        "merged_at": "2012-12-18T05:45:49Z",
        "body": "Fixes #1027.\n\nAll tests pass in python2.7.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-12-17T23:23:27Z",
        "closed_at": "2012-12-18T05:49:45Z",
        "merged_at": "2012-12-18T05:49:45Z",
        "body": "MANIFEST.in contained test_requests.py but was missing requirements.txt that it depends on. \nNow both files will be included in the .tar.gz file that can be downloaded from PyPI.\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-12-16T15:01:40Z",
        "closed_at": "2012-12-16T20:14:23Z",
        "merged_at": "2012-12-16T20:14:23Z",
        "body": "I think someone made a typo:\n\nself.headers = CaseInsensitiveDict(self.headers)\n\nshould be:\n\nself.headers = CaseInsensitiveDict(headers)\n\nCheers,\nBartek\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 85,
        "deletions": 74,
        "changed_files": 3,
        "created_at": "2012-12-15T13:20:21Z",
        "closed_at": "2012-12-17T19:27:36Z",
        "merged_at": "2012-12-17T19:27:36Z",
        "body": "Thoughts? Not sure whether we want a separate section on the Requests org in general, but we can add that as a separate change if we do.\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2012-12-15T12:13:26Z",
        "closed_at": "2012-12-15T21:14:41Z",
        "merged_at": "2012-12-15T21:14:41Z",
        "body": "The old URL appears to be broken, redirecting to\u00a0https://travis-ci.org//kennethreitz/requests\n\nAlso, according to [their wiki](http://about.travis-ci.org/docs/user/status-images/) the _secure_ isn't required anymore.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 23,
        "changed_files": 4,
        "created_at": "2012-12-14T22:11:11Z",
        "closed_at": "2012-12-15T04:06:56Z",
        "merged_at": "2012-12-15T04:06:56Z",
        "body": "These files look like they were accidentally added to the repository. Sorry if I'm wrong. :)\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-12-12T15:47:21Z",
        "closed_at": "2012-12-15T04:07:18Z",
        "merged_at": "2012-12-15T04:07:18Z",
        "body": "Fixes #1000.\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 201,
        "deletions": 23,
        "changed_files": 7,
        "created_at": "2012-12-12T12:52:04Z",
        "closed_at": "2012-12-12T16:39:00Z",
        "merged_at": null,
        "body": "Hi!\n\nI'd like to suggest a new feature - two types of timeouts.\nRegular one - happens when we wait for response from server on existing connection.\nAnd a new one - connection timeout. Happens only when we try to create a new socket connection.\nI added new request parameter connect_timeout and two new exceptions ConnectionTimeout and OperationTimeout.\n\nBut why anybody would need such a thing?\n\nIt can be useful when a call to some HTTP API takes a long time to answer the query (for ex. reading lots of data), but not so much to connect to the server.\nWith this new feature we can set bigger timeout and smaller connect_timeout, so network failures, dead API servers or DNS problems could be detected fast.\n\nOther use case is - write request gone bad.\nWe connected to the server, called PUT to create some new record and caught timeout while waiting for response. Some async APIs work so that your request was actually processed despite broken connection.\nAnd with two separate exceptions we can react differently in such a case - on ConnectionTimeout we know for sure nothing've been done so we can repeat the call. On OperationTimeout we may (or may not) poll the server for some indication that something is already going on and if not repeat the call.\n\nOn implementation:\n\nI've implemented this feature in a way that does not break expected behavior for an existing code using the library.\nNew exceptions - ConnectionTimeout and OperationTimeout are subclasses of existing Timeout class.\nSame goes for urllib3 TimeoutError and it's new subclasses.\n\nNew parameter connect_timeout is optional and when not given, value of the timeout parameter is used for both timeouts.\nNew HTTPConnectionTwo class (lame name, any suggestions?) takes one timeout in **init** method and then checks whether it's a single value or a pair, so it also can be initialized exactly like HTTPConnection.\n\nAnd thank you so much for the great library!\n## \n\nPasha Kirichenko\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 10,
        "changed_files": 6,
        "created_at": "2012-12-06T16:51:13Z",
        "closed_at": "2012-12-06T18:21:15Z",
        "merged_at": "2012-12-06T18:21:15Z",
        "body": "Per @kennethreitz's implied intent in 5c1bc201c46297d39d591e5d30e0e65a989bd22c, this change implements the Apache 2.0 license across requests, in every location I could find a license specified.\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-12-06T12:38:34Z",
        "closed_at": "2012-12-06T18:23:54Z",
        "merged_at": null,
        "body": "When trying to upload filename with non ASCII symbols (for example: \"\u0422\u0435\u0441\u0442\u043e\u0432\u044b\u0439 \u0444\u0430\u0439\u043b.txt\") I'm getting this exception:\n\n> > UnicodeDecodeError: 'ascii' codec can't decode byte 0xd0 in position 60: ordinal not in range(128)\n\nThis commit fixes this. \n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2012-12-04T18:16:41Z",
        "closed_at": "2012-12-05T01:34:20Z",
        "merged_at": "2012-12-05T01:34:20Z",
        "body": "Small one. Resolves issue #979.\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 57,
        "deletions": 44,
        "changed_files": 3,
        "created_at": "2012-12-03T00:06:27Z",
        "closed_at": "2012-12-03T06:51:53Z",
        "merged_at": null,
        "body": "In [RFC-5988](http://tools.ietf.org/html/rfc5988) link headers are allowed to specify multiple rels per link by separating them with a space\n\n```\nLink: </>;rel=\"rel1 rel2\"\n```\n\nIn addition, there can be multiple links with the same rel, which the current .links() implementation doesn't allow since it overwrites earlier links with later ones.\n\nThis patch adds both of those capabilities, and in addition changes the \"url\" tag to the \"href\" tag in order to align better with the RFCs terminology (because the link header derives from the link html tag, which uses href).\n\nSeveral of the regex's used are modified version of those from the mnot/redbot project.\n\nI added unit tests in the patch, but there are also some basic end to end tests [here](https://gist.github.com/4191608)\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 127,
        "deletions": 10,
        "changed_files": 3,
        "created_at": "2012-12-02T00:34:37Z",
        "closed_at": "2012-12-02T08:56:44Z",
        "merged_at": "2012-12-02T08:56:44Z",
        "body": "Fix for issue https://github.com/kennethreitz/requests/issues/875\n- Proxy is now also comes from the connection pool if keep-alive is enabled\n- Also contains tests to see if a connection is pooled or not\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2012-12-01T18:05:14Z",
        "closed_at": "2012-12-01T22:59:47Z",
        "merged_at": null,
        "body": "Hi Kenneth,\n\nI know you remain unconvinced about https://github.com/kennethreitz/requests/issues/769 etc., but I keep wanting to make my code simpler by writing this\n\n```\nrequests.post(url, json={...}).json\n```\n\nAnd I suspect I'm very much not alone. I'd like to start by maintaining a fork that is at least reasonably correct, if not good enough for inclusion. So, if you could poke some holes in my first stab at implementing this, I would appreciate it.\n\nThanks.\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-12-01T14:39:18Z",
        "closed_at": "2012-12-01T15:56:48Z",
        "merged_at": "2012-12-01T15:56:48Z",
        "body": "I renamed my Github account from @gwrtheyrn to @dbrgn.\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-11-28T03:14:53Z",
        "closed_at": "2012-11-28T16:40:09Z",
        "merged_at": "2012-11-28T16:40:09Z",
        "body": "Someone forgot a comma\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 13,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-11-26T18:30:24Z",
        "closed_at": "2012-11-26T20:26:39Z",
        "merged_at": "2012-11-26T20:26:39Z",
        "body": "I'm not sure what else could be added to satisfy #601. If this is sufficient,\nI suggest closing that.\n\nAlso, this is just a docs change, if Travis fails (since it seems backed up\nand I don't have the time to make sure this passes) it isn't my fault. ;)\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2012-11-25T16:21:34Z",
        "closed_at": "2012-11-25T19:20:29Z",
        "merged_at": null,
        "body": "I wanted to use requests to transfer a file chunk by chunk. However, before I transferred the body, I copied a header from the original response to the new response. Since request decodes gzip and deflate, the header was wrong and my content couldn't be interpreted by the browser.\n\nThis patch adds an option to `iter_content.` to disable decoding of gzip or deflate content.\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2012-11-25T02:49:27Z",
        "closed_at": "2012-11-25T03:54:29Z",
        "merged_at": "2012-11-25T03:54:29Z",
        "body": "Closes #223\n\nSorry this took so long.\n",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 22,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2012-11-24T21:44:17Z",
        "closed_at": "2012-11-26T08:40:27Z",
        "merged_at": "2012-11-26T08:40:27Z",
        "body": "This is an attempt to solve issue #910 (and hopefully #896 by association).\n\nThis solution is unlikely to cause a regression except in one specific case, where the form data _is_ urlencoded but doesn't have the correct Content-Type header set. If we think that's a likely scenario, I can go back and make the test for that case less restrictive. The flip side is that we will not mistakenly include data we shouldn't.\n\nThere aren't any tests for OAuth functionality in Requests, so I have no idea if this makes things worse or better. My local tests seem to suggest that everything is ok though, so let's assume it's all awesome. =D\n\nNB: I'm aware that we've moved the OAuth stuff to requests/requests-oauth. I'll raise an equivalent PR over there if we decide to use this one, but there are a few open issues here that make raising this PR here useful as well.\n\n@idan: Does this look right to you?\n@michaelhelmick: Does my branch resolve your issues?\n",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2012-11-24T14:26:21Z",
        "closed_at": "2012-11-26T08:30:49Z",
        "merged_at": "2012-11-26T08:30:49Z",
        "body": "Resolves Issue #882, Requests now functions with Python 3.1 (again!).\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 26,
        "deletions": 8,
        "changed_files": 5,
        "created_at": "2012-11-23T15:56:20Z",
        "closed_at": "2012-11-26T08:31:45Z",
        "merged_at": "2012-11-26T08:31:45Z",
        "body": "This fixes issue #888. That safe_mode doesn't work when doing requests from a Session instance.\n\nCould be fixed in a number of different ways of course, and if you don't like the way I've done it here, the failing test should still be useful.\n",
        "comments": 15
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 13,
        "changed_files": 1,
        "created_at": "2012-11-22T16:12:29Z",
        "closed_at": "2012-11-23T10:01:20Z",
        "merged_at": "2012-11-23T10:01:20Z",
        "body": "Adding a try/except block just masks any issues that are raised here, issues that the developer should definitely be made aware of.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-11-21T18:40:29Z",
        "closed_at": "2012-11-23T10:02:18Z",
        "merged_at": "2012-11-23T10:02:18Z",
        "body": "This will permit the deletion of just that one file in order\nto fall back to the [probably more accurate but less consistent]\nDistro provided CA certs.  \n\nI need to be able to add our internal CA and I don't want to have to patch your module every time I upgrade.  Personally, I think it is backwards to prefer your own CA certs with no good way to prefer\nthe OS/Distro provided certs.  I realize it makes your testing much easier since you have a known\nlist of certs.  Providing an environment override is a poor substitute to an actual API.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 68,
        "deletions": 5,
        "changed_files": 3,
        "created_at": "2012-11-18T12:09:48Z",
        "closed_at": "2012-11-23T10:03:28Z",
        "merged_at": "2012-11-23T10:03:28Z",
        "body": "This change is in response to issue #879.\n\nThe `no_proxy` environment variable is a pretty strange beast, so this code is a little less elegant than I'd like.\n\nI also concluded that the right place to handle it was in `get_environ_proxies()`, but it might be better to hoist some of this code out and handle it in `models.py`. If you think that's a better idea, let me know and I'll make the changes to do that instead.\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-11-17T13:01:56Z",
        "closed_at": "2012-11-23T10:04:21Z",
        "merged_at": "2012-11-23T10:04:21Z",
        "body": "This resolves Issue #883.\n\nAt least, it does on my box. We'll see what Travis says.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-11-16T23:06:11Z",
        "closed_at": "2012-11-17T11:03:33Z",
        "merged_at": "2012-11-17T11:03:33Z",
        "body": "Resolves issue #917.\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 69,
        "deletions": 45,
        "changed_files": 126,
        "created_at": "2012-11-16T13:46:12Z",
        "closed_at": "2012-11-27T18:32:58Z",
        "merged_at": null,
        "body": "Long short story again... This PR aims at fixing #916 and #918 while still keeping dependencies vendored (unlike in #929 where I had removed them)... So, what I did was to remove everything except `__init__.py` from the`packages` folder (which made up `requests.packages`) from inside \"requests\" and separate it into three packages inside the `dependencies` folder:\n- `dependencies/common`: This contains all the packages needed by **requests** and which work _both_ on PY2 and PY3 ( currently **urllib3** only ). It will be made into a package (`requests.packages.common`) by `setuptools`/`distutils` during installation via the `package_dir` instruction.\n- `dependencies/python2`: This contains PY2 specific packages ( currently **oauthlib** and **chardet** ). It will be made into a package (`requests.packages.environment`) during installation on PY2 (via the `package_dir` instruction).\n- `dependencies/python3`: This contains PY3 specific packages ( currently **chardet2** ). It will be made into a package (`requests.packages.environment`) during installation on PY3 (via the `package_dir` instruction).\n\nNext, I added a `recursive-include` targeting the `dependencies` folder, so that _all_ the packages get included when `sdist`ing (no matter what version of Python is used to do the actual packaging)... Finally I moved the `requests` source folder to `source/requests` to cheat `nose`'s test loader and force it to use the installed version instead. A few changes to the `Makefile` were also necessary, and that's all there's to it.\n\nI have tested this in every supported Python version and is working great (Travis CI says the same). If you want to test `pip` before merging I have uploaded a testing package of this precise version which installs flawlessly under Python2.6+.\n\n```\npip install requests-packaging-fixes\n```\n\n**Edit:** The problems described in #916 and #916 had been caused not by a change on `setup.py` (since there were none which could potentially have caused this) but due to the fact that 0.14.1 and 0.14.2 were packaged under different versions of Python. I could reproduce the current behaviour by checking-out both sources and packaging them with Python3 for 0.14.1 (this would include all vendored packages) and with Python2 for 0.14.2 (this would leave out **chardet2**). Weird, but true.\n",
        "comments": 10
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-11-13T15:45:44Z",
        "closed_at": "2012-11-15T10:11:55Z",
        "merged_at": "2012-11-15T10:11:55Z",
        "body": "In environment, where SIGCHILD interrupted (e.g. running code under gunicorn) \u2014 platform.system() and platform.release() causes `IOError: [Errno 10] No child processes`\n\nTail of the stacktrace in this case:\n\n```\nFile \"/Users/cleg/Projects/nimble-all/server/eggs/braintree-2.14.1-py2.7.egg/braintree/util/http_strategy/requests_strategy.py\", line 2, in <module>\n \u00a0 \u00a0import requests\n \u00a0File \"/usr/local/lib/python2.7/site-packages/requests/__init__.py\", line 53, in <module>\n \u00a0 \u00a0from .models import Request, Response\n \u00a0File \"/usr/local/lib/python2.7/site-packages/requests/models.py\", line 27, in <module>\n \u00a0 \u00a0from .defaults import SCHEMAS\n \u00a0File \"/usr/local/lib/python2.7/site-packages/requests/defaults.py\", line 34, in <module>\n \u00a0 \u00a0'User-Agent': default_user_agent(),\n \u00a0File \"/usr/local/lib/python2.7/site-packages/requests/utils.py\", line 546, in default_user_agent\n \u00a0 \u00a0'%s/%s' % (platform.system(), platform.release()),\n \u00a0File \"/usr/local/Cellar/python/2.7.3/Frameworks/Python.framework/Versions/2.7/lib/python2.7/platform.py\", line 1303, in release\n \u00a0 \u00a0return uname()[2]\n \u00a0File \"/usr/local/Cellar/python/2.7.3/Frameworks/Python.framework/Versions/2.7/lib/python2.7/platform.py\", line 1250, in uname\n \u00a0 \u00a0processor = _syscmd_uname('-p','')\n \u00a0File \"/usr/local/Cellar/python/2.7.3/Frameworks/Python.framework/Versions/2.7/lib/python2.7/platform.py\", line 1007, in _syscmd_uname\n \u00a0 \u00a0rc = f.close()\nIOError: [Errno 10] No child processes\n```\n\nI've implementer simple workaround to make this code workable in any circumstances. Maybe it's not the best solution in this case, but it does the trick. Maybe better add general error handling to whole  `default_user_agent` function. \n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 74,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2012-11-10T02:09:28Z",
        "closed_at": "2012-11-16T22:35:18Z",
        "merged_at": null,
        "body": "Adding support for NTLM authentication. Relies on https://github.com/bnoordhuis/python-ntlm.\n",
        "comments": 41
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2012-11-08T22:31:09Z",
        "closed_at": "2012-11-09T00:24:36Z",
        "merged_at": "2012-11-09T00:24:36Z",
        "body": "",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 70,
        "deletions": 19884,
        "changed_files": 117,
        "created_at": "2012-11-08T13:59:45Z",
        "closed_at": "2012-11-15T10:20:28Z",
        "merged_at": null,
        "body": "Long short story, the associated commit aims at fixing #916 by refactoring the setup script and moving dependencies out of the package itself... These are now downloaded from PyPI whenever necessary before installation (via `install_requires`) while keeping compatibility with Python 2 and Python 3 in the same codebase (`chardet` is now resolved via two external requirements file).\n\nThe only downside of this is that one cannot import `requests` in `setup.py` (since that would require importing `charder`, which is not available at that time). Thus, the version is repeated both in `setup.py` and `requests/__init__.py`. I'll have a go at that once I find some more time, but for now this seems like acceptable for me.\n\n**Note:** The package's version had been kept as `0.14.1` in the previous release. I decided to amend that to `0.14.2` instead of `0.14.3.dev0` or something like that, since maybe @kennethreitz wants to manage that himself. :-)\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 28,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2012-11-03T20:08:12Z",
        "closed_at": "2012-11-15T10:13:30Z",
        "merged_at": "2012-11-15T10:13:30Z",
        "body": "It wasn't utf-8 encoding strings in values that are iterable but not a list.\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 10,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2012-10-30T21:22:23Z",
        "closed_at": "2012-11-23T10:05:18Z",
        "merged_at": null,
        "body": "r.raise_for_status and r.ok should not report success when response has wonky data. this occurs when you use grequests and the greenlet encounters problems (timeout, etc)\n\n``` python\nimport grequests\nurls = [grequests.get('http://google.com/?q={}'.format(n), timeout=.001) for n in range(3)]\nresponses = grequests.map(urls, size=2)\nprint '# responses={}'.format(len(responses))\nfor r in responses:\n    print 'status_code={}; ok={}; error={}'.format(r.status_code, r.ok, r.error)\n    r.raise_for_status()\n```\n\n```\nTraceback (most recent call last):\n  File \"/Users/darrell/.virtualenvs/clarence/lib/python2.7/site-packages/gevent/greenlet.py\", line 390, in run\n    result = self._run(*self.args, **self.kwargs)\n  File \"/Users/darrell/.virtualenvs/clarence/lib/python2.7/site-packages/requests/models.py\", line 631, in send\n    raise ConnectionError(sockerr)\nConnectionError: [Errno 65] No route to host\n<Greenlet at 0x1013f2c30: <bound method Request.send of <Request [GET]>>(prefetch=True)> failed with ConnectionError\n\nTraceback (most recent call last):\n  File \"/Users/darrell/.virtualenvs/clarence/lib/python2.7/site-packages/gevent/greenlet.py\", line 390, in run\n    result = self._run(*self.args, **self.kwargs)\n  File \"/Users/darrell/.virtualenvs/clarence/lib/python2.7/site-packages/requests/models.py\", line 631, in send\n    raise ConnectionError(sockerr)\nConnectionError: [Errno 65] No route to host\n<Greenlet at 0x1013f2af0: <bound method Request.send of <Request [GET]>>(prefetch=True)> failed with ConnectionError\n\nTraceback (most recent call last):\n  File \"/Users/darrell/.virtualenvs/clarence/lib/python2.7/site-packages/gevent/greenlet.py\", line 390, in run\n    result = self._run(*self.args, **self.kwargs)\n  File \"/Users/darrell/.virtualenvs/clarence/lib/python2.7/site-packages/requests/models.py\", line 631, in send\n    raise ConnectionError(sockerr)\nConnectionError: [Errno 65] No route to host\n<Greenlet at 0x1013f27d0: <bound method Request.send of <Request [GET]>>(prefetch=True)> failed with ConnectionError\n\n# responses=3\nstatus_code=None; ok=True; error=None\nstatus_code=None; ok=True; error=None\nstatus_code=None; ok=True; error=None\n```\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2012-10-30T15:32:53Z",
        "closed_at": "2012-11-08T06:08:33Z",
        "merged_at": "2012-11-08T06:08:33Z",
        "body": "While installing `requests` using the `python setup.py --quiet install` command, I noticed the following warnings:\n\n```\nwarning: no files found matching 'tests/*.'\nzip_safe flag not set; analyzing archive contents...\nrequests.certs: module references __file__\n```\n\nAfter a bit of digging I found out that the first of those had to do with the `tests/*.` (notice the dot) pattern used in `MANIFEST.in`, so that I corrected it in the second of the associated commits. The other two messages (the last of which is the reasoning behind the choice) show that the package is not [\"zip-safe\"](http://bit.ly/PjdL9X), so that I added the `zip_safe=False` flag to the `setup.py` file in the first of the associated commits.\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 33,
        "deletions": 2,
        "changed_files": 3,
        "created_at": "2012-10-27T16:58:18Z",
        "closed_at": "2012-11-23T10:05:53Z",
        "merged_at": null,
        "body": "We ran in to this issue where IRIs convert to URIs (through Django's iri_to_uri) would blow up in requests.\n\nThe issues seems to be when IRIs are converted to URIs they are percent-quote encoded, and when requests processes it with IDNA, it blows up because the URL components exceed 64 characters (since now it's three characters per actual character at least). However, they are valid URLs because they may encode to fewer than 64 characters in IDNA.\n\nThe solution is to reverse the percent-quote encoding, and then re-encode with IDNA.\n\nUpdate: Solved merge conflict\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 33,
        "deletions": 2,
        "changed_files": 3,
        "created_at": "2012-10-26T22:12:18Z",
        "closed_at": "2012-10-27T15:01:58Z",
        "merged_at": null,
        "body": "We ran in to this issue where IRIs convert to URIs (through Django's `iri_to_uri`) would blow up in requests.\n\nThe issues seems to be when IRIs are converted to URIs they are percent-quote encoded, and when requests processes it with IDNA, it blows up because the URL components exceed 64 characters (since now it's three characters per actual character at least). However, they are valid URLs because they may encode to fewer than 64 characters in IDNA.\n\nThe solution is to reverse the percent-quote encoding, and then re-encode with IDNA.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 127,
        "deletions": 1,
        "changed_files": 4,
        "created_at": "2012-10-25T15:47:38Z",
        "closed_at": "2012-10-27T15:02:55Z",
        "merged_at": "2012-10-27T15:02:55Z",
        "body": "Here's a proposed fix for issue #765.\n\nWhen requesting JSON data for a response with no encoding specified, detect the encoding from `self.content` using a custom UTF encoding detector that uses knowledge about JSON to make an educated guess as to the encoding used.\n\nIf no encoding could be determined, decoding fails, or the JSON decoding fails, fall back to `self.text` and `chardet` guessing.\n\nTests included, tested on python 2.6, 2.7, 3.1, 3.2, 3.3. All code PEP-8 and pyflakes clean.\n",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2012-10-23T06:23:34Z",
        "closed_at": "2012-10-23T14:26:09Z",
        "merged_at": null,
        "body": "See #889 for motivation.\n\nMy understanding is that this was added in order to fix tests, which were trying to POST `__file__` and failing on the second run, once `__file__` began to refer to a .pyc instead of a .py?\n\nIt looks like postbin/httpbin no longer choke on .pyc files, so we should be able to omit this.\n\ncc @sigmavirus24\n",
        "comments": 34
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2012-10-22T22:04:01Z",
        "closed_at": "2012-10-22T23:49:15Z",
        "merged_at": "2012-10-22T23:49:15Z",
        "body": "compat.py: relevant imports added\nutils.py: then those imports are imported here.\n\nNothing else was changed, but I saw mentions of quoting later in\nutils.py but I wasnt sure what to do about that.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2012-10-19T19:18:54Z",
        "closed_at": "2012-10-21T15:52:03Z",
        "merged_at": "2012-10-21T15:52:03Z",
        "body": "Make value of Contents-Encoding header case insensitive per RFC 2616.\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 31,
        "deletions": 9,
        "changed_files": 3,
        "created_at": "2012-10-19T18:01:07Z",
        "closed_at": "2012-10-23T14:30:11Z",
        "merged_at": null,
        "body": "This also acts as a workaround for #827, which in some cases, if you are\nconnecting to an SSL server that does not support SSLv2 or SSLv3 (and,\nfor exapmle, only supports TLSv1), would cause an illegal EOL SSL error.\nIf you select the right SSL protocol version, you won't see this error.\n\nKenneth, it looks like you tried to fix this in a previous revision by hard-coding the SSL version, and then you rolled it back.  This makes it configurable via parameter to requests.requesttype()\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 41,
        "deletions": 40,
        "changed_files": 2,
        "created_at": "2012-10-18T19:28:07Z",
        "closed_at": "2012-10-20T12:37:57Z",
        "merged_at": "2012-10-20T12:37:57Z",
        "body": "-- the incetive for this being that with self.assertEqual you get an\nerror message if the test fails\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 141,
        "deletions": 89,
        "changed_files": 8,
        "created_at": "2012-10-16T20:59:48Z",
        "closed_at": "2012-11-27T18:32:58Z",
        "merged_at": null,
        "body": "Let's not wait for urllib3 for this.\n\nhttp://kennethreitz.com/the-future-of-python-http.html\n- Requests would ship with HTTP and HTTPS TransportAdapters.\n- Take the current urllib3 integration and move it into said adapters.\n\nAs far as I can tell, we'd need two types of Adapters:\n- Connections\n- Requests/Responses\n\nPerhaps we could just have a connection adapter, which is akin to a Requests' Session.\n",
        "comments": 17
    },
    {
        "merged": false,
        "additions": 27,
        "deletions": 14,
        "changed_files": 1,
        "created_at": "2012-10-16T19:39:10Z",
        "closed_at": "2012-10-17T14:19:22Z",
        "merged_at": null,
        "body": "Based on content-length divided by chunk_size.\n\nKind of a rough commit, more for the idea or anything else.\n\nOther options would be to make a new release of clint, or create a generator class to wrap iter_content in application code.\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 26,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2012-10-15T18:30:47Z",
        "closed_at": "2012-10-15T20:07:15Z",
        "merged_at": null,
        "body": "This adds an [EditorConfig file](http://editorconfig.org) to denote code style for `*.py` and `*.rst` files.  This EditorConfig file is a human and machine readable code style guide.  Currently EditorConfig files can be read by various text editors/IDEs using plugins.\n\nThis EditorConfig file correctly reflects your code style except for the following errors which were revealed by an EditorConfig checker [I'm developing](https://github.com/treyhunner/editorconfig-tools):\n\n```\ndocs/community/support.rst: No final newline found\ndocs/dev/authors.rst: No final newline found\ndocs/_themes/README.rst: Tab indentation found\ndocs/conf.py: No final newline found\nrequests/packages/oauthlib/common.py: Trailing whitespace found\nrequests/packages/oauthlib/oauth1/rfc5849/signature.py: Trailing whitespace found\n```\n\nAll of the above errors except for the last two (in `requests/packages`) would be resolved by #892.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 8,
        "changed_files": 4,
        "created_at": "2012-10-15T18:25:24Z",
        "closed_at": "2012-10-15T19:55:51Z",
        "merged_at": "2012-10-15T19:55:51Z",
        "body": "This fixes the following code style issues in all `*.rst` and `*.py` files outside of `requests/packages`:\n- use 4 spaces for indentation (not tabs)\n- trim trailing whitespace from the ends of lines\n- insert a final newline in every file (except for completely empty ones)\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 79,
        "deletions": 34,
        "changed_files": 16,
        "created_at": "2012-10-08T21:44:44Z",
        "closed_at": "2012-10-17T14:20:55Z",
        "merged_at": "2012-10-17T14:20:55Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 19,
        "deletions": 7,
        "changed_files": 3,
        "created_at": "2012-10-08T09:21:19Z",
        "closed_at": "2012-10-17T14:21:40Z",
        "merged_at": "2012-10-17T14:21:40Z",
        "body": "When I post files with CJK parameters I got this exception:\n\n```\nTraceback (most recent call last):\n  File \"/home/everbird/code/requests/tests/test_requests.py\", line 358, in test_POSTBIN_GET_POST_FILES_WITH_CJK_PARAMS\n    data={'some': '\u4e2d\u6587'})\n  File \"/home/everbird/code/requests/requests/api.py\", line 98, in post\n    return request('post', url, data=data, **kwargs)\n  File \"/home/everbird/code/requests/requests/safe_mode.py\", line 39, in wrapped\n    return function(method, url, **kwargs)\n  File \"/home/everbird/code/requests/requests/api.py\", line 51, in request\n    return session.request(method=method, url=url, **kwargs)\n  File \"/home/everbird/code/requests/requests/sessions.py\", line 241, in request\n    r.send(prefetch=prefetch)\n  File \"/home/everbird/code/requests/requests/models.py\", line 529, in send\n    (body, content_type) = self._encode_files(self.files)\n  File \"/home/everbird/code/requests/requests/models.py\", line 365, in _encode_files\n    new_fields.append((field, str(val)))\nUnicodeDecodeError: 'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128)\n```\n\nFor py2, `str` is actually `unicode` according to `requests/compat.py`. It is OK like this:\n\n``` python\nIn [1]: str('a')\nOut[1]: 'a'\n\nIn [2]: unicode('a')\nOut[2]: u'a'\n```\n\nbut it failed as below:\n\n``` python\nIn [3]: str('\u4e2d\u6587')\nOut[3]: '\\xe4\\xb8\\xad\\xe6\\x96\\x87'\n\nIn [4]: unicode('\u4e2d\u6587')\n---------------------------------------------------------------------------\nUnicodeDecodeError                        Traceback (most recent call last)\n<ipython-input-4-a7400b671605> in <module>()\n----> 1 unicode('\u4e2d\u6587')\n\nUnicodeDecodeError: 'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128)\n```\n\nIn `requests/models.py` at line 363-365 the `str()` seems should be the builtin `str`, not `unicode`. So I wrote a test named `test_POSTBIN_GET_POST_FILES_WITH_CJK_PARAMS` and fixed it.\n\nHope it helps. \n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 18,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2012-10-01T22:51:12Z",
        "closed_at": "2012-10-02T00:05:42Z",
        "merged_at": null,
        "body": "Don't know if this is worth it, but it helps me on a project I'm working on.  It's a little nicer than handling the cookie object directly.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2012-10-01T17:13:58Z",
        "closed_at": "2012-10-01T18:15:48Z",
        "merged_at": "2012-10-01T18:15:48Z",
        "body": "Prior to this, you could sneak a list of anything to register_hook and it\nwould accept it. This will check if the items in the list are callable before\nregistering them. Also added a regression test to make sure if this gets\nchanged it will be noticed.\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2012-10-01T00:26:06Z",
        "closed_at": "2012-10-01T16:52:32Z",
        "merged_at": "2012-10-01T16:52:32Z",
        "body": "Since you can iterate over a cookiejar, this is simpler and more efficient than using nested for loops.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2012-09-29T22:36:24Z",
        "closed_at": "2012-10-01T17:26:59Z",
        "merged_at": "2012-10-01T17:26:59Z",
        "body": "`httplib.cookiejar.DefaultCookiePolicy` changed its implementation of function `set_ok_verifiability` in Python 3.3\n\nIt now checks `request.unverifiable` instead of `request.is_unverifiable()`\n",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-09-25T22:36:15Z",
        "closed_at": "2012-10-01T16:53:56Z",
        "merged_at": "2012-10-01T16:53:56Z",
        "body": "If encoding is None, decoding will throw the following TypeError:\n\n```\n  File \"/home/env/local/lib/python2.7/site-packages/requests-0.14.0-py2.7.egg/requests/models.py\", line 825, in text\n    content = str(self.content, encoding, errors='replace')\nTypeError: unicode() argument 2 must be string, not None\n\n```\n\nIf this is the case, attempt to run without any set encoding\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 8,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2012-09-24T16:03:04Z",
        "closed_at": "2012-09-26T20:37:38Z",
        "merged_at": null,
        "body": "headers = {'Content-Length': 0}\n\nAlso add regression test.\n\nFixes #865.\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 38,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2012-09-20T15:48:00Z",
        "closed_at": "2012-09-23T01:49:19Z",
        "merged_at": "2012-09-23T01:49:19Z",
        "body": "Sorry for the delay on this.\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2012-09-13T15:12:12Z",
        "closed_at": "2012-09-17T17:23:57Z",
        "merged_at": null,
        "body": "I think it should be okay to use response headers for content length, falling back on len(response.content) if they aren't provided. I tested this against httpbin('stream') and it seems okay. #854\n",
        "comments": 8
    },
    {
        "merged": false,
        "additions": 31,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2012-09-11T19:42:14Z",
        "closed_at": "2012-09-12T17:50:03Z",
        "merged_at": null,
        "body": "Redone pull for fixing proxies using empty proxies as if they are real.\n\nI.e.: if you had this set up:\n\n``` python\nproxy = {\"https\" : \"\"}\n```\n\nRequests would try to connect via empty proxy (\"\") instead of through a regular connection.\n",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-09-11T12:40:15Z",
        "closed_at": "2012-09-12T17:58:20Z",
        "merged_at": "2012-09-12T17:58:20Z",
        "body": "Cut the fat... rebased.\nRelated to #843\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-09-10T05:49:22Z",
        "closed_at": "2012-09-11T03:03:35Z",
        "merged_at": null,
        "body": "no_proxies not use full URLs.\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 52,
        "deletions": 1,
        "changed_files": 3,
        "created_at": "2012-09-07T01:20:11Z",
        "closed_at": "2012-09-11T03:03:23Z",
        "merged_at": null,
        "body": "'NoneType' object is not iterable\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2012-09-06T23:33:28Z",
        "closed_at": "2012-09-07T07:10:21Z",
        "merged_at": "2012-09-07T07:10:21Z",
        "body": "After #831, the tests added in #764 (which relied on iter_content()\ncrashing if the response was prefetched) no longer tested what they\nwere intended to test.\n\nTest-only change, no expected changes in functionality.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2012-09-06T14:24:29Z",
        "closed_at": "2012-09-11T03:15:43Z",
        "merged_at": "2012-09-11T03:15:43Z",
        "body": "Fixes #839.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-09-06T14:17:06Z",
        "closed_at": "2012-09-07T07:06:51Z",
        "merged_at": "2012-09-07T07:06:51Z",
        "body": "I was tripped up when playing around with streaming APIs by the non-inclusion of the prefetch=False parameter in the documentation's example.\n\nI see that the default value of prefetch was changed in v 0.13.6, so this is probably just a hangover of that change.\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 17,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2012-09-04T22:31:11Z",
        "closed_at": "2012-09-09T09:32:43Z",
        "merged_at": null,
        "body": "See http://bugs.python.org/issue3819 for a discussion\non a similar change in urllib2\n",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 11,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-09-04T06:58:52Z",
        "closed_at": "2012-09-11T03:04:45Z",
        "merged_at": null,
        "body": "Take #4.\nThanks @sigmavirus24\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 11,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2012-09-03T08:19:14Z",
        "closed_at": "2012-09-04T06:59:22Z",
        "merged_at": null,
        "body": "Replaces #834 and #823. We can do this ;)\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 61,
        "deletions": 48,
        "changed_files": 5,
        "created_at": "2012-09-03T03:13:19Z",
        "closed_at": "2012-09-11T03:05:07Z",
        "merged_at": "2012-09-11T03:05:07Z",
        "body": "Use dicts and lists where necessary but accept both dicts and lists of\n2-tuples everywhere.\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 26,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2012-09-01T02:12:32Z",
        "closed_at": "2012-09-11T03:05:51Z",
        "merged_at": null,
        "body": "This is for commit https://github.com/SecurityForUs/requests/commit/e35e561a55f4223b4b69312c01677042a854327c\n\nCurrently if you pass proxy settings like this:\n\n``` python\nproxy = {\"https\" : \"\"}\nreq = requests.get(\"http://www.google.com\", proxies=proxy)\n```\n\nThe request will be sent through an empty proxy (\"\").  Every request will return a 404 since it cannot connect to a non-existent proxy.  While I know there should be error checking for this on the developer's side, I thought it would be helpful to pass along a fix to this as well.\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2012-08-31T22:10:35Z",
        "closed_at": "2012-08-31T23:49:18Z",
        "merged_at": null,
        "body": "When prefetch = True (by default in 0.13.9) it causes iter_\\* functions (i.e.: iter_content() & iter_lines()) to fail with the raised error stating the content has already been consumed.\n\nI specified it as 'False' for default so such functions can work.  There is not a lot of information on how to fix the issue (with the GitHub links stating the issue is fixed when it really isn't).  For people who don't know the inner workings of Request it can be very discouraging.\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 14,
        "changed_files": 1,
        "created_at": "2012-08-30T17:33:54Z",
        "closed_at": "2012-08-31T23:49:47Z",
        "merged_at": "2012-08-31T23:49:47Z",
        "body": "The default for prefetch changed in 0.13.6 so have updated the relevant section in the docs.  Anything amis?  Not sure if you'd rather alter the default instead although I'd say defaulting to True sounds sensible.\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 12,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2012-08-30T08:50:11Z",
        "closed_at": "2012-08-30T12:45:56Z",
        "merged_at": null,
        "body": "So one can do: requests.get(\"http://foobar.com\", prefetch=False).save_as(\"/tmp/foobar.com.html\")\nWill add it to the 'advanced docs' if this is accepted.\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 40,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2012-08-30T08:48:40Z",
        "closed_at": "2012-08-31T23:51:25Z",
        "merged_at": null,
        "body": "iter_content() doesn't work with requests with prefetch=True, which makes sense, but a warning might help.\n",
        "comments": 9
    },
    {
        "merged": false,
        "additions": 11,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2012-08-30T08:47:14Z",
        "closed_at": "2012-08-30T12:46:39Z",
        "merged_at": null,
        "body": "There was no test for iter_content.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 16,
        "deletions": 15,
        "changed_files": 2,
        "created_at": "2012-08-29T19:29:28Z",
        "closed_at": "2012-09-11T03:06:53Z",
        "merged_at": "2012-09-11T03:06:53Z",
        "body": "I discovered this bug when using the auth.OAuth1 auth provider. If I did a simple\n\n``` python\noauth = OAuth1(key,secret,signature_type=SIGNATURE_TYPE_BODY)\nrequests.post(url, data={'some':'param'}, auth=oauth)\n```\n\nonly the data <code>{'some':'param'}</code> gets transmitted, all the OAuth specific parameters aren't packed into the body.\n\nMy patch moves the data encoding after the calling into the auth provider.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 25,
        "deletions": 24,
        "changed_files": 1,
        "created_at": "2012-08-28T04:55:03Z",
        "closed_at": "2012-08-29T11:29:42Z",
        "merged_at": "2012-08-29T11:29:42Z",
        "body": "Sorry, it's me again.\n\nauth.py still have problems. POST with data can't be signed correctly. So i dive into the code and rewrite it.\n\nAnd in fact, there's no \"multipart/form-encoded\" but only \"multipart/form-data\".\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 29,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2012-08-27T23:36:56Z",
        "closed_at": "2012-08-28T05:38:47Z",
        "merged_at": "2012-08-28T05:38:47Z",
        "body": "Yay, I had to nuke my branch to get here, but here's the improved docstring :-)\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 19,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2012-08-27T21:26:03Z",
        "closed_at": "2012-08-28T05:45:46Z",
        "merged_at": null,
        "body": "Otherwise, it's tricky for clients to write code that adds params without them poking inside the innards of `Session`, which can be problematic when the implementation changes.\n\nThis was motivated by the fact that I just ran some code of mine that depends on requests and it failed, because my virtualenv had a newer version of requests (0.13.9) and the code was written against 0.13.1 and had code that looked like this:\n\n``` python\nself.session.params['access_token'] = response_obj['access_token']\n```\n\nI do this to add an `access_token` parameter after the user logs in and obtains an access token, because this parameter is needed on subsequent requests after the login.\n\nThis worked in 0.13.1, because in 0.13.1, `session.params` was a dict, but it is now a list of tuples. The problem arises because there was no public interface for setting params and because this is Python, one can manipulate the attributes of the class whenever they desire. When the implementation changes, this breaks code that relies on that implementation.\n\nSo I propose to add a `add_params` method to `Session`, which is the official interface for clients to use to add parameters and it can change in the future if the implementation changes and clients code will still work.\n\nI guess this is all a really long way of saying...abstraction :-)\n",
        "comments": 13
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2012-08-23T06:20:47Z",
        "closed_at": "2012-08-25T04:48:30Z",
        "merged_at": "2012-08-25T04:48:30Z",
        "body": "os was imported twice.\n\nNot much of a change. Tests worked A-Ok\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2012-08-22T21:35:59Z",
        "closed_at": "2012-08-25T14:35:06Z",
        "merged_at": "2012-08-25T14:35:06Z",
        "body": "This pull request resolves the discussion in #378 by preventing None values from being posted.\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 16,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2012-08-21T14:40:05Z",
        "closed_at": "2012-08-25T14:35:37Z",
        "merged_at": null,
        "body": "I added support for custom mimetypes in mutipart request.\n\nUsage:\nr = requests.post(url, files={'file': ('file.xml', file_content)})\nor\nr = requests.post(url, files={'file': ('file.xml', file_content, 'text/xml')})\nor\nr = requests.post(url, files={'file': ('file.xml', file_content, 'application/xml')})\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-08-20T09:19:04Z",
        "closed_at": "2012-08-25T14:41:15Z",
        "merged_at": "2012-08-25T14:41:15Z",
        "body": "Fix kennethreitz/requests#790\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2012-08-20T02:53:22Z",
        "closed_at": "2012-08-20T05:38:39Z",
        "merged_at": "2012-08-20T05:38:39Z",
        "body": "When attempting to request (get or post) to a resource responding only to SSL version 3, we'd get the following response on Ubuntu 12.04:  \n\n```\n\n>>> import requests\n>>> requests.post(\"https://sis-portal-prod.uttyler.edu/psp/TAPPRD/EMPLOYEE/EMPL/?&cmd=login\")\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"requests/api.py\", line 98, in post\n    return request('post', url, data=data, **kwargs)\n  File \"requests/safe_mode.py\", line 39, in wrapped\n    return function(method, url, **kwargs)\n  File \"requests/api.py\", line 51, in request\n    return session.request(method=method, url=url, **kwargs)\n  File \"requests/sessions.py\", line 243, in request\n    r.send(prefetch=prefetch)\n  File \"requests/models.py\", line 630, in send\n    raise SSLError(e)\nrequests.exceptions.SSLError: [Errno 1] _ssl.c:504: error:1407742E:SSL routines:SSL23_GET_SERVER_HELLO:tlsv1 alert protocol version\n\n```\n\nThere's a [good number of people](http://www.google.com/search?q=python+error%3A1407742E%3ASSL+routines%3ASSL23_GET_SERVER_HELLO%3Atlsv1+alert+protocol+version&sugexp=chrome,mod=8&sourceid=chrome&ie=UTF-8) having the error. \n\nFix taken from [this thread](http://bugs.python.org/issue11220). Specs pass. Even if you don't accept this into master, hopefully someone will see this pull request on Google. \n",
        "comments": 22
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2012-08-19T20:40:47Z",
        "closed_at": "2012-08-20T07:55:17Z",
        "merged_at": "2012-08-20T07:55:17Z",
        "body": "There's an important fix in the code that I found when Travis ran the tests after the first commit in this PR. It was a mistake I made in not keeping my naming consistent.\n\nRelated to #795\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-08-18T20:24:45Z",
        "closed_at": "2012-08-18T21:32:48Z",
        "merged_at": "2012-08-18T21:32:48Z",
        "body": "Addresses #792.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 106,
        "deletions": 53,
        "changed_files": 5,
        "created_at": "2012-08-18T17:50:27Z",
        "closed_at": "2012-08-18T22:54:49Z",
        "merged_at": "2012-08-18T22:54:49Z",
        "body": "Accept lists of `(key, val)` tuples everywhere.\n\nThis should close/solve issue #179. Unfortunately @jkbr had duplicated some of the effort so I had to remove his contributions there, but all the tests pass.\n\nAlso, I apologize in advance for the likely very ugly history. I wanted to keep up-to-date while working on this so there are a few (possibly unnecessary) merge commits.\n",
        "comments": 11
    },
    {
        "merged": true,
        "additions": 92,
        "deletions": 74,
        "changed_files": 2,
        "created_at": "2012-08-18T05:41:58Z",
        "closed_at": "2012-08-19T00:42:41Z",
        "merged_at": "2012-08-19T00:42:41Z",
        "body": "Fixes issues described in #788.\n\nAlso extended the digest test case to do two requests with digest auth and check the history length to confirm the second one is zero (ie no second 401).\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-08-17T10:16:02Z",
        "closed_at": "2012-08-17T20:47:47Z",
        "merged_at": "2012-08-17T20:47:47Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 67,
        "deletions": 47,
        "changed_files": 17,
        "created_at": "2012-08-16T22:14:11Z",
        "closed_at": "2012-08-17T20:57:01Z",
        "merged_at": "2012-08-17T20:57:01Z",
        "body": "These are generally only whitespace fixes. I excluded the `packages` directory for now. Let me know if you want that code cleaned up also. \n\nI can do other PEP8 fixes if interested; unused imports, one import per line for different modules, etc.\n\n=)\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 35,
        "deletions": 35,
        "changed_files": 6,
        "created_at": "2012-08-16T20:26:44Z",
        "closed_at": "2012-08-17T20:59:29Z",
        "merged_at": "2012-08-17T20:59:29Z",
        "body": "I don't think there is a reason for the leading underscore in this section of documentation, but if there is, this pull request can be ignored, or used to clarify the documentation. \n",
        "comments": 13
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2012-08-16T07:11:56Z",
        "closed_at": "2012-09-02T08:44:20Z",
        "merged_at": null,
        "body": "This allows iter_content and iter_lines to succeed without\ncrashing even after the response content has been fetched\n(iter_content gives you a one-item iterator containing the\ncontent).\n\nIt should mitigate the API break I introduced in #760 (as discussed on #775 and #597).\n",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 7,
        "changed_files": 2,
        "created_at": "2012-08-15T23:31:56Z",
        "closed_at": "2012-09-11T03:07:09Z",
        "merged_at": null,
        "body": "Very minor change, but thought I'd submit anyway.  Figured 3 less LOC might be considered a contribution. :)\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-08-15T17:20:03Z",
        "closed_at": "2012-08-19T00:40:53Z",
        "merged_at": "2012-08-19T00:40:53Z",
        "body": "This should fix the issue in #776.\n\nAny unit test for this problem requires either the existence of a proxy to test against or the using of some pretty gnarly test hooks. You want it anyway?\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2012-08-14T23:13:40Z",
        "closed_at": "2012-08-19T00:41:23Z",
        "merged_at": null,
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2012-08-10T16:49:52Z",
        "closed_at": "2012-08-13T21:14:19Z",
        "merged_at": "2012-08-13T21:14:19Z",
        "body": "I'm not super invested in this: I think the UnicodeError is reasonably clear, but it probably helps to throw a Requests based exception when there is an error in the URL. The InvalidURL exception subclasses ValueError, which means anyone catching this by looking for ValueErrors will still catch this exception.\n\nThat said, you might just want to keep throwing the Unicode Error.\n\n(Inspired by me really wanting to close #697.)\n",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 41,
        "deletions": 6,
        "changed_files": 2,
        "created_at": "2012-08-10T13:50:12Z",
        "closed_at": "2012-08-10T16:05:08Z",
        "merged_at": "2012-08-10T16:05:08Z",
        "body": "My first run at dealing with #524 and #527. Let me know what you think of the changes and if you want me to take a different approach with some or all of it.\n\nI've set the Compliance section up so that it is easily expanded if/when you want to document other compliance cases.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 18,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2012-08-08T18:58:42Z",
        "closed_at": "2012-08-08T20:23:10Z",
        "merged_at": "2012-08-08T20:23:10Z",
        "body": "On connection refused, requests recently started throwing lower-level socket.error exceptions instead of ConnectionError, which does not match the API docs and breaks existing code. I reported this here: https://github.com/kennethreitz/requests/issues/748\n\nI believe the following commit introduced this bug: https://github.com/kennethreitz/requests/commit/e02fb2eb6c2acfa67793a2c77a3c7bd47998a024\n\nThis pull request simply catches socket.error in Request.send, and re-raises ConnectionError\n\nIt also adds two (now passing) unit tests, based on existing ones that are commented out (I left them untouched).\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 26,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2012-08-08T12:40:01Z",
        "closed_at": "2012-08-08T20:18:40Z",
        "merged_at": "2012-08-08T20:18:40Z",
        "body": "This should provide the functionality requested in #423. This does _not_ implement schema-less URLs, and if we want that it should be filed as a separate issue.\n\nI've tested with `furl` on Python 2.7, and this seems to work fine.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2012-08-06T16:42:59Z",
        "closed_at": "2012-08-06T21:05:22Z",
        "merged_at": "2012-08-06T21:05:22Z",
        "body": "Resolves #759.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 2,
        "changed_files": 3,
        "created_at": "2012-08-04T03:22:06Z",
        "closed_at": "2012-08-04T15:39:25Z",
        "merged_at": "2012-08-04T15:39:25Z",
        "body": "Fixes kennethreitz/requests#747.\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 55,
        "deletions": 8,
        "changed_files": 4,
        "created_at": "2012-08-03T20:04:38Z",
        "closed_at": "2012-08-08T20:24:03Z",
        "merged_at": null,
        "body": "",
        "comments": 14
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-08-02T11:19:14Z",
        "closed_at": "2012-08-02T20:53:06Z",
        "merged_at": "2012-08-02T20:53:06Z",
        "body": "This should resolve Issue #750. No explicit test in this pull request, let me know if you want one.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 77,
        "deletions": 21,
        "changed_files": 3,
        "created_at": "2012-07-27T15:17:21Z",
        "closed_at": "2012-08-11T06:30:21Z",
        "merged_at": "2012-08-11T06:30:21Z",
        "body": "- Properly handle repeated data fields for multipart/form-data requests (#737)\n- Allow a list of 2-tuples as the `files` agument.\n- Consistently serialize lists a of parameters (#729).\n- Use BytesIO for bytes.\n",
        "comments": 16
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 15,
        "changed_files": 1,
        "created_at": "2012-07-27T11:19:54Z",
        "closed_at": "2012-07-31T01:13:17Z",
        "merged_at": "2012-07-31T01:13:17Z",
        "body": "AWS S3 authentication adds content type header (when it exist) to\ncanonical string that is signed. Since it is set after authentication\nis done authentication on S3 fails\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 18232,
        "deletions": 3,
        "changed_files": 80,
        "created_at": "2012-07-26T07:11:58Z",
        "closed_at": "2012-07-27T05:28:35Z",
        "merged_at": null,
        "body": "...in the request URL params all being doubled (and the URL doesn't need to be updated based on the signing anyway)\n\nThis was noticed when attempting a file upload OAuth1a request to PyPI - the params were all doubled-up when performing POST with URL params (the only way to do OAuth1a file upload AFAIK.)\n\nI don't believe the OAuth signing should ever modify they URL so I believe this modification is safe.\n",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-07-25T16:41:39Z",
        "closed_at": "2012-07-27T05:29:18Z",
        "merged_at": "2012-07-27T05:29:18Z",
        "body": "This commit fixes #498, at least in the Python 2.7 environment on Appengine.\nVerified that it works on appengine.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2012-07-21T17:14:04Z",
        "closed_at": "2012-07-27T05:29:58Z",
        "merged_at": "2012-07-27T05:29:58Z",
        "body": "This _should_ resolve issue #735. I'd love it if someone could run a test on a Windows box, as I don't have easy access to one at the minute.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2012-07-20T18:35:00Z",
        "closed_at": "2012-07-24T13:46:35Z",
        "merged_at": "2012-07-24T13:46:35Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2012-07-18T10:59:45Z",
        "closed_at": "2012-07-18T14:44:37Z",
        "merged_at": "2012-07-18T14:44:37Z",
        "body": "If python support < 2.6 is required, will need to make this import conditional\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2012-07-14T22:30:26Z",
        "closed_at": "2012-07-27T05:33:51Z",
        "merged_at": "2012-07-27T05:33:51Z",
        "body": "Co-Authored By: Timnit Gebru tgebru@gmail.com @tgebru\nCo-Authored By: Sarah Gonzalez smar.gonz@gmail.com @smargonz\nCo-Authored By: Leila Muhtasib muhtasib@gmail.com @muhtasib\n\nThis is a fix for Issue #661.\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 31,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2012-07-14T21:15:30Z",
        "closed_at": "2012-07-27T05:34:07Z",
        "merged_at": null,
        "body": "This is a fix for issue #695. \n\nAdditional co-authors:\n@smargonz\n@vickimo\n@tgebru\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2012-07-14T20:12:25Z",
        "closed_at": "2012-07-14T22:48:07Z",
        "merged_at": "2012-07-14T22:48:07Z",
        "body": "Modified code to use the current fix versus the old fix, which was broken.\n\nCo-Authored By: Timnit Gebru tgebru@gmail.com @tgebru\nCo-Authored By: Sarah Gonzalez smar.gonz@gmail.com @smargonz\nCo-Authored By: Leila Muhtasib muhtasib@gmail.com @muhtasib\n\nThis is a fix for issue #541 and #547.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2012-07-13T19:25:50Z",
        "closed_at": "2012-07-13T20:49:13Z",
        "merged_at": "2012-07-13T20:49:13Z",
        "body": "This is a fix for issue #699\n\nA simple solution was to bubble up the error from urllib3. TimeoutError inherits from _HTTPError, so we could just add a line and raise a Timeout.\n\nThe error message will indicate whether the error is of type socket timeout or of type no connections available in the connection pool.\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2012-07-13T17:02:07Z",
        "closed_at": "2012-07-13T19:26:00Z",
        "merged_at": null,
        "body": "This is a fix for issue #699\n\nA simple solution was to bubble up the error from urllib3. TimeoutError inherits from _HTTPError, so we could just add a line and raise a Timeout.\n\nThe error message will indicate whether the error is of type socket timeout or of type no connections available in the connection pool.\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 491,
        "deletions": 490,
        "changed_files": 1,
        "created_at": "2012-07-12T20:04:32Z",
        "closed_at": "2012-07-27T05:35:06Z",
        "merged_at": null,
        "body": "On Google App Engine (runtime 2.7 thread safe) there is a ImportError\nwhen ever calling get_netrc_auth (stacktrace at the end of the comment)\nI'm adding a except pass on the Import error to workaround that error. I\nwill open an issues on the App Engine tracker so that will fix that on\nthier end also.\n\nFile \"/base/data/home/apps/.../requests/api.py\", line 87, in post\nreturn request('post', url, data=data, *_kwargs)\nFile \"/base/data/home/apps/.../requests/safe_mode.py\", line 37, in\nwrapped\nreturn function(method, url, *_kwargs)\nFile \"/base/data/home/apps/.../requests/api.py\", line 42, in request\nreturn s.request(method=method, url=url, **kwargs)\nFile \"/base/data/home/apps/.../requests/sessions.py\", line 230, in\nrequest\nr.send(prefetch=prefetch)\nFile \"/base/data/home/apps/.../requests/models.py\", line 483, in send\nself.auth = get_netrc_auth(url)\nFile \"/base/data/home/apps/.../requests/utils.py\", line 79, in\nget_netrc_auth\nfor loc in locations:\nFile \"/base/data/home/apps/.../requests/utils.py\", line 76, in <genexpr>\nlocations = (os.path.expanduser('~/{0}'.format(f)) for f in NETRC_FILES)\nFile \"/base/python27_runtime/python27_dist/lib/python2.7/posixpath.py\",\nline 259, in expanduser\nimport pwd\nImportError: No module named pwd\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2012-07-11T16:37:18Z",
        "closed_at": "2012-07-12T07:09:22Z",
        "merged_at": "2012-07-12T07:09:21Z",
        "body": "Following discussion on Issue #701, it seems like we should rethrow SSLErrors regardless of whether `verify` is true or not. SSLErrors are not raised by invalid certificates with `verify = False` anyway, so anything caused by anything else should be rethrown.\n\nI can't think of a good test for this, so if you have an idea I'd love to hear it.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 16,
        "deletions": 5,
        "changed_files": 3,
        "created_at": "2012-07-09T23:14:22Z",
        "closed_at": "2012-07-12T19:06:53Z",
        "merged_at": "2012-07-12T19:06:53Z",
        "body": "I noticed that the params were not correctly handled in the presence of a fragment.\n\n``` python\nrequests.get('http://example.com/path?key=value#fragment',\n    params={'a': 'b'}, return_response=False).full_url\n```\n\nIs my fix ok?\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 33,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2012-07-07T20:18:40Z",
        "closed_at": "2012-07-08T07:42:17Z",
        "merged_at": "2012-07-08T07:42:17Z",
        "body": "With this change the default user agent will include more details by default.\n\nPython:\n\n```\npython -c \"import requests; print requests.get('http://httpbin.org/user-agent').json\"\n{u'user-agent': u'python-requests/0.13.2 CPython/2.7.3 Darwin/11.4.0'}\n```\n\nPyPy:\n\n```\npypy -c \"import requests; print requests.get('http://httpbin.org/user-agent').json\"  \n{u'user-agent': u'python-requests/0.13.2 PyPy/1.9.0 Darwin/11.4.0'}\n```\n",
        "comments": 9
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2012-07-02T00:09:30Z",
        "closed_at": "2012-07-02T03:00:28Z",
        "merged_at": null,
        "body": "Just adding some nice rounded corners for the **pre** element of Sphinx theme, I don't know if you want to commit it, it looks like in this project: http://odbrasil.readthedocs.org\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-06-30T22:47:28Z",
        "closed_at": "2012-07-01T01:07:12Z",
        "merged_at": null,
        "body": "",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-06-30T22:46:32Z",
        "closed_at": "2012-07-01T01:07:27Z",
        "merged_at": "2012-07-01T01:07:27Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-06-30T22:45:19Z",
        "closed_at": "2012-07-01T01:07:35Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2012-06-30T22:41:34Z",
        "closed_at": "2012-07-02T11:31:09Z",
        "merged_at": "2012-07-02T11:31:09Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1988,
        "deletions": 2,
        "changed_files": 21,
        "created_at": "2012-06-29T03:12:25Z",
        "closed_at": "2012-11-27T18:32:58Z",
        "merged_at": null,
        "body": "",
        "comments": 38
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-06-21T19:10:08Z",
        "closed_at": "2012-06-26T00:57:02Z",
        "merged_at": "2012-06-26T00:57:02Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 8,
        "deletions": 11,
        "changed_files": 2,
        "created_at": "2012-06-21T12:05:33Z",
        "closed_at": "2012-06-21T14:48:26Z",
        "merged_at": null,
        "body": "Hi,\n\nI use requests a lot to interact with some applications made by other developers who use a programming language where a JSON encoding implementation doesn't exist.\nSometimes, their JSON content is wrong, I must notify them.\n\nFor me, it's important to catch the JSON decoding problem in the same way as the others errors, with an exception.\n\nWith this patch, the user of requests can handle the exception himself.\n\nThanks for your feedback.\n",
        "comments": 20
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-06-19T11:36:34Z",
        "closed_at": "2012-06-19T13:28:57Z",
        "merged_at": "2012-06-19T13:28:57Z",
        "body": "Commit d3acb783b95623d0378db02bd9832fb11850204b updated `urllib3`, which involved the removal of the `mimetools_choose_boundary` package. This package is still being referred to in `setup.py`, which is causing the install to fail. This pull request resolves this problem, and therefore also resolves Issue #685.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2012-06-19T04:04:13Z",
        "closed_at": "2012-06-20T23:52:38Z",
        "merged_at": "2012-06-20T23:52:38Z",
        "body": "Existing usage doesn't pass GET querystring parameters along to oauthlib,\nso it wasn't signing those properly, which causes problems with APIs that\nrely heavily on GET parameters. By passing in r.full_url instead of r.url,\noauthlib can parse out the correct parameters and sign them properly.\n",
        "comments": 8
    },
    {
        "merged": false,
        "additions": 14,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2012-06-16T14:22:30Z",
        "closed_at": "2012-07-12T21:47:04Z",
        "merged_at": null,
        "body": "This patch solves the issue #423 https://github.com/kennethreitz/requests/issues/423\n\nWe added a small test file showing that now a request like\n<code>requests.get(furl('http://example.com/ ').set({'query': 'string'}))</code>\nis working properly.\n\nAuthors:\nIulian Stana\nVlad Traist\u0103-Popescu\nConstantin \u0218erban-R\u0103doi\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 26,
        "deletions": 14,
        "changed_files": 2,
        "created_at": "2012-06-15T19:21:11Z",
        "closed_at": "2012-07-27T05:34:44Z",
        "merged_at": null,
        "body": "",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 17,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2012-06-15T19:06:27Z",
        "closed_at": "2012-07-27T05:37:13Z",
        "merged_at": null,
        "body": "",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 10,
        "changed_files": 3,
        "created_at": "2012-06-15T14:03:36Z",
        "closed_at": "2012-06-21T19:04:18Z",
        "merged_at": null,
        "body": "The logic is the same. The only time we don't want to return 'data' is when it\nisn't a file and can be iterated over.\n",
        "comments": 13
    },
    {
        "merged": true,
        "additions": 80,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2012-06-14T14:21:22Z",
        "closed_at": "2012-06-14T16:50:40Z",
        "merged_at": "2012-06-14T16:50:40Z",
        "body": "I've edited the advanced docs with a simple tutorial of how to access the request object from a response, and I also provided a listing of methods and attributes accessible using a Request object and a Response object. This section is entitled \"Request and Response Objects\". I would have found this simple listing tremendously useful had it existed in the original documentation, and I hope others find it useful as well.\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-06-14T04:18:19Z",
        "closed_at": "2012-06-14T17:18:23Z",
        "merged_at": "2012-06-14T17:18:23Z",
        "body": "In particular, this happens when encountering redirects. The first request doesn't have a Content-Type, but the second request does (it was added by the OAuth1 object), so when it tries to apply the authorization details again, it falls off and returns None instead of the original response. This change simply moves the return up one level, so it always returns the request regardless of whether it was modified along the way.\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 117,
        "deletions": 69,
        "changed_files": 4,
        "created_at": "2012-06-12T00:12:46Z",
        "closed_at": "2012-11-27T18:32:58Z",
        "merged_at": null,
        "body": "",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-06-08T13:01:54Z",
        "closed_at": "2012-06-09T11:30:19Z",
        "merged_at": "2012-06-09T11:30:19Z",
        "body": " `urlparse` cannot handle `Response` objects, so the way this is written this code always results in an exception.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 25,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2012-06-07T08:34:03Z",
        "closed_at": "2012-06-08T02:06:50Z",
        "merged_at": "2012-06-08T02:06:50Z",
        "body": "The underlying httplib already allows passing an open file object as body\nto its HTTPConnection.request method. I think requests should allow that\nas well.\n\nThis also fixes issue #292 in requests. httplib will automatically add the content-length header if a real file object is passed. This will most likely break for non-file streams but it is a start.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 18,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2012-06-06T15:10:47Z",
        "closed_at": "2012-06-07T01:02:46Z",
        "merged_at": "2012-06-07T01:02:46Z",
        "body": "I just saw `response.json` in your #djangocon presentation, which is awesome and was still unknown to me. I updated the docs accordingly.\n\nIn case you don't like the 2nd commit, just ignore or revert it.\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 12,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2012-06-05T14:28:27Z",
        "closed_at": "2012-06-07T00:00:04Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2012-06-04T20:20:40Z",
        "closed_at": "2012-06-04T22:24:14Z",
        "merged_at": "2012-06-04T22:24:14Z",
        "body": "Also fixed nearby comments to wrap at 79 characters as per PEP8\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 55,
        "deletions": 10,
        "changed_files": 4,
        "created_at": "2012-06-04T18:22:19Z",
        "closed_at": "2012-06-05T15:52:19Z",
        "merged_at": null,
        "body": "Should solve #637.\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 130,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2012-06-01T21:19:42Z",
        "closed_at": "2012-07-27T05:36:41Z",
        "merged_at": "2012-07-27T05:36:41Z",
        "body": "Currently has two issues which may be related:\n- doesn't work with redirects, we try to authenticate the server a second\n  time with a fully completed kerberos context.\n- 403 responses result in the wrong response object being returned, but\n  this is also true for http digest authentication due to a bug in hook\n  handling in general.\n",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2012-06-01T20:58:18Z",
        "closed_at": "2012-06-04T14:44:56Z",
        "merged_at": "2012-06-04T14:44:56Z",
        "body": "Since response objects for failures (4xx/5xx responses) evaluate to False\nin a boolean context, any hook which returns such a failure response will\nevaluate to False.\n\nThe way hooks were setup, any failure response resulting from a hook would\nbe ignored, and the initial response before it got processed by the hook\nwould be substituted in its place. This commit changes that logic to test\nfor None so that hooks that return failures can do so.\n\nThis would close out issue 644 (https://github.com/kennethreitz/requests/issues/644) which I opened earlier. It has some discussion about my findings, so you may want to look there for reference.\n\nI've run the tests before and after this and the only tests that break as a result of this (as far as I can tell since I'm running python 2.6) are those in test_DIGESTAUTH_WRONG_HTTP_401_GET. That's because the bug that this fixes was hiding a bug in httpbin which is returning a 403 instead of a 401 on a failed digest authentication (it gets http basic right). I've submitted a pull request for httpbin that should address that (https://github.com/kennethreitz/httpbin/pull/48).\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2012-06-01T20:53:14Z",
        "closed_at": "2012-06-29T00:23:15Z",
        "merged_at": null,
        "body": "We're using some features that weren't available in unittest in python\n2.6, but they are available in unittest2 which can be pip installed.\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2012-05-30T15:36:33Z",
        "closed_at": "2012-05-30T19:48:33Z",
        "merged_at": "2012-05-30T19:48:33Z",
        "body": "I added the following part to the docs (\"Proxies\" section):\n\n![Screenshot](http://ich-wars-nicht.ch/tmp/screenshots/20120530_173532.png)\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-05-28T14:58:25Z",
        "closed_at": "2012-05-29T23:55:04Z",
        "merged_at": null,
        "body": "...pe sequences\n\nEspecially relevent to security testing, an HTTP client will be asked to send requests containing invalid uri-escape sequences. This raises a ValueError if an attempt is made to parse a string argument as a signed integer with radix 16. The method unquote_unreserved attempts to unquote any uri-escaped sequences in the unreserved character set. Because a uri-escaped character is hex-encoded, we can simply add a check to ensure the sequence is alphanumeric prior to parsing.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-05-28T13:29:34Z",
        "closed_at": "2012-05-29T23:45:54Z",
        "merged_at": "2012-05-29T23:45:54Z",
        "body": "self.encoding is accessed in text-property instead of content-property.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-05-27T18:30:27Z",
        "closed_at": "2012-05-29T23:44:56Z",
        "merged_at": "2012-05-29T23:44:56Z",
        "body": "Adds support for no_proxy environment variable\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 21,
        "deletions": 14,
        "changed_files": 1,
        "created_at": "2012-05-24T03:18:20Z",
        "closed_at": "2012-05-29T23:51:48Z",
        "merged_at": "2012-05-29T23:51:48Z",
        "body": "```\nthis try catch is a poor man's patch for issue #630\nhttps://github.com/kennethreitz/requests/issues/630\n```\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 17,
        "changed_files": 5,
        "created_at": "2012-05-23T21:14:10Z",
        "closed_at": "2012-05-29T23:41:39Z",
        "merged_at": "2012-05-29T23:41:39Z",
        "body": "Hi,\n\nReforked the repository to do away with the git mess I had created. Hope this works this time.\n\nThanks,\nArup\n",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 17,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-05-23T19:08:21Z",
        "closed_at": "2012-05-23T20:40:49Z",
        "merged_at": null,
        "body": "Also use the preferred directory-based certificate store if supported by the SSL module (openSUSE 12.2+)\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2012-05-23T12:25:40Z",
        "closed_at": "2012-06-29T00:26:30Z",
        "merged_at": "2012-06-29T00:26:30Z",
        "body": "openSUSE ships Mozilla CA certificates in a directory (/etc/ssl/certs) and for compatibility as a bundled pem (/etc/ssl/ca-bundle.pem), the first is preferred though. This patch adds support for both, i.e. if a path is found in POSSIBLE_CA_BUNDLE_PATHS, it checks whether the ssl module supports it. Otherwise, the pem file is used (listed after '/etc/ssl/certs' in POSSIBLE_CA_BUNDLE_PATHS).\n",
        "comments": 21
    },
    {
        "merged": false,
        "additions": 149,
        "deletions": 1487,
        "changed_files": 21,
        "created_at": "2012-05-17T19:00:55Z",
        "closed_at": "2012-05-20T01:42:57Z",
        "merged_at": null,
        "body": "Hi kennethreitz,\n\nI have changed the code to make the configuration part of the config object instead of being a parameter.\n\nThis is the actual commit: \n\nhttps://github.com/amalakar/requests/commit/ae3b13920875c3068a19f04c3bc8f7d4cbdfd76f\n\nGit issue: After realizing you had issue merging yesterday I did some 'rebase' and this pull request now has 17 other commits :( I am not sure if this can be merged. If not I will try something else. I come from svn world and looks like I need to learn git. My way of learning via trial and error is not working well here.\n\nThanks,\nArup\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 260,
        "deletions": 125,
        "changed_files": 2,
        "created_at": "2012-05-17T09:22:55Z",
        "closed_at": "2012-05-29T23:49:51Z",
        "merged_at": "2012-05-29T23:49:51Z",
        "body": "Issue #503 raised a few problems with the lack of clarity in the quickstart documentation. This pull request rewrites that documentation, to cover the issues raised in #503, and for general clarity.\n\nIf there are other docs rewrites you'd like, or changes to this one, I'd be happy to update this pull request with further commits.\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 36,
        "deletions": 3,
        "changed_files": 5,
        "created_at": "2012-05-16T22:35:54Z",
        "closed_at": "2012-05-17T00:10:31Z",
        "merged_at": "2012-05-17T00:10:31Z",
        "body": "I tried to add the feature as requested in issue #505. When store_cookies is set to False, all the cookies sent by the server would be just ignored. The user can still provide cookies using the cookie param though and they would be passed to the server as well. Just that the ones sent by the server are ignored.\n\nThanks,\nArup\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-05-16T18:02:15Z",
        "closed_at": "2012-05-17T00:34:03Z",
        "merged_at": "2012-05-17T00:34:03Z",
        "body": "Previously, when attempting to call del on a dictionary key that did not exist, a KeyError was raised. This commit changes the default behavior to be case-insensitive.\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 105,
        "deletions": 26,
        "changed_files": 8,
        "created_at": "2012-05-15T23:59:16Z",
        "closed_at": "2012-07-18T03:39:34Z",
        "merged_at": null,
        "body": "Please do not merge this! This is intended as a \"design review\" :-) It needs more comments and tests before it is production ready.\n\nThis implements explicit disposal of sockets in urllib3 and Requests that does not rely on instantaneous garbage collection via reference counts (e.g., for PyPy). It should fix #520 without removing the `Response.request` member, or otherwise breaking the API (or the reference cycle, depending on whether you're a glass-half-full or glass-half-empty person).\n\nIt's split into three commits: one is a test case, one adds explicit disposal, one defaults `prefetch=True` and changes the tests to match.\n\n@shazow maybe you could take a look at the urllib3 changes?\n\nThanks everyone.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-05-15T14:18:16Z",
        "closed_at": "2012-05-15T15:31:43Z",
        "merged_at": "2012-05-15T15:31:43Z",
        "body": "Since base_headers is a dictionary, it's reference was shared with all instances of Session objects. This patch deep copies all config options. Using deepcopy here should not incur a large performance penalty.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2012-05-13T23:11:47Z",
        "closed_at": "2012-05-14T02:47:19Z",
        "merged_at": "2012-05-14T02:47:19Z",
        "body": "I cloned, followed the todo and had failures as no certifi or chardet.\n\nFixed up so easy to get started.\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2012-05-13T10:02:05Z",
        "closed_at": "2012-05-13T18:01:22Z",
        "merged_at": "2012-05-13T18:01:22Z",
        "body": "Just removing something I saw while browsing the code.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-05-12T17:24:14Z",
        "closed_at": "2012-05-12T21:23:04Z",
        "merged_at": "2012-05-12T21:23:04Z",
        "body": "A minor typo fix in the send docstring.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 72,
        "deletions": 55,
        "changed_files": 5,
        "created_at": "2012-05-10T14:59:32Z",
        "closed_at": "2012-05-10T18:06:25Z",
        "merged_at": "2012-05-10T18:06:25Z",
        "body": "We throw exceptions in models.py even if in safe_mode. We catch those exceptions at the API level and return a blank Response with the error field filled with the exception thrown. See safe_mode.py for details.\n\nDiscussed here: #583\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-05-10T14:18:20Z",
        "closed_at": "2012-05-10T18:07:01Z",
        "merged_at": "2012-05-10T18:07:00Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2012-05-08T15:05:09Z",
        "closed_at": "2012-07-27T05:59:13Z",
        "merged_at": null,
        "body": "Seriously, I think you should merge this one. The latest release and the `develop` branch still have the default `chunk_size` \"reversed\" for `iter_content()` and `iter_lines()` contrarilly to what you mentioned here: https://github.com/kennethreitz/requests/pull/589#issuecomment-5567553\n\nThis pull request may be canned by Travis CI again, but as I mentioned in the above pull request, the issue is located either in the test logic or the way lines ending in `\\r\\n` in `iter_lines()` depending how you interpret the issue... (I think the later is the real problem as even without changing `chunk_size`, `iter_lines()` could return different results for the same input depending on where the line-ending ends inside the buffer read by `iter_content()`). Not knowing how you perceive the issue, I did not attempt to fix it.\n\n----- Original idea:\n\nFollowing discussion about issue #539 Kenneth agreed that a default\n`chunk_size` of 1 for `iter_lines()` would make more sense, but\napparently changed `chunk_size` for `iter_content()` by mistake\ninstead, which did solve the `iter_lines()` issue but also changed the\ndefault `iter_content()` chunk to 1 bytes which is not desirable.\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 27,
        "deletions": 6,
        "changed_files": 5,
        "created_at": "2012-05-08T09:19:50Z",
        "closed_at": "2012-05-08T15:06:51Z",
        "merged_at": "2012-05-08T15:06:51Z",
        "body": "For example, I want to use `request.async` and save cookies to session:\n\n```\nimport requests\nfrom requests import async\n\ns = requests.Session()\nasync.map([async.get('http://httpbin.org/cookies/set/async/yes', session=s)])\nprint 'cookies:', s.cookies\n```\n\ncookies are empty. \nIt's because when `Session.request()` is called with `return_response=False`, it returns request without updating session cookies [sessions.py#L234](https://github.com/kennethreitz/requests/blob/9bf53676b87fa4951e23f67d2251f5dfae4e5206/requests/sessions.py#L234)\n\nSo, I think we can solve it by moving cookies saving logic to `Request._build_response()`. Or maybe there is more suitable place?\n",
        "comments": 10
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2012-05-06T17:08:45Z",
        "closed_at": "2012-05-08T05:07:45Z",
        "merged_at": null,
        "body": "Following discussion about issue #539 Kenneth agreed that a default\n`chunk_size` of 1 for `iter_lines()` would make more sense, but\napparently changed `chunk_size` for `iter_content()` by mistake\ninstead, which did solve the `iter_lines()` issue but also changed the\ndefault `iter_content()` chunk to 1 bytes which is not desirable.\n\nAlso changed default for `decode_unicode` to `False` instead of `None` in `iter_lines()`.\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-05-04T11:47:20Z",
        "closed_at": "2012-05-04T18:48:35Z",
        "merged_at": "2012-05-04T18:48:35Z",
        "body": "Doh! http://ci.kennethreitz.com/job/requests/236/PYTHON=2.7/console\n\nThis might be a reason to take pyflakes out of the Jenkins target (`ci`).\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-05-04T10:46:07Z",
        "closed_at": "2012-05-04T18:49:49Z",
        "merged_at": "2012-05-04T18:49:49Z",
        "body": "This will fix the iter_lines IndexError, which may be caused either by `chunk == ''` (empty string), or `chunk.endswith('\\n\\n')`.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 19,
        "deletions": 5,
        "changed_files": 3,
        "created_at": "2012-05-04T05:16:59Z",
        "closed_at": "2012-05-04T06:28:07Z",
        "merged_at": "2012-05-04T06:28:07Z",
        "body": "This provides a utility function that reads the environment proxies. It returns proxies in a format compatible with request's proxy parameter.\n\nMoreover, it can be used in the request models for proxy defaults.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 35,
        "deletions": 10,
        "changed_files": 5,
        "created_at": "2012-05-04T03:02:48Z",
        "closed_at": "2012-05-04T06:29:04Z",
        "merged_at": "2012-05-04T06:29:04Z",
        "body": "Mostly what was discussed for #574.\n\nThis patch will run pyflakes on a whitelisted set of files during the Jenkins build (but not the Travis); I can remove that if you'd prefer to keep it separate.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 28,
        "changed_files": 5,
        "created_at": "2012-05-02T07:10:18Z",
        "closed_at": "2012-05-03T08:35:47Z",
        "merged_at": "2012-05-03T08:35:47Z",
        "body": "- Raise a ValueError on .text when chardet is unavailable\n- `make ci` runs everything except test_requests_async and test_requests_ext\n",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 106,
        "deletions": 90,
        "changed_files": 6,
        "created_at": "2012-04-30T20:12:08Z",
        "closed_at": "2012-05-01T10:01:24Z",
        "merged_at": null,
        "body": "In python 2.x, requests sets str = unicode in requests/compat.py. This causes\nisinstance(foo, str) to return True even if foo is a unicode string.\n\nSupersedes #556, which I totally broke.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 536,
        "deletions": 120,
        "changed_files": 11,
        "created_at": "2012-04-25T07:58:50Z",
        "closed_at": "2012-05-02T00:22:38Z",
        "merged_at": "2012-05-02T00:22:38Z",
        "body": "This is my update of dhagrow's branch. It makes the backing store for cookies be a `CookieJar`, and adds compatibility with passed-in `CookieJar` subclasses like `LWPCookieJar`.\n\nThe default `CookieJar` implementation is compatible with existing code that expects `response.cookies` to be a dict.\n\nThis branch is complete to the best of my knowledge, but I haven't tested it against Python 3.x, since the current `develop` branch is broken against 3.x. I thought about trying to fix it but this change is confusing enough already :-)\n\nI would appreciate suggestions for additional tests :-)\n\n```\nTraceback (most recent call last):\n  File \"./test_requests_https.py\", line 10, in <module>\n    import requests\n  File \"/home/shivaram/workspace/requests/requests/__init__.py\", line 25, in <module>\n    from . import utils\n  File \"/home/shivaram/workspace/requests/requests/utils.py\", line 476, in <module>\n    _unreserved_hextochr = dict((binascii.b2a_hex(c), c) for c in _unreserved_set)\n  File \"/home/shivaram/workspace/requests/requests/utils.py\", line 476, in <genexpr>\n    _unreserved_hextochr = dict((binascii.b2a_hex(c), c) for c in _unreserved_set)\nTypeError: 'str' does not support the buffer interface\n```\n",
        "comments": 30
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 15,
        "changed_files": 3,
        "created_at": "2012-04-24T09:06:04Z",
        "closed_at": "2012-05-16T05:49:27Z",
        "merged_at": "2012-05-16T05:49:27Z",
        "body": "My understanding is that Python's `random` module is not recommended for cryptographic use. `os.urandom` should provide random bytes on all major platforms: Linux, OS X, *nix, and Windows:\n\nhttp://docs.python.org/library/os.html#os.urandom\nhttp://docs.python.org/release/3.0.1/library/os.html#os.urandom\n\nSince the function provides a `str` under 2.x and a `bytes` under 3.x, and the result is fed directly into SHA, there shouldn't be an issue with the encoding.\n\nThoughts? Thanks for your time.\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 83,
        "deletions": 78,
        "changed_files": 2,
        "created_at": "2012-04-23T09:55:39Z",
        "closed_at": "2012-04-23T13:26:02Z",
        "merged_at": "2012-04-23T13:26:02Z",
        "body": "An updated version of https://github.com/kennethreitz/requests/pull/535 with Python 3.x compatibility.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 63,
        "deletions": 1,
        "changed_files": 4,
        "created_at": "2012-04-21T02:21:36Z",
        "closed_at": "2012-05-08T04:58:18Z",
        "merged_at": "2012-05-08T04:58:20Z",
        "body": "Added test and updated _encode_files.\n\nHad me really confused there for a moment with the bytes = str, str = unicode.... I haven't gotten a py3 environment up yet. I really need to, I know. Passes all tests in py2.\n",
        "comments": 24
    },
    {
        "merged": false,
        "additions": 33,
        "deletions": 26,
        "changed_files": 1,
        "created_at": "2012-04-19T06:22:51Z",
        "closed_at": "2012-04-30T20:12:32Z",
        "merged_at": null,
        "body": "In python 2.x, requests sets str = unicode in `requests/compat.py`. This causes\n`isinstance(foo, str)` to return True even if foo is a unicode string.\n\nWould appreciate review of this change because my understanding of how this impacts py3x compatibility is tenuous.\n",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2012-04-18T06:09:24Z",
        "closed_at": "2012-04-23T02:36:19Z",
        "merged_at": null,
        "body": "The u before the string in the tests breaks py3k\n",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 67,
        "deletions": 5,
        "changed_files": 4,
        "created_at": "2012-04-17T01:00:47Z",
        "closed_at": "2012-04-23T01:53:31Z",
        "merged_at": "2012-04-23T01:53:31Z",
        "body": "I thought it might be a good idea to attempt to use the OS's certificate bundle on systems where one is available. I was thinking something like this:\n1. It could be dangerous to install `certifi` and then forget about it, in case a CA in it is compromised (like with Diginotar).\n2. Might be good not to depend on another package?\n\nAnyway, thanks for your time.\n\nI used github for the smoke test because, amusingly enough, httpbin's certificate didn't verify on my system (Fedora 16):\n\n```\n[shivaram@good-fortune ~]$ curl -v https://httpbin.org/get\n* About to connect() to httpbin.org port 443 (#0)\n*   Trying 107.21.118.103... connected\n* Connected to httpbin.org (107.21.118.103) port 443 (#0)\n* Initializing NSS with certpath: sql:/etc/pki/nssdb\n*   CAfile: /etc/pki/tls/certs/ca-bundle.crt\n  CApath: none\n* Peer's certificate issuer is not recognized: 'CN=RapidSSL CA,O=\"GeoTrust, Inc.\",C=US'\n* NSS error -8179\n* Closing connection #0\n* Peer certificate cannot be authenticated with given CA certificates\ncurl: (60) Peer certificate cannot be authenticated with given CA certificates\nMore details here: http://curl.haxx.se/docs/sslcerts.html\n\ncurl performs SSL certificate verification by default, using a \"bundle\"\n of Certificate Authority (CA) public keys (CA certs). If the default\n bundle file isn't adequate, you can specify an alternate file\n using the --cacert option.\nIf this HTTPS server uses a certificate signed by a CA represented in\n the bundle, the certificate verification probably failed due to a\n problem with the certificate (it might be expired, or the name might\n not match the domain name in the URL).\nIf you'd like to turn off curl's verification of the certificate, use\n the -k (or --insecure) option.\n```\n",
        "comments": 18
    },
    {
        "merged": true,
        "additions": 23,
        "deletions": 2,
        "changed_files": 3,
        "created_at": "2012-04-13T15:33:16Z",
        "closed_at": "2012-04-14T10:19:10Z",
        "merged_at": "2012-04-14T10:19:10Z",
        "body": "Possible fix for issue #549.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 21,
        "deletions": 8,
        "changed_files": 3,
        "created_at": "2012-04-12T16:39:18Z",
        "closed_at": "2012-04-12T19:44:45Z",
        "merged_at": "2012-04-12T19:44:45Z",
        "body": "Fixes this issue:\n\n``` python\n>>> import requests\n>>> requests.get('http://google.com:banana')\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/Users/umbrae/Envs/rdb/lib/python2.6/site-packages/requests/api.py\", line 51, in get\n    return request('get', url, **kwargs)\n[...snip...]\n  File \"/Users/umbrae/Envs/rdb/lib/python2.6/site-packages/requests/packages/urllib3/connectionpool.py\", line 579, in get_host\n    raise LocationParseError(\"Failed to parse: %s\")\nrequests.packages.urllib3.exceptions.LocationParseError: (LocationParseError(...), 'Failed to parse: Failed to parse: %s')\n```\n\nTo now return a wrapped exception, which hides the use of urllib3 and is more intuitive to catch:\n\n``` python\n>>> import requests\nre>>> requests.get('http://google.com:banana')\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"requests/api.py\", line 52, in get\n    return request('get', url, **kwargs)\n  File \"requests/api.py\", line 40, in request\n    return s.request(method=method, url=url, **kwargs)\n  File \"requests/sessions.py\", line 208, in request\n    r.send(prefetch=prefetch)\n  File \"requests/models.py\", line 506, in send\n    raise InvalidURL(e)\nrequests.exceptions.InvalidURL: (LocationParseError(...), 'Failed to parse: Failed to parse: google.com')\n```\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 55,
        "deletions": 23,
        "changed_files": 3,
        "created_at": "2012-04-12T14:38:37Z",
        "closed_at": "2012-04-13T06:34:45Z",
        "merged_at": "2012-04-13T06:34:45Z",
        "body": "The most straightforward way to fix #541 seems to be to deregister the hook on the first 401. This is what I have implemented here.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-04-10T09:14:14Z",
        "closed_at": "2012-04-10T15:43:47Z",
        "merged_at": "2012-04-10T15:43:47Z",
        "body": "The ability to send arrays in the values of query params doesn't seem to be documented anywhere. So, I added a small mention of it.\n\nThis was added in this change: https://github.com/kennethreitz/requests/commit/73b414ab4564486f2335f02a1727fd0f4d005608\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 4,
        "changed_files": 3,
        "created_at": "2012-04-08T22:51:34Z",
        "closed_at": "2012-04-09T03:13:38Z",
        "merged_at": "2012-04-09T03:13:38Z",
        "body": "Calling the content attribute on a response that has no content causes an error after the second time. On async requests, prefetch is set to true by default so all calls to content from an async response cause an error.\n\nMy change does change the default value for _content. All tests pass and I added a new one to replicate the issue and ensure that it works with my patch.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-04-06T15:51:14Z",
        "closed_at": "2012-04-06T17:01:19Z",
        "merged_at": "2012-04-06T17:01:19Z",
        "body": "In setup.py the path to test_requests.py is incorrect - breaking python setup.py test, this fixes it.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 84,
        "deletions": 79,
        "changed_files": 3,
        "created_at": "2012-04-04T10:16:58Z",
        "closed_at": "2012-04-11T15:02:46Z",
        "merged_at": "2012-04-11T15:02:46Z",
        "body": "Currently a URL with invalid %encodings will cause an exception to be thrown in unquote_unreserved.\n\nThis patch reimplements unquote_unreserved to be almost identical to urllib.unquote, thus fixing the problem and simplifying the code.\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 7,
        "deletions": 5,
        "changed_files": 3,
        "created_at": "2012-04-02T18:31:14Z",
        "closed_at": "2012-05-08T05:06:16Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2012-04-02T09:15:34Z",
        "closed_at": "2012-04-23T02:34:12Z",
        "merged_at": "2012-04-23T02:34:12Z",
        "body": "If you run setup from outside the project directory it will fail on attempting to open the README, etc. files.\n\nfor eg.\n\npython requests/setup.py install\n\nnow works because the full path name is used in reading the file. implement as a separate func since it is used three times. \n\nthis is a pretty common bug, but I see it a lot because of my deploy scripts\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2012-03-28T08:48:30Z",
        "closed_at": "2012-03-31T02:58:38Z",
        "merged_at": "2012-03-31T02:58:38Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2012-03-27T19:18:31Z",
        "closed_at": "2012-04-02T18:24:58Z",
        "merged_at": null,
        "body": "Tests now use MissingSchema and InvalidSchema added in b973d08b0e46d25c4e5b9b7e8e5e6a4ca440594a.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2012-03-27T13:44:06Z",
        "closed_at": "2012-05-02T22:58:08Z",
        "merged_at": "2012-05-02T22:58:08Z",
        "body": "Having the hook called so late makes it impossible to overwrite the HTTP request\ncalling behavior and set self.sent to True in case of possible cache matches\nfor example.\n\nThis way we can interfere before we waste any CPU time to calculate\na request.\n\nAs a side note I am not sure if this whole process should be splitted into two parts: pre_prepare_request and pre_request so that one hook really can interfere before we calculate anything and the other can use the certificate and gathered authentication information to make it's decisions... not sure \n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2012-03-25T15:04:58Z",
        "closed_at": "2012-03-25T19:00:57Z",
        "merged_at": "2012-03-25T19:00:57Z",
        "body": "Here's a potential fix for #510. Adds MissingSchema and InvalidSchema which inherit both RequestException and ValueError.\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2012-03-24T07:01:24Z",
        "closed_at": "2012-03-24T18:07:00Z",
        "merged_at": null,
        "body": "requests/packages/urllib3/connectionpool.py\n- Added the url that couldn't be parsed to LocationParseError message.\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2012-03-21T12:39:00Z",
        "closed_at": "2012-05-08T05:06:40Z",
        "merged_at": null,
        "body": "This occurred to me as a potential workaround for issues with pre-request hooks\nbeing unable to alter `body` within their scope. Particularly those found in\noauth-requests, where the body of a request cannot be recalculated. Here the\nissue seems to be that `body` is assigned as a local variable. So if we simply\nmake `body` an attribute of the object we can manually override its value in\nthe scope of the hook. Here is a simple example of what this might look like:\n`request.data, request._enc_data = request._encode_params(my_params)` this sets\nus up for `request.body = request._enc_data` and we can now alter body as we\nshould like.\n",
        "comments": 29
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-03-20T14:34:59Z",
        "closed_at": "2012-03-22T02:32:19Z",
        "merged_at": null,
        "body": "[The docs](http://docs.python-requests.org/en/v0.10.7/user/quickstart/#redirection-and-history) imply that GET, HEAD and OPTION should all default to following redirects, but currently `allow_redirects` defaults to False for HEAD requests.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 27,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2012-03-18T19:41:38Z",
        "closed_at": "2012-03-19T02:07:31Z",
        "merged_at": "2012-03-19T02:07:31Z",
        "body": "I added some documentation on passing parameters in a get request. I didn't see it documented anywhere else and had to dig through the source to figure out the argument.\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 74,
        "deletions": 58,
        "changed_files": 11,
        "created_at": "2012-03-16T20:11:53Z",
        "closed_at": "2012-03-17T19:15:35Z",
        "merged_at": null,
        "body": "Issue #194\n",
        "comments": 12
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 33,
        "changed_files": 2,
        "created_at": "2012-03-16T15:29:37Z",
        "closed_at": "2012-03-19T02:16:23Z",
        "merged_at": null,
        "body": "Generator for non-chunked encoding uses method read of\nhttplib.HTTPResponse which also checks and correctly handles\nchunked encoding.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2012-03-15T18:42:57Z",
        "closed_at": "2012-03-19T02:08:51Z",
        "merged_at": "2012-03-19T02:08:51Z",
        "body": "...ct.poll and requests.async in the same project\n\nFix for issue #487, including a regression test that checks the\nexistence of select.poll before and after loading requests.async.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 23,
        "deletions": 5,
        "changed_files": 3,
        "created_at": "2012-03-14T23:01:49Z",
        "closed_at": "2012-03-15T00:29:39Z",
        "merged_at": "2012-03-15T00:29:39Z",
        "body": "Exposed key_file and cert_file in requests, to support https client certificates.\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-03-14T00:12:50Z",
        "closed_at": "2012-03-16T01:14:35Z",
        "merged_at": "2012-03-16T01:14:35Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 682,
        "deletions": 17,
        "changed_files": 8,
        "created_at": "2012-03-09T22:41:37Z",
        "closed_at": "2012-05-08T05:05:26Z",
        "merged_at": null,
        "body": "Hi all,\n\nI've now managed to add proper SOCKS proxy and HTTPS/SSL proxy support (took me about 6 hours, but was well worth the effort)\n- SOCKS proxy support is done via a slightly modified SocksIpy.\n- All unit tests seem to pass fine (have included tests/test_proxies.py as it's own file, as the test will only pass if you have the necessary proxy servers running - obv.)\n- proxiesDict should be backwards compatible (have tested it with multiple values) - now accepts 'socks4://' and 'socks5'://\n- HTTPS/SSL proxy support uses the _tunnel() method exposed from httplib\n- HTTPS/SSL proxy support forcibly disables SSL certificate validation\n- Has been tested extensively against 'Burp Proxy' and 'dante-server'\n- DNS lookups are still performed by native socket()\n\nThis code is going to be used extensively by one of our clients, so if we find any problems I'll let you know.\n\nHope this helps!\n\nCal\n\n---\n\nExample usage:\n\n```\n\n# SOCKS5 proxy for HTTP/HTTPS\nproxiesDict = {\n    'http' : \"socks5://1.2.3.4:1080\",\n    'https' : \"socks5://1.2.3.4:1080\"\n}\n\n# SOCKS4 proxy for HTTP/HTTPS\nproxiesDict = {\n    'http' : \"socks4://1.2.3.4:1080\",\n    'https' : \"socks4://1.2.3.4:1080\"\n}\n\n# HTTP proxy for HTTP/HTTPS\nproxiesDict = {\n    'http' : \"1.2.3.4:1080\",\n    'https' : \"1.2.3.4:1080\"\n}\n\n\n```\n\ntest_requests.py before modifications:\n\n```\n\nFAILED (failures=1, errors=14)\n\n```\n\ntest_requests.py after modifications:\n\n```\n\nFAILED (failures=1, errors=14)\n\n```\n\nHere is the result of the test_proxies.py (slightly trimmed):\n\n```\n\nHTTPS via SOCKS5\n------------------------------------------------------------\n<br><p>Your IP address is<br><b>173.255.xxx.xxx</b></p>\n\nHTTP via SOCKS5\n------------------------------------------------------------\n<br><p>Your IP address is<br><b>173.255.xxx.xxx</b></p>\n\nHTTPS via HTTP Proxy\n------------------------------------------------------------\n<br><p>Your IP address is<br><b>89.238.xxx.xxx</b></p>\n\nHTTP via HTTP Proxy\n------------------------------------------------------------\n<br><p>Your IP address is<br><b>89.238.xxx.xxx</b></p>\n\nHTTPS via no proxy\n------------------------------------------------------------\n<br><p>Your IP address is<br><b>82.30.xxx.xxx</b></p>\n\nHTTP via no proxy\n------------------------------------------------------------\n<br><p>Your IP address is<br><b>82.30.xxx.xxx</b></p>\n\n\n```\n",
        "comments": 35
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2012-03-09T22:31:39Z",
        "closed_at": "2012-03-16T01:15:28Z",
        "merged_at": "2012-03-16T01:15:28Z",
        "body": "This attempts to fix an issue where encoding of a string might fail when the\nencoding is set to some unknown format. Here we attempt to catch the\nLookupException and subsequently blindly encode the string one final time.\nThat is we call str() over response.content without specifying an encoding.\nThis may still fail in certain cases but does properly handle the case of #338\nby returning the expected string.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 2,
        "changed_files": 3,
        "created_at": "2012-03-08T21:25:34Z",
        "closed_at": "2012-03-08T22:57:58Z",
        "merged_at": "2012-03-08T22:57:58Z",
        "body": "Here's a potential fix for #436 - @RonnyPfannschmidt is this what you had in mind?\n",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 33,
        "deletions": 1,
        "changed_files": 3,
        "created_at": "2012-03-08T19:24:18Z",
        "closed_at": "2012-03-09T16:38:42Z",
        "merged_at": null,
        "body": "Hey there, maintainer dudes,\n\nKeeping track of the setup environments for python 2 and 3 (and keeping them separate)\nwas driving me nuts, so I've added support for testing with tox and nosetests.\n\nIf you have tox installed--\n\n```\n pip install tox\n```\n\nThen for each environment it will build requests into its own virtualenv with its own dependencies, \nrun all the tests, and give you results.\n\nCurrently, this exposes that gevent is outside of the requests setup.py\n(by design, I imagine) so it needs to be included seperately for\ntest_requests_async.py to work without throwing a RunTimeException.  \n\nSome tests in the Python 3 environment fail because \n\nAnd envoy is not in the requirements of setup, despite being referenced in the test cases.\n\nTox is a great way to test on multiple virtual environments (and it interfaces with hudson jenkins too, if that counts as a win).\n\nDanver Braganza\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 35,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2012-03-08T12:46:51Z",
        "closed_at": "2012-03-09T16:07:21Z",
        "merged_at": "2012-03-09T16:07:21Z",
        "body": "Hi,\n\nI recently received [an issue](https://github.com/jgorset/facepy/issues/21) that describes difficulties in using proxies with [Facepy](http://github.com/jgorset/facepy), a Facebook Graph API client that uses requests internally. I would like to keep proxies out of my interface, so I've facilitated the configuration of proxies in requests through the environment variables `HTTP_PROXY` and `HTTPS_PROXY`.\n\nI'm not sure how I might test this feature, but if you have any ideas please let me know and I'll get right to it.\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 53,
        "deletions": 2,
        "changed_files": 3,
        "created_at": "2012-03-07T01:05:38Z",
        "closed_at": "2012-03-09T16:46:36Z",
        "merged_at": null,
        "body": "Added testcase showing a non-standard unicode character (in this case,\nA-umlaut), returned by the server in a redirect, breaks py27 requests.\n\nI have a class of urls which I need to get in py27 which break,\nbecause the server returns a _relative redirect_ with a high unicode\ncharacter in it.  Because of how str and unicode are re-bound in py_27\nmode for requests, this means that unicode is being called on an\nobject that does not implicitly convert to unicode (it has an ord >\n127).\n\nThe other minor change I made is a small hack to remove the unicode-literal u from\ntest_requests_ext.py so it can be run on python3.   \n\nThis fix, which seems to work for me (hurray), is to urllib.quote the\nrelative returned by the server.  This percent-encodes the non-standard\ncharacters in the unicode, and then everything behaves nicely.\n\nAll tests pass for python 2.7.2 and python 3.2.2 on Linux.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 21,
        "deletions": 25,
        "changed_files": 2,
        "created_at": "2012-03-05T17:49:55Z",
        "closed_at": "2012-03-09T16:07:21Z",
        "merged_at": "2012-03-09T16:07:21Z",
        "body": "1. Do not use rstrip() as this would also throw away meaningful whitespaces\n2. Avoid assuming what striplines() considers a line break terminator, the list of those is quite long in Unicode.\n3. Add tests for the above edge cases.\n\nThis should look much better now. The only question I have is whether iter_content() could yield an empty chunk? generate()/generate_chunked() never do but the decoder might. In that case, I'll need to amend this.\n",
        "comments": 10
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2012-02-28T17:15:36Z",
        "closed_at": "2012-03-08T22:58:00Z",
        "merged_at": "2012-03-08T22:58:00Z",
        "body": "To avoid UnicodeDecodeError's like on http://blip.fm/~1abvfu\n\nNote: This doesn't have a test, which sucks, because for the life of me I can't seem to figure out how to trigger this error with httpbin. Maybe flask has better handling of UTF-8 characters than the server used at blip.fm and others? Really not sure.\n\nHere's an ad-hoc test for you:\n\nBefore:\n\n```\n>>> import requests\n>>> requests.head('http://blip.fm/~1abvfu', allow_redirects=True)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"requests/api.py\", line 73, in head\n    return request('head', url, **kwargs)\n  File \"requests/api.py\", line 39, in request\n    return s.request(method=method, url=url, **kwargs)\n  File \"requests/sessions.py\", line 200, in request\n    r.send(prefetch=prefetch)\n  File \"requests/models.py\", line 559, in send\n    self._build_response(r)\n  File \"requests/models.py\", line 232, in _build_response\n    url = urljoin(r.url, url)\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/urlparse.py\", line 219, in urljoin\n    params, query, fragment))\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/urlparse.py\", line 184, in urlunparse\n    return urlunsplit((scheme, netloc, url, query, fragment))\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/urlparse.py\", line 190, in urlunsplit\n    url = '//' + (netloc or '') + url\nUnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 62: ordinal not in range(128)\n```\n\nAfter:\n\n```\n>>> import requests\n>>> requests.head('http://blip.fm/~1abvfu', allow_redirects=True)\n<Response [200]>\n```\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-02-23T16:29:48Z",
        "closed_at": "2012-02-26T04:15:57Z",
        "merged_at": "2012-02-26T04:15:57Z",
        "body": "A typo causing `TypeError: str() takes at most 1 argument (2 given)`.\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 33,
        "deletions": 22,
        "changed_files": 1,
        "created_at": "2012-02-22T15:19:15Z",
        "closed_at": "2012-05-08T05:04:51Z",
        "merged_at": null,
        "body": "This a patch for issue #GH-445\n\nPerfomance improvements are left to be done. For example, only recalculating when `request.data` or `request.files` have changed.\n- File pointers are reset to position 0 to re-read files, when `_encode_body` is called several times.\n- _enc_data is recalculated using data which might have changed.\n",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-02-21T23:28:58Z",
        "closed_at": "2012-02-26T04:14:11Z",
        "merged_at": "2012-02-26T04:14:11Z",
        "body": "This fix resolves issues #440 and #286 by allowing the '=' character in cookie values.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 31,
        "deletions": 8,
        "changed_files": 2,
        "created_at": "2012-02-19T10:02:19Z",
        "closed_at": "2012-02-20T17:07:17Z",
        "merged_at": "2012-02-20T17:07:17Z",
        "body": "Addresses #439, along a test.\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 7,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2012-02-19T09:58:46Z",
        "closed_at": "2012-02-20T17:04:35Z",
        "merged_at": null,
        "body": "There seems to be some fiddling to be done before the tests can be run successfully right after a clone. Changes in this pull request is how I got them to work on my clone.\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 1,
        "changed_files": 3,
        "created_at": "2012-02-16T22:33:31Z",
        "closed_at": "2012-02-20T17:21:43Z",
        "merged_at": "2012-02-20T17:21:43Z",
        "body": "This pull request handles part of the problem raised in issue #380. Specifically, urls whose scheme is not HTTP or HTTPS will throw ValueErrors.\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 10,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2012-02-15T21:59:32Z",
        "closed_at": "2012-02-20T17:32:14Z",
        "merged_at": null,
        "body": "None should be able to be passed as a value in a header. This particular\nchange means that the header will not be passed through to the remote\ndestination. This fixes issue #345.\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2012-02-15T12:59:03Z",
        "closed_at": "2012-02-20T17:34:06Z",
        "merged_at": null,
        "body": "When running `make test`, several tests failed with a similar error:\n\n``` bash\n$ make test\nnosetests --with-color ./tests/*\n............EEE..............................................EEE...................................................EEE..................................\n======================================================================\nERROR: test_POSTBIN_GET_POST_FILES (test_requests_async.RequestsTestSuite)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/usr/lib/python2.7/unittest/case.py\", line 327, in run\n    testMethod()\n  File \"/home/christopher/code/requests/tests/test_requests.py\", line 294, in test_POSTBIN_GET_POST_FILES\n    with open('test_requests.py') as f:\nIOError: [Errno 2] No such file or directory: 'test_requests.py'\n\n(...)\n\n----------------------------------------------------------------------\nRan 152 tests in 11.122 seconds\nFAILED (errors=9)\n```\n\nThe problem was that the current working directory was the root of the project, so calling `open('test_requests.py')` failed because it's now in the tests directory.\n\nAfter the fix:\n\n``` bash\n$ make test\nnosetests --with-color ./tests/*\n................................................................................................................................................................................................................................................................................................................\n----------------------------------------------------------------------\nRan 304 tests in 19.953 seconds\nOK\n```\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 45,
        "deletions": 11,
        "changed_files": 4,
        "created_at": "2012-02-15T01:16:31Z",
        "closed_at": "2012-02-15T06:00:59Z",
        "merged_at": "2012-02-15T06:00:59Z",
        "body": "My [previous branch](https://github.com/mgiuca/requests/tree/py3-uri-encoding) fixed URI cleanup for path components. This branch extends that fix to address Issue #429, which requires URI cleanup for the query part of the URI.\n\nI have added comprehensive tests for the sanitisation of the query part of the URI, and rearranged the call to `utils.requote_path` so that it is now applied to the whole URI after it is constructed, and not just the path. Note that this required that all URI components be converted to UTF-8 before the URI is reconstructed (since the URI is now sanitised _after_ reconstruction). I have renamed `utils.requote_path` to `requote_uri` to reflect its new role.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-02-14T10:31:45Z",
        "closed_at": "2012-02-15T06:08:21Z",
        "merged_at": "2012-02-15T06:08:21Z",
        "body": "Discussion on commit Lukasa/requests@f72c13ffdad47ff684d102b6d9fb6122db899891 suggested it might be better to keep the characters that are disallowed in the RFC separate from those that are. This is mostly stylistic, so you can take it or leave it.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 74,
        "deletions": 9,
        "changed_files": 3,
        "created_at": "2012-02-14T02:16:51Z",
        "closed_at": "2012-02-14T09:49:09Z",
        "merged_at": "2012-02-14T09:49:09Z",
        "body": "Fixes for Issue #369, as described in my [comment on that thread](https://github.com/kennethreitz/requests/issues/369#issuecomment-3953802).\n",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 34,
        "deletions": 18,
        "changed_files": 2,
        "created_at": "2012-02-12T12:43:50Z",
        "closed_at": "2012-02-20T17:35:04Z",
        "merged_at": null,
        "body": "fixed a bug: Requests doesn't allow multiple values for a single key if the request is with files.\n\nThis fix is not elegant though...\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2012-02-09T02:53:38Z",
        "closed_at": "2012-02-15T08:06:03Z",
        "merged_at": null,
        "body": "#336 fixed.\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2012-02-06T12:42:45Z",
        "closed_at": "2012-02-06T17:08:04Z",
        "merged_at": "2012-02-06T17:08:03Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2012-02-06T11:47:35Z",
        "closed_at": "2012-02-12T10:14:03Z",
        "merged_at": null,
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2012-02-05T03:27:08Z",
        "closed_at": "2012-02-12T10:16:48Z",
        "merged_at": "2012-02-12T10:16:48Z",
        "body": "Since requests 0.10.1 dropped Python5 support, to catch an exception and\nstore the exception object in a variable the \"as\" keyword can be used so\nPython3 will not raise a SyntaxError.\n\nKind regards,\nDaniele Tricoli\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2012-02-05T02:58:02Z",
        "closed_at": "2012-02-05T19:00:40Z",
        "merged_at": "2012-02-05T19:00:40Z",
        "body": "Use basestring instead of str to determine when to return headers as-is. This makes sure that unicode instances aren't enumerated.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2012-01-30T13:02:58Z",
        "closed_at": "2012-01-30T14:41:17Z",
        "merged_at": "2012-01-30T14:41:17Z",
        "body": "I hope I\u2019m not overlooking something regarding the two try-except blocks, but I can\u2019t think of a scenario where they\u2019d make any difference. Thanks.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2012-01-30T07:28:31Z",
        "closed_at": "2012-01-30T14:33:37Z",
        "merged_at": "2012-01-30T14:33:36Z",
        "body": "Previously this URL would not work:\n\n```\nhttp://example.com?foo=bar\n```\n\nBut this URL would work:\n\n```\nhttp://example.com/?foo=bar\n```\n\nEven though a slash is required for a valid URL, it is a common use case\nfor the slash to be left out, so it would be a good idea to account for this.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2012-01-26T19:44:48Z",
        "closed_at": "2012-01-27T17:16:58Z",
        "merged_at": "2012-01-27T17:16:58Z",
        "body": "This adds a failing test for unicode headers in python 2.x (I've tested python 2.6) \nI've tried to fix this the original problem is that in [utils.py (line 149)](https://github.com/kennethreitz/requests/blob/develop/requests/utils.py#L149) doesn't check for unicode, or rather that it doesn't import the str and bytes definitions from compat). However, you _might_ want to change the order of the [definitions of str and bytes for python 2 in compat](https://github.com/kennethreitz/requests/blob/develop/requests/compat.py#L89), because, at the moment, they end up both being defined as unicode.\nRight, so, if one fixes this (I've got the code if you want that too), and then there ends up being a problem with gevent's socket just calling data.decode(), which fails on my linux box, because that ends up trying to convert everything to ascii (which seems to be default behaviour).\nI can work around this by making sure I only ever pass py2's strs as keys and values, but I'd like to make it work if you can point me in the right direction.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2012-01-26T02:22:51Z",
        "closed_at": "2012-01-26T06:40:30Z",
        "merged_at": "2012-01-26T06:40:30Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 80,
        "deletions": 31,
        "changed_files": 14,
        "created_at": "2012-01-26T00:56:22Z",
        "closed_at": "2012-02-12T10:15:09Z",
        "merged_at": null,
        "body": "I noticed yesterday that requests doesn't work on Python 2.5 ( or Jython ). These commits make running the tests slightly easier to setup.\n\nThe core tests now pass on cPython 2.5. All tests (core, async, ext) pass on cPython 2.6. Working on changes to support Jython (currently one failing test in test_safe_mode).\n\nIf you want me to rework anything, let me know. But I really would like to re-enable Python 2.5 support.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 148,
        "deletions": 86,
        "changed_files": 2,
        "created_at": "2012-01-24T20:50:08Z",
        "closed_at": "2012-01-25T14:27:09Z",
        "merged_at": "2012-01-25T14:27:09Z",
        "body": "Almost all are failing... Need some feedback if it makes any sense.\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2012-01-24T20:25:16Z",
        "closed_at": "2012-01-25T14:27:08Z",
        "merged_at": "2012-01-25T14:27:08Z",
        "body": "In the case of using requests.Request or async.request the pre_request hook wasn't very useful because it was called when the request was made rather than when the request was being sent. I moved the dispatch_hook call to just before the call out to conn.urlopen in request.send. Considering that multiple hooks was implemented instead of Response.response_time, I think that this is important because it allows users to time responses. Example: https://gist.github.com/1667527\n",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 10,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2012-01-22T12:50:22Z",
        "closed_at": "2012-01-23T07:56:44Z",
        "merged_at": null,
        "body": "select only goes up to 1024 FDs.  So once we have used more than that,\nthis would fail.  poll (or epoll) fixes this.  This solution uses poll\nand seems to work.\n\nMy only test has been using a single session to fetch 10**4 pages a few\ntimes.\n\nIs there a more robust testing tool (framework?) that I should use.\n\nPS:  Ken et al,  this is my first attempt at a pull request, so if this is not\nthe right way to do it, please educate me.  I have several more suggested\nchanges that I'd like to put forward for your consideration.\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-01-21T19:06:56Z",
        "closed_at": "2012-01-23T07:56:55Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2012-01-21T10:09:51Z",
        "closed_at": "2012-01-21T11:44:51Z",
        "merged_at": null,
        "body": "Ref. HyperText Transfer Protocol, [section 3.7.1](http://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html#sec3.7.1) on Canonicalization and Text Defaults.\n",
        "comments": 11
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2012-01-20T21:35:47Z",
        "closed_at": "2012-01-21T13:13:15Z",
        "merged_at": "2012-01-21T13:13:15Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 26,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2012-01-17T23:47:44Z",
        "closed_at": "2012-01-23T07:59:22Z",
        "merged_at": null,
        "body": "Added requests.Response.response_time to keep track of how long requests take. The user could keep track of this himself except for when he is using requests.async. \n",
        "comments": 10
    },
    {
        "merged": true,
        "additions": 41,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2012-01-17T16:46:28Z",
        "closed_at": "2012-01-19T02:55:12Z",
        "merged_at": "2012-01-19T02:55:12Z",
        "body": "this branch adds custom reading for chunked responses\nthat way the iter_content function has chunk boundaries as additional boundaries,\n\nadditionally iter_lines will no longer keep a completed line in pending\n\nthat way using requests for chunk streamed update notifications from couchdb gets actually usefull\n\nthere are probably some rough edges i need to check, but the basic stuff works,\nplease review and yell at me\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 19,
        "deletions": 11,
        "changed_files": 1,
        "created_at": "2012-01-16T18:32:58Z",
        "closed_at": "2012-01-20T20:54:22Z",
        "merged_at": null,
        "body": "use of new HTTPBIN_HOST environment variable\nplatform specific import of envoy\n\nCaution, it's not tested under Linux.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2012-01-13T17:40:34Z",
        "closed_at": "2012-01-13T22:38:09Z",
        "merged_at": "2012-01-13T22:38:09Z",
        "body": "I read issue #354 and it was simple enough so I added the prefetch doc line to api.py. I believe that should take care of the issue.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-01-10T23:57:25Z",
        "closed_at": "2012-01-12T20:52:03Z",
        "merged_at": "2012-01-12T20:52:03Z",
        "body": "When there's a query string in the request URL, we need to separate it from the parsed path with a question mark when constructing the digest input.\n\n(Sorry, I didn't add a test case for the problem.)\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-01-10T15:54:02Z",
        "closed_at": "2012-01-10T19:07:46Z",
        "merged_at": "2012-01-10T19:07:46Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-01-10T10:20:24Z",
        "closed_at": "2012-01-10T19:10:02Z",
        "merged_at": "2012-01-10T19:10:02Z",
        "body": "Old code had a name error in it.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2012-01-10T10:13:07Z",
        "closed_at": "2012-01-10T19:08:53Z",
        "merged_at": "2012-01-10T19:08:53Z",
        "body": "Having just a warning when an exception is raised in a hook is unhelpful because the location of the error is not included. Printing the entire traceback fixes that.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-01-09T05:47:35Z",
        "closed_at": "2012-01-10T19:11:01Z",
        "merged_at": "2012-01-10T19:11:01Z",
        "body": "The `request` method of `Session` class does not take a `session` argument. But `api.request` does. So, it has to be popped before you can send the whole `kwargs` dict to `Session.request` method.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2012-01-06T15:20:39Z",
        "closed_at": "2012-01-06T16:20:49Z",
        "merged_at": "2012-01-06T16:20:49Z",
        "body": "...a schema.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 0,
        "changed_files": 5,
        "created_at": "2012-01-05T04:10:35Z",
        "closed_at": "2012-01-06T06:04:11Z",
        "merged_at": "2012-01-06T06:04:11Z",
        "body": "I'm not 100% on:\n1. The name of the setting. Settled on `eager_mode`.\n2. The placing of the `raise_for_status()` method call. Settled on the very end of `Request.send()`.\n\nLet me know if this is something you guys are interested in adding or not. It's pretty lightweight and I've included a test case.\n\n_PS: the test `test_invalid_content` was failing before and after I added this feature._\n",
        "comments": 22
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 23,
        "changed_files": 1,
        "created_at": "2012-01-02T21:27:17Z",
        "closed_at": "2012-01-06T06:11:31Z",
        "merged_at": "2012-01-06T06:11:31Z",
        "body": "Fixes universal line ending handling, but takes away ability to specyfy\ncustom line endings.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 26,
        "deletions": 31,
        "changed_files": 2,
        "created_at": "2011-12-31T03:19:42Z",
        "closed_at": "2011-12-31T17:42:34Z",
        "merged_at": "2011-12-31T17:42:34Z",
        "body": "...press.\n\nstream_decompress will now iterate over the raw data if there is a problem with decompression\nRemove gzip decoding from Response.content, as urllib3 was doing it anyway.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2011-12-22T21:53:36Z",
        "closed_at": "2011-12-22T23:17:45Z",
        "merged_at": "2011-12-22T23:17:45Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 26,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2011-12-21T05:16:06Z",
        "closed_at": "2011-12-28T09:20:24Z",
        "merged_at": null,
        "body": "Quick fix for issue #30. Note that this doesn't do hostname matching when verifying, although this is an issue in urllib3 - maybe it should use [`backports.ssl_match_hostname`](http://pypi.python.org/pypi/backports.ssl_match_hostname/) if available.\n\nFor example, you can set the global `ca_certs` and enable cert verification with\n\n```\nimport requests\n\nrequests.defaults.defaults['verify_cert'] = True\nrequests.defaults.defaults['ca_certs'] = '/etc/ssl/certs/ca-certificates.crt'\n```\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 23,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2011-12-20T07:05:47Z",
        "closed_at": "2011-12-22T16:56:05Z",
        "merged_at": "2011-12-22T16:56:05Z",
        "body": "Currently, if the response does not terminate with a newline, iter_lines truncates the trailing remainder.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2011-12-17T19:56:12Z",
        "closed_at": "2011-12-19T00:14:56Z",
        "merged_at": "2011-12-19T00:14:56Z",
        "body": "A new class is auth.py adds the `Proxy-Authorization` header to a Request object.\n\nIf a proxy is specified in the request, the `send()` method is going to look for authentication info in the proxy URL string and set up the proxy auth from there.\n\nNone of this works with out the changes to urllib3 in #293, however.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 17,
        "changed_files": 10,
        "created_at": "2011-12-11T08:02:29Z",
        "closed_at": "2011-12-11T16:04:27Z",
        "merged_at": "2011-12-11T16:04:26Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2011-12-09T07:49:39Z",
        "closed_at": "2011-12-09T16:42:19Z",
        "merged_at": "2011-12-09T16:42:19Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2011-11-29T06:58:22Z",
        "closed_at": "2011-11-29T08:06:54Z",
        "merged_at": "2011-11-29T08:06:54Z",
        "body": "The existing behavior was a little opaque for me--I was making a PUT request which returned a HTTP 204 with a 0-byte body. I was never reading the body and was wondering why my connections were not being reused.\n\nThanks so much for the requests library--we use it at App.net and absolutely love it. I threw away a big spaghetti'd-out mess of a homegrown urllib2 wrapper and haven't looked back.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2011-11-25T03:18:59Z",
        "closed_at": "2011-11-26T04:04:24Z",
        "merged_at": "2011-11-26T04:04:24Z",
        "body": "This allows usage of an existing session to make a request with the request and the get, post etc. function.\n\nI made this so that it is easier to create async requests with pre-existing sessions. Currently, we have to do\n\n```\nasync.map([my_session.get(url, return_response=False, prefetch=True) for url in urls])\n```\n\nI got the `return_response` and `prefetch` arguments from inspecting the source of async module. This isn't very pleasant.\n\nWith the proposed simple change in this pull request, one can do\n\n```\nasync.map([async.get(url, use_session=my_session) for url in urls])\n```\n\nwhich feels more natural.\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2011-11-25T02:20:07Z",
        "closed_at": "2011-11-26T15:09:38Z",
        "merged_at": "2011-11-26T15:09:38Z",
        "body": "Hey Kenneth,\n\nIf I call `async.map` this way\n\n```\nasync.map(async.get(u) for u in urls)\n```\n\nI get an empty list as the list of responses. But it works if I do\n\n```\nasync.map([async.get(u) for u in urls])\n```\n\nThe proposed change fixes this.\n\nIf in case, this kind of usage is not intended, i.e., if only a list has to be passed to the `async.map` function, please make it clear in the documentation. Currently it says \"A _collection_ of Requests objects\" which does not necessarily imply a _list_.\n\nThanks.\n\nNote: I just hacked up a simple solution in the github editor, you might want to ignore it and fix it up your style :)\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2011-11-20T09:21:13Z",
        "closed_at": "2011-11-26T15:10:08Z",
        "merged_at": "2011-11-26T15:10:08Z",
        "body": "Logging should display the query string as well, shouldn't it?\n\nTest script:\n\n``` python\nimport requests\nimport sys\n\nmy_config = {'verbose': sys.stderr}\nmy_params = {'q': 'test'}\nr = requests.get('http://www.google.de/search', params=my_params, config=my_config)\n```\n\nBefore:\n`2011-11-20T10:13:37.502444   GET   http://www.google.de/search`\nAfter:\n`2011-11-20T10:14:02.652295   GET   http://www.google.de/search?q=test`\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 30,
        "deletions": 1,
        "changed_files": 3,
        "created_at": "2011-11-18T22:58:43Z",
        "closed_at": "2011-11-19T05:26:08Z",
        "merged_at": "2011-11-19T05:26:08Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2011-11-18T22:53:41Z",
        "closed_at": "2011-11-19T05:26:11Z",
        "merged_at": "2011-11-19T05:26:11Z",
        "body": "Current Session class allows to set a parameter hooks, but this parameter is not used in requests.\nThis change fixes that by using Session's hooks as defaults for every requests, letting override per request.\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 91,
        "deletions": 79,
        "changed_files": 5,
        "created_at": "2011-11-17T11:47:29Z",
        "closed_at": "2011-11-26T15:14:27Z",
        "merged_at": "2011-11-26T15:14:27Z",
        "body": "My attempt to address #275.\n\nThis seems a lot more explicit/clean, though I confess that I'm not aware of the considerations that led to the current implementation.\n\nI also think this is a good first step towards implementing OAuth support (#65).\n",
        "comments": 12
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2011-11-17T10:32:21Z",
        "closed_at": "2011-11-18T20:06:40Z",
        "merged_at": "2011-11-18T20:06:40Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2011-11-17T00:04:53Z",
        "closed_at": "2011-11-18T19:48:49Z",
        "merged_at": "2011-11-18T19:48:49Z",
        "body": "The Request class currently does a urllib.quote(urllib.unquote(path)) cycle to ensure consistent quoting on the input URL.  Unfortunately this breaks paths that contain quoted slashes (i.e. \"%2F\") since they get unquoted by urllib.unquote but are re-quoted by urllib.quote.\n\nThis patch adds a requote_path() function that does the same thing but is careful not to destroy quoted slashes.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2011-11-16T04:06:32Z",
        "closed_at": "2011-11-18T20:34:07Z",
        "merged_at": "2011-11-18T20:34:07Z",
        "body": "- added support for explicit filenames\n- use \";\" as cookie separator for multiple values\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2011-11-15T15:16:15Z",
        "closed_at": "2012-03-31T03:32:47Z",
        "merged_at": null,
        "body": "E.g., after a POST with a 302 response, we should do a GET. This is how all browsers do it for historical reasons. And some websites even don't work otherwise.\n\nSee also: http://stackoverflow.com/questions/8138137/http-post-request-receives-a-302-should-the-redirect-request-be-a-get\n",
        "comments": 19
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2011-11-15T07:53:52Z",
        "closed_at": "2011-11-15T13:58:10Z",
        "merged_at": "2011-11-15T13:58:10Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2011-11-14T09:04:19Z",
        "closed_at": "2011-11-14T21:42:18Z",
        "merged_at": "2011-11-14T21:42:18Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2011-11-14T08:45:15Z",
        "closed_at": "2011-11-14T21:42:24Z",
        "merged_at": "2011-11-14T21:42:24Z",
        "body": "> > > requests.codes['temporary_redirect']\n> > > 307\n> > > requests.codes.teapot\n> > > 418\n> > > requests.codes['\\o/']\n> > > 200\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2011-11-14T07:15:36Z",
        "closed_at": "2011-11-14T21:43:01Z",
        "merged_at": "2011-11-14T21:43:01Z",
        "body": "Removed some closed issues from todo and added a reference to [requests-oauth](https://github.com/maraujop/requests-oauth) in quickstart. \n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2011-11-13T02:16:29Z",
        "closed_at": "2011-11-13T03:52:05Z",
        "merged_at": "2011-11-13T03:52:05Z",
        "body": "> .>\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2011-11-10T23:34:27Z",
        "closed_at": "2011-11-11T22:56:17Z",
        "merged_at": "2011-11-11T22:56:17Z",
        "body": "",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2011-11-10T23:14:46Z",
        "closed_at": "2011-11-12T15:19:04Z",
        "merged_at": "2011-11-12T15:19:11Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 19,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2011-11-08T07:39:43Z",
        "closed_at": "2011-11-10T06:01:50Z",
        "merged_at": "2011-11-10T06:01:50Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 29,
        "deletions": 5,
        "changed_files": 5,
        "created_at": "2011-11-07T23:42:54Z",
        "closed_at": "2011-11-10T06:16:33Z",
        "merged_at": "2011-11-10T06:16:33Z",
        "body": "Hello!\n\nWhile doing some work with a RESTful API, I noticed that the otherwise excellent requests library does not seem to support the OPTIONS request method. The way it should be handled apparently is the same as the HEAD method. So, this change here merely copies the various definitions and references to the HEAD method and changes it to OPTIONS.\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2011-11-03T06:36:05Z",
        "closed_at": "2011-11-05T03:32:04Z",
        "merged_at": "2011-11-05T03:32:04Z",
        "body": "The `auth.dispatch` method creates a modified `auth` tuple. When the tuple is passed to a new request (as a result of a redirect) then the new `auth` is incorrect and authorization will fail. This one-liner simply resets the `auth` tuple to the original tuple.\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 125,
        "deletions": 3,
        "changed_files": 4,
        "created_at": "2011-10-31T08:07:55Z",
        "closed_at": "2011-11-05T03:30:42Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2011-10-30T12:24:38Z",
        "closed_at": "2011-11-05T03:30:29Z",
        "merged_at": null,
        "body": "`params` and `data` are marked as dictionaries in the constructor prototype. However `_encode_params` returns lists or None sometimes.\n\nThere is a big inconsistency in `_encode_params` that could affect hooks. It's affecting me in request-oauth-hook. Thus I have to do these type of checkings:\nhttps://github.com/maraujop/requests-oauth-hook/blob/dev/oauth_hook/hook.py#L184\n\nSo if params is a dictionary, I understand it should be an empty dictionary or a filled dictionary, but not a list or None. The same happens to data.\n\nI haven't been able to run `requests_tests` sorry, they failed before I did a change to the code. This will likely affect you in other parts of the code. \n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2011-10-24T21:34:32Z",
        "closed_at": "2011-10-25T00:54:05Z",
        "merged_at": "2011-10-25T00:54:05Z",
        "body": "Pull request for Issue #208\n\nSorry it's from master rather then develop (my git fu is lacking).\n\nThis patch aims to emulate the Python 2.6 behavior as closely as possible.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 394,
        "deletions": 345,
        "changed_files": 11,
        "created_at": "2011-10-23T14:05:46Z",
        "closed_at": "2011-10-23T19:18:34Z",
        "merged_at": "2011-10-23T19:18:34Z",
        "body": "- Remove auth handlers \u2014\u00a0create headers by hand.\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 172,
        "deletions": 134,
        "changed_files": 7,
        "created_at": "2011-10-22T17:36:28Z",
        "closed_at": "2011-10-22T22:16:50Z",
        "merged_at": "2011-10-22T22:16:50Z",
        "body": "The primary API will create and discard sessions.\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2011-10-21T06:59:13Z",
        "closed_at": "2011-10-21T14:24:11Z",
        "merged_at": "2011-10-21T14:24:11Z",
        "body": "I added a sentence to advanced.rst to help future readers avoid the confusion I expressed in IRC today.\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 937,
        "deletions": 0,
        "changed_files": 8,
        "created_at": "2011-10-20T22:44:52Z",
        "closed_at": "2012-04-23T02:35:38Z",
        "merged_at": null,
        "body": "It took me a while to integrate the changes in develop (waited too long). But I created this new feature branch now which I will use to work on the unit tests. So might be best to leave it open until I have reached a good level of coverage.\n",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2011-10-20T10:53:19Z",
        "closed_at": "2011-10-20T12:46:17Z",
        "merged_at": "2011-10-20T12:46:17Z",
        "body": "Read through the docs, found a broken link. Slightly annoying (two out of ten on the ISO scale of annoyance) so decided to fix it.\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 31,
        "deletions": 8,
        "changed_files": 2,
        "created_at": "2011-10-15T21:06:50Z",
        "closed_at": "2012-01-23T07:57:07Z",
        "merged_at": null,
        "body": "A new setting is added: `async_module`, which defaults to 'gevent'. If gevent is not found eventlet is tried in turn, and if 'eventlet' is set explicitly, gevent will not be used.\n\nExample to use eventlet:\n\n```\nfrom requests.config import settings\nsettings.async_module = 'eventlet'\nfrom requests import async\n....\n```\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 75,
        "deletions": 35,
        "changed_files": 3,
        "created_at": "2011-10-15T18:17:54Z",
        "closed_at": "2011-10-15T21:01:26Z",
        "merged_at": null,
        "body": "Hi,\n\nSince Gevent and Eventlet are similar I thought I'd add support for the latter :-)\n\nSince both need monkeypatching things can get a bit tricky. Please see my proposal in the pull request commit.\n\nWith this approach someone which would like to use Gevent would do:\n\n`from requests.async import gevent as async`\n\nand someone who want to use Eventlet would do:\n\n`from requests.async import eventlet as async`\n\nHow does it sound look to you? Any suggestion?\n\nIf you find it ok I'll complete the pull request with required changes to documentation.\n\nCheers,\n",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 26,
        "deletions": 47,
        "changed_files": 2,
        "created_at": "2011-10-15T14:00:27Z",
        "closed_at": "2011-10-15T15:56:26Z",
        "merged_at": "2011-10-15T15:56:26Z",
        "body": "Powered by httpbin.\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 119,
        "deletions": 30,
        "changed_files": 6,
        "created_at": "2011-10-13T23:57:04Z",
        "closed_at": "2011-10-14T01:15:19Z",
        "merged_at": "2011-10-14T01:15:19Z",
        "body": "``` python\n# -*- coding: utf-8 -*-\n\nimport requests\nfrom requests import async\n\nurls = [\n    'http://www.readability.com',\n    'http://tablib.org',\n    'http://httpbin.org',\n    'http://python-requests.org',\n    'http://kennethreitz.com'\n]\n\nurls = urls + urls\n\n```\n\n**Standard (14.125s)**\n\n``` python\nfor url in urls:\n     r = requests.get(url)\n     r.content\n```\n\n**Standard + Gevent (1.589s)**\n\n``` pycon\n>>> rs = [async.get(u) for u in urls]\n>>> async.map(rs)\n[<Response [200]>, <Response [200]>, ...]\n```\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1850,
        "deletions": 230,
        "changed_files": 23,
        "created_at": "2011-10-13T23:42:22Z",
        "closed_at": "2011-11-10T03:05:44Z",
        "merged_at": "2011-11-10T03:05:44Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2011-10-10T19:20:51Z",
        "closed_at": "2011-11-13T05:38:16Z",
        "merged_at": null,
        "body": "Most of the values in the `files` dictionary are open file objects, which means they have a `name` attribute. Requests, though, sends the key name instead of file name. This can cause some unexpected shit if the server decides to use that information.\n\nNote: I'm not sure whether this change will work on Python <= 2.6.\n",
        "comments": 8
    },
    {
        "merged": false,
        "additions": 25,
        "deletions": 4,
        "changed_files": 4,
        "created_at": "2011-10-05T18:39:59Z",
        "closed_at": "2011-10-09T11:06:15Z",
        "merged_at": null,
        "body": "Fixes issue #183\n\nI did this on top of the 0.6.1 release because I need to use it in production.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 25,
        "deletions": 27,
        "changed_files": 2,
        "created_at": "2011-09-26T09:03:10Z",
        "closed_at": "2011-10-03T14:11:48Z",
        "merged_at": "2011-10-03T14:11:48Z",
        "body": "We were only quoting path but params and query also need to be encoded. Everything is now in utils.py / get_clean_url (feel free to rename the function if you wish).\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2011-09-22T10:49:03Z",
        "closed_at": "2011-09-22T13:23:37Z",
        "merged_at": "2011-09-22T13:23:37Z",
        "body": "I ran the pep8 checker (version 0.6.1) on the code base and tried to clean up as many pep8 errors as I could.  Everything except line-width errors are gone (I was worried about messing up the documentor since I.haven't fiddled with it).  Code base didn't have very many pep8 errors (awesome!).\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2011-09-22T09:16:50Z",
        "closed_at": "2011-09-22T13:25:12Z",
        "merged_at": "2011-09-22T13:25:12Z",
        "body": "For example, this link returns a binary charset that is an unknown python encoding.\n\nhttp://cdn.blipstatic.com/images/blip/blipIcon.png\n-> Content-Type: image/png; charset=binary\n\nIn that case we simply return the raw content.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 138,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2011-09-17T17:02:41Z",
        "closed_at": "2011-09-17T20:26:30Z",
        "merged_at": "2011-09-17T20:26:30Z",
        "body": "Successively adding unit tests for request here. Reopened from [here](https://github.com/kennethreitz/requests/pull/166).\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 14,
        "deletions": 5,
        "changed_files": 3,
        "created_at": "2011-09-16T10:09:01Z",
        "closed_at": "2011-09-23T16:05:25Z",
        "merged_at": null,
        "body": "This change adds a new attribute to the Response objects,\nstatus_msg.  This typically returns something like \"OK\"\nfor 200 responses or \"Not Found\" for 404 responses.\n\nThe status message can provide some additional semantic information\nabout the response outside of the response body and response headers.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 71,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2011-09-15T22:44:14Z",
        "closed_at": "2011-09-16T02:30:33Z",
        "merged_at": "2011-09-16T02:30:33Z",
        "body": "This might be somewhat related to issue #153. I think it would make sense to split up testing into a unit testing and an integration testing part (loosely defined). In the unit tests the actual methods are tested with everything mocked out. This way it can be assured that the respective external methods are always called with the right arguments. In the integration testing suite it is allowed to call external entities (like `httpbin.org`) for testing the overall function. So I just moved the existing tests there.\n\nI have restructured the tests organization a bit and added some basic unit tests for the `api` module. However I would like to get your feedback on this, before going on. As this will definitely be some work and take a while to reach a somewhat good level of coverage.\n",
        "comments": 8
    },
    {
        "merged": false,
        "additions": 23,
        "deletions": 11,
        "changed_files": 3,
        "created_at": "2011-09-15T18:21:00Z",
        "closed_at": "2011-09-16T16:48:06Z",
        "merged_at": null,
        "body": "`models.Response` can't easily be subclassed (I'm making the assumption that there isn't a way that I don't know about)\n\nI'd like to be able to pass a subclass of `models.Response` to `get`, `post` etc. I know there is a `response` hook however I don't want to do something like `response.__class__ = MyResponse` or add custom methods to the `Response` instance one by one. Being able to subclass would be much cleaner.\n",
        "comments": 14
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2011-09-15T09:58:27Z",
        "closed_at": "2011-09-15T14:07:14Z",
        "merged_at": "2011-09-15T14:07:14Z",
        "body": "This issue is fixed in Python 2.7 (http://bugs.python.org/issue918368), but here is the fix for requests.\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 514,
        "deletions": 191,
        "changed_files": 19,
        "created_at": "2011-09-08T23:07:28Z",
        "closed_at": "2011-10-22T23:46:50Z",
        "merged_at": null,
        "body": "A case can arise where a GET request, with params,  receives a 302\nredirect and the subsequent request has param garbase appended to the\nurl.\n\nExample:\n\n```\nclient> GET /some/url?id=1 HTTP/1.1\nclient> Host: example.com\n\nserver< HTTP/1.1 302 Moved Temporarily\nserver< Location: http://example.com/some/url?id=1&extra_data=2\n\n## this is the bad request right here. Note the [('id', 1)] stuck on\n# the end\nclient> GET /some/url?id=1&extra_data=2&[('id', 1)] HTTP/1.1.\nclient> Host: example.com\n\n# the server of course doesn't like it\nserver< HTTP/1.0 400 Bad request.\n```\n\nThis issue is caused by the conditional branch in _encode_params for the\nsecond request not urlencoding the list of tuples for the\nRequest._enc_params attribute.\n\ngithub note: possible fix for kennethreitz/requests#157\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 69,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2011-09-04T16:28:13Z",
        "closed_at": "2011-09-05T20:39:10Z",
        "merged_at": null,
        "body": "Make it possible to not load the whole response into memory at once.  This is especially helpful if you download huge responses from the interwebs.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2011-09-02T13:18:30Z",
        "closed_at": "2011-09-05T20:22:59Z",
        "merged_at": "2011-09-05T20:22:59Z",
        "body": "Only the path should be unquoted/quoted (not the query, otherwise it makes a wrong redirection).\nFor example if you have:\n\n```\nLocation: /test?foo=bar\n```\n\nOnly /test should be unquoted + quoted, not the query string.\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 8,
        "changed_files": 3,
        "created_at": "2011-08-31T08:44:28Z",
        "closed_at": "2011-09-05T20:29:46Z",
        "merged_at": null,
        "body": "- Moved tests into .test submodule. As you can see instead of `import requests` i used `import __init__ as requests` \u2014 this will work in the same way. Some relative import magic might have been used but AFAIK it won't work on python 2.5\n- Changed `open('test_requests.py')` to `StringIO('Test.')` \u2014\u00a0this will always work and behave properly. Using plain file open might not work if user is testing requests from some different location (e.g. test module after install via pip.) Although it is possible to make usual file open work by some clever path calculations but i'm not sure if this is really needed.\n- Added additional try/except during json import to ensure proper import.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2011-08-30T10:04:21Z",
        "closed_at": "2011-08-31T03:58:37Z",
        "merged_at": "2011-08-31T03:58:37Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 14,
        "deletions": 2,
        "changed_files": 3,
        "created_at": "2011-08-29T16:03:48Z",
        "closed_at": "2011-09-03T15:45:12Z",
        "merged_at": null,
        "body": "This patch allow you turn off allow_redirects for GET or HEAD methods. \n",
        "comments": 11
    },
    {
        "merged": true,
        "additions": 123,
        "deletions": 5,
        "changed_files": 4,
        "created_at": "2011-08-24T03:47:58Z",
        "closed_at": "2011-09-05T20:27:49Z",
        "merged_at": "2011-09-05T20:27:49Z",
        "body": "For Issue #97. Once you create a request, just run r.request.curl for the curl command. For example: \n\n``` python\n>>> import requests\n>>> r = requests.get(\"http://httpbin.org\");\n>>> r.request.curl\n'curl -L -X GET -H \"Accept-Encoding:gzip\" -H \"User-Agent:python-requests.org\" \"http://httpbin.org\"'\n```\n\nStill have the following to do:\n- OAuth\n",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 186,
        "deletions": 33,
        "changed_files": 4,
        "created_at": "2011-08-23T13:13:39Z",
        "closed_at": "2011-10-11T12:39:49Z",
        "merged_at": "2011-10-11T12:39:49Z",
        "body": "As per feature request #134\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2011-08-23T09:39:07Z",
        "closed_at": "2011-08-23T13:34:47Z",
        "merged_at": "2011-08-23T13:34:47Z",
        "body": "People that download the tarball should also be fortunate enough to test that Requests works as intended :-)\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 22,
        "deletions": 26,
        "changed_files": 1,
        "created_at": "2011-08-21T09:08:41Z",
        "closed_at": "2011-08-21T10:59:21Z",
        "merged_at": "2011-08-21T10:59:21Z",
        "body": "Originally my main goal was to just make `Response.content` attribute visible in `dir(response)`. After writing a custom `__dir__` it struck me that a simple refactoring of the content attribute into a property would make a much more cleaner solution.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2011-08-20T11:07:56Z",
        "closed_at": "2011-08-20T23:23:58Z",
        "merged_at": "2011-08-20T23:23:58Z",
        "body": "Reading single lines is really useful when dealing with APIs , for example consuming streaming data from twitter. \n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2011-08-19T16:31:39Z",
        "closed_at": "2011-08-19T23:40:08Z",
        "merged_at": "2011-08-19T23:40:08Z",
        "body": "Hello! I've just fixed issue #128: \nhttps://github.com/kennethreitz/requests/issues/128\n\nActual problem was quite subtle:\n`Response.__getattr__` didn't trow AttributeError\non attributes other then `content` so you would\nget `None` for any non-existent attribute.\n\nlxml tried to perform `.getvalue()` call and it resulted into:\n- `response.getvalue -> None`\n- `response.getvalue() -> TypeError: ...`\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2011-08-17T12:40:26Z",
        "closed_at": "2011-08-17T13:45:40Z",
        "merged_at": "2011-08-17T13:45:40Z",
        "body": "The kwarg is named `headers`, not `header`. Also, its a dict, not a set.\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2011-08-17T10:57:01Z",
        "closed_at": "2011-08-18T00:18:56Z",
        "merged_at": null,
        "body": "Support PURGE request. Not sure if this is valid by any spec, but caches like Varnish use it to issue cache clear from upstream server. http://drupal.org/node/900444\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2011-08-17T10:40:44Z",
        "closed_at": "2011-08-17T13:41:39Z",
        "merged_at": "2011-08-17T13:41:39Z",
        "body": "This fine patch would surely enhance the experience.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 30,
        "deletions": 7,
        "changed_files": 2,
        "created_at": "2011-08-17T08:24:30Z",
        "closed_at": "2011-08-20T00:13:03Z",
        "merged_at": "2011-08-20T00:13:02Z",
        "body": "This pull request contains 3 fixes:\n- Fix a potential memory leak. See http://bugs.python.org/issue1208304 for more details.\n- Raise a TooManyRedirects exception with more than 30 redirects in order to prevent infinite redirections.\n- Correctly handle any kind of unicode url. Works for urls with the path not encoded (ex: http://fr.news.yahoo.com/mariage-gay-d\u00e9bat-relanc\u00e9-\u00e0-lassembl\u00e9e-065517796.html) and so on...\n\n```\n>>> r = requests.get(u'http://fr.news.yahoo.com/mariage-gay-d\u00e9bat-relanc\u00e9-\u00e0-lassembl\u00e9e-065517796.html')\n>>> r.status_code\n200\n>>> r = requests.get('http://fr.news.yahoo.com/mariage-gay-d\u00e9bat-relanc\u00e9-\u00e0-lassembl\u00e9e-065517796.html')\n>>> r.status_code\n200\n```\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 9,
        "changed_files": 1,
        "created_at": "2011-08-16T08:22:50Z",
        "closed_at": "2011-09-25T23:46:35Z",
        "merged_at": null,
        "body": "As a result of #111 this code is redundant because headers are correctly overloaded if add_header is used for updating headers. \n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 92,
        "deletions": 1,
        "changed_files": 4,
        "created_at": "2011-08-16T06:07:02Z",
        "closed_at": "2011-08-17T04:42:26Z",
        "merged_at": "2011-08-17T04:42:26Z",
        "body": "One feature I consistently use, especially for writing quick one-off scripts, is automatic cookie handling.  I've implemented this via a Session object whose instance properties can be set to be automatically passed whenever an http method call is performed.  A CookieJar is instantiated by default with each Session instance.  If you're interested in merging this feature but feel the docs/tests I added are lacking let me know and I can go over them more thoroughly.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 22,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2011-08-15T14:52:22Z",
        "closed_at": "2011-08-16T01:45:17Z",
        "merged_at": "2011-08-16T01:45:17Z",
        "body": "Use socket.setdefaulttimeout(timeout) only if timeout argument doesn't exist (Python <2.6) - https://github.com/kennethreitz/requests/issues/112\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2011-08-15T10:03:18Z",
        "closed_at": "2011-08-16T01:50:11Z",
        "merged_at": "2011-08-16T01:50:11Z",
        "body": "headers.update is not the same that add headers one by one with add_header because add_header capitalize each key.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2011-08-14T13:14:56Z",
        "closed_at": "2011-08-14T14:40:37Z",
        "merged_at": "2011-08-14T14:40:37Z",
        "body": "Found a small typo in the docs.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2011-08-14T10:31:17Z",
        "closed_at": "2011-08-14T14:40:36Z",
        "merged_at": "2011-08-14T14:40:36Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2011-08-14T06:51:11Z",
        "closed_at": "2011-08-14T14:41:33Z",
        "merged_at": "2011-08-14T14:41:33Z",
        "body": "(I haven\u2019t checked the sphinx output, but I\u2019m fairly confident on this one.)\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2011-08-09T08:06:15Z",
        "closed_at": "2011-08-09T10:37:58Z",
        "merged_at": "2011-08-09T10:37:58Z",
        "body": "In response to issue #75.\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2011-08-04T19:48:37Z",
        "closed_at": "2011-08-05T01:07:49Z",
        "merged_at": "2011-08-05T01:07:49Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2011-08-02T15:05:25Z",
        "closed_at": "2011-08-13T13:37:39Z",
        "merged_at": "2011-08-13T13:37:39Z",
        "body": "Fixes correct \"relative\" redirections. Example: http://digg.com/d1qIwX, which redirects to \"/news/story/A_Manifesto_How_to_Save_Media\", which requests transforms to: http://digg.com//news/story/A_Manifesto_How_to_Save_Media\" which results in an endless redirect loop.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 30,
        "deletions": 7,
        "changed_files": 3,
        "created_at": "2011-07-23T20:22:52Z",
        "closed_at": "2011-07-24T02:12:52Z",
        "merged_at": "2011-07-24T02:12:52Z",
        "body": "Just a very small modification:\nModify CaseInsensitiveDict to cache lower key computation and use dict lookup instead of list.\n(I don't know whether this affects anything: AFAIK headers are below 1000 key size...)\n\nGT\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 31,
        "deletions": 6,
        "changed_files": 2,
        "created_at": "2011-07-13T09:16:54Z",
        "closed_at": "2011-07-24T02:12:51Z",
        "merged_at": "2011-07-24T02:12:51Z",
        "body": "If we need to use a multivalued param like in http://localhost/service?q=*&facet.field=fieldA&facet.field=fieldB, now we can use arrays in the params dictionary:\n\n``` python\nr = requests.get('http://localhost/service',\n                 params={'q':'*', 'facet.field':['fieldA','fieldB']})\n```\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 20,
        "changed_files": 1,
        "created_at": "2011-06-29T09:13:12Z",
        "closed_at": "2011-07-04T16:01:55Z",
        "merged_at": "2011-07-04T16:01:55Z",
        "body": "Added the possibility to access headers without fetching the whole body (fixes #86).\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2011-06-26T05:33:03Z",
        "closed_at": "2011-06-26T07:50:54Z",
        "merged_at": null,
        "body": "parse_qs and then urlencode, things will changed.\n\n[test code and result](http://min.us/ldLJUS)\n\nThank you for this great lib,\n\nthe result of parse_qs is something like {'oauth': ['sig'], 'status': ['hanzi ok']}\nurlencode can't handle list as dictionary value without doseq\ndoseq does three things,\n1. if value is not list or unicode, behave like doseq=False\n1. if value is unicode, decode unicode\n2. if value is list, handle list as dict value\n\nit will fall to decode if the unicode value is not encoded in ascii, Chinese for example.\nbut _encode_params already made sure that no unicode will pass to urlencode,\nso I think it's safe to add doseq.\n\nsnippet from Python2.7/Lib/urllib.py\n\n``` python\n   if not doseq:\n        # preserve old behavior\n        for k, v in query:\n            k = quote_plus(str(k))\n            v = quote_plus(str(v))\n            l.append(k + '=' + v)\n    else:\n        for k, v in query:\n            k = quote_plus(str(k))\n            if isinstance(v, str):\n                v = quote_plus(v)\n                l.append(k + '=' + v)\n            elif _is_unicode(v):\n                # is there a reasonable way to convert to ASCII?\n                # encode generates a string, but \"replace\" or \"ignore\"\n                # lose information and \"strict\" can raise UnicodeError\n                v = quote_plus(v.encode(\"ASCII\",\"replace\"))\n                l.append(k + '=' + v)\n            else:\n                try:\n                    # is this a sufficient test for sequence-ness?\n                    len(v)\n                except TypeError:\n                    # not a sequence\n                    v = quote_plus(str(v))\n                    l.append(k + '=' + v)\n                else:\n                    # loop over the sequence\n                    for elt in v:\n                        l.append(k + '=' + quote_plus(str(elt)))\n```\n\nit's the first time I use github pull request, I'm sorry for the duplicated pull request\nreallly appreciate for this great lib, it helps me a lot.\nand I'm looking forward to oauth feature so I don't need to roll my own:)\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2011-06-24T10:23:38Z",
        "closed_at": "2011-06-24T22:24:49Z",
        "merged_at": "2011-06-24T22:24:49Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 29,
        "deletions": 13,
        "changed_files": 3,
        "created_at": "2011-06-19T20:50:59Z",
        "closed_at": "2011-06-21T04:03:54Z",
        "merged_at": "2011-06-21T04:03:54Z",
        "body": "Implements the feature explained in issue #54\n\nNow you can do a GET/POST/.... through a proxy.\n\nE.g: \n\n``` pycon\n>>> requests.get('http://docs.python.org/', proxies={'http' : 'localhost:3128'})\n< Response [200]>\n```\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 53,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2011-06-10T03:56:02Z",
        "closed_at": "2011-07-24T01:45:01Z",
        "merged_at": null,
        "body": " Fixed bug where not capitalizing a header properly caused that header to not be set.\n\nI noticed when doing a post to a service that expected a json request body that my typo \"content-type\" rather than \"Content-type\" in my headers dictionary caused the Content-type to default to \"application/x-www-urlencoded\" rather than \"application/json\".  \n\nI added a pair of tests that illustrate the problem with posts to postbin.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2011-06-09T10:34:54Z",
        "closed_at": "2011-06-09T22:09:15Z",
        "merged_at": "2011-06-09T22:09:15Z",
        "body": "Well, just a crude test case, I couldn't find a simpler website to check cookie support (also tried with some public phpinfo, but that's gross ;) ).\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 40,
        "changed_files": 1,
        "created_at": "2011-05-27T07:21:30Z",
        "closed_at": "2011-05-27T12:01:44Z",
        "merged_at": "2011-05-27T12:01:44Z",
        "body": "`UserDict.DictMixin` derivatives should support [keys()](http://docs.python.org/library/userdict.html#UserDict.DictMixin), not `__keys__()`.  I'm guessing it was probably a typo :)\n\nI took a peak at the code when I found the bug, and wonder if it wouldn't just be easier to use the attached code instead?  Maybe I'm missing something, but the only problem I can see is if you suddenly decided to start supporting _much_ older versions of Python.\n\nThanks,\n\nJames\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 16,
        "deletions": 10,
        "changed_files": 1,
        "created_at": "2011-05-27T06:33:55Z",
        "closed_at": "2011-05-27T11:59:34Z",
        "merged_at": "2011-05-27T11:59:34Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 10,
        "deletions": 10,
        "changed_files": 1,
        "created_at": "2011-05-26T18:31:16Z",
        "closed_at": "2011-05-27T06:27:50Z",
        "merged_at": null,
        "body": "_I wonder if there's a coderwall achievement for insignificant commits..._\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2011-05-22T09:40:51Z",
        "closed_at": "2011-05-22T15:26:07Z",
        "merged_at": "2011-05-22T15:26:07Z",
        "body": "![Meme](http://i.imgur.com/kXzcW.jpg)\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 36,
        "changed_files": 4,
        "created_at": "2011-05-20T18:38:28Z",
        "closed_at": "2011-05-21T17:04:37Z",
        "merged_at": "2011-05-21T17:04:37Z",
        "body": "I've completed the migration of the requests settings to the new `settings` module, but my attempt to facilitate for manipulating settings outside of the context manager (eg. `requests.settings.timeout = 5`) has been thwarted by the namespace collision of the context manager and the module.\n\nI'm probably just being stupid. You'll figure it out.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 32,
        "deletions": 19,
        "changed_files": 3,
        "created_at": "2011-05-19T08:19:23Z",
        "closed_at": "2011-05-19T15:39:06Z",
        "merged_at": "2011-05-19T15:39:06Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 7,
        "changed_files": 2,
        "created_at": "2011-05-12T17:34:52Z",
        "closed_at": "2011-05-14T17:04:53Z",
        "merged_at": "2011-05-14T17:04:53Z",
        "body": "raised Attribute Error when post str data something like json because of not having 'items' attribute.\nmove encoding data to utf-8 inside hasattr(data, 'items')\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2011-05-12T08:27:35Z",
        "closed_at": "2011-05-12T14:12:16Z",
        "merged_at": "2011-05-12T14:12:16Z",
        "body": "Hi Kenneth,\n\nI've pushed a commit that improves upon [b6f60](https://github.com/kennethreitz/requests/commit/b6f6048cff7189afee6a4fb89f9f0cdca0095b66) to encode both keys and values as UTF-8 byte strings, coincidentally fixing a bug that caused byte strings that were already encoded as UTF-8 from being encoded again and causing an UnicodeDecodeError.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 44,
        "deletions": 14,
        "changed_files": 2,
        "created_at": "2011-04-21T16:21:38Z",
        "closed_at": "2011-05-12T07:56:28Z",
        "merged_at": "2011-05-12T07:56:28Z",
        "body": "I've implemented a `settings` context manager as described in [pull request #25](https://github.com/kennethreitz/requests/pull/25#issuecomment-1039541).\n\n```\n>>> import requests\n>>> with requests.settings(timeout=0.5):\n...     requests.get('http://example.org') # Times out after 0.5 seconds\n...     requests.get('http://example.org', timeout=10) # Times out after 10 seconds\n```\n\nSettings may also be manipulated separately:\n\n```\n>>> import requests\n>>> requests.timeout = 0.5\n>>> requests.get('http://example.org') # Times out after 0.5 seconds\n```\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 12,
        "changed_files": 2,
        "created_at": "2011-04-21T12:51:12Z",
        "closed_at": "2011-04-21T14:28:33Z",
        "merged_at": "2011-04-21T14:28:32Z",
        "body": "I've implemented an optional `timeout` argument to the request functions. It defaults to `None`, which is the default timeout of python's socket library.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 10,
        "changed_files": 1,
        "created_at": "2011-04-21T12:05:23Z",
        "closed_at": "2011-04-21T14:17:03Z",
        "merged_at": "2011-04-21T14:17:02Z",
        "body": "I made some insignificant corrections to the README.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2011-03-09T11:33:18Z",
        "closed_at": "2011-03-09T18:23:25Z",
        "merged_at": "2011-03-09T18:23:25Z",
        "body": "Since `bool(CookieJar()) == False`, the checks for an available cookiejar need to compare it to None, rather than just ask `if cookiejar`.\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 11,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2011-03-06T19:11:43Z",
        "closed_at": "2011-03-07T00:03:05Z",
        "merged_at": null,
        "body": "These changes alter the way headers are handled in the `Request.send()` (line 181) method. `req.headers` will now be updated by, instead of assigned to, the `self.headers` value. This will preserve the headers generated by poster's multipart encoding.\n\nI added a new test case `test_POSTBIN_GET_POST_FILES_WITH_HEADERS`. All tests pass.\n\nPlease let me know if you have any questions.\n",
        "comments": 2
    }
]