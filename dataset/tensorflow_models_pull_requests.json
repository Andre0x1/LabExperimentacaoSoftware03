[
    {
        "merged": true,
        "additions": 0,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-08-24T18:11:41Z",
        "closed_at": "2023-08-24T20:26:29Z",
        "merged_at": "2023-08-24T20:26:29Z",
        "body": "## Type of change\r\n\r\n- [ ] Documentation update\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2023-08-07T05:54:27Z",
        "closed_at": "2023-09-12T16:46:18Z",
        "merged_at": "2023-09-12T16:46:18Z",
        "body": "# Description\r\nUpdating Readme",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 36,
        "deletions": 12,
        "changed_files": 3,
        "created_at": "2023-07-26T17:23:39Z",
        "closed_at": "2023-07-26T21:28:25Z",
        "merged_at": "2023-07-26T21:28:25Z",
        "body": "# Description\r\n\r\nFixed vggish_smoke_test failures due to resampy changes.\r\n\r\nhttps://github.com/bmcfee/resampy/pull/98 seems to have updated\r\nresampy's default filters in a way that made the VGGish smoke\r\ntest's embedding outputs drift too far from the expected values\r\nwhen upgrading from resampy 0.2.2 to 0.3.0 or later.\r\n\r\nFixed the test by not resampling in the critical path of generating\r\nan embedding.\r\n\r\n## Type of change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\n\r\nTested by running the smoke test on a config from last summer and a recent representative config\r\n\r\n**Test Configuration**:\r\nDebian-based Linux system, Python 3.10\r\nNumPy 1.21.6 / TF 2.8.2\r\nNumPy 1.24.3 / TF 2.13.0\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 8,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-07-14T17:34:42Z",
        "closed_at": "2023-07-19T23:10:14Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nRecent update of Pillow removed `getsize` method from ImageFont class, so making code compatible with both <10.0.0 and >10.0.0 versions.\r\n\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\n\r\n- [x] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 6,
        "changed_files": 3,
        "created_at": "2023-06-30T18:36:39Z",
        "closed_at": "2023-07-20T20:42:40Z",
        "merged_at": "2023-07-20T20:42:39Z",
        "body": "# Description\r\n\r\n\r\n\r\n## Type of change\r\n\r\n- [ ] Documentation update\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 33,
        "deletions": 33,
        "changed_files": 1,
        "created_at": "2023-06-27T22:39:26Z",
        "closed_at": "2023-06-30T15:30:36Z",
        "merged_at": null,
        "body": "## Type of change\r\n\r\n- [ ] Documentation update\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 123,
        "deletions": 123,
        "changed_files": 2,
        "created_at": "2023-06-27T20:58:53Z",
        "closed_at": "2023-06-30T15:32:22Z",
        "merged_at": null,
        "body": "## Type of change\r\n\r\n- [ ] Documentation update\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 35,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2023-06-26T19:29:35Z",
        "closed_at": "2023-06-29T18:23:50Z",
        "merged_at": "2023-06-29T18:23:50Z",
        "body": "# Description\r\n\r\nRemove deprecated `tf.keras.layers.experimental.SyncBatchNormalization` and added `synchronized` as argument in `tf.keras.layers.BatchNormalization`.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 26,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-06-16T22:40:52Z",
        "closed_at": "2023-06-21T15:09:06Z",
        "merged_at": "2023-06-21T15:09:06Z",
        "body": "# Description\r\n\r\nWhile training darknet image classification some of the default parameters are not present and causing error while trained using `official,core.train_lib.run_experiment`.\r\n\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1402,
        "deletions": 5,
        "changed_files": 15,
        "created_at": "2023-05-29T23:19:59Z",
        "closed_at": "2023-06-10T02:38:31Z",
        "merged_at": "2023-06-10T02:38:31Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] A new research paper code implementation\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 750,
        "deletions": 0,
        "changed_files": 7,
        "created_at": "2023-04-18T21:57:36Z",
        "closed_at": "2023-06-09T21:32:52Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] A new research paper code implementation\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2627,
        "deletions": 0,
        "changed_files": 14,
        "created_at": "2023-03-30T13:12:31Z",
        "closed_at": "2023-05-09T18:03:16Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  A Pix2Seq implementation in TensorFlow Model Garden\r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [o ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  Instructions to run train/eval are provided in README.\r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [o] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [o] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [o] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [o] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [o] I have commented my code, particularly in hard-to-understand areas.\r\n- [o] I have made corresponding changes to the documentation.\r\n- [o] My changes generate no new warnings.\r\n- [o] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-03-23T11:07:17Z",
        "closed_at": "2023-03-24T20:52:12Z",
        "merged_at": "2023-03-24T20:52:12Z",
        "body": "Updated the broken link for Classification in the documentation",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 67,
        "deletions": 39,
        "changed_files": 2,
        "created_at": "2023-03-08T19:24:06Z",
        "closed_at": "2023-03-23T06:59:37Z",
        "merged_at": "2023-03-23T06:59:37Z",
        "body": "Added a file stale.yaml inside .github/workflows to stale and closed issues/PRs from workflows.\r\nDisabled probot by deleting stale.yml file from .github folder.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 11,
        "changed_files": 1,
        "created_at": "2023-02-16T18:33:23Z",
        "closed_at": "2023-02-21T17:21:47Z",
        "merged_at": "2023-02-21T17:21:47Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2023-02-06T06:46:01Z",
        "closed_at": "2023-02-27T20:27:06Z",
        "merged_at": "2023-02-27T20:27:06Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 11,
        "changed_files": 1,
        "created_at": "2023-02-02T21:28:43Z",
        "closed_at": "2023-07-18T01:22:06Z",
        "merged_at": "2023-07-18T01:22:06Z",
        "body": "# Description\r\n\r\n- [ ] Documentation update\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 5,
        "changed_files": 3,
        "created_at": "2023-01-31T20:53:50Z",
        "closed_at": "2023-04-24T02:36:05Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n- [ ] Documentation update\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 6,
        "changed_files": 4,
        "created_at": "2023-01-31T19:25:58Z",
        "closed_at": "2023-02-21T17:22:40Z",
        "merged_at": "2023-02-21T17:22:40Z",
        "body": "# Description\r\n\r\n- [ ] Documentation update\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2023-01-30T04:41:16Z",
        "closed_at": "2023-02-20T05:45:58Z",
        "merged_at": "2023-02-20T05:45:58Z",
        "body": "Updated the broken link for MLPerf Repo and fixed some typos in TF doc.\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 11,
        "changed_files": 1,
        "created_at": "2023-01-29T04:51:31Z",
        "closed_at": "2023-01-30T04:23:48Z",
        "merged_at": "2023-01-30T04:23:47Z",
        "body": "Fixing typos in TF doc\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 10,
        "changed_files": 3,
        "created_at": "2023-01-26T21:02:51Z",
        "closed_at": "2023-01-30T05:23:37Z",
        "merged_at": "2023-01-30T05:23:36Z",
        "body": "# Description\r\n\r\n- [ ] Documentation update\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2023-01-26T19:34:44Z",
        "closed_at": "2023-01-30T05:23:37Z",
        "merged_at": "2023-01-30T05:23:36Z",
        "body": "# Description\r\n\r\n- [ ] Documentation update\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 47,
        "deletions": 47,
        "changed_files": 7,
        "created_at": "2023-01-24T21:27:28Z",
        "closed_at": "2023-02-22T19:17:34Z",
        "merged_at": "2023-02-22T19:17:34Z",
        "body": "# Description\r\n\r\n- [ ] Documentation update\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 27,
        "deletions": 27,
        "changed_files": 3,
        "created_at": "2023-01-24T20:03:22Z",
        "closed_at": "2023-01-26T18:22:07Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n- [ ] Documentation update\r\n\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2023-01-23T19:28:29Z",
        "closed_at": "2023-01-24T02:00:48Z",
        "merged_at": "2023-01-24T02:00:48Z",
        "body": "Removing Expand/Collapse button to keep the page in sync\r\n\r\n# Description \r\n\r\n- [x] Documentation update \r\n\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 47,
        "deletions": 36,
        "changed_files": 1,
        "created_at": "2023-01-20T21:41:27Z",
        "closed_at": "2023-01-30T05:10:38Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nFixed broken colab while load pre-trained weights of MoViNet-A0-Stream\r\n\r\n## Type of change\r\n\r\n- [x] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2023-01-19T21:38:24Z",
        "closed_at": "2023-01-19T22:47:14Z",
        "merged_at": "2023-01-19T22:47:14Z",
        "body": "# Description\r\n\r\n- [ ] Documentation update\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2023-01-19T21:22:41Z",
        "closed_at": "2023-01-19T22:50:53Z",
        "merged_at": "2023-01-19T22:50:53Z",
        "body": "# Description\r\n\r\n- [ ] Documentation update\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2023-01-19T20:18:48Z",
        "closed_at": "2023-01-23T21:33:19Z",
        "merged_at": "2023-01-23T21:33:19Z",
        "body": "# Description\r\n\r\n- [ ] Documentation update\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2023-01-19T19:09:42Z",
        "closed_at": "2023-01-21T17:51:43Z",
        "merged_at": "2023-01-21T17:51:43Z",
        "body": "# Description\r\n\r\n\r\n## Type of change\r\n\r\n- [ ] Documentation update\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 33,
        "deletions": 33,
        "changed_files": 1,
        "created_at": "2023-01-18T22:06:27Z",
        "closed_at": "2023-01-21T17:40:47Z",
        "merged_at": "2023-01-21T17:40:47Z",
        "body": "# Description\r\n\r\n## Type of change\r\n\r\n- [ ] Documentation update\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2023-01-17T19:49:23Z",
        "closed_at": "2023-01-20T18:58:50Z",
        "merged_at": "2023-01-20T18:58:50Z",
        "body": "# Description\r\n\r\nTypos correction\r\n\r\n## Type of change\r\n\r\n\r\n- [ ] Documentation update\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 12,
        "changed_files": 1,
        "created_at": "2023-01-11T18:51:14Z",
        "closed_at": "2023-01-15T02:33:12Z",
        "merged_at": "2023-01-15T02:33:12Z",
        "body": "# Description\r\n\r\nDownloadable Checkpoints using CLI\r\n\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2023-01-08T23:05:00Z",
        "closed_at": "2023-01-11T21:59:13Z",
        "merged_at": "2023-01-11T21:59:13Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 76,
        "deletions": 75,
        "changed_files": 15,
        "created_at": "2023-01-07T00:08:39Z",
        "closed_at": "2023-01-07T02:43:00Z",
        "merged_at": "2023-01-07T02:43:00Z",
        "body": "Keeping seq_flow_lite code in sync.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2023-01-06T06:10:40Z",
        "closed_at": "2023-01-11T19:57:25Z",
        "merged_at": "2023-01-11T19:57:25Z",
        "body": "Fixed typos in TF documentation.\r\nThank you\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2023-01-05T20:18:11Z",
        "closed_at": "2023-01-13T23:09:24Z",
        "merged_at": "2023-01-13T23:09:24Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2022-12-18T02:44:37Z",
        "closed_at": "2022-12-19T11:49:49Z",
        "merged_at": "2022-12-19T11:49:49Z",
        "body": "# Description\r\nUpdated a broken link for the GLDv2 baseline link to include the subdirectory **datasets**\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Documentation update\r\n\r\n## Tests\r\n1- Tried clicking the [link](https://github.com/tensorflow/models/blob/master/research/delf/delf/python/google_landmarks_dataset/README.md) and it took me to the [corresponding page](https://github.com/tensorflow/models/tree/master/research/delf/delf/python/datasets/google_landmarks_dataset) instead of the error produced previously.\r\n\r\n**Test Configuration**:\r\nN.A\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [N.A] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 12,
        "changed_files": 1,
        "created_at": "2022-12-16T01:49:08Z",
        "closed_at": "2022-12-16T07:07:47Z",
        "merged_at": "2022-12-16T07:07:47Z",
        "body": "# Description\r\n\r\nUpdate checkpoints(ckpts) links to downloadable from CLI\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n\r\n- [x] Documentation update\r\n\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2677,
        "deletions": 0,
        "changed_files": 22,
        "created_at": "2022-12-14T21:45:28Z",
        "closed_at": "2023-02-08T19:54:25Z",
        "merged_at": "2023-02-08T19:54:25Z",
        "body": "# Description\r\n\r\n> :memo: Uploading the repo for Long Range Arena\r\n>  \r\n> *  Transformer & Linformer are included\r\n> *  A custom task for document matching (AAN) is included  \r\n> * Dataset is hosted on GCP Bucket, see README.md for Details\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Ran Pylint according to [Google Guideline](https://google.github.io/styleguide/pyguide.html) , \"Your code has been rated at 9.10/10\"\r\n> * Auto formatted with `yapf -i --style='{based_on_style: google, indent_width: 2}' `\r\n> * Ran experiments on Cloud TPU\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [X] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [X] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [X] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [X] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [X] I have commented my code, particularly in hard-to-understand areas.\r\n- [X] I have made corresponding changes to the documentation.\r\n- [X] My changes generate no new warnings.\r\n- [X] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 348,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2022-11-23T19:08:40Z",
        "closed_at": "2022-11-23T23:22:54Z",
        "merged_at": "2022-11-23T23:22:54Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\n- [x] A new research paper code implementation\r\n\r\nAdditional data creation for [FFF-NER](https://arxiv.org/abs/2205.11799)\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1969,
        "deletions": 0,
        "changed_files": 14,
        "created_at": "2022-11-21T19:56:11Z",
        "closed_at": "2022-11-22T16:05:41Z",
        "merged_at": "2022-11-22T16:05:40Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\n- [x] A new research paper code implementation\r\n\r\nImplementation of [FFF-NER](https://arxiv.org/abs/2205.11799)\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 12,
        "changed_files": 4,
        "created_at": "2022-11-18T16:03:06Z",
        "closed_at": "2023-04-06T20:41:24Z",
        "merged_at": "2023-04-06T20:41:24Z",
        "body": "This prevents the call to `absl.logging.info()` at import.\r\n\r\n# Description\r\n\r\nFor us, the call to `absl.logging.info()` was particularly problematic, because it calls `logging.basicConfig()`.\r\n\r\nOur code later called `logging.basicConfig(level=logging.INFO)`, but that call had no effect since logging was already set up.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\nI didn't have time, but ideally a test should make sure that logging isn't touched when importing the modules.\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 115,
        "deletions": 25,
        "changed_files": 3,
        "created_at": "2022-11-03T19:02:57Z",
        "closed_at": "2022-11-21T17:35:33Z",
        "merged_at": "2022-11-21T17:35:33Z",
        "body": "# Description\r\nCode breaks when bounding box coordinates  crosses the original image width or height itself. \r\n\r\n* When number of `bbox_annotations` is same as `num_annotations_skipped` in a single example include a check, not to create the `feature_dict` and just return any empty `feature_dict`.\r\n* Later included another check in `tfrecord_lib.py` whether `tf_example` is not empty while writing to output `tfrecord` file.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1969,
        "deletions": 0,
        "changed_files": 14,
        "created_at": "2022-11-01T18:57:38Z",
        "closed_at": "2022-11-21T19:17:00Z",
        "merged_at": "2022-11-21T19:17:00Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\n- [x] A new research paper code implementation\r\n\r\nImplementation of [FFF-NER](https://arxiv.org/abs/2205.11799)\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2022-10-12T17:35:56Z",
        "closed_at": "2022-11-14T21:40:40Z",
        "merged_at": null,
        "body": "Updated the broken link for Image classification with Model Garden tutorial in TF documentation.\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2022-10-10T20:36:03Z",
        "closed_at": "2022-10-12T04:12:57Z",
        "merged_at": "2022-10-12T04:12:57Z",
        "body": "Adding new assignee list\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2022-09-23T20:08:45Z",
        "closed_at": "2022-12-09T19:06:16Z",
        "merged_at": "2022-12-09T19:06:16Z",
        "body": "# Description\r\n\r\nUpdated Broken link reference for `Tfrecord file format` generation for custom dataset in this [README](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/using_your_own_dataset.md) file\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Documentation update\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2022-09-21T18:29:36Z",
        "closed_at": "2022-09-24T03:17:05Z",
        "merged_at": "2022-09-24T03:17:05Z",
        "body": "Update Broken links for `DeepMAC model` and `create_coco_tf_record.py` references.\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2022-09-21T17:52:54Z",
        "closed_at": "2022-11-14T21:45:58Z",
        "merged_at": null,
        "body": "Update Broken link for `Mask RCNN code` reference\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 26,
        "changed_files": 1,
        "created_at": "2022-09-14T22:23:39Z",
        "closed_at": "2022-09-18T00:54:01Z",
        "merged_at": "2022-09-18T00:54:01Z",
        "body": "Fixes tensorflow/models#9451 by creating image from example that can be downloaded.\r\n\r\n# Description\r\n\r\nA Neutral Style Transfer example from 2018 has never worked fully because it offers a cue to download a file that is never generated in the code. This PR generates that file, so the example will generate a downloadable image.\r\n\r\nhttps://blog.tensorflow.org/2018/08/neural-style-transfer-creating-art-with-deep-learning.html\r\n\r\nI found the issue in https://github.com/tensorflow/models/issues/9451 but it has not yet been solved.\r\n\r\n\r\n## Type of change\r\n\r\n- [ x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\nN/A\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ x] I have made corresponding changes to the documentation.\r\n- [ x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2022-09-09T09:58:54Z",
        "closed_at": "2022-09-13T17:39:22Z",
        "merged_at": "2022-09-13T17:39:22Z",
        "body": "Switch `official/nlp/bert` to `official/legacy/bert` for open sourced model garden.\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2022-09-07T10:35:19Z",
        "closed_at": "2022-12-28T13:33:05Z",
        "merged_at": "2022-12-28T13:33:05Z",
        "body": "Updated the version of tf_slim as it was giving error after install_delf.sh. Fixes #10754 \r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 7,
        "changed_files": 3,
        "created_at": "2022-09-06T22:30:20Z",
        "closed_at": "2022-09-23T04:57:48Z",
        "merged_at": "2022-09-23T04:57:48Z",
        "body": "@MarkDaoust @markmcd \r\n\r\nCurrently, importing TF Models throws an `ImportError` as there's no `cv2` dependency. This PR should fix this step with `pip install opencv-python`.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2022-08-24T23:59:49Z",
        "closed_at": "2022-09-04T00:03:34Z",
        "merged_at": "2022-09-04T00:03:34Z",
        "body": "# Description\r\n\r\nThis PR adds minimum token permissions for the GITHUB_TOKEN in GitHub Actions workflow using https://github.com/step-security/secure-workflows. \r\nAll GitHub Actions workflows have a GITHUB_TOKEN with `write` access to multiple scopes. \r\nHere is an example of the permissions in one of the workflows:\r\nhttps://github.com/tensorflow/models/runs/7824930711?check_suite_focus=true#step:1:19\r\n\r\nAfter this change, the scopes will be reduced to the minimum needed for the workflow. \r\n\r\n## Motivation\r\n- This is a security best practice, so if the GITHUB_TOKEN is compromised due to a vulnerability or compromised Action, the damage will be reduced. \r\n- GitHub recommends defining minimum GITHUB_TOKEN permissions. \r\nhttps://docs.github.com/en/actions/security-guides/automatic-token-authentication#modifying-the-permissions-for-the-github_token\r\n- The Open Source Security Foundation (OpenSSF) [Scorecards](https://github.com/ossf/scorecard) also treats not setting token permissions as a high-risk issue. This change will help increase the Scorecard score for this repository. \r\n\r\nSigned-off-by: Varun Sharma <varunsh@stepsecurity.io>\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [x] Other (Specify)\r\n\r\nImprovement to the GitHub Actions workflow\r\n\r\n## Tests\r\n\r\nNo tests run. This is a standard configuration for workflows and does not affect rest of the code. \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2022-08-02T17:58:07Z",
        "closed_at": "2022-08-03T03:27:06Z",
        "merged_at": "2022-08-03T03:27:06Z",
        "body": null,
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2022-07-20T07:58:57Z",
        "closed_at": "2022-07-20T18:47:10Z",
        "merged_at": "2022-07-20T18:47:10Z",
        "body": "Added a link to the model-garden guide that was published on TF webpage\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2022-07-18T09:46:23Z",
        "closed_at": "2022-07-18T17:23:00Z",
        "merged_at": "2022-07-18T17:22:59Z",
        "body": "Update `nlp model building` broken link.  \r\nFixes https://github.com/tensorflow/models/issues/10711\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 45,
        "deletions": 45,
        "changed_files": 1,
        "created_at": "2022-07-09T03:28:14Z",
        "closed_at": "2022-07-16T03:33:46Z",
        "merged_at": "2022-07-16T03:33:46Z",
        "body": "# Description\r\n\r\nFix typos, indentation, capitalisation and punctuation in lfads.py.\r\n\r\n## Type of change\r\n\r\n- [x] Documentation update\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 609,
        "deletions": 83,
        "changed_files": 9,
        "created_at": "2022-07-07T00:30:51Z",
        "closed_at": "2022-07-07T19:30:38Z",
        "merged_at": "2022-07-07T19:30:37Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n> Current DETR implementation supports TFDS only as an input source. To utilize my dataset or downloaded tfrecord files in the framework, I extend it to support tfrecord inputs on local or cloud storage.\r\n> In addition, I add a backbone factory in modeling to make flexible choosing backbone for feature encoding.\r\n> I have organized the configuration list, which currently contains all the parameters in task configuration. I add subgroups for the parameters to make it clear. (task.model, task.losses, ...)\r\n> No additional dependencies are required.\r\n> TPU compatibility checked.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [O] New feature (non-breaking change which adds functionality)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [O] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [O] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [O] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [O] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [O] I have commented my code, particularly in hard-to-understand areas.\r\n- [O] I have made corresponding changes to the documentation.\r\n- [O] My changes generate no new warnings.\r\n- [O] I have added tests that prove my fix is effective or that my feature works.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 609,
        "deletions": 83,
        "changed_files": 9,
        "created_at": "2022-07-06T01:05:29Z",
        "closed_at": "2022-07-07T00:26:35Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n> Current DETR implementation supports TFDS only as an input source. To utilize my dataset or downloaded tfrecord files in the framework, I extend it to support tfrecord inputs on local or cloud storage.\r\n> In addition, I add a backbone factory in modeling to make flexible choosing backbone for feature encoding.\r\n> I have organized the configuration list, which currently contains all the parameters in task configuration. I add subgroups for the parameters to make it clear. (task.model, task.losses, ...)\r\n> No additional dependencies are required.\r\n> TPU compatibility checked.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [O] New feature (non-breaking change which adds functionality)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [O] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [O] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [O] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [O] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [O] I have commented my code, particularly in hard-to-understand areas.\r\n- [O] I have made corresponding changes to the documentation.\r\n- [O] My changes generate no new warnings.\r\n- [O] I have added tests that prove my fix is effective or that my feature works.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 72,
        "deletions": 471,
        "changed_files": 7,
        "created_at": "2022-07-05T15:55:00Z",
        "closed_at": "2022-07-05T18:44:46Z",
        "merged_at": "2022-07-05T18:44:46Z",
        "body": "Reverts tensorflow/models#10689\r\n(Messed up the steps for internal review.)\r\nLet's revert this and recreate a new PR. Sorry about this.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 471,
        "deletions": 72,
        "changed_files": 7,
        "created_at": "2022-07-02T09:26:21Z",
        "closed_at": "2022-07-05T15:08:00Z",
        "merged_at": "2022-07-05T15:07:59Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n> Current DETR implementation supports TFDS only as an input source. To utilize my dataset or downloaded tfreocrd files in the framework, I extend it to support tfrecord inputs on local or cloud storage.\r\n> In addition, I add a backbone factory in modeling to make flexible choosing backbone for feature encoding.\r\n> I have organized the configuration list, which currently contains all the parameters in task configuration. I add subgroups for the parameters to make it clear. (task.model, task.losses, ...)\r\n> No additional dependencies are required.\r\n> TPU compatibility checked.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [O] New feature (non-breaking change which adds functionality)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [O] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [O] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [O] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [O] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [O] I have commented my code, particularly in hard-to-understand areas.\r\n- [O] I have made corresponding changes to the documentation.\r\n- [O] My changes generate no new warnings.\r\n- [O] I have added tests that prove my fix is effective or that my feature works.",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2022-06-14T13:23:27Z",
        "closed_at": "2022-06-15T18:21:54Z",
        "merged_at": "2022-06-15T18:21:54Z",
        "body": "Added installation approach for Windows.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1066,
        "deletions": 436,
        "changed_files": 1,
        "created_at": "2022-05-16T17:58:26Z",
        "closed_at": "2022-06-07T18:54:45Z",
        "merged_at": "2022-06-07T18:54:45Z",
        "body": "# Add tutorial sections to the COTS notebook.\r\n\r\nAdd more descriptive text and example code explaining how this works. Break up the code into smaller chunks.\r\n\r\nMainly:\r\n\r\n* Add a walkthrough of how to decode the detection results.\r\n* Show the detection results on a pair of images to motivate the \"Tracker\" code.\r\n* Upgrade the optical flow code to run on a batches of detections .\r\n* Demonstrate the optical flow aspect before getting into the tracker.\r\n\r\nHere is a [copy with the outputs rendered](https://colab.sandbox.google.com/drive/1I2TDSUJxXl_1BmI8OaZsHKhNP_E2iZ2k?resourcekey=0-qJjR9zYIvSFYhKOtb87d1A#scrollTo=GUQ1x137ysLD)\r\n\r\n\r\n## Change type\r\n\r\n- [x] Documentation update\r\n\r\n## Tests\r\n\r\nSpot checked the final output video, Detection IDs and frame numbers all seem identical. \r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 1061,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2022-05-09T22:53:41Z",
        "closed_at": "2022-05-10T21:16:15Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nCoral reefs are some of the most diverse and important ecosystems in the world, however, they face a number of rising threats that have resulted in massive global declines. In Australia, outbreaks of the coral-eating crown-of-thorns starfish (COTS) have been shown to cause major coral loss, with just 15 starfish in a hectare being able to strip a reef of 90% of its coral tissue. While COTS naturally exist in the Indo-Pacific, overfishing and excess run-off nutrients have led to massive outbreaks that are devastating already vulnerable coral communities.\r\n\r\nControlling COTS populations is critical to promoting coral growth and resilience, so Google teamed up with Australia\u2019s national science agency, [CSIRO](https://www.csiro.au/en/), to tackle this problem. We trained ML object detection models to help scale underwater surveys, enabling the monitoring and mapping out of these harmful invertebrates with the ultimate goal of helping control teams to address and prioritize outbreaks.\r\n\r\n## Type of change\r\n\r\nAdd a COTS detection inference and tracking pipeline notebook.\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 162,
        "deletions": 74,
        "changed_files": 7,
        "created_at": "2022-05-08T16:44:32Z",
        "closed_at": "2022-07-19T19:43:02Z",
        "merged_at": "2022-07-19T19:43:02Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> Adding Unittests for YT8M Projects \r\n> Modifying minor issues while training --segment_labels training process\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**: \r\n```bash\r\npython -m unittest official.projects.yt8m.configs.yt8m_test\r\n```\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 13,
        "changed_files": 1,
        "created_at": "2022-05-06T23:28:07Z",
        "closed_at": "2022-05-07T22:59:01Z",
        "merged_at": null,
        "body": "Updated readme as tensorflow-text gets installated automatically by pip\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 27,
        "deletions": 27,
        "changed_files": 22,
        "created_at": "2022-05-04T14:41:31Z",
        "closed_at": "2022-05-05T17:32:12Z",
        "merged_at": "2022-05-05T17:32:12Z",
        "body": "# Description\r\nFix some typos in official/.\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2022-05-04T14:33:47Z",
        "closed_at": "2023-04-21T15:45:46Z",
        "merged_at": null,
        "body": "# Description\r\nFix some typos in research/.\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2022-04-26T14:59:48Z",
        "closed_at": "2022-04-28T00:51:27Z",
        "merged_at": "2022-04-28T00:51:27Z",
        "body": "# Description\r\n\r\nAll links on git.io will stop redirecting after April 29, 2022: https://github.blog/changelog/2022-04-25-git-io-deprecation/\r\n\r\nReplace `https://git.io/deepmac` with `https://google.github.io/deepmac/`\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\n- [x] Documentation update\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2022-04-26T11:04:41Z",
        "closed_at": "2022-04-27T04:55:26Z",
        "merged_at": "2022-04-27T04:55:26Z",
        "body": "Updated broken link with correct reference for `Mask RCNN code`\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 143,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2022-04-25T22:49:49Z",
        "closed_at": "2023-09-25T21:23:51Z",
        "merged_at": "2023-09-25T21:23:51Z",
        "body": "# Description\r\n\r\nThis PR adds a new YOLOv4-tiny config that achieves 21.21AP. It also updates the YOLO project's README.md to include metrics and a place for checkpoints.\r\n\r\n## Type of change\r\n\r\n- [x] A new research paper code implementation\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 10
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2022-04-22T18:22:51Z",
        "closed_at": "2022-04-24T23:51:46Z",
        "merged_at": "2022-04-24T23:51:46Z",
        "body": "Update readme with pypi package for tf-models-official instead of tf\r\n\r\nAdd a link to releases. We only have official models and orbit library in the pip package.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2022-04-08T22:40:15Z",
        "closed_at": "2022-04-09T00:48:58Z",
        "merged_at": "2022-04-09T00:48:58Z",
        "body": "# Description\r\n\r\nThere used to be only one EfficientNet implementation. Now there is v1 and v2. This PR replaces the existing broken link with two links, one to each of the versions.\r\n\r\n## Type of change\r\n\r\nDocumentation update\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2022-04-06T22:31:30Z",
        "closed_at": "2022-04-07T23:46:52Z",
        "merged_at": "2022-04-07T23:46:52Z",
        "body": "Updating __init__.py files are to import code correctly",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 11,
        "deletions": 11,
        "changed_files": 10,
        "created_at": "2022-03-31T05:19:41Z",
        "closed_at": "2022-03-31T15:47:38Z",
        "merged_at": null,
        "body": "Hey! We noticed your repository had a few instances of gendered language. We've attempted to make the changes to gender neutral language. These are not always perfect, but we hope they will assist maintainers in finding and fixing issues :)\r\n\r\nYou can learn more about this project and why gender neutral language matters at [inclusivecoding.wixsite.com](https://inclusivecoding.wixsite.com/home). If you have feedback for this bot, please provide it [here](https://forms.gle/MnEH24gWbzPLSnnv7).",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 16,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2022-03-27T13:41:03Z",
        "closed_at": "2022-03-29T00:10:45Z",
        "merged_at": "2022-03-29T00:10:45Z",
        "body": "# Description\r\nadd a get_config implementation, and  thus eliminating the error:\r\n```\r\nWARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \r\nLayer Encoder has arguments ['self', 'num_layers', 'mlp_dim', 'num_heads', 'dropout_rate', 'attention_dropout_rate', 'kernel_regularizer', 'inputs_positions', 'init_stochastic_depth_rate', 'kernel_initializer', 'add_pos_embed']\r\nin `__init__` and therefore must override `get_config()`.\r\n```\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\nI ran the model again and the error has been eliminated.\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [X] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [X] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [X] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [X] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [X] I have commented my code, particularly in hard-to-understand areas.\r\n- [X] I have made corresponding changes to the documentation.\r\n- [X] My changes generate no new warnings.\r\n- [X] I have added tests that prove my fix is effective or that my feature works (it's a bugfix) .\r\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2022-03-25T19:53:20Z",
        "closed_at": "2022-03-25T22:13:45Z",
        "merged_at": null,
        "body": "A `README.md` with a deprecation message is created.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2022-03-24T21:13:20Z",
        "closed_at": "2022-03-25T03:25:45Z",
        "merged_at": "2022-03-25T03:25:45Z",
        "body": "Formatted `BibTex` for correct citation.\r\n\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 88,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2022-03-23T08:49:14Z",
        "closed_at": "2022-03-23T20:23:27Z",
        "merged_at": "2022-03-23T20:23:27Z",
        "body": "Updated README.md with the installation approach. Also, formatted text for consistency.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2022-03-22T09:26:09Z",
        "closed_at": "2022-03-25T04:14:54Z",
        "merged_at": "2022-03-25T04:14:54Z",
        "body": "# Description\r\nChanged the movielens dataset URL as the earlier one isn't accessible.\r\n\r\nThe URL http://files.grouplens.org/datasets/movielens/  is no more accessible via `http`. It is accessible using `https`. So, updated the url in the script from where the movielens dataset is downloaded.\r\n\r\n\r\n## Type of change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\n\r\n```\r\n         python movielens.py --data_dir=./data --dataset=ml-1m\r\n         python ncf_keras_main.py --data_dir=./data --dataset=ml-1m --distribution_strategy=one_device --num_gpus=1\r\n```\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 251,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2022-03-18T16:11:25Z",
        "closed_at": "2022-03-23T06:11:38Z",
        "merged_at": "2022-03-23T06:11:38Z",
        "body": "Adding `SECURITY.md` to model repository as it is a way to inform the user about any security vulnerabilities and how to report in case if they notice any vulnerability.\r\n\r\n- [ ] Documentation update\r\n\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 79,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2022-03-18T14:36:06Z",
        "closed_at": "2022-03-23T06:11:15Z",
        "merged_at": "2022-03-23T06:11:15Z",
        "body": "Adding a new CODE_OF_CONDUCT.md to models repository\r\n\r\n\r\n- [ ] Documentation update\r\n\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 38,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2022-03-17T19:21:57Z",
        "closed_at": "2022-03-23T16:30:14Z",
        "merged_at": null,
        "body": "Release notes file is added to the models repository\r\n\r\n# Description\r\n\r\nAdded a release notes file\r\n\r\n\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n\r\n- [ ] Documentation update\r\n\r\n\r\n\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3380,
        "deletions": 2,
        "changed_files": 18,
        "created_at": "2022-03-16T08:23:45Z",
        "closed_at": "2022-06-02T18:10:23Z",
        "merged_at": "2022-06-02T18:10:23Z",
        "body": "# Description\r\nThis PR adds the Panoptic Deeplab architecture described in  [Panoptic-DeepLab\r\n](https://arxiv.org/pdf/1911.10194.pdf)\r\n\r\n## Type of change\r\n- [x] A new research paper code implementation\r\n\r\n## Tests\r\n  - `python -m official.vision.beta.projects.panoptic_maskrcnn.modeling.heads.panoptic_deeplab_heads_test`\r\n  - `python -m official.vision.beta.projects.panoptic_maskrcnn.modeling.factory_test`\r\n  - `python -m official.vision.beta.projects.panoptic_maskrcnn.modeling.panoptic_deeplab_model_test`\r\n  - `python -m official.vision.beta.projects.panoptic_maskrcnn.modeling.layers.panoptic_deeplab_merge_test`\r\n  - `python -m official.vision.beta.projects.panoptic_maskrcnn.tasks.panoptic_deeplab_test`\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2022-03-09T07:38:21Z",
        "closed_at": "2022-06-24T04:52:09Z",
        "merged_at": null,
        "body": "Looks like this is a typo. All the other models uses small learning rate excepti this specific model. As the user mentioned below, the loss spikes with this learning rate.\r\n\r\nUpdated learning rate and warmup_learning_rate based on the following GH issue\r\n\r\nFixes https://github.com/tensorflow/models/issues/10509\r\n\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 305,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2022-03-05T20:14:18Z",
        "closed_at": "2022-03-16T16:32:34Z",
        "merged_at": null,
        "body": "# Description\r\nThis PR adds the  dataloader for Panoptic Deeplab architecture described in  [Panoptic-DeepLab\r\n](https://arxiv.org/pdf/1911.10194.pdf)\r\n\r\n## Type of change\r\n- [x] A new research paper code implementation\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2912,
        "deletions": 0,
        "changed_files": 14,
        "created_at": "2022-02-25T05:26:14Z",
        "closed_at": "2022-03-22T20:24:26Z",
        "merged_at": "2022-03-22T20:24:26Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] A new research paper code implementation\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n`longformer_attention_test.py` and `longformer_encoder_test.py`.\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2022-02-04T02:29:52Z",
        "closed_at": "2022-03-09T22:44:18Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 698,
        "deletions": 2,
        "changed_files": 9,
        "created_at": "2022-01-28T23:41:07Z",
        "closed_at": "2022-02-02T00:32:59Z",
        "merged_at": "2022-02-02T00:32:59Z",
        "body": "Open source the implementation of the pQRNN model.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2022-01-20T06:33:54Z",
        "closed_at": "2022-01-20T15:53:19Z",
        "merged_at": "2022-01-20T15:53:19Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2022-01-19T00:50:00Z",
        "closed_at": "2022-01-20T22:01:56Z",
        "merged_at": "2022-01-20T22:01:56Z",
        "body": "Link to an example in [README.md](https://github.com/tensorflow/models/tree/master/official/README.md) is throwing 404 error.\r\n\r\nLink is updated\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2022-01-16T07:13:14Z",
        "closed_at": "2022-01-20T06:34:34Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2022-01-14T07:20:46Z",
        "closed_at": "2022-01-20T21:41:20Z",
        "merged_at": null,
        "body": "Fixes https://github.com/tensorflow/models/issues/10450\r\n\r\nLinks to the model files and checkpoints are throwing an error. This PR is to update those links.\r\n\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1490,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2022-01-13T19:01:54Z",
        "closed_at": "2023-04-06T17:06:18Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [x] Other (Specify): jupyter/colab notebook showing the effect of the augmentations\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1792,
        "deletions": 0,
        "changed_files": 10,
        "created_at": "2022-01-12T19:08:14Z",
        "closed_at": "2022-03-16T16:32:44Z",
        "merged_at": null,
        "body": "# Description\r\nThis PR adds the Panoptic Deeplab architecture described in  [Panoptic-DeepLab\r\n](https://arxiv.org/pdf/1911.10194.pdf)\r\n\r\n## Type of change\r\n- [x] A new research paper code implementation\r\n\r\n## Tests\r\n  - `python -m official.vision.beta.projects.panoptic_maskrcnn.modeling.heads.panoptic_deeplab_heads_test`\r\n  - `python -m official.vision.beta.projects.panoptic_maskrcnn.modeling.factory_test`\r\n  - `python -m official.vision.beta.projects.panoptic_maskrcnn.modeling.panoptic_deeplab_model_test`\r\n  - `python -m official.vision.beta.projects.panoptic_maskrcnn.modeling.layers.panoptic_deeplab_merge_test`\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 407,
        "deletions": 0,
        "changed_files": 8,
        "created_at": "2022-01-07T01:36:32Z",
        "closed_at": "2022-01-13T23:03:08Z",
        "merged_at": "2022-01-13T23:03:08Z",
        "body": "# Description\r\n\r\nAdded another model, VGG-16, and necessary configurations to train on the ImageNet dataset to the respective Image classification folder.\r\n\r\n## Type of change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] A new research paper code implementation\r\n\r\n## Tests and configurations\r\n\r\nI trained and tested the model myself on the ImageNet dataset with the following configurations, which are similar to the original paper implementation:\r\n\r\n| Parameter                | value  |\r\n| ------------------------ | ------ |\r\n| Batch size           | `256`   |\r\n| Epochs               | `90`   |\r\n| Learning Rate                   | `0.01`  |\r\n| Momentum             | `0.9`  |\r\n| Learning Rate Schedule | `Stepwise` |\r\n| Boundaries | `[30, 60]` |\r\n| Learning rate multipler | `0.1` | \r\n| Weight decay | `1e-4` |\r\n| Dropout | `0.5` |\r\n| Label Smoothing | `0` |\r\n\r\nThey can also be found extensively in the `examples/vgg16/gpu.yaml` file. \r\n\r\nAfter 90 epochs, I obtained a validation Top-1 error of 72.8% and a Top-5 error of 91.1%. which confirms previous results [1, 2]. You can also check the performance of the network throughout the training by accessing the [Weights and Biases report](https://wandb.ai/gohan/train_imagenet/runs/1zokrwti).\r\n\r\nOn the ImageNet test set, I got 71.1% and 90.3% of Top-1 and Top-5 errors, which again confirms previous results. I made available the weights for the fully trained model in [Google Drive](https://drive.google.com/drive/folders/1rAPS1wPz2nHT1rw_mZ_QqbjMSFxdrl63?usp=sharing). \r\n\r\nTo train the network you just need to run:\r\n\r\n`python3 classifier_trainer.py --mode=train_and_eval --model_type=vgg --dataset=imagenet --model_dir=vgg16 --data_dir=imagenet-data/ILSVRC/tfrecords/ --config_file=configs/examplesvgg16/gpu.yaml`\r\n\r\nRefences:\r\n\r\n- [1] - https://github.com/keras-team/keras-applications\r\n- [2] - https://pytorch.org/hub/pytorch_vision_vgg/\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2021-12-25T17:10:29Z",
        "closed_at": "2021-12-28T15:32:35Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nFix typo in the download urls for TF2 mobilenet v1 and v2 classification checkpoints.\r\n\r\n# Change type\r\n\r\n- [x] Documentation update\r\n\r\n# Tests\r\n\r\nNot relevant since it's just a docs update.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 45,
        "deletions": 30,
        "changed_files": 1,
        "created_at": "2021-12-23T20:27:57Z",
        "closed_at": "2021-12-29T22:54:06Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-12-19T14:10:20Z",
        "closed_at": "2022-01-06T04:44:37Z",
        "merged_at": "2022-01-06T04:44:37Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1732,
        "deletions": 0,
        "changed_files": 12,
        "created_at": "2021-12-03T01:11:30Z",
        "closed_at": "2021-12-11T05:58:33Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nAdded the Roformer Model.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] A new research paper code implementation\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1751,
        "deletions": 0,
        "changed_files": 12,
        "created_at": "2021-12-02T22:41:37Z",
        "closed_at": "2021-12-03T01:10:00Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nImplementation of Roformer.\r\nCo-authored-by: Lesheng Jin < leshenj15@ucsd.edu>\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] A new research paper code implementation\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 156,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2021-11-30T23:06:43Z",
        "closed_at": "2023-02-10T21:08:38Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nAdded serving module for YOLO.\r\n\r\n- [x] A new research paper code implementation\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 14,
        "changed_files": 1,
        "created_at": "2021-11-30T10:34:30Z",
        "closed_at": "2023-06-05T18:49:32Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n- setup.py must be copied before runing python -m install .\r\n- if pip is not upgraded, the instalation hangs\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\nThis is a ipynb change: a manual execution of the notebook was ran.\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [X] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [X] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [X] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [X] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [X] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2021-11-23T18:55:56Z",
        "closed_at": "2021-12-15T16:24:21Z",
        "merged_at": "2021-12-15T16:24:21Z",
        "body": "# Description\r\n\r\nFixed preprocessing link and added clarifications about vocabulary size.\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1704,
        "deletions": 0,
        "changed_files": 9,
        "created_at": "2021-11-16T17:54:18Z",
        "closed_at": "2023-02-09T18:25:51Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nThis PR adds a TFRecord Generator and Dataloader for Pix3D dataset using Mesh R-CNN annotations. The annotations and were obtained from the official Mesh R-CNN repository: https://github.com/facebookresearch/meshrcnn/blob/main/datasets/pix3d/download_pix3d.sh\r\n\r\nIn addition to the COCO annotations, the Pix3D TFRecord Generator produces the following new annotations:\r\n\r\n| Name | Shape | Dtype | Description |\r\n| - | - | - | - |\r\n| model/vertices | [None, 3] | float32 | The (x,y,z) coordinates of the mesh vertices |\r\n| model/faces | [None, 3] | int64 | The indices of the 3 vertices composing each face |\r\n| model/voxel_indices | [None, 3] | int64 | The indices of the occupied voxels in the voxel grid |\r\n| model/voxel_shape | [3] | int64 | The shape of the voxel grid |\r\n| model/rot_mat | [3, 3] | float32 | Matrix to rotate the mesh coordinates so that it is aligned it to the image |\r\n| model/trans_mat | [3] | float32 | Vector to translate the mesh coordinates so that it is aligned it to the image |\r\n| model/intrinsic_mat | [3] | float32 | Vector containing the intrinsic camera parameters: f, px, py |\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] A new research paper code implementation\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * TFRecord Generator Test:  `python -m official.vision.beta.projects.mesh_rcnn.data.create_pix3d_tf_record_test`\r\n> * Dataloader Test: `python -m official.vision.beta.projects.mesh_rcnn.dataloaders.meshrcnn_input_test`\r\n> * Preprocess Ops Test: `python -m official.vision.beta.projects.mesh_rcnn.ops.meshrcnn_preprocess_ops_test`\r\n\r\n**Test Configuration**:\r\nIn `create_pix3d_tf_record_test`, ensure that `pix3d_dir` is set to the directory where the raw Pix3D dataset is located. A test annotation file is provided under official/vision/beta/projects/mesh_rcnn/data called `tfrecord_pix3d_test_annotations.json`. This file should be copied into the raw dataset directory.\r\n\r\nIn `meshrcnn_input_test`, alter the `input_path` string in the DataConfig class to the path of the TFRecord directory. This string should correspond to the `OUTPUT_DIR/FILE_PREFIX` flag when running `create_pix3d_tf_record`.\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 419,
        "deletions": 11,
        "changed_files": 6,
        "created_at": "2021-11-13T05:48:27Z",
        "closed_at": "2022-04-05T04:54:50Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nKmeans and config changes to run k-means and generate anchors prior to training a model.\r\n\r\n\r\nNote: Please delete options that are not relevant.\r\n- [x] A new research paper code implementation\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2021-11-09T19:28:44Z",
        "closed_at": "2021-12-11T06:00:29Z",
        "merged_at": "2021-12-11T06:00:29Z",
        "body": "# Description\r\n\r\n> Remove duplicate lines from the readme for training and evaluating object detectors \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Documentation update\r\n\r\n## Tests\r\n\r\n> This is just a documentation update\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 23,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2021-11-09T16:38:34Z",
        "closed_at": "2022-07-19T01:46:53Z",
        "merged_at": null,
        "body": "* Assemblenet++ implementation with TF2 (UCF101 Dataset)\r\n\r\n* pylint.sh passed\r\n\r\n* train.py document updated\r\n\r\n* README.md updated - AssembleNet and AssembleNet++\r\n\r\n* YAML and configuration updated - AssembleNet and AssembleNet++\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> Tensorflow2 Migration for AssembleNet++ completed \r\n> Providing New experiment (UCF101 Dataset)\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [x] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n ```bash\r\npython -m official.vision.beta.projects.assemblenet.trian \\\r\n--mode=train_and_eval --experiment=assemblenetplus_ucf101 \\\r\n--model_dir='YOUR_GS_BUCKET_TO_SAVE_MODEL' \\\r\n--config_file=./official/vision/beta/projects/assemblenet/\\\r\n--ucf101_assemblenet_plus_tpu.yaml \\\r\n--tpu=TPU_NAME \r\n```\r\nTest with Training and evaluation with new experiment configuration and AssembleNet++ Implementation.\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 172,
        "deletions": 24,
        "changed_files": 5,
        "created_at": "2021-10-28T16:02:58Z",
        "closed_at": "2022-01-12T22:26:09Z",
        "merged_at": "2022-01-12T22:26:09Z",
        "body": "# Description\r\nUpdated readme with steps to run the project\r\n\r\n## Type of change\r\n- [x] A new research paper code implementation\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1697,
        "deletions": 0,
        "changed_files": 12,
        "created_at": "2021-10-28T08:38:15Z",
        "closed_at": "2021-11-29T06:29:21Z",
        "merged_at": "2021-11-29T06:29:21Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] A new research paper code implementation\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1301,
        "deletions": 52,
        "changed_files": 23,
        "created_at": "2021-10-25T19:38:20Z",
        "closed_at": "2021-12-11T05:59:57Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nfixes box clipping dureing eval\r\n\r\n## Type of change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1623,
        "deletions": 1588,
        "changed_files": 2,
        "created_at": "2021-10-20T15:49:01Z",
        "closed_at": "2023-02-02T00:08:08Z",
        "merged_at": null,
        "body": "# Description\r\nAdded support to MixupAndCutmix for both sparse and one-hot encoded input labels.  Also ensured that float16 image inputs are cast as float32 for mixup and cutmix ops while preserving the input data type on output from distort method.\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**: \r\nI added an additional test to the augment_test.py file testing float16 image inputs and one-hot encoded label inputs.\r\nI successfully passed this new test and all other existing tests ensuring that previous functionality is preserved.\r\n\r\n## Checklist\r\n\r\n- [x ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ x] I have made corresponding changes to the documentation.\r\n- [ x] My changes generate no new warnings.\r\n- [ x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1007,
        "deletions": 49,
        "changed_files": 20,
        "created_at": "2021-10-16T15:05:49Z",
        "closed_at": "2021-11-12T20:24:20Z",
        "merged_at": "2021-11-12T20:24:20Z",
        "body": "# Description\r\n\r\nChanges to experiment naming and adds 3 experiments for Yolo Large. \r\n\r\n## Type of change\r\n- [x] A new research paper code implementation\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 0,
        "changed_files": 0,
        "created_at": "2021-10-09T16:34:02Z",
        "closed_at": "2021-11-02T07:04:15Z",
        "merged_at": "2021-11-02T07:04:14Z",
        "body": "# Description\r\nThis PR adds the Panoptic FPN architecture described in [Panoptic Feature Pyramid Networks\r\n](https://arxiv.org/pdf/1901.02446.pdf)\r\n\r\n## Type of change\r\n- [x] A new research paper code implementation\r\n\r\n## Tests\r\n  - `python -m official.vision.beta.modeling.heads.segmentation_heads_test`\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1129,
        "deletions": 26,
        "changed_files": 8,
        "created_at": "2021-10-01T18:24:14Z",
        "closed_at": "2021-11-09T04:06:18Z",
        "merged_at": "2021-11-09T04:06:18Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> Tensorflow2 Migration for AssembleNet++ completed \r\n> Providing New experiment (UCF101 Dataset)\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [x] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n>\r\n\r\n ```bash\r\npython -m official.vision.beta.projects.assemblenet.trian \\\r\n--mode=train_and_eval --experiment=assemblenetplus_ucf101 \\\r\n--model_dir='YOUR_GS_BUCKET_TO_SAVE_MODEL' \\\r\n--config_file=./official/vision/beta/projects/assemblenet/\\\r\n--ucf101_assemblenet_plus_tpu.yaml \\\r\n--tpu=TPU_NAME \r\n```\r\nTest with Training and evaluation with new experiment configuration and AssembleNet++ Implementation.\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2279,
        "deletions": 164,
        "changed_files": 32,
        "created_at": "2021-10-01T07:37:29Z",
        "closed_at": "2021-10-11T17:47:38Z",
        "merged_at": "2021-10-11T17:47:38Z",
        "body": "# Description\r\nAll training requirements for YOLO\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\nTests the datapipeline using the task. \r\n```\r\npython3.8 -m official.vision.beta.projects.yolo.tasks.yolo_test\r\npython3.8 -m official.vision.beta.projects.yolo.dataloaders.yolo_input_test\r\n```\r\n\r\n# Train Yolo\r\n```\r\npython3.8 -m official.vision.beta.projects.yolo.train --experiment=scaled_yolo --mode train_and_eval --config_file yolo/configs/experiments/yolov4-csp/tpu/640.yaml --model_dir ../checkpoints/yolov4-csp-640\r\n```\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 0,
        "changed_files": 0,
        "created_at": "2021-09-29T19:47:23Z",
        "closed_at": "2021-11-02T07:04:14Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nPanoptic segmentation contribution from @srihari-humbarwadi \r\n\r\n* added `PanopticSegmentationModule`\r\n* added tests for `PanopticSegmentationModule`\r\n* added script to export `saved_model`\r\n* added registry_imports\r\n* added training script\r\n* fixed docstrings\r\n* pass model as an arg to serving module\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 422,
        "deletions": 0,
        "changed_files": 5,
        "created_at": "2021-09-28T14:19:31Z",
        "closed_at": "2021-09-29T19:31:43Z",
        "merged_at": "2021-09-29T19:31:43Z",
        "body": "# Description\r\n - added panoptic segmentation serving module\r\n - added script to export `saved_model`\r\n - training script\r\n\r\n## Type of change\r\n- [x] A new research paper code implementation\r\n\r\n## Tests\r\n  - `python -m official.vision.beta.projects.panoptic_maskrcnn.serving.panoptic_segmentation_test`\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-09-22T14:58:44Z",
        "closed_at": "2021-09-27T03:52:15Z",
        "merged_at": null,
        "body": "Updating broken link with correct colab link in Movinet . ref https://github.com/tensorflow/models/issues/10271\r\n\r\n# Description\r\nUpdated with the [**`correct URL`**](https://colab.research.google.com/github/tensorflow/models/blob/master/official/vision/beta/projects/movinet/movinet_tutorial.ipynb) in place of [**`dead links`**](https://colab.research.google.com/github/tensorflow/models/tree/master/official/vision/beta/projects/movinet/movinet_tutorial.ipynb) in Movinet. \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2839,
        "deletions": 1300,
        "changed_files": 25,
        "created_at": "2021-09-17T06:05:59Z",
        "closed_at": "2021-09-28T18:09:23Z",
        "merged_at": "2021-09-28T18:09:23Z",
        "body": "# Description\r\n\r\nThis set of functions are used to apply random augmentation to the images for the YOLO data pipeline including mosaic, affine based scaling, translation, rotation, and perspective warping. This also adds the image padding and distortion operations used by Darknet. \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\nTo be added.\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 351,
        "deletions": 2,
        "changed_files": 3,
        "created_at": "2021-09-15T15:39:55Z",
        "closed_at": "2021-11-16T23:32:59Z",
        "merged_at": "2021-11-16T23:32:59Z",
        "body": "Added README for global features model",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1731,
        "deletions": 244,
        "changed_files": 13,
        "created_at": "2021-09-10T04:48:24Z",
        "closed_at": "2021-09-14T04:42:55Z",
        "merged_at": "2021-09-14T04:42:55Z",
        "body": "# Description\r\nAddition of the Yolo Loss function factory, Darknet dynamic loss function, and the Scaled Yolo Loss function. Further Updating all existing components to be up to date with the most performant model state. We fixed a bug with the dilated darknet that would cause the construction to crash as model size is scaled. Finally, this PR adds updates to the detection generator in order to integrate shared loss utility functions required for decoding the models outputs. \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n```\r\n# loss and operation tests\r\npython3.8 -m official.vision.beta.projects.yolo.ops.box_ops_test\r\npython3 -m official.vision.beta.projects.yolo.losses.yolo_loss_test\r\n\r\n# layer tests\r\npython3 -m official.vision.beta.projects.yolo.modeling.layers.detection_generator_test\r\npython3.8 -m official.vision.beta.projects.yolo.modeling.layers.nn_blocks_test\r\n\r\n# model tests\r\npython3.8 -m official.vision.beta.projects.yolo.modeling.backbones.darknet_test\r\npython3.8 -m official.vision.beta.projects.yolo.modeling.decoders.yolo_decoder_test\r\npython3.8 -m official.vision.beta.projects.yolo.modeling.heads.yolo_head_test\r\n```\r\n**Test Configuration**:\r\n-  Python3.8 or higher \r\n-  tf 2.6.0\r\n-  1 GPU\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2021-09-09T01:09:43Z",
        "closed_at": "2021-09-09T07:55:09Z",
        "merged_at": "2021-09-09T07:55:09Z",
        "body": "# Description\r\nFixed invalid json\r\n## Type of change\r\n\r\n\r\n- [ v] Bug fix (non-breaking change which fixes an issue)\r\n- [v ] Documentation update\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 12,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2021-09-08T15:36:05Z",
        "closed_at": "2021-10-12T15:59:38Z",
        "merged_at": null,
        "body": "# In this commit i have added dice loss to losses folder\r\n\r\n\r\n> * dice loss can be used as a loss function for training segmentation . models\r\n>\r\n\r\n## Tests\r\n\r\ntested the file using unittest\r\n\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 22,
        "deletions": 21,
        "changed_files": 1,
        "created_at": "2021-09-07T23:57:00Z",
        "closed_at": "2021-09-08T21:04:27Z",
        "merged_at": "2021-09-08T21:04:27Z",
        "body": "# Description\r\nUpdate mechanism for choosing outputs from tflite-oriented saved model export.  Explicitly sets up the serving_default signature in the saved_models to provide named outputs for 'predictions', 'embeddings', and 'log_mel_spectrogram'.\r\n\r\n## Type of change\r\n\r\n- [v] Bug fix for #10246\r\n- [v] Enhancement to construct saved_models (and tflite outputs) with explicit outputs.\r\n\r\n## Tests\r\n\r\n```\r\n$ python3 export.py yamnet.h5 export\r\n```\r\nnow runs to completion instead of crashing.\r\n\r\n## Checklist\r\n\r\n- [v] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [v] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [v] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [v] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [v] I have commented my code, particularly in hard-to-understand areas.\r\n- [n/a] I have made corresponding changes to the documentation.\r\n- [v] My changes generate no new warnings.\r\n- [n/a] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 24,
        "deletions": 19,
        "changed_files": 1,
        "created_at": "2021-09-07T20:21:14Z",
        "closed_at": "2021-09-07T23:58:41Z",
        "merged_at": null,
        "body": "# Description\r\nUpdate mechanism for choosing outputs from tflite-oriented saved model export\r\n\r\n## Type of change\r\n\r\n- [v] Bug fix for #10246\r\n\r\n## Tests\r\n\r\n```\r\n$ python3 export.py yamnet.h5 export\r\n```\r\nnow runs to completion instead of crashing.\r\n\r\n## Checklist\r\n\r\n- [v] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [v] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [v] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [v] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [v] I have commented my code, particularly in hard-to-understand areas.\r\n- [n/a] I have made corresponding changes to the documentation.\r\n- [v] My changes generate no new warnings.\r\n- [n/a] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2021-08-31T17:48:24Z",
        "closed_at": "2021-09-01T21:03:17Z",
        "merged_at": "2021-09-01T21:03:17Z",
        "body": "# Description\r\n\r\nUpdate readme of deeplab to link to deeplab2\r\n\r\n## Type of change\r\n\r\n- [ x] Documentation update\r\n\r\n\r\n## Tests\r\n\r\nNo tests\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ x] I have made corresponding changes to the documentation.\r\n- [ x] My changes generate no new warnings.\r\n- [ x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2021-08-30T18:55:13Z",
        "closed_at": "2021-09-02T00:55:57Z",
        "merged_at": "2021-09-02T00:55:57Z",
        "body": "same as https://github.com/tensorflow/models/pull/9053\r\n\r\n# Description\r\nsets `clip_boxes=False`, as it makes `tf.image.combined_non_max_suppression` coordinate agnostic after https://github.com/tensorflow/tensorflow/commit/35e39cd3f102d663d198074e95ff77197d2e0a1d\r\n\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [x] Other\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1511,
        "deletions": 6,
        "changed_files": 3,
        "created_at": "2021-08-27T14:00:18Z",
        "closed_at": "2021-09-02T04:31:16Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1487,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2021-08-27T10:32:20Z",
        "closed_at": "2022-01-13T23:11:00Z",
        "merged_at": null,
        "body": "Implementation of the Data-Efficient Image Transformer (DEIT) without distillation but including new augmentations:\r\n\r\n- ColorJitter\r\n- Stochastic Depth for the Transformer Encoder\r\n- RandomErasing\r\n- Mixup and Cutmix\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] A new research paper code implementation\r\n\r\n## Tests\r\n\r\nI ran several training procedures (varying the augmentation techniques) and added basic unit tests to the new augmentations.\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2021-08-26T08:15:48Z",
        "closed_at": "2021-09-01T22:56:47Z",
        "merged_at": "2021-09-01T22:56:46Z",
        "body": "# Description\r\n\r\nFixing documentation on the structure of the data.\r\n\r\nAs can be seen from the following lines https://github.com/tensorflow/models/blob/a1facb469a51e9e25f8fa19dd1ade7f44082f80f/official/recommendation/ranking/data/data_pipeline.py#L71-L87\r\n\r\n\r\nThe structure of the tsv dataset should be label, numerical features and categorical features.\r\n\r\n\r\n## Type of change\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n\r\n\r\n## Tests\r\n\r\nDocumentation update, no testing needed.\r\n\r\n## Checklist\r\n\r\n- [X] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 271,
        "deletions": 47,
        "changed_files": 5,
        "created_at": "2021-08-25T13:26:58Z",
        "closed_at": "2021-09-29T19:45:19Z",
        "merged_at": null,
        "body": "# Description\r\nExtends existing `create_coco_tf_record.py` script to load and export panoptic annotations in tfrecord files\r\n\r\n## Type of change\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2021-08-24T17:38:22Z",
        "closed_at": "2021-09-07T21:55:47Z",
        "merged_at": "2021-09-07T21:55:47Z",
        "body": "# Description\r\nThe order of the input tensors is incorrect and therefore the sample notebook does not run. https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/centernet_on_device.ipynb\r\n\r\nThe sample code has the order of the input tensors as `boxes, classes, scores, num_detections`, but actually the order should be `scores, boxes,  num_detections, classes`\r\n\r\nThis PR corrects the indexes of the input tensors and the sample notebook runs.\r\n\r\n## Type of change\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\n1. Run the sample notebook, you will receive an error when visualizing the bounding boxes\r\n2. Try my change, you won't receive an error and it will work\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n- [X] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [X] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [X] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [X] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [X] My changes generate no new warnings.\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 664,
        "deletions": 341,
        "changed_files": 38,
        "created_at": "2021-08-23T22:03:17Z",
        "closed_at": "2021-09-14T21:20:03Z",
        "merged_at": "2021-09-14T21:20:03Z",
        "body": "# Description\r\n\r\nUpdate seq_flow_lite so it uses Tensorflow 2.6.0 when building\r\n\r\n## Type of change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\n\r\nBuilt the custom TF and TFLite ops.  Tests do not build, but they weren't building before this change.\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 21,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2021-08-16T04:58:55Z",
        "closed_at": "2021-08-16T06:35:47Z",
        "merged_at": null,
        "body": "# Security Policy\r\n\r\n## Supported Versions\r\n\r\nUse this section to tell people about which versions of your project are\r\ncurrently being supported with security updates.\r\n\r\n| Version | Supported          |\r\n| ------- | ------------------ |\r\n| 5.1.x   | :white_check_mark: |\r\n| 5.0.x   | :x:                |\r\n| 4.0.x   | :white_check_mark: |\r\n| < 4.0   | :x:                |\r\n\r\n## Reporting a Vulnerability\r\n\r\nUse this section to tell people how to report a vulnerability.\r\n\r\nTell them where to go, how often they can expect to get an update on a\r\nreported vulnerability, what to expect if the vulnerability is accepted or\r\ndeclined, etc.\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 646,
        "deletions": 49,
        "changed_files": 12,
        "created_at": "2021-08-11T15:00:01Z",
        "closed_at": "2021-09-29T07:03:56Z",
        "merged_at": "2021-09-29T07:03:55Z",
        "body": "# Description\r\nadded `PanopticSegmentationGenerator` layer, which is needed for merging instance and semantic segmentation masks.\r\n\r\n## Type of change\r\n- [x] A new research paper code implementation\r\n\r\n## Tests\r\n  - `python -m official.vision.beta.projects.panoptic_maskrcnn.modeling.layers.panoptic_segmentation_generator_test`\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 39,
        "deletions": 17,
        "changed_files": 1,
        "created_at": "2021-08-10T01:42:45Z",
        "closed_at": "2021-08-19T16:01:22Z",
        "merged_at": "2021-08-19T16:01:22Z",
        "body": "# Description\r\n\r\nUpdate bike video dataset path.\r\n\r\nAdd link to TF2 port with build file for compiling the ICP op.\r\n\r\nFixes #9158.\r\n\r\nMerges changes from #10091.\r\n\r\n## Type of change\r\n\r\n- [X] Documentation update",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 336,
        "deletions": 8,
        "changed_files": 4,
        "created_at": "2021-08-09T20:22:43Z",
        "closed_at": "2021-12-29T05:23:48Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nThis PR adds the YOLO detection generator.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n```\r\npython3.8 -m official.vision.beta.projects.yolo.modeling.decoders.yolo_decoder_test\r\n```\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 14
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-08-05T21:41:30Z",
        "closed_at": "2022-06-21T21:12:33Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nFixed spelling\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n\r\n## Checklist\r\n\r\n- [X] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [X] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [X] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [X] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [X] I have commented my code, particularly in hard-to-understand areas.\r\n- [X] I have made corresponding changes to the documentation.\r\n- [X] My changes generate no new warnings.\r\n- [X] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 839,
        "deletions": 35,
        "changed_files": 16,
        "created_at": "2021-08-05T12:11:53Z",
        "closed_at": "2021-08-20T17:02:54Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nImplementation of the Data-Efficient Image Transformer (DEIT) without distillation but including new augmentations:\r\n- ColorJitter\r\n- Stochastic Depth for the Transformer Encoder\r\n- RandomErasing\r\n- Mixup and Cutmix\r\n- Repeated Augmentation\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Documentation update\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] A new research paper code implementation\r\n\r\n## Tests\r\n\r\nI ran several training procedures (varying the augmentation techniques) and added basic unit tests to the new augmentations. More details on the experiments and models will follow.\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 6087,
        "deletions": 2,
        "changed_files": 39,
        "created_at": "2021-08-04T17:34:46Z",
        "closed_at": "2021-12-14T22:49:20Z",
        "merged_at": null,
        "body": "This is a test pull request for code review purpose.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2021-08-03T20:49:55Z",
        "closed_at": "2021-08-04T20:45:00Z",
        "merged_at": "2021-08-04T20:45:00Z",
        "body": "fixes https://github.com/tensorflow/models/issues/10161\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2021-07-28T18:24:08Z",
        "closed_at": "2021-07-30T16:04:31Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nAdded task definition for Panoptic Mask R-CNN\r\n\r\nContribution from @srihari-humbarwadi (https://github.com/tensorflow/models/pull/10165)\r\n\r\n* added PanopticMaskRCNNTask config\r\n* added tests for config\r\n* added Panoptic MaskRCNN task\r\n* added tests for Panoptic MaskRCNN task\r\n* fixed typo\r\n* set default segmentation loss weight to 1.0\r\n* added class docstrings\r\n* support `segmentation_decoder` checkpoint\r\n* added `init_checkpoint_modules` description\r\n* compute `steps_per_epoch` with `train_batch_size`\r\n* flattened semantic_segmentation loss attributes\r\n\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 706,
        "deletions": 9,
        "changed_files": 5,
        "created_at": "2021-07-27T17:11:14Z",
        "closed_at": "2021-07-28T18:22:01Z",
        "merged_at": "2021-07-28T18:22:01Z",
        "body": "# Description\r\nAdded task definition for Panoptic Mask R-CNN \r\n\r\n## Type of change\r\n- [x] A new research paper code implementation\r\n\r\n## Tests\r\n - `PanopticMaskRCNNTask`\r\n   - `python -m official.vision.beta.projects.panoptic_maskrcnn.tasks.panoptic_maskrcnn_test`\r\n - configs\r\n   - `python -m official.vision.beta.projects.panoptic_maskrcnn.configs.panoptic_maskrcnn_test`\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 21,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2021-07-25T02:12:35Z",
        "closed_at": "2021-07-25T03:44:15Z",
        "merged_at": null,
        "body": "# Security Policy\r\n\r\n## Supported Versions\r\n\r\nUse this section to tell people about which versions of your project are\r\ncurrently being supported with security updates.\r\n\r\n| Version | Supported          |\r\n| ------- | ------------------ |\r\n| 5.1.x   | :white_check_mark: |\r\n| 5.0.x   | :x:                |\r\n| 4.0.x   | :white_check_mark: |\r\n| < 4.0   | :x:                |\r\n\r\n## Reporting a Vulnerability\r\n\r\nUse this section to tell people how to report a vulnerability.\r\n\r\nTell them where to go, how often they can expect to get an update on a\r\nreported vulnerability, what to expect if the vulnerability is accepted or\r\ndeclined, etc.\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [x] TensorFlow 2 migration\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 21,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2021-07-25T02:08:16Z",
        "closed_at": "2021-08-06T16:35:57Z",
        "merged_at": null,
        "body": "# Security Policy\r\n\r\n## Supported Versions\r\n\r\nUse this section to tell people about which versions of your project are\r\ncurrently being supported with security updates.\r\n\r\n| Version | Supported          |\r\n| ------- | ------------------ |\r\n| 5.1.x   | :white_check_mark: |\r\n| 5.0.x   | :x:                |\r\n| 4.0.x   | :white_check_mark: |\r\n| < 4.0   | :x:                |\r\n\r\n## Reporting a Vulnerability\r\n\r\nUse this section to tell people how to report a vulnerability.\r\n\r\nTell them where to go, how often they can expect to get an update on a\r\nreported vulnerability, what to expect if the vulnerability is accepted or\r\ndeclined, etc.\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [x] TensorFlow 2 migration\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 110,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2021-07-19T20:19:00Z",
        "closed_at": "2021-07-27T15:58:47Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nContribution from @srihari-humbarwadi\r\n\r\n#10112\r\n\r\n* Added `panoptic_maskrcnn_input.Parser`\r\n* Added tests for `panoptic_maskrcnn_input.Parser`\r\n* added `DataConfig`\r\n* fixed doc-string\r\n* Added type annotations\r\n\r\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 20584,
        "deletions": 7070,
        "changed_files": 143,
        "created_at": "2021-07-17T18:35:25Z",
        "closed_at": "2021-07-19T20:08:10Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [x] TensorFlow 2 migration\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] A new research paper code implementation\r\n- [x] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 20585,
        "deletions": 7071,
        "changed_files": 144,
        "created_at": "2021-07-17T17:56:54Z",
        "closed_at": "2021-07-19T20:10:43Z",
        "merged_at": null,
        "body": "\r\n[CONTRIBUTING.md](https://github.com/tensorflow/models/files/6835108/CONTRIBUTING.md)\r\n[ISSUES.md](https://github.com/tensorflow/models/files/6835109/ISSUES.md)\r\n[README.md](https://github.com/tensorflow/models/files/6835110/README.md)\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [x] TensorFlow 2 migration\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] A new research paper code implementation\r\n- [x] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1034,
        "deletions": 0,
        "changed_files": 6,
        "created_at": "2021-07-14T15:07:37Z",
        "closed_at": "2021-07-23T04:59:45Z",
        "merged_at": null,
        "body": "# Description\r\nAdded task definition for Panoptic Mask R-CNN \r\n\r\n## Type of change\r\n- [x] A new research paper code implementation\r\n\r\n## Tests\r\n - `PanopticMaskRCNNTask`\r\n   - `python -m official.vision.beta.projects.panoptic_maskrcnn.tasks.panoptic_maskrcnn_test`\r\n - configs\r\n   - `python -m official.vision.beta.projects.panoptic_maskrcnn.configs.panoptic_maskrcnn_test`\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 29613,
        "deletions": 17707,
        "changed_files": 164,
        "created_at": "2021-07-12T13:51:20Z",
        "closed_at": "2021-07-15T18:04:54Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 254,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2021-07-12T13:47:37Z",
        "closed_at": "2021-07-15T18:04:07Z",
        "merged_at": null,
        "body": "A. HISTORY OF THE SOFTWARE\r\n==========================\r\n\r\nPython was created in the early 1990s by Guido van Rossum at Stichting\r\nMathematisch Centrum (CWI, see http://www.cwi.nl) in the Netherlands\r\nas a successor of a language called ABC.  Guido remains Python's\r\nprincipal author, although it includes many contributions from others.\r\n\r\nIn 1995, Guido continued his work on Python at the Corporation for\r\nNational Research Initiatives (CNRI, see http://www.cnri.reston.va.us)\r\nin Reston, Virginia where he released several versions of the\r\nsoftware.\r\n\r\nIn May 2000, Guido and the Python core development team moved to\r\nBeOpen.com to form the BeOpen PythonLabs team.  In October of the same\r\nyear, the PythonLabs team moved to Digital Creations, which became\r\nZope Corporation.  In 2001, the Python Software Foundation (PSF, see\r\nhttps://www.python.org/psf/) was formed, a non-profit organization\r\ncreated specifically to own Python-related Intellectual Property.\r\nZope Corporation was a sponsoring member of the PSF.\r\n\r\nAll Python releases are Open Source (see http://www.opensource.org for\r\nthe Open Source Definition).  Historically, most, but not all, Python\r\nreleases have also been GPL-compatible; the table below summarizes\r\nthe various releases.\r\n\r\n    Release         Derived     Year        Owner       GPL-\r\n                    from                                compatible? (1)\r\n\r\n    0.9.0 thru 1.2              1991-1995   CWI         yes\r\n    1.3 thru 1.5.2  1.2         1995-1999   CNRI        yes\r\n    1.6             1.5.2       2000        CNRI        no\r\n    2.0             1.6         2000        BeOpen.com  no\r\n    1.6.1           1.6         2001        CNRI        yes (2)\r\n    2.1             2.0+1.6.1   2001        PSF         no\r\n    2.0.1           2.0+1.6.1   2001        PSF         yes\r\n    2.1.1           2.1+2.0.1   2001        PSF         yes\r\n    2.1.2           2.1.1       2002        PSF         yes\r\n    2.1.3           2.1.2       2002        PSF         yes\r\n    2.2 and above   2.1.1       2001-now    PSF         yes\r\n\r\nFootnotes:\r\n\r\n(1) GPL-compatible doesn't mean that we're distributing Python under\r\n    the GPL.  All Python licenses, unlike the GPL, let you distribute\r\n    a modified version without making your changes open source.  The\r\n    GPL-compatible licenses make it possible to combine Python with\r\n    other software that is released under the GPL; the others don't.\r\n\r\n(2) According to Richard Stallman, 1.6.1 is not GPL-compatible,\r\n    because its license has a choice of law clause.  According to\r\n    CNRI, however, Stallman's lawyer has told CNRI's lawyer that 1.6.1\r\n    is \"not incompatible\" with the GPL.\r\n\r\nThanks to the many outside volunteers who have worked under Guido's\r\ndirection to make these releases possible.\r\n\r\n\r\nB. TERMS AND CONDITIONS FOR ACCESSING OR OTHERWISE USING PYTHON\r\n===============================================================\r\n\r\nPYTHON SOFTWARE FOUNDATION LICENSE VERSION 2\r\n--------------------------------------------\r\n\r\n1. This LICENSE AGREEMENT is between the Python Software Foundation\r\n(\"PSF\"), and the Individual or Organization (\"Licensee\") accessing and\r\notherwise using this software (\"Python\") in source or binary form and\r\nits associated documentation.\r\n\r\n2. Subject to the terms and conditions of this License Agreement, PSF hereby\r\ngrants Licensee a nonexclusive, royalty-free, world-wide license to reproduce,\r\nanalyze, test, perform and/or display publicly, prepare derivative works,\r\ndistribute, and otherwise use Python alone or in any derivative version,\r\nprovided, however, that PSF's License Agreement and PSF's notice of copyright,\r\ni.e., \"Copyright (c) 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010,\r\n2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021 Python Software Foundation;\r\nAll Rights Reserved\" are retained in Python alone or in any derivative version\r\nprepared by Licensee.\r\n\r\n3. In the event Licensee prepares a derivative work that is based on\r\nor incorporates Python or any part thereof, and wants to make\r\nthe derivative work available to others as provided herein, then\r\nLicensee hereby agrees to include in any such work a brief summary of\r\nthe changes made to Python.\r\n\r\n4. PSF is making Python available to Licensee on an \"AS IS\"\r\nbasis.  PSF MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR\r\nIMPLIED.  BY WAY OF EXAMPLE, BUT NOT LIMITATION, PSF MAKES NO AND\r\nDISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS\r\nFOR ANY PARTICULAR PURPOSE OR THAT THE USE OF PYTHON WILL NOT\r\nINFRINGE ANY THIRD PARTY RIGHTS.\r\n\r\n5. PSF SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF PYTHON\r\nFOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS\r\nA RESULT OF MODIFYING, DISTRIBUTING, OR OTHERWISE USING PYTHON,\r\nOR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.\r\n\r\n6. This License Agreement will automatically terminate upon a material\r\nbreach of its terms and conditions.\r\n\r\n7. Nothing in this License Agreement shall be deemed to create any\r\nrelationship of agency, partnership, or joint venture between PSF and\r\nLicensee.  This License Agreement does not grant permission to use PSF\r\ntrademarks or trade name in a trademark sense to endorse or promote\r\nproducts or services of Licensee, or any third party.\r\n\r\n8. By copying, installing or otherwise using Python, Licensee\r\nagrees to be bound by the terms and conditions of this License\r\nAgreement.\r\n\r\n\r\nBEOPEN.COM LICENSE AGREEMENT FOR PYTHON 2.0\r\n-------------------------------------------\r\n\r\nBEOPEN PYTHON OPEN SOURCE LICENSE AGREEMENT VERSION 1\r\n\r\n1. This LICENSE AGREEMENT is between BeOpen.com (\"BeOpen\"), having an\r\noffice at 160 Saratoga Avenue, Santa Clara, CA 95051, and the\r\nIndividual or Organization (\"Licensee\") accessing and otherwise using\r\nthis software in source or binary form and its associated\r\ndocumentation (\"the Software\").\r\n\r\n2. Subject to the terms and conditions of this BeOpen Python License\r\nAgreement, BeOpen hereby grants Licensee a non-exclusive,\r\nroyalty-free, world-wide license to reproduce, analyze, test, perform\r\nand/or display publicly, prepare derivative works, distribute, and\r\notherwise use the Software alone or in any derivative version,\r\nprovided, however, that the BeOpen Python License is retained in the\r\nSoftware, alone or in any derivative version prepared by Licensee.\r\n\r\n3. BeOpen is making the Software available to Licensee on an \"AS IS\"\r\nbasis.  BEOPEN MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR\r\nIMPLIED.  BY WAY OF EXAMPLE, BUT NOT LIMITATION, BEOPEN MAKES NO AND\r\nDISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS\r\nFOR ANY PARTICULAR PURPOSE OR THAT THE USE OF THE SOFTWARE WILL NOT\r\nINFRINGE ANY THIRD PARTY RIGHTS.\r\n\r\n4. BEOPEN SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF THE\r\nSOFTWARE FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS\r\nAS A RESULT OF USING, MODIFYING OR DISTRIBUTING THE SOFTWARE, OR ANY\r\nDERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.\r\n\r\n5. This License Agreement will automatically terminate upon a material\r\nbreach of its terms and conditions.\r\n\r\n6. This License Agreement shall be governed by and interpreted in all\r\nrespects by the law of the State of California, excluding conflict of\r\nlaw provisions.  Nothing in this License Agreement shall be deemed to\r\ncreate any relationship of agency, partnership, or joint venture\r\nbetween BeOpen and Licensee.  This License Agreement does not grant\r\npermission to use BeOpen trademarks or trade names in a trademark\r\nsense to endorse or promote products or services of Licensee, or any\r\nthird party.  As an exception, the \"BeOpen Python\" logos available at\r\nhttp://www.pythonlabs.com/logos.html may be used according to the\r\npermissions granted on that web page.\r\n\r\n7. By copying, installing or otherwise using the software, Licensee\r\nagrees to be bound by the terms and conditions of this License\r\nAgreement.\r\n\r\n\r\nCNRI LICENSE AGREEMENT FOR PYTHON 1.6.1\r\n---------------------------------------\r\n\r\n1. This LICENSE AGREEMENT is between the Corporation for National\r\nResearch Initiatives, having an office at 1895 Preston White Drive,\r\nReston, VA 20191 (\"CNRI\"), and the Individual or Organization\r\n(\"Licensee\") accessing and otherwise using Python 1.6.1 software in\r\nsource or binary form and its associated documentation.\r\n\r\n2. Subject to the terms and conditions of this License Agreement, CNRI\r\nhereby grants Licensee a nonexclusive, royalty-free, world-wide\r\nlicense to reproduce, analyze, test, perform and/or display publicly,\r\nprepare derivative works, distribute, and otherwise use Python 1.6.1\r\nalone or in any derivative version, provided, however, that CNRI's\r\nLicense Agreement and CNRI's notice of copyright, i.e., \"Copyright (c)\r\n1995-2001 Corporation for National Research Initiatives; All Rights\r\nReserved\" are retained in Python 1.6.1 alone or in any derivative\r\nversion prepared by Licensee.  Alternately, in lieu of CNRI's License\r\nAgreement, Licensee may substitute the following text (omitting the\r\nquotes): \"Python 1.6.1 is made available subject to the terms and\r\nconditions in CNRI's License Agreement.  This Agreement together with\r\nPython 1.6.1 may be located on the Internet using the following\r\nunique, persistent identifier (known as a handle): 1895.22/1013.  This\r\nAgreement may also be obtained from a proxy server on the Internet\r\nusing the following URL: http://hdl.handle.net/1895.22/1013\".\r\n\r\n3. In the event Licensee prepares a derivative work that is based on\r\nor incorporates Python 1.6.1 or any part thereof, and wants to make\r\nthe derivative work available to others as provided herein, then\r\nLicensee hereby agrees to include in any such work a brief summary of\r\nthe changes made to Python 1.6.1.\r\n\r\n4. CNRI is making Python 1.6.1 available to Licensee on an \"AS IS\"\r\nbasis.  CNRI MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR\r\nIMPLIED.  BY WAY OF EXAMPLE, BUT NOT LIMITATION, CNRI MAKES NO AND\r\nDISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS\r\nFOR ANY PARTICULAR PURPOSE OR THAT THE USE OF PYTHON 1.6.1 WILL NOT\r\nINFRINGE ANY THIRD PARTY RIGHTS.\r\n\r\n5. CNRI SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF PYTHON\r\n1.6.1 FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS\r\nA RESULT OF MODIFYING, DISTRIBUTING, OR OTHERWISE USING PYTHON 1.6.1,\r\nOR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.\r\n\r\n6. This License Agreement will automatically terminate upon a material\r\nbreach of its terms and conditions.\r\n\r\n7. This License Agreement shall be governed by the federal\r\nintellectual property law of the United States, including without\r\nlimitation the federal copyright law, and, to the extent such\r\nU.S. federal law does not apply, by the law of the Commonwealth of\r\nVirginia, excluding Virginia's conflict of law provisions.\r\nNotwithstanding the foregoing, with regard to derivative works based\r\non Python 1.6.1 that incorporate non-separable material that was\r\npreviously distributed under the GNU General Public License (GPL), the\r\nlaw of the Commonwealth of Virginia shall govern this License\r\nAgreement only as to issues arising under or with respect to\r\nParagraphs 4, 5, and 7 of this License Agreement.  Nothing in this\r\nLicense Agreement shall be deemed to create any relationship of\r\nagency, partnership, or joint venture between CNRI and Licensee.  This\r\nLicense Agreement does not grant permission to use CNRI trademarks or\r\ntrade name in a trademark sense to endorse or promote products or\r\nservices of Licensee, or any third party.\r\n\r\n8. By clicking on the \"ACCEPT\" button where indicated, or by copying,\r\ninstalling or otherwise using Python 1.6.1, Licensee agrees to be\r\nbound by the terms and conditions of this License Agreement.\r\n\r\n        ACCEPT\r\n\r\n\r\nCWI LICENSE AGREEMENT FOR PYTHON 0.9.0 THROUGH 1.2\r\n--------------------------------------------------\r\n\r\nCopyright (c) 1991 - 1995, Stichting Mathematisch Centrum Amsterdam,\r\nThe Netherlands.  All rights reserved.\r\n\r\nPermission to use, copy, modify, and distribute this software and its\r\ndocumentation for any purpose and without fee is hereby granted,\r\nprovided that the above copyright notice appear in all copies and that\r\nboth that copyright notice and this permission notice appear in\r\nsupporting documentation, and that the name of Stichting Mathematisch\r\nCentrum or CWI not be used in advertising or publicity pertaining to\r\ndistribution of the software without specific, written prior\r\npermission.\r\n\r\nSTICHTING MATHEMATISCH CENTRUM DISCLAIMS ALL WARRANTIES WITH REGARD TO\r\nTHIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\r\nFITNESS, IN NO EVENT SHALL STICHTING MATHEMATISCH CENTRUM BE LIABLE\r\nFOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\r\nWHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\r\nACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT\r\nOF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\r\n\r\n![Logo](https://storage.googleapis.com/model_garden_artifacts/TF_Model_Garden.png)\r\n\r\n# Welcome to the Model Garden for TensorFlow\r\n\r\nThe TensorFlow Model Garden is a repository with a number of different implementations of state-of-the-art (SOTA) models and modeling solutions for TensorFlow users. We aim to demonstrate the best practices for modeling so that TensorFlow users\r\ncan take full advantage of TensorFlow for their research and product development.\r\n\r\n| Directory | Description |\r\n|-----------|-------------|\r\n| [official](official) | \u2022 A collection of example implementations for SOTA models using the latest TensorFlow 2's high-level APIs<br />\u2022 Officially maintained, supported, and kept up to date with the latest TensorFlow 2 APIs by TensorFlow<br />\u2022 Reasonably optimized for fast performance while still being easy to read |\r\n| [research](research) | \u2022 A collection of research model implementations in TensorFlow 1 or 2 by researchers<br />\u2022 Maintained and supported by researchers |\r\n| [community](community) | \u2022 A curated list of the GitHub repositories with machine learning models and implementations powered by TensorFlow 2 |\r\n| [orbit](orbit) | \u2022 A flexible and lightweight library that users can easily use or fork when writing customized training loop code in TensorFlow 2.x. It seamlessly integrates with `tf.distribute` and supports running on different device types (CPU, GPU, and TPU). |\r\n\r\n## [Announcements](https://github.com/tensorflow/models/wiki/Announcements)\r\n\r\n| Date | News |\r\n|------|------|\r\n| July 10, 2020 | TensorFlow 2 meets the [Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection) ([Blog](https://blog.tensorflow.org/2020/07/tensorflow-2-meets-object-detection-api.html)) |\r\n| June 30, 2020 | [SpineNet: Learning Scale-Permuted Backbone for Recognition and Localization](https://github.com/tensorflow/models/tree/master/official/vision/detection#train-a-spinenet-49-based-mask-r-cnn) released ([Tweet](https://twitter.com/GoogleAI/status/1278016712978264064)) |\r\n| June 17, 2020 | [Context R-CNN: Long Term Temporal Context for Per-Camera Object Detection](https://github.com/tensorflow/models/tree/master/research/object_detection#june-17th-2020) released ([Tweet](https://twitter.com/GoogleAI/status/1276571419422253057)) |\r\n| May 21, 2020 | [Unifying Deep Local and Global Features for Image Search (DELG)](https://github.com/tensorflow/models/tree/master/research/delf#delg) code released |\r\n| May 19, 2020 | [MobileDets: Searching for Object Detection Architectures for Mobile Accelerators](https://github.com/tensorflow/models/tree/master/research/object_detection#may-19th-2020) released |\r\n| May 7, 2020 | [MnasFPN with MobileNet-V2 backbone](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#mobile-models) released for object detection |\r\n| May 1, 2020 | [DELF: DEep Local Features](https://github.com/tensorflow/models/tree/master/research/delf) updated to support TensorFlow 2.1 |\r\n| March 31, 2020 | [Introducing the Model Garden for TensorFlow 2](https://blog.tensorflow.org/2020/03/introducing-model-garden-for-tensorflow-2.html) ([Tweet](https://twitter.com/TensorFlow/status/1245029834633297921)) |\r\n\r\n## Contributions\r\n\r\n[![help wanted:paper implementation](https://img.shields.io/github/issues/tensorflow/models/help%20wanted%3Apaper%20implementation)](https://github.com/tensorflow/models/labels/help%20wanted%3Apaper%20implementation)\r\n\r\nIf you want to contribute, please review the [contribution guidelines](https://github.com/tensorflow/models/wiki/How-to-contribute).\r\n\r\n## License\r\n\r\n[Apache License 2.0](LICENSE)\r\n\r\n[[https://drive.google.com/file/d/15oEpd6DhYRFPZXq1I4h7oA1zBtM4-RuP/view?usp=sharing](url)\r\n\r\n[CONTRIBUTING.md](https://github.com/tensorflow/models/files/6801887/CONTRIBUTING.md)\r\n[ISSUES.md](https://github.com/tensorflow/models/files/6801888/ISSUES.md)\r\n[README.md](https://github.com/tensorflow/models/files/6801889/README.md)\r\n](url)\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 365,
        "deletions": 1,
        "changed_files": 3,
        "created_at": "2021-07-09T15:14:57Z",
        "closed_at": "2021-07-19T20:07:48Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nContribution from @srihari-humbarwadi \r\n\r\nhttps://github.com/tensorflow/models/pull/10112\r\n\r\n* Added `panoptic_maskrcnn_input.Parser`\r\n* Added tests for `panoptic_maskrcnn_input.Parser`\r\n* added `DataConfig`\r\n* fixed doc-string\r\n* Added type annotations\r\n\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 10,
        "changed_files": 1,
        "created_at": "2021-07-07T19:22:22Z",
        "closed_at": "2023-01-20T20:20:08Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nwhen sub layers are created in `self.build` with subsequent `build` call, the names of the weights of sublayers get the name of the main layer which prevents keras saving in `h5` format. Fix it by moving layer creation into init, then they will be built when they are called.\r\n\r\n## Type of change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\n\r\nno functionality was added or changed, so old test should be enough\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 16,
        "changed_files": 1,
        "created_at": "2021-07-06T17:12:43Z",
        "closed_at": "2022-06-21T21:12:18Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nI modified the installation of the Object Detection to reflect the steps provided in the [Object Detection API with TensorFlow 2](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md) tutorial.\r\n\r\nI want to use the TensorFlow object detection API for my high school research project, but the provided sample code wouldn't run in Google Colab.\r\n\r\n## Type of change\r\n\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\n\r\nI ran the code in Google Colab and it managed to detect the objects as it expected.\r\n\r\n**Test Configuration**: Google Colab\r\n\r\n## Checklist\r\n\r\n- [X] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [X] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [X] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [X] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [X] I have added tests that prove my fix is effective or that my feature works.\r\n- [x] My changes generate no new warnings.\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 365,
        "deletions": 1,
        "changed_files": 3,
        "created_at": "2021-07-05T19:29:01Z",
        "closed_at": "2021-07-09T15:13:29Z",
        "merged_at": "2021-07-09T15:13:29Z",
        "body": "# Description\r\nDataloader for Panoptic Mask R-CNN input\r\n\r\n## Type of change\r\n- [x] A new research paper code implementation\r\n\r\n## Tests\r\n`python -m official.vision.beta.projects.panoptic_maskrcnn.dataloaders.panoptic_maskrcnn_input_test`\r\n\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2021-07-01T07:46:49Z",
        "closed_at": "2023-01-24T17:16:16Z",
        "merged_at": null,
        "body": "The Line `MODEL_DIR={path to model directory}` was repeated twice so I've deleted an occurrence of it",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 3444,
        "deletions": 22,
        "changed_files": 18,
        "created_at": "2021-06-25T07:09:10Z",
        "closed_at": "2021-06-25T22:35:22Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [x] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 3432,
        "deletions": 21,
        "changed_files": 16,
        "created_at": "2021-06-25T06:46:29Z",
        "closed_at": "2021-06-25T22:35:36Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [x] TensorFlow 2 migration\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] A new research paper code implementation\r\n- [x] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 21,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2021-06-25T02:59:08Z",
        "closed_at": "2021-06-25T22:34:02Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-06-24T11:20:42Z",
        "closed_at": "2021-06-28T15:32:52Z",
        "merged_at": "2021-06-28T15:32:52Z",
        "body": "# Description\r\n\r\n- [x] Documentation update: Fixed a typographical error.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 23,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2021-06-24T04:43:12Z",
        "closed_at": "2021-08-19T16:09:24Z",
        "merged_at": null,
        "body": "fixes https://github.com/tensorflow/models/issues/9158\r\nSpecial thanks to Guangming (https://guangmingw.github.io/) for his help with restoring the bike video dataset.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 0,
        "changed_files": 0,
        "created_at": "2021-06-22T18:00:02Z",
        "closed_at": "2021-07-02T07:04:46Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nFactory method to build Panoptic Mask R-CNN model\r\n\r\nThis PR is contribution from @srihari-humbarwadi. ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-06-21T11:51:41Z",
        "closed_at": "2021-06-25T18:26:37Z",
        "merged_at": "2021-06-25T18:26:37Z",
        "body": "# Description\r\n\r\nFixed link in README\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Documentation update\r\n\r\n## Tests\r\n\r\nGo to `official/nlp/transformer/README.md`,\r\nBefore fix: click the `beam_search.py` link, it jumps to a 404 page.\r\nAfter fix: click the `beam_search_v1.py` link, it jumps to the right source code file.\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 88,
        "deletions": 12,
        "changed_files": 2,
        "created_at": "2021-06-19T16:46:48Z",
        "closed_at": "2021-07-01T17:04:49Z",
        "merged_at": "2021-07-01T17:04:48Z",
        "body": "# Description\r\n\r\n> * Fixed this issue #10062\r\n\r\n## Type of change\r\n\r\n- [x] Breaking change (Models trained with 3D causal convolution won't work as expected)\r\n\r\n\r\n## Tests\r\n\r\n> * Tested against standard convolution implementation, with different kernels, strides and input shape. This kind of test requires time to run, so it is not included in the pull request.\r\n> * The tests are the same as the one provided originally, the results have been corrected.\r\n\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 206,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2021-06-17T19:00:32Z",
        "closed_at": "2021-06-22T17:57:57Z",
        "merged_at": "2021-06-22T17:57:57Z",
        "body": "# Description\r\nFactory method to build Panoptic Mask R-CNN model\r\n\r\n## Type of change\r\n- [x] A new research paper code implementation\r\n\r\n## Tests\r\n`python -m official.vision.beta.projects.panoptic_maskrcnn.modeling.factory_test`\r\n\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2135,
        "deletions": 0,
        "changed_files": 15,
        "created_at": "2021-06-15T16:22:37Z",
        "closed_at": "2021-09-03T18:53:36Z",
        "merged_at": "2021-09-03T18:53:36Z",
        "body": "# Description\r\nThis pull request adds the implementation of the BASNet (Encoder, Decoder, Refinement module).\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\nTests are provided for each of the building blocks. The tests provide checking to see if the outputs of the layers go to None anywhere in the layer.\r\n\r\n**Test Configuration**: Currently, we use unittest in the Python3 standard library in order to verify the correctness of our code.\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 3259,
        "deletions": 122,
        "changed_files": 7,
        "created_at": "2021-06-15T02:41:41Z",
        "closed_at": "2021-06-15T06:31:39Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [x] TensorFlow 2 migration\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] A new research paper code implementation\r\n- [x] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1189,
        "deletions": 0,
        "changed_files": 7,
        "created_at": "2021-06-12T14:32:32Z",
        "closed_at": "2021-06-17T18:38:31Z",
        "merged_at": null,
        "body": "# Description\r\nFactory method to build Panoptic Mask R-CNN model\r\n\r\n## Type of change\r\n- [x] A new research paper code implementation\r\n\r\n## Tests\r\n`python -m official.vision.beta.projects.panoptic_maskrcnn.modeling.factory_test`\r\n\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2021-06-09T16:19:06Z",
        "closed_at": "2021-06-14T23:20:56Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 38,
        "deletions": 37,
        "changed_files": 2,
        "created_at": "2021-06-09T07:20:55Z",
        "closed_at": "2021-06-09T14:20:37Z",
        "merged_at": "2021-06-09T14:20:37Z",
        "body": "Fixed linting error for panoptic-segmentation project\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] My changes generate no new warnings.\r\n\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 0,
        "changed_files": 0,
        "created_at": "2021-06-08T21:43:32Z",
        "closed_at": "2021-06-17T07:05:25Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nContribution from @srihari-humbarwadi \r\n\r\n* Added `PanopticMaskRCNNModel` model\r\n* test checkpoint loading for segmentation objects\r\n* fixed docstring\r\n* subclassed `MaskRCNNModel`\r\n* always enable mask and segmentation heads\r\n* added __init__.py\r\n* added README.md\r\n\r\n## Type of change\r\n\r\n- [x] New model implementation\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2021-06-05T20:55:22Z",
        "closed_at": "2021-06-08T18:51:40Z",
        "merged_at": "2021-06-08T18:51:40Z",
        "body": "\r\n# Description\r\n\r\nThe original VGGish embedding Colab by malcolmslaney didn't work with the current VGGish and tensorflow.  \r\nThis PR changes the link to an updated Colab doc.\r\n\r\nFixes issue #9220 \r\n\r\n## Type of change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [x] TensorFlow 2 migration\r\n\r\n## Tests\r\n\r\nI ran the new Colab in both Chrome and MacOS Safari, using the latest TensorFlow and TensorFlow/models distros.\r\n\r\n## Checklist\r\n\r\n- [v] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [v] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [v] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [v] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [v] I have commented my code, particularly in hard-to-understand areas.\r\n- [v] I have made corresponding changes to the documentation.\r\n- [v] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 840,
        "deletions": 0,
        "changed_files": 4,
        "created_at": "2021-06-05T15:51:16Z",
        "closed_at": "2021-06-08T17:51:16Z",
        "merged_at": "2021-06-08T17:51:16Z",
        "body": "# Description\r\n\r\n> :memo: A unified top-down model that extends existing `MaskRCNNModel` to support panoptic segmentation \r\n## Type of change\r\n- [x] A new research paper code implementation\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n\r\n> `python -m official.vision.beta.projects.panoptic_maskrcnn.modeling.panoptic_maskrcnn_model_test` \r\nAlong with the existing `MaskRCNNModel` test cases, I have included additional test cases for\r\n\r\n> For instance heads and stuff segmentation heads\r\n>* shared/separate backbones\r\n>* shared/separate decoders\r\n\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n ",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 495,
        "deletions": 251,
        "changed_files": 13,
        "created_at": "2021-06-03T10:13:02Z",
        "closed_at": "2021-08-16T20:05:17Z",
        "merged_at": null,
        "body": "# Description\r\nThis PR updates all the ops needed for the YOLO detection generator and adds an nms_ops file that holds the nms used for box filtering on the TPU. This PR adds DIOU nms as well as a quick NMS that is used for compiling the model in tflite.   \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\nbox op and math op test cases \r\n```\r\npython3.8 -m official.vision.beta.projects.yolo.ops.box_ops_test\r\n```\r\n\r\nnms op tests will be included in the next commit\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 10
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2021-06-01T17:53:48Z",
        "closed_at": "2021-06-14T23:20:57Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1558,
        "deletions": 22,
        "changed_files": 17,
        "created_at": "2021-06-01T16:38:21Z",
        "closed_at": "2021-06-02T00:04:23Z",
        "merged_at": "2021-06-02T00:04:23Z",
        "body": "Cherry picking and merging DLRM model code into 2.5 branch.\r\n\r\nTesting with TF 2.5.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 9,
        "changed_files": 2,
        "created_at": "2021-05-28T00:23:37Z",
        "closed_at": "2021-05-28T14:07:47Z",
        "merged_at": "2021-05-28T14:07:47Z",
        "body": "# Description\r\n\r\nFix issues related to linting.\r\n\r\n## Type of change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-05-27T05:38:04Z",
        "closed_at": "2021-06-11T12:18:21Z",
        "merged_at": "2021-06-11T12:18:21Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Correct a typo in MobileBERT README\r\n> \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [X] Documentation update\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [X] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [X] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 16,
        "deletions": 5,
        "changed_files": 4,
        "created_at": "2021-05-27T03:50:13Z",
        "closed_at": "2021-07-27T16:10:49Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nYolo implementation contributed from Purdue University students\r\n\r\n## Type of change\r\n\r\n- [x] TensorFlow 2 implementation\r\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2021-05-27T01:18:46Z",
        "closed_at": "2021-05-27T03:39:14Z",
        "merged_at": "2021-05-27T03:39:14Z",
        "body": "# Description\r\n\r\nAdds a disclaimer that the model is not complete. \r\n\r\n## Type of change\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\nN/A\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 426,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2021-05-21T19:18:17Z",
        "closed_at": "2021-05-24T17:44:19Z",
        "merged_at": "2021-05-24T17:44:19Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\nAdded a script and some corresponding changes to support training and predicting superglue. This script currently only supports the AX-g task and the RTE task\r\n## Type of change \r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2021-05-13T21:24:59Z",
        "closed_at": "2021-05-24T18:15:00Z",
        "merged_at": "2021-05-24T18:15:00Z",
        "body": "# Description\r\n\r\nAdds a documentation note about including references to training logs.\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 30,
        "deletions": 6,
        "changed_files": 3,
        "created_at": "2021-05-11T07:22:00Z",
        "closed_at": "2021-08-02T05:05:52Z",
        "merged_at": null,
        "body": "This PR allows maskrcnn evaluation to be done directly from record file. This will be useful in deepmac_maskrcnn.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 270,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2021-05-04T10:19:19Z",
        "closed_at": "2021-05-12T17:28:08Z",
        "merged_at": "2021-05-12T17:28:08Z",
        "body": "This PR adds export script for DeepMAC project. The majority of the code is same as in [beta directory](https://github.com/tensorflow/models/tree/master/official/vision/beta/serving). Just made necessary import and variable changes. ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2021-04-30T03:37:21Z",
        "closed_at": "2021-04-30T18:31:57Z",
        "merged_at": "2021-04-30T18:31:57Z",
        "body": "PiperOrigin-RevId: 371256980\r\n\r\n# Description\r\nCherry-pick of `Disabling Tensorboard profiling for NCF.` from Master branch.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2021-04-27T05:12:15Z",
        "closed_at": "2021-04-29T18:53:19Z",
        "merged_at": null,
        "body": "Test the main function.\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2021-04-26T12:08:20Z",
        "closed_at": "2021-04-30T20:58:12Z",
        "merged_at": "2021-04-30T20:58:12Z",
        "body": "Signed-off-by: Pablo Ribalta Lorenzo <pribalta@nvidia.com>\r\n\r\n# Description\r\n\r\nAdd NVIDIA BERT to the community section of Model Garden\r\n\r\n## Type of change\r\n\r\n- [x] A new research paper code implementation\r\n\r\n## Tests\r\n\r\nn/a\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-04-23T06:43:20Z",
        "closed_at": "2021-05-07T20:12:49Z",
        "merged_at": null,
        "body": "This commit https://github.com/tensorflow/models/commit/6e5c5a1bd50e07aab485fddf7bab958b80d95bee seems to have introduced a slight bug in the parameter parsing. This issue is in the following line:\r\n\r\nhttps://github.com/tensorflow/models/blob/6e5c5a1bd50e07aab485fddf7bab958b80d95bee/research/object_detection/builders/model_builder.py#L950\r\n\r\nThat evaluates to `True` even if the pipeline config does not have the `center_head_params` set to anything. A fix is to change the line to something like (which is what my commit does):\r\n\r\n```\r\nif oc_config.center_head_params.num_filters and oc_config.center_head_params.kernel_sizes:\r\n```\r\n\r\nThat restores the original default behavior and seems to match the author's intent. Issue https://github.com/tensorflow/models/issues/9880 contains complete instructions as to how to reproduce the environment and to test the code.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 178,
        "deletions": 191,
        "changed_files": 23,
        "created_at": "2021-04-20T23:02:18Z",
        "closed_at": "2021-04-23T00:48:02Z",
        "merged_at": "2021-04-23T00:48:02Z",
        "body": "# Description\r\n\r\nSome general cleanup of the DELF codebase, including:\r\n- Cleanup after PRs #9796 and #9901\r\n- Fix old imports `delf.python.detect_to_retrieve import dataset` to point to the correct new location\r\n- Remove \u201capp\u201d import from TF and use directly the one from \u201cabsl\u201d package\r\n- Some other remaining general cleanup, eg to standardize formatting\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\n\r\nExisting tests now all pass.\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [X] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [X] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [X] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [X] I have commented my code, particularly in hard-to-understand areas.\r\n- [X] I have made corresponding changes to the documentation.\r\n- [X] My changes generate no new warnings.\r\n- [X] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-04-20T16:16:33Z",
        "closed_at": "2021-05-13T16:44:14Z",
        "merged_at": "2021-05-13T16:44:14Z",
        "body": "# Description\r\n\r\nUpdate bot_config.yml\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [x] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2590,
        "deletions": 633,
        "changed_files": 12,
        "created_at": "2021-04-18T20:23:40Z",
        "closed_at": "2021-05-25T00:03:15Z",
        "merged_at": "2021-05-25T00:03:15Z",
        "body": "YOLO Family: Updated model\r\n\r\n* Fix bugs in the model\r\n* Add [dilated Darknet](https://github.com/zzzDavid/Dilated-Convolutional-Layer-Implementation) implementation\r\n* Add head and decoder to the model\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n```\r\npython3.8 -m official.vision.beta.projects.yolo.modeling.backbones.darknet_test\r\npython3.8 -m official.vision.beta.projects.yolo.modeling.decoders.yolo_decoder_test\r\npython3.8 -m official.vision.beta.projects.yolo.modeling.heads.yolo_head_test\r\npython3.8 -m official.vision.beta.projects.yolo.modeling.layers.nn_blocks_test\r\n```\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2021-04-15T18:03:24Z",
        "closed_at": "2021-09-02T05:48:35Z",
        "merged_at": "2021-09-02T05:48:35Z",
        "body": "# Description\r\n\r\nThis PR aims to help migrate the TensorFlow code from 1.x to 2.x for the AttentionOCR model in the research folder by updating deprecated tf.contrib.metricsreferences.\r\n\r\nThe changes will partly address #8703\r\n\r\n## Type of change\r\n\r\n- [x] TensorFlow 2 migration\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 13,
        "deletions": 10,
        "changed_files": 8,
        "created_at": "2021-04-14T19:56:01Z",
        "closed_at": "2021-04-14T23:57:45Z",
        "merged_at": "2021-04-14T23:57:45Z",
        "body": "# Description\r\n\r\nThis PR aims to help migrate the TensorFlow code from 1.x to 2.x for the AttentionOCR model in the research folder by updating deprecated tf.flags references.\r\n\r\nThe changes will partly address #8703\r\n\r\n## Type of change\r\n\r\n- [x] TensorFlow 2 migration\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2325,
        "deletions": 0,
        "changed_files": 20,
        "created_at": "2021-04-14T02:22:55Z",
        "closed_at": "2021-06-15T16:23:50Z",
        "merged_at": null,
        "body": "# Description\r\nThis pull request adds the implementation of the BASNet (Encoder, Decoder, Refinement module).\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\nTests are provided for each of the building blocks. The tests provide checking to see if the outputs of the layers go to None anywhere in the layer.\r\n\r\n**Test Configuration**: Currently, we use unittest in the Python3 standard library in order to verify the correctness of our code.\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 164,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2021-04-13T21:39:54Z",
        "closed_at": "2021-06-09T16:04:38Z",
        "merged_at": "2021-06-09T16:04:38Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Fixes #9877\r\n> * DELG model applies attention to block 3 as in the paper, rather than to auto-encoder output, as in DELF.  \r\n> * Enabled AttentionModel to specify an attention target in addition to attention source.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1015,
        "deletions": 0,
        "changed_files": 5,
        "created_at": "2021-04-13T19:52:24Z",
        "closed_at": "2021-07-13T17:03:26Z",
        "merged_at": "2021-07-13T17:03:26Z",
        "body": "# Description\r\n\r\nAdding the CNN Image Retrieval model implementation based on the following papers:\r\n\r\n[1] Fine-tuning CNN Image Retrieval with No Human Annotation,\r\nRadenovi\u0107 F., Tolias G., Chum O., TPAMI 2018 [arXiv]\r\nhttps://arxiv.org/abs/1711.02512\r\n\r\n[2] CNN Image Retrieval Learns from BoW: Unsupervised Fine-Tuning with Hard\r\nExamples, Radenovi\u0107 F., Tolias G., Chum O., ECCV 2016 [arXiv]\r\nhttps://arxiv.org/abs/1604.02426\r\n\r\n## Type of change\r\n\r\n- [x] A new research paper code implementation",
        "comments": 10
    },
    {
        "merged": true,
        "additions": 863,
        "deletions": 229,
        "changed_files": 9,
        "created_at": "2021-04-13T19:46:01Z",
        "closed_at": "2021-07-07T18:27:36Z",
        "merged_at": "2021-07-07T18:27:36Z",
        "body": "# Description\r\n\r\nAdding the CNN Image Retrieval model implementation based on the following papers:\r\n\r\n[1] Fine-tuning CNN Image Retrieval with No Human Annotation,\r\nRadenovi\u0107 F., Tolias G., Chum O., TPAMI 2018 [arXiv]\r\nhttps://arxiv.org/abs/1711.02512\r\n\r\n[2] CNN Image Retrieval Learns from BoW: Unsupervised Fine-Tuning with Hard\r\nExamples, Radenovi\u0107 F., Tolias G., Chum O., ECCV 2016 [arXiv]\r\nhttps://arxiv.org/abs/1604.02426\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] A new research paper code implementation",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 592,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2021-04-13T19:40:48Z",
        "closed_at": "2021-07-13T17:02:50Z",
        "merged_at": "2021-07-13T17:02:49Z",
        "body": "# Description\r\n\r\nAdding the CNN Image Retrieval model implementation based on the following papers:\r\n\r\n[1] Fine-tuning CNN Image Retrieval with No Human Annotation,\r\nRadenovi\u0107 F., Tolias G., Chum O., TPAMI 2018 [arXiv]\r\nhttps://arxiv.org/abs/1711.02512\r\n\r\n[2] CNN Image Retrieval Learns from BoW: Unsupervised Fine-Tuning with Hard\r\nExamples, Radenovi\u0107 F., Tolias G., Chum O., ECCV 2016 [arXiv]\r\nhttps://arxiv.org/abs/1604.02426\r\n\r\n## Type of change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] A new research paper code implementation\r\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 434,
        "deletions": 1,
        "changed_files": 4,
        "created_at": "2021-04-13T19:31:46Z",
        "closed_at": "2021-04-16T17:06:27Z",
        "merged_at": "2021-04-16T17:06:27Z",
        "body": "# Description\r\n\r\nAdding the CNN Image Retrieval model implementation based on the following papers:\r\n\r\n[1] Fine-tuning CNN Image Retrieval with No Human Annotation,\r\nRadenovi\u0107 F., Tolias G., Chum O., TPAMI 2018 [arXiv]\r\nhttps://arxiv.org/abs/1711.02512\r\n\r\n[2] CNN Image Retrieval Learns from BoW: Unsupervised Fine-Tuning with Hard\r\nExamples, Radenovi\u0107 F., Tolias G., Chum O., ECCV 2016 [arXiv]\r\nhttps://arxiv.org/abs/1604.02426\r\n\r\n## Type of change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] A new research paper code implementation",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2021-04-12T11:31:01Z",
        "closed_at": "2021-04-16T19:36:06Z",
        "merged_at": "2021-04-16T19:36:06Z",
        "body": "Signed-off-by: Pablo Ribalta Lorenzo <pribalta@nvidia.com>\r\n\r\n# Description\r\n\r\nThis PR adds NVIDIA EfficientNet to the catalog of community models\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\n- [x] A new research paper code implementation\r\n\r\n## Tests\r\n\r\nn/a\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2021-04-05T21:47:42Z",
        "closed_at": "2021-04-12T15:27:43Z",
        "merged_at": "2021-04-12T15:27:43Z",
        "body": "# Description\r\n\r\n* Added Transformer-LT Official FP32 inference\r\n* Removed Wide & Deep Int8 inference (not TF2)\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Documentation update\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 89,
        "deletions": 1,
        "changed_files": 3,
        "created_at": "2021-04-03T14:32:29Z",
        "closed_at": "2021-04-03T19:13:26Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2021-03-31T17:35:04Z",
        "closed_at": "2021-04-04T04:31:51Z",
        "merged_at": "2021-04-04T04:31:51Z",
        "body": "Signed-off-by: Pablo Ribalta Lorenzo <pribalta@nvidia.com>\r\n\r\n# Description\r\n\r\nThis PR adds DLRM to the community section of TensorFlow model Garden\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] A new research paper code implementation\r\n\r\n## Tests\r\n\r\nn/a\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2054,
        "deletions": 25,
        "changed_files": 15,
        "created_at": "2021-03-30T17:40:46Z",
        "closed_at": "2021-07-07T09:06:44Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nAdding the CNN Image Retrieval model implementation based on the following papers:\r\n\r\n  [1] Fine-tuning CNN Image Retrieval with No Human Annotation,\r\n    Radenovi\u0107 F., Tolias G., Chum O., TPAMI 2018 [arXiv]\r\n    https://arxiv.org/abs/1711.02512\r\n\r\n  [2] CNN Image Retrieval Learns from BoW: Unsupervised Fine-Tuning with Hard\r\n    Examples, Radenovi\u0107 F., Tolias G., Chum O., ECCV 2016 [arXiv]\r\n    https://arxiv.org/abs/1604.02426\r\n\r\n## Type of change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] A new research paper code implementation\r\n\r\n## Tests\r\n\r\n Tests for the added modules are provided.\r\n\r\n**Test Configuration**:\r\nSame requirements as for the DELF library.\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 2475,
        "deletions": 0,
        "changed_files": 19,
        "created_at": "2021-03-25T10:57:20Z",
        "closed_at": "2021-03-29T05:49:50Z",
        "merged_at": "2021-03-29T05:49:49Z",
        "body": "# Description\r\n\r\nTested with pylint.sh script.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-03-23T19:08:21Z",
        "closed_at": "2021-03-24T05:16:13Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 11006,
        "deletions": 3548,
        "changed_files": 431,
        "created_at": "2021-03-23T04:56:56Z",
        "closed_at": "2021-03-24T18:34:24Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nyt8m entire code checked with pylint.sh\r\nA few style changes were made but nothing regarding the functionality of the code.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-03-23T00:51:28Z",
        "closed_at": "2021-03-23T06:08:16Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 74,
        "deletions": 38,
        "changed_files": 2,
        "created_at": "2021-03-19T21:28:45Z",
        "closed_at": "2021-03-25T20:46:55Z",
        "merged_at": "2021-03-25T20:46:55Z",
        "body": "Job runs on presubmit only on files modified by change, ~1 minute runtime.\r\nJob will pick up preexisting errors in files, which will have to be fixed then or ignored.\r\n\r\nSee this example of a failing run: https://github.com/tensorflow/models/runs/2190095742\r\nPassing: https://github.com/tensorflow/models/runs/2190106888",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2021-03-16T21:02:40Z",
        "closed_at": "2021-03-19T19:42:13Z",
        "merged_at": "2021-03-19T19:42:13Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-03-15T03:01:54Z",
        "closed_at": "2021-03-19T21:26:01Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\nUpdate to tf2.x API\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [x] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 147,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2021-03-13T14:56:26Z",
        "closed_at": "2021-03-19T19:53:14Z",
        "merged_at": "2021-03-19T19:53:14Z",
        "body": "# Description\r\n\r\nAdding the dataset-related modules for the implementation of the research paper [https://arxiv.org/pdf/1711.02512.pdf].\r\n\r\n## Type of change\r\nNew modules added.\r\n\r\nNote: Please delete options that are not relevant.\r\n- [ ] A new research paper code implementation\r\n\r\n## Tests\r\nProvided unit tests for the new changes. \r\n\r\n**Test Configuration**:\r\nCode is working with the official Delg installation instructions.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 171,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2021-03-11T23:32:40Z",
        "closed_at": "2021-03-16T19:13:14Z",
        "merged_at": "2021-03-16T19:13:14Z",
        "body": "TensorFlow uses a subset of pylint functionality. Script will download the latest pylint rules from the main repo at runtime.\r\n\r\nRequires `python3.8 -m pip install pylint==2.4.4`.\r\nThis will eventually be run on-PR in this repo, but first we'll have to fix the ~900 existing violations.\r\nScript should be usable manually for now -- call it from within a subdirectory to avoid processing the entire repo.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2021-03-05T16:02:17Z",
        "closed_at": "2021-03-19T19:58:09Z",
        "merged_at": "2021-03-19T19:58:09Z",
        "body": "# Description\r\n\r\nThis PR adds wide & deep by NVIDIA to community projects\r\n\r\n## Type of change\r\n\r\n- [x] A new research paper code implementation\r\n\r\n## Tests\r\n\r\nn/a\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-03-03T22:43:09Z",
        "closed_at": "2022-10-14T17:04:03Z",
        "merged_at": null,
        "body": "Currently the Object Detection API installation fails due to missing `setup.py`\r\nThis PR tries to fix it and points to TF2 `setup.py`.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2021-03-03T02:09:17Z",
        "closed_at": "2021-03-03T17:48:34Z",
        "merged_at": "2021-03-03T17:48:34Z",
        "body": "For pip `find_packages` to find this submodule\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\nExtremely simple yet necessary change for the code under _official/nlp/tools_ to be usable for those installing via `tf-model-official` or `tf-model-nightly`. Otherwise, the code in the _tools_ dir is not accessible except via git repo clone.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-03-02T12:22:22Z",
        "closed_at": "2021-03-02T17:21:03Z",
        "merged_at": "2021-03-02T17:21:03Z",
        "body": "# Description\r\n\r\nFix typo\r\n\r\n## Type of change\r\n\r\n- [x] Documentation update\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-03-01T15:11:48Z",
        "closed_at": "2021-03-02T05:15:11Z",
        "merged_at": "2021-03-02T05:15:11Z",
        "body": "\u2026models/issues/9760\r\n\r\nPiperOrigin-RevId: 359996828\r\n\r\n# Description\r\n\r\nThe file models/official/requirements.txt contains the line\r\n\r\ndataclasses\r\n\r\nWhich should be changed to\r\n\r\ndataclasses;python_version<\"3.7\"\r\n\r\nBecause\r\n\r\nSince 3.7 dataclassesis a part of standard library and installation of this package is not needed.\r\nPandas (e.g., 1.2.1) cannot work with the installed package 'dataclasses' which causes tensorflow to fail when it calls to pandas during import.\r\n\r\n## Type of change\r\n\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\n\r\n- Pull official from repository\r\n- Modify models/official/requirements.txt (dataclasses --> dataclasses;python_version<\"3.7\")\r\n- Create wheel, by using \"pip wheel\"\r\n- Install created wheel\r\n \r\n**Test Configuration**:\r\n- Connection to models git repository\r\n- Python 3.6 (to check that dataclasses package is installed), Python 3.7 (to check that it is not).\r\n\r\n## Checklist\r\n\r\nThe change has been already committed by saberkun to the models master branch (https://github.com/tensorflow/models/commit/0f1f2c4014f62a49067e3f943ed0d8f71699f724) as a response to the issue #9760, so check list probably is not necessary, but anyway:\r\n\r\n- [X] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [X] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n - [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [X] My changes generate no new warnings.\r\n- [X] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-03-01T15:07:47Z",
        "closed_at": "2021-03-02T05:14:51Z",
        "merged_at": "2021-03-02T05:14:51Z",
        "body": "\u2026models/issues/9760\r\n\r\nPiperOrigin-RevId: 359996828\r\n\r\n# Description\r\n\r\nThe file models/official/requirements.txt contains the line\r\n\r\ndataclasses\r\n\r\nWhich should be changed to\r\n\r\ndataclasses;python_version<\"3.7\"\r\n\r\nBecause\r\n\r\nSince 3.7 dataclassesis a part of standard library and installation of this package is not needed.\r\nPandas (e.g., 1.2.1) cannot work with the installed package 'dataclasses' which causes tensorflow to fail when it calls to pandas during import.\r\n\r\n## Type of change\r\n\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\n\r\n- Pull official from repository\r\n- Modify models/official/requirements.txt (dataclasses --> dataclasses;python_version<\"3.7\")\r\n- Create wheel, by using \"pip wheel\"\r\n- Install created wheel\r\n \r\n**Test Configuration**:\r\n- Connection to models git repository\r\n- Python 3.6 (to check that dataclasses package is installed), Python 3.7 (to check that it is not).\r\n\r\n## Checklist\r\n\r\nThe change has been already committed by saberkun to the models master branch (https://github.com/tensorflow/models/commit/0f1f2c4014f62a49067e3f943ed0d8f71699f724) as a response to the issue #9760, so check list probably is not necessary, but anyway:\r\n\r\n- [X] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [X] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n - [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [X] My changes generate no new warnings.\r\n- [X] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-03-01T15:06:38Z",
        "closed_at": "2021-03-02T05:14:25Z",
        "merged_at": "2021-03-02T05:14:25Z",
        "body": "\u2026models/issues/9760\r\n\r\nPiperOrigin-RevId: 359996828\r\n\r\n# Description\r\n\r\nThe file models/official/requirements.txt contains the line\r\n\r\ndataclasses\r\n\r\nWhich should be changed to\r\n\r\ndataclasses;python_version<\"3.7\"\r\n\r\nBecause\r\n\r\nSince 3.7 dataclassesis a part of standard library and installation of this package is not needed.\r\nPandas (e.g., 1.2.1) cannot work with the installed package 'dataclasses' which causes tensorflow to fail when it calls to pandas during import.\r\n\r\n## Type of change\r\n\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\n\r\n- Pull official from repository\r\n- Modify models/official/requirements.txt (dataclasses --> dataclasses;python_version<\"3.7\")\r\n- Create wheel, by using \"pip wheel\"\r\n- Install created wheel\r\n \r\n**Test Configuration**:\r\n- Connection to models git repository\r\n- Python 3.6 (to check that dataclasses package is installed), Python 3.7 (to check that it is not).\r\n\r\n## Checklist\r\n\r\nThe change has been already committed by saberkun to the models master branch (https://github.com/tensorflow/models/commit/0f1f2c4014f62a49067e3f943ed0d8f71699f724) as a response to the issue #9760, so check list probably is not necessary, but anyway:\r\n\r\n- [X] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [X] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n - [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [X] My changes generate no new warnings.\r\n- [X] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 11006,
        "deletions": 3548,
        "changed_files": 431,
        "created_at": "2021-02-28T10:46:24Z",
        "closed_at": "2021-03-24T18:35:13Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> Reformat code, verified using 3 different pylintrc files\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 166,
        "deletions": 108,
        "changed_files": 12,
        "created_at": "2021-02-26T21:20:24Z",
        "closed_at": "2021-02-27T07:54:35Z",
        "merged_at": "2021-02-27T07:54:35Z",
        "body": "# Description\r\n\r\n> Modifications for resolving pylint issues plus some minor fixes.\r\n>  \r\n\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2393,
        "deletions": 0,
        "changed_files": 18,
        "created_at": "2021-02-26T19:16:09Z",
        "closed_at": "2021-02-27T09:42:15Z",
        "merged_at": null,
        "body": "updated README.md\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2399,
        "deletions": 3,
        "changed_files": 22,
        "created_at": "2021-02-26T01:04:45Z",
        "closed_at": "2021-02-27T19:46:53Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nContributions from @hylee817 @KimSSung for the YT8M project\r\n\r\n## Type of change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)",
        "comments": 14
    },
    {
        "merged": true,
        "additions": 118,
        "deletions": 117,
        "changed_files": 5,
        "created_at": "2021-02-23T23:25:47Z",
        "closed_at": "2021-02-24T08:25:17Z",
        "merged_at": "2021-02-24T08:25:17Z",
        "body": "# Description\r\n\r\nSmall formatting/convention changes after PR #9727, to keep convention consistent with original code. \r\n\r\n## Type of change\r\n\r\n- [X] Other (format/convention changes)\r\n\r\n## Tests\r\n\r\nAll existing tests continue to pass.\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [X] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [X] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [X] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [X] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [X] I have commented my code, particularly in hard-to-understand areas.\r\n- [X] I have made corresponding changes to the documentation.\r\n- [X] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-02-17T05:57:16Z",
        "closed_at": "2021-02-22T04:52:27Z",
        "merged_at": "2021-02-22T04:52:27Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [x] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2021-02-17T05:50:40Z",
        "closed_at": "2021-02-22T04:52:56Z",
        "merged_at": "2021-02-22T04:52:56Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [x] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-02-15T21:02:14Z",
        "closed_at": "2021-02-17T06:03:10Z",
        "merged_at": "2021-02-17T06:03:10Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 598,
        "deletions": 121,
        "changed_files": 11,
        "created_at": "2021-02-12T11:21:24Z",
        "closed_at": "2021-02-12T16:47:56Z",
        "merged_at": "2021-02-12T16:47:56Z",
        "body": "# Description\r\n\r\nThis commit introduces supporting modules (ranking losses, normalization and pooling layers) for the implementation of the following papers:\r\n\r\n**Fine-tuning CNN Image Retrieval with No Human Annotation**,  \r\nRadenovi\u0107 F., Tolias G., Chum O., \r\nTPAMI 2018 [[arXiv](https://arxiv.org/abs/1711.02512)]\r\n\r\n**CNN Image Retrieval Learns from BoW: Unsupervised Fine-Tuning with Hard Examples**,  \r\nRadenovi\u0107 F., Tolias G., Chum O., \r\nECCV 2016 [[arXiv](http://arxiv.org/abs/1604.02426)]\r\n\r\n## Type of change\r\n\r\nAdded ranking losses, normalization and pooling layers.\r\n\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] A new research paper code implementation\r\n\r\n## Tests\r\n\r\nCode is compatible with the DELF library. For every implemented function we provide tests in the corresponding modules.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 19,
        "changed_files": 3,
        "created_at": "2021-02-10T05:11:54Z",
        "closed_at": "2021-04-20T20:08:01Z",
        "merged_at": "2021-04-20T20:08:01Z",
        "body": "# Description\r\n\r\nModifying the `object_detection_tutorial.ipynb` colab tutorial to work with a fresh colab environment.\r\n\r\nMost of these changes are pretty straight forward. The exception is the change to `utils/ops.py`. This is an issue with types, where tensorflow can better handle different numpy types than the other way around:\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ntf.uint8 == np.uint8\r\n# True\r\n\r\ntf.uint8 == np.dtype(\"uint8\")\r\n# True\r\n\r\nnp.uint8 == tf.uint8\r\n# True\r\n\r\nnp.dtype(\"uint8\") == tf.uint8\r\n# TypeError: Cannot interpret 'tf.uint8' as a data type\r\n```\r\n\r\n## Type of change\r\n\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\n\r\nLoading this notebook into a fresh colab environment, all cells will succeed.\r\n\r\n**Note**: there is a caveat that the change in `research/object_detection/utils/ops.py ` will not propagate to the notebook.\r\nAn alternative solution that will work for testing is to cast the detection masks via:\r\n```python\r\ntf.convert_to_tensor(output_dict['detection_masks'])\r\n```\r\n\r\n## Checklist\r\n\r\n- [X] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [X] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [X] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [X] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [X] I have commented my code, particularly in hard-to-understand areas.\r\n- [X] I have made corresponding changes to the documentation.\r\n- [X] My changes generate no new warnings.\r\n- [X] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 0,
        "changed_files": 0,
        "created_at": "2021-02-09T08:16:13Z",
        "closed_at": "2021-05-24T04:03:53Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2021-02-06T14:28:00Z",
        "closed_at": "2021-02-26T00:45:06Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n**Root Cause**\r\nFix wrong learning rate scheduling for BERT models.\r\nThe root cause is that the PolynomialDecay starts the decay from first training step, where the warm up period may still be in effect. So then warm up period ends, the learning rate is at the highest value, the PolynomialDecay kicks in and the effective learning rate is lower than it should be at that step because it has alredy started decaying from the first step.\r\n\r\nThis fix is to ensure that we start the decay at the end of warm up period and end the decay correctly at the last training step with the correct target value.\r\n\r\n## Type of change\r\n\r\n- [ /] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\n\r\n**Test Configuration**:\r\n\r\nTesting steps:\r\n\r\nCalling the **official.nlp.optimization.create_optimizer** with the parameters below and plot effective learning rate:\r\n  init_lr = 0.005,\r\n  num_train_steps = 40000,\r\n  num_warmup_steps = 10000,\r\n  end_lr=0.0,\r\n  optimizer_type='adamw'\r\n\r\nYou can see the result that the effective learning rate has the discontinued value when polynomial decay starts working:\r\n![image](https://user-images.githubusercontent.com/11656659/107120889-0dd5ed80-68c2-11eb-8ddf-79f1eb7cde0f.png)\r\n\r\nAfter this fix, the effective learning rate will be like below:\r\n![image](https://user-images.githubusercontent.com/11656659/107120904-1e866380-68c2-11eb-9d0b-26f34b3df5be.png)\r\n\r\n## Checklist\r\n\r\n- [ /] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ /] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ /] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ /] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ /] I have commented my code, particularly in hard-to-understand areas.\r\n- [ /] I have made corresponding changes to the documentation.\r\n- [ /] My changes generate no new warnings.\r\n- [ /] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 50,
        "deletions": 8,
        "changed_files": 2,
        "created_at": "2021-02-01T20:40:22Z",
        "closed_at": "2021-02-08T05:25:18Z",
        "merged_at": "2021-02-08T05:25:18Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\nAdded the processor for the SuperGlue task AX-g\r\n\r\n## Type of change\r\n\r\nnew feature\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Documentation update\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2021-01-31T11:19:20Z",
        "closed_at": "2021-04-05T04:05:11Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nFix download links for the MobileNet V1 and V2 checkpoints.\r\n\r\n## Type of change\r\n\r\n- [X] Documentation update",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-01-29T12:51:13Z",
        "closed_at": "2021-01-31T07:25:03Z",
        "merged_at": "2021-01-31T07:25:03Z",
        "body": "Signed-off-by: Pablo Ribalta Lorenzo <pribalta@nvidia.com>\r\n\r\nThis PR is a follow-up on the NVIDIA ELECTRA model that was merged recently (https://github.com/tensorflow/models/pull/9648), in order to correct the features the model supports.\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Documentation update\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1250,
        "deletions": 6,
        "changed_files": 11,
        "created_at": "2021-01-27T20:47:48Z",
        "closed_at": "2021-02-25T21:38:58Z",
        "merged_at": "2021-02-25T21:38:58Z",
        "body": "YOLO Family: Data Loaders \r\n\r\n* Data Loading\r\n* preprocessing_ops\r\n* Dataloader PR Clean-Up\r\n* First Set Of Code Review Fixes\r\n* deleting imagenet\r\n* Testing Functions\r\n* Preserve aspect ratio\r\n\r\nCo-Authored-By: Vishnu Banna <vishnubanna@users.noreply.github.com>\r\n\r\n* Put back the testing functions\r\n\r\nCo-Authored-By: Akhil Chinnakotla <The-Indian-Chinna@users.noreply.github.com>\r\n\r\n* Lint\r\n\r\nCo-Authored-By: Akhil Chinnakotla <The-Indian-Chinna@users.noreply.github.com>\r\n\r\n* Add forgotten build_grided_gt function\r\n\r\nCo-Authored-By: Vishnu Banna <vishnubanna@users.noreply.github.com>\r\n\r\n* Add postprocessing function back\r\n\r\nCo-Authored-By: Vishnu Banna <vishnubanna@users.noreply.github.com>\r\n\r\n* Change set to list\r\n\r\nCo-Authored-By: Vishnu Banna <vishnubanna@users.noreply.github.com>\r\n\r\n* Fix small bugs\r\n\r\nCo-Authored-By: Vishnu Banna <vishnubanna@users.noreply.github.com>\r\n\r\n* Add test case for training\r\n\r\nCo-Authored-By: Vishnu Banna <vishnubanna@users.noreply.github.com>\r\n\r\n* Rename utils to ops\r\n\r\nCo-Authored-By: Vishnu Banna <vishnubanna@users.noreply.github.com>\r\n\r\n* Remove pct_rand\r\n\r\nCo-Authored-By: Vishnu Banna <vishnubanna@users.noreply.github.com>\r\n\r\n* More correct documentationin box_ops\r\n\r\n* Remove junk files\r\n\r\n* added tests for preprocessing_ops\r\n\r\n* Add more descriptive comments\r\n\r\n* Do not hardcode randomscale\r\n\r\n* Remove useless BoxOps\r\n\r\nCo-Authored-By: Vishnu Banna <vishnubanna@users.noreply.github.com>\r\n\r\n* added test for box_ops\r\n\r\n* Merge branch 'dataloaders_pr' of https://github.com/PurdueCAM2Project/tf-models into dataloaders_pr\r\n\r\n* Updated Docstring\r\n\r\n* Lint\r\n\r\nCo-authored-by: Akhil Chinnakotla <The-Indian-Chinna@users.noreply.github.com>\r\nCo-authored-by: anivegesana <anirudh.vegesana@gmail.com>\r\nCo-authored-by: Tyan3001 <yan262@purdue.edu>\r\nCo-authored-by: Vishnu Banna <vishnubanna@users.noreply.github.com>\r\nCo-authored-by: Akhil Chinnakotla <The-Indian-Chinna@users.noreply.github.com>\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1171,
        "deletions": 60,
        "changed_files": 19,
        "created_at": "2021-01-27T20:33:08Z",
        "closed_at": "2021-04-16T22:39:36Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nAdded to this PR is the Decoder used in the YOLO Object Detection Model. It adds the Decoder for the Darknet53 BackBone and various nn_blocks used in the Decoder, like the SPP block, Route Processing Block, and the Route Merging block. These three blocks are used to simplify the process of merging and processing backbone outputs for object detection. \r\n\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [x] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n### test everything\r\n```\r\npython3.8 -m official.vision.beta.projects.yolo.test \r\n```\r\n### test this PR\r\n```\r\npython3.8 -m official.vision.beta.projects.yolo.modeling.decoders.yolo_decoder_test\r\n```\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.",
        "comments": 8
    },
    {
        "merged": false,
        "additions": 1091,
        "deletions": 2,
        "changed_files": 11,
        "created_at": "2021-01-27T19:25:50Z",
        "closed_at": "2021-01-27T20:30:04Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nAdded to this PR is the Decoder used in the YOLO Object Detection Model. It adds the Decoder for the Darknet53 BackBone and various nn_blocks used in the Decoder, like the SPP block, Route Processing Block, and the Route Merging block. These three blocks are used to simplify the process of merging and processing backbone outputs for object detection. \r\n\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [x] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n### test everything\r\npython3.8 -m official.vision.beta.projects.yolo.test \r\n\r\n### test this PR\r\npython3.8 -m official.vision.beta.projects.yolo.modeling.decoders.yolo_decoder_test\r\n\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 11
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-01-26T12:55:13Z",
        "closed_at": "2021-03-14T01:03:06Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2021-01-25T08:55:15Z",
        "closed_at": "2021-03-24T05:30:35Z",
        "merged_at": "2021-03-24T05:30:35Z",
        "body": "# Description\r\nThe test that verifies that all label ids are non-negative is not influenced by the loop, so it can be performed once at the beginning. This avoids a quadratic runtime, which has a high impact on execution time for very long sequences.\r\n\r\n\r\n## Type of change\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\n - official/nlp/data/tagging_data_lib_test.py\r\n \r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n\r\nCode owners: @saberkun @chenGitHuber @lehougoogle @rachellj218 @jaeyounkim\r\n\r\nCC: My intern host sundermeyer@google.com and co-host fhartmann@google.com ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-01-25T07:52:52Z",
        "closed_at": "2021-01-25T22:30:10Z",
        "merged_at": "2021-01-25T22:30:10Z",
        "body": "https://huntr.dev/users/Asjidkalam has fixed the Arbitrary Code Execution vulnerability \ud83d\udd28. Think you could fix a vulnerability like this?\n\nGet involved at https://huntr.dev/\n\nQ | A\nVersion Affected | ALL\nBug Fix | YES\nOriginal Pull Request | https://github.com/418sec/models/pull/1\nVulnerability README | https://github.com/418sec/huntr/blob/master/bounties/other/models/1/README.md\n\n### User Comments:\n\n### \ud83d\udcca Metadata *\r\nArbitrary code exec vulnerability \r\n\r\n#### Bounty URL:  https://www.huntr.dev/bounties/1-other-models\r\n\r\n### \u2699\ufe0f Description *\r\n\r\nArbitrary Code Excecution in Tensorflow/Models.The TensorFlow Model Garden is a repository with a number of different implementations of state-of-the-art (SOTA) models and modeling solutions for TensorFlow users. We aim to demonstrate the best practices for modeling so that TensorFlow users can take full advantage of TensorFlow for their research and product development\r\n\r\n### \ud83d\udcbb Technical Description *\r\n\r\nThis package was vulnerable to Arbitrary code execution due to a use of a known vulnerable function load() in pyyaml. Changing that to safe_load or using SafeLoader will fix the issue.\r\n\r\n### \ud83d\udc1b Proof of Concept (PoC) *\r\n\r\nInstall the package and run the below code:\r\n```javascript\r\n// poc.js\r\nimport params_dict\r\nexploit = params_dict.read_yaml_to_params_dict('exploit.yml')\r\nprint(exploit)\r\n\r\n//exploit.yml\r\n!!python/object/new:type\r\n  args: [\"z\", !!python/tuple [], {\"extend\": !!python/name:exec }]\r\n  listitems: \"__import__('os').system('xcalc')\"\r\n```\r\n\r\n\r\n### \ud83d\udd25 Proof of Fix (PoF) *\r\n\r\nAfter applying the fix, run the PoC again, calc wont pop and no code will be executed. Hence code exec is mitigated.\r\n\r\n\r\n### \ud83d\udc4d User Acceptance Testing (UAT)\r\n\r\nOnly `SafeLoader` is used, no breaking changes introduced.\r\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-01-23T16:46:49Z",
        "closed_at": "2022-06-05T02:18:48Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nIn this PR I fix a broken link to the TF2 model zoo markdown file.\r\n\r\n## Type of change\r\n\r\n- [x] Documentation update\r\n\r\n## Tests\r\n\r\nN/A\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2021-01-19T10:56:39Z",
        "closed_at": "2021-01-23T00:40:00Z",
        "merged_at": "2021-01-23T00:40:00Z",
        "body": "Signed-off-by: Pablo Ribalta Lorenzo <pribalta@nvidia.com>\r\n\r\n# Description\r\n\r\nThis pull requests adds the NVIDIA implementation of the ELECTRA model, to the Natural Language Processing section of the community repository.\r\n\r\nNo dependencies are required for this change.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] A new research paper code implementation\r\n\r\n## Tests\r\n\r\nThe code is extensively tested, both for performance and accuracy. Detailed steps to reproduce and benchmarks are available in the README file in the model's repository: https://github.com/NVIDIA/DeepLearningExamples/blob/master/TensorFlow2/LanguageModeling/ELECTRA/README.md\r\n\r\n**Test Configuration**:\r\n\r\nELECTRA provides tests for DGX A100 40GB, DGX V100 16GB and DGX V100 32GB. Single- and multi-GPU setups are benchmarked as well as multi-node on a Pyxis/Enroot SLURM cluster\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-01-19T02:06:00Z",
        "closed_at": "2021-01-19T18:54:42Z",
        "merged_at": "2021-01-19T18:54:42Z",
        "body": "Fix hard-coded parameter values\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 16,
        "changed_files": 1,
        "created_at": "2021-01-18T19:56:00Z",
        "closed_at": "2021-01-20T19:41:50Z",
        "merged_at": "2021-01-20T19:41:50Z",
        "body": "Delete research/setup.py. This is not used by anyone\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-01-16T03:01:48Z",
        "closed_at": "2021-01-16T21:39:11Z",
        "merged_at": "2021-01-16T21:39:11Z",
        "body": "fix a mistake in https://github.com/tensorflow/models/tree/master/official/nlp/nhnet/README.md\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\nfix the issue#9639\r\nfix a mistake in the document of NHNET\r\nhttps://github.com/tensorflow/models/tree/master/official/nlp/nhnet\r\n\r\nIn the README.md line 85. There is a mistake in the script to process the crawled data. The script is shown as follow:\r\n``` shell\r\n# Recall that we use DATA_FOLDER=/path/to/downloaded_dataset.\r\n$ python3 raw_data_preprocess.py \\\r\n    -crawled_articles=/tmp/nhnet \\\r\n    -vocab=/path/to/bert_checkpoint/vocab.txt \\\r\n    -do_lower_case=True \\\r\n    -len_title=15 \\\r\n    -len_passage=200 \\\r\n    -max_num_articles=5 \\\r\n    -data_folder=$DATA_FOLDER\r\n```\r\nThe file name is wrong. There is not a raw_data_preprocess.py in the folder. It should be row_data_process.py.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 21,
        "changed_files": 1,
        "created_at": "2021-01-15T06:32:20Z",
        "closed_at": "2021-01-23T14:01:43Z",
        "merged_at": "2021-01-23T14:01:43Z",
        "body": "# Description\r\n\r\nRemove instructions for the bike video dataset since it is no longer available.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2021-01-11T20:54:32Z",
        "closed_at": "2021-01-11T22:25:41Z",
        "merged_at": "2021-01-11T22:25:41Z",
        "body": "Pin TFA in r2.2.0 to 0.8.3. For reference, [TF 2.2.0 released](https://github.com/tensorflow/tensorflow/releases/tag/v2.2.0-rc0) on 3/10/20, and [TFA 0.8.3 released](https://github.com/tensorflow/addons/releases/tag/v0.8.3) on 3/4/20.\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 24,
        "deletions": 23,
        "changed_files": 1,
        "created_at": "2021-01-06T18:31:51Z",
        "closed_at": "2023-01-20T20:25:45Z",
        "merged_at": null,
        "body": "Running fine_tuning_bert.ipynb in colaboratory raises an error in [this](https://colab.research.google.com/github/tensorflow/models/blob/master/official/colab/fine_tuning_bert.ipynb#scrollTo=hlVdgJKmj389&line=1&uniqifier=1) cell:\r\n`ValueError: Input 0 is incompatible with layer transformer_encoder_2: expected shape=(None, 512), found shape=(2, 23)`\r\n\r\nThis is because `manual_encoder`, that was created [here](https://colab.research.google.com/github/tensorflow/models/blob/master/official/colab/fine_tuning_bert.ipynb#scrollTo=rIO8MI7LLijh&line=1&uniqifier=1), expects batch with length 512. That is strange, because it must work with batch of every length (the longest sequence in batch). That's why there should be one more config option in `trainsformer_config` [here](https://colab.research.google.com/github/tensorflow/models/blob/master/official/colab/fine_tuning_bert.ipynb#scrollTo=5r_yqhBFSVEM&line=1&uniqifier=1):\r\n`transformer_config['sequence_length'] = None`\r\nAfter that code works as expected up to the end of the notebook without errors.\r\n\r\nP.S: there are some auto changes in unicode symbols, think it was done automatically by my VS Code (windows 10). Hope it didn't make things worse.\r\n\r\n## Type of change\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\n> * Just open notebook in colab, then Runtime -> Run all. Previous version on notebook raises an error, that was mentioned earlier .\r\n\r\n**Test Configuration**:\r\ngoogle colab\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2021-01-05T09:28:52Z",
        "closed_at": "2021-01-09T04:24:04Z",
        "merged_at": "2021-01-09T04:24:03Z",
        "body": "# Description\r\nfixed typo: changed `COCO_TRIAN_EXAMPLES` to `COCO_TRAIN_EXAMPLES` \r\n\r\n- [x] Other (Specify) fixed typo in naming\r\n\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] My changes generate no new warnings.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2021-01-05T05:43:39Z",
        "closed_at": "2021-01-12T07:35:20Z",
        "merged_at": "2021-01-12T07:35:20Z",
        "body": "# Description\r\n\r\nREADME update for DELF training with autoencoder.\r\n\r\n## Type of change\r\n\r\n- [x] Documentation update\r\n\r\n## Tests\r\n\r\nN/A\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 203,
        "changed_files": 1,
        "created_at": "2020-12-31T18:41:25Z",
        "closed_at": "2021-01-27T20:52:44Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [x] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-12-25T22:33:40Z",
        "closed_at": "2021-08-29T07:00:32Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 7,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2020-12-21T20:50:27Z",
        "closed_at": "2022-10-23T01:35:25Z",
        "merged_at": null,
        "body": "Two changes:\r\n- Dropout layers were taking the same names as the dropout rates, hence messing deserialization process (`ValueError: rate is neither scalar nor scalar tensor <tensorflow.python.keras.layers.core.Dropout object at 0x7f80860cd5f8>`). Found by saving as .h5, loading and then trying to save as saved_model.\r\n- I believe attention_dropout is already being applied to the attention weights in the MultiHeadAttention layer, so probably unnecessary to add another dropout to the latter layer's outputs.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 76,
        "deletions": 76,
        "changed_files": 50,
        "created_at": "2020-12-21T08:44:15Z",
        "closed_at": "2020-12-23T23:07:08Z",
        "merged_at": "2020-12-23T23:07:08Z",
        "body": "I've written custom parsers and emitters for everything from docstrings to classes and functions. However, I recently came across an issue with the TensorFlow codebase: inconsistent use of `Args:` and `Arguments:` in its docstrings. It is easy enough to extend my parsers to support both variants, however it looks like `Arguments:` is wrong anyway, as per:\r\n\r\n  - https://google.github.io/styleguide/pyguide.html#doc-function-args @ [`ddccc0f`](https://github.com/google/styleguide/blob/ddccc0f/pyguide.md)\r\n\r\n  - https://chromium.googlesource.com/chromiumos/docs/+/master/styleguide/python.md#describing-arguments-in-docstrings @ [`9fc0fc0`](https://chromium.googlesource.com/chromiumos/docs/+/9fc0fc0/styleguide/python.md)\r\n\r\n  - https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html @ [`c0ae8e3`](https://github.com/sphinx-contrib/napoleon/blob/c0ae8e3/docs/source/example_google.rst)\r\n\r\nTherefore, only `Args:` is valid. This PR replaces them throughout the codebase.\r\n\r\nPS: For related PRs, see tensorflow/tensorflow/pull/45420",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 10,
        "changed_files": 6,
        "created_at": "2020-12-21T08:43:34Z",
        "closed_at": "2020-12-22T06:47:27Z",
        "merged_at": "2020-12-22T06:47:27Z",
        "body": "I've written custom parsers and emitters for everything from docstrings to classes and functions. However, I recently came across an issue with the TensorFlow codebase: inconsistent use of `Args:` and `Arguments:` in its docstrings. It is easy enough to extend my parsers to support both variants, however it looks like `Arguments:` is wrong anyway, as per:\r\n\r\n  - https://google.github.io/styleguide/pyguide.html#doc-function-args @ [`ddccc0f`](https://github.com/google/styleguide/blob/ddccc0f/pyguide.md)\r\n\r\n  - https://chromium.googlesource.com/chromiumos/docs/+/master/styleguide/python.md#describing-arguments-in-docstrings @ [`9fc0fc0`](https://chromium.googlesource.com/chromiumos/docs/+/9fc0fc0/styleguide/python.md)\r\n\r\n  - https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html @ [`c0ae8e3`](https://github.com/sphinx-contrib/napoleon/blob/c0ae8e3/docs/source/example_google.rst)\r\n\r\nTherefore, only `Args:` is valid. This PR replaces them throughout the codebase.\r\n\r\nPS: For related PRs, see tensorflow/tensorflow/pull/45420",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2020-12-14T23:43:22Z",
        "closed_at": "2020-12-16T04:41:14Z",
        "merged_at": "2020-12-16T04:41:14Z",
        "body": "# Description\r\n\r\nIn today's earlier PR (https://github.com/tensorflow/models/pull/9555), we added a configurable image size for training. It turns out that there was a missing code location that needs to be changed in order for it to work properly. This PR fixes it.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\n\r\nRan training with new option and confirmed it fixes issue.\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [X] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [X] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [X] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [X] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [X] I have commented my code, particularly in hard-to-understand areas.\r\n- [X] I have made corresponding changes to the documentation.\r\n- [X] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-12-14T19:12:21Z",
        "closed_at": "2020-12-19T15:36:49Z",
        "merged_at": "2020-12-19T15:36:49Z",
        "body": "# Description\r\n\r\nAdded an example shell script and more info on running create_pretraining_data.py. There is a lack of info on how to run and leverage this script including info on what params are needed.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 290,
        "deletions": 101,
        "changed_files": 6,
        "created_at": "2020-12-12T02:40:04Z",
        "closed_at": "2020-12-14T21:26:24Z",
        "merged_at": "2020-12-14T21:26:24Z",
        "body": "# Description\r\n\r\nImplementation of the autoencoder layer in the DELG model.  \r\n\r\n## Type of change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] A new research paper code implementation\r\n\r\n## Tests\r\n\r\nTested training on a 8xGPU and tested exporting local features and global and local features.\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2020-12-11T18:47:32Z",
        "closed_at": "2022-11-23T23:40:45Z",
        "merged_at": null,
        "body": "## Description\r\nFixes #9547\r\nAdding `compat.v1` modules for TF2 compatibility.\r\nFor more info see https://github.com/tensorflow/models/issues/9547\r\n\r\n## Type of change\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\n- [ ] TensorFlow 2 migration\r\n\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 135,
        "deletions": 2,
        "changed_files": 3,
        "created_at": "2020-12-09T05:55:19Z",
        "closed_at": "2022-01-14T01:57:59Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 2171,
        "deletions": 0,
        "changed_files": 19,
        "created_at": "2020-12-07T21:35:15Z",
        "closed_at": "2021-01-11T21:48:14Z",
        "merged_at": "2021-01-11T21:48:14Z",
        "body": "# Description\r\n\r\nThis pull request adds the backbones of the YOLOv3 and v4 families (Darknet53, TinyYOLOv3, CSPDarknet53, and TinyYOLOv4).\r\n\r\nTo train the CSPDarknet53 image classification backbone on ImageNet, use the following command in the official directory:\r\n```\r\npython3 -m official.vision.beta.projects.yolo.train --mode=train_and_eval --experiment=darknet_classification --model_dir=training_dir --config_file=official/vision/beta/projects/yolo/configs/experiments/darknet53.yaml\r\n```\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\nTests are provided for each of the building blocks. The tests provide checking to see if the outputs or gradients of the layers go to `None` anywhere in the layer.\r\n\r\n**Test Configuration**: Currently, we use `unittest` in the Python3 standard library in order to verify the correctness of our code.\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 13,
        "changed_files": 1,
        "created_at": "2020-12-05T17:48:29Z",
        "closed_at": "2023-02-02T19:59:31Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nPR improves the numerical stability of PenaltyReducedLogisticFocalLoss. The line of reasoning is the same as in https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits.\r\n\r\nIn particular, it uses the fact that `-log(sigmoid(x)) = log(1+exp(-abs(-x))) + max(-x,0)`. See https://www.tensorflow.org/api_docs/python/tf/math/log_sigmoid for reference. \r\n\r\nWith that, we can also derive:\r\n``` \r\n  - log(1 - sigmoid(x))\r\n= - log(sigmoid(x)) - log(exp(-x))\r\n= - log(sigmoid(x)) + x\r\n=   log(1+exp(-abs(-x))) + max(-x,0) + x\r\n=   log(1+exp(-abs(-x))) + max(x,0)\r\n```\r\n\r\n## Type of change\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Other (Improved numerical stability)\r\n\r\n## Tests\r\n`research/object_detection/core/losses_test.py` passes the tests without `_sigmoid_clip_value` even for +inf and -inf.\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 84,
        "deletions": 84,
        "changed_files": 55,
        "created_at": "2020-12-05T10:46:16Z",
        "closed_at": "2020-12-21T08:45:02Z",
        "merged_at": null,
        "body": "I've written custom parsers and emitters for everything from docstrings to classes and functions. However, I recently came across an issue with the TensorFlow codebase: inconsistent use of `Args:` and `Arguments:` in its docstrings. It is easy enough to extend my parsers to support both variants, however it looks like `Arguments:` is wrong anyway, as per:\n\n  - https://google.github.io/styleguide/pyguide.html#doc-function-args @ [`ddccc0f`](https://github.com/google/styleguide/blob/ddccc0f/pyguide.md)\n\n  - https://chromium.googlesource.com/chromiumos/docs/+/master/styleguide/python.md#describing-arguments-in-docstrings @ [`9fc0fc0`](https://chromium.googlesource.com/chromiumos/docs/+/9fc0fc0/styleguide/python.md)\n\n  - https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html @ [`c0ae8e3`](https://github.com/sphinx-contrib/napoleon/blob/c0ae8e3/docs/source/example_google.rst)\n\nTherefore, only `Args:` is valid. This PR replaces them throughout the codebase.\n\nPS: For related PRs, see tensorflow/tensorflow/pull/45420",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-12-01T23:11:21Z",
        "closed_at": "2020-12-02T01:50:02Z",
        "merged_at": "2020-12-02T01:50:02Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1033,
        "deletions": 229,
        "changed_files": 29,
        "created_at": "2020-11-25T18:47:44Z",
        "closed_at": "2020-11-26T00:13:25Z",
        "merged_at": "2020-11-26T00:13:25Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 993,
        "deletions": 220,
        "changed_files": 29,
        "created_at": "2020-11-24T23:45:33Z",
        "closed_at": "2020-11-25T16:27:49Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1250,
        "deletions": 6,
        "changed_files": 11,
        "created_at": "2020-11-21T17:22:15Z",
        "closed_at": "2021-01-27T20:10:18Z",
        "merged_at": "2021-01-27T20:10:18Z",
        "body": "This pull request adds the detection data loader, box utilities, iou utilities, preprocessing operations and input test to the YOLOv3 and v4 families.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n\r\n**Test Configuration**:\r\n\r\nTests are provided for the detection pipeline that utilizes all of the files in the pull request. The test provided preprocesses the coco dataset and allows the user to see the outputted preprocessed image with bounding boxes drawn on to the image. This test is not automated and the  user will have to click through a set of images and check the validity of the images manually.\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.",
        "comments": 11
    },
    {
        "merged": true,
        "additions": 98,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-11-11T16:02:44Z",
        "closed_at": "2020-11-20T18:47:53Z",
        "merged_at": "2020-11-20T18:47:53Z",
        "body": "Adds a file to repro recent reported regression.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-11-11T12:12:02Z",
        "closed_at": "2022-05-20T05:24:05Z",
        "merged_at": "2022-05-20T05:24:05Z",
        "body": "Corrected the broken link of installation instruction\r\n\r\n# Description\r\n\r\nUpdated the broken link of [\"installation instructions\"](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md) in [object_detection_tutorial.ipynb](https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb)\r\n\r\nCorrect link is https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md\r\n\r\nMotivation for this change : To correct the hyperlink to the \"installation instruction\" for the benefit of community \r\n \r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  We have opened the new link and ensure that it is working\r\n\r\n> * Provide instructions so we can reproduce.  \r\nPlease open this link, https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md\r\n\r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2364,
        "deletions": 3,
        "changed_files": 23,
        "created_at": "2020-11-07T13:01:58Z",
        "closed_at": "2021-02-26T00:33:48Z",
        "merged_at": "2021-02-26T00:33:48Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [x] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 2406,
        "deletions": 1407,
        "changed_files": 93,
        "created_at": "2020-11-06T00:18:59Z",
        "closed_at": "2020-11-06T21:26:05Z",
        "merged_at": "2020-11-06T21:26:05Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  Rename sequence_projection to seq_flow_lite\r\n>\r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [x] TensorFlow 2 migration\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 477,
        "deletions": 279,
        "changed_files": 1,
        "created_at": "2020-10-30T08:28:15Z",
        "closed_at": "2021-03-29T04:55:44Z",
        "merged_at": null,
        "body": "# Description\r\n> I made changes for enabling the eager execution, so this code should work for users that are using Tensorflow version 2.x, rather than using the tensorflow 1.x.\r\n\r\n## Type of change\r\n- [ ] TensorFlow 2 migration\r\n\r\n## Tests\r\n> For the testing I used google colaboratory for testing the code and the result for it\r\n1. First is that download the file or copy the code\r\n2. Put the code or the file into google colaboratory\r\n3. Change the runtime type into GPU used case\r\n4. Make sure to use tensorflow version 2.x\r\n5. Run All of the code cells\r\n\r\n**Test Configuration**: You could use your own personal or local IDE or code editor for testing\r\n\r\n## Checklist\r\n> The image file, shows the result of the code\r\n![result NST](https://user-images.githubusercontent.com/56186156/97677121-57918980-1ac4-11eb-97cc-171165cff3d4.JPG)\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-10-30T01:04:07Z",
        "closed_at": "2020-11-09T02:50:50Z",
        "merged_at": null,
        "body": "I cannot found model.ckpt in the archive file (deeplabv3_pascal_train_aug_2018_01_04.tar.gz).\r\nAs I found another named file (model.ckpt.data-00000-of-00001) instead of the file, I use it by renaming,\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [x] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ x] I have made corresponding changes to the documentation.\r\n- [ x] My changes generate no new warnings.\r\n- [ x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 69,
        "deletions": 84,
        "changed_files": 1,
        "created_at": "2020-10-22T17:37:09Z",
        "closed_at": "2020-10-22T18:54:31Z",
        "merged_at": "2020-10-22T18:54:30Z",
        "body": "# Description\r\n\r\nUpdated YAMNet visualization notebook to match latest model code.\r\n\r\n## Type of change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\n\r\nRan the notebook in public Colab.\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] My changes generate no new warnings.\r\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 2171,
        "deletions": 0,
        "changed_files": 19,
        "created_at": "2020-10-22T15:08:52Z",
        "closed_at": "2020-12-07T21:32:41Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nThis pull request adds the backbones of the YOLOv3 and v4 families (Darknet53, TinyYOLOv3, CSPDarknet53, and TinyYOLOv4).\r\n\r\nTo train the CSPDarknet53 image classification backbone on ImageNet, use the following command in the official directory:\r\n```\r\npython3 -m official.vision.beta.projects.yolo.train --mode=train_and_eval --experiment=darknet_classification --model_dir=training_dir --config_file=official/vision/beta/projects/yolo/configs/experiments/darknet53.yaml\r\n```\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\nTests are provided for each of the building blocks. The tests provide checking to see if the outputs or gradients of the layers go to `None` anywhere in the layer.\r\n\r\n**Test Configuration**: Currently, we use `unittest` in the Python3 standard library in order to verify the correctness of our code.\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 12
    },
    {
        "merged": true,
        "additions": 77,
        "deletions": 82,
        "changed_files": 5,
        "created_at": "2020-10-02T06:32:59Z",
        "closed_at": "2020-10-06T21:34:15Z",
        "merged_at": "2020-10-06T21:34:15Z",
        "body": "# Description\r\n\r\nSmall change to backpropagate global and attention layers together in the DELF and DELG trainings.\r\n\r\n## Type of change\r\n\r\n- [x] Other (Optimization)\r\n\r\n## Tests\r\n\r\n- Training on 8 GPUs\r\n- Model export\r\n- Features extraction\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1646,
        "deletions": 73,
        "changed_files": 19,
        "created_at": "2020-09-28T03:14:17Z",
        "closed_at": "2020-10-12T23:41:45Z",
        "merged_at": "2020-10-12T23:41:45Z",
        "body": "The Mobilenet V1, V2, V3 (small, large, edgetpu) versions have been implemented and integrated into the tf-vision framework.\r\n\r\nIn particular, some existing blocks and layers have been modified to make them usable in the Mobilenet implementation.\r\n\r\n1. I have modified SqueezeExcitation for the Mobilenet migration.\r\n  - added two additional parameter: `divisible_by` and `gating_activation`\r\n  - removed `expand_ratio` and added explicit `out_filters`\r\n2. I have modified InvertedBottleneckBlock for the Mobilenet migration.\r\n  - added `use_depthwise`, `use_residual`, `regularize_depthwise` boolean flag; \r\n  - added explicit activiation function for embedded `SqueezeExcitation` call and depthwise part\r\n  - added a parameter `target_backbone` to indicate where the `InvertedBottleneckBlock` is used. It is because the \r\n  `SqueezeExcitation` call for building EfficientNet and MobileNet are slightly different.\r\n3. I have added a `DepthwiseSeparableConvBlock` block in nn_blocks.py as well for building MobilenetV1\r\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1459,
        "deletions": 68,
        "changed_files": 15,
        "created_at": "2020-09-25T03:06:51Z",
        "closed_at": "2020-09-27T23:30:13Z",
        "merged_at": "2020-09-27T23:30:13Z",
        "body": "The Mobilenet V1, V2, V3 (small, large, edgetpu) versions have been implemented and integrated into the tf-vision framework.\r\n\r\nIn particular, some existing blocks and layers have been modified to make them usable in the Mobilenet implementation.\r\n\r\n1. I have modified SqueezeExcitation for the Mobilenet migration.\r\n  - added two additional parameter: `divisible_by` and `gating_activation`\r\n  - removed `expand_ratio` and added explicit `out_filters`\r\n2. I have modified InvertedBottleneckBlock for the Mobilenet migration.\r\n  - added `use_depthwise`, `use_residual`, `regularize_depthwise` boolean flag; \r\n  - added explicit activiation function for embedded `SqueezeExcitation` call and depthwise part\r\n  - added a parameter `target_backbone` to indicate where the `InvertedBottleneckBlock` is used. It is because the \r\n  `SqueezeExcitation` call for building EfficientNet and MobileNet are slightly different.\r\n3. I have added a `DepthwiseSeparableConvBlock` block in nn_blocks.py as well for building MobilenetV1\r\n\r\nOne more thing to mention, since the implementation of `hard_sigmoid` implemented in `keras.activations.hard_sigmoid` is different from that required in Mobilenet. I have implemented a customized one as well.\r\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 159,
        "deletions": 63,
        "changed_files": 4,
        "created_at": "2020-09-22T14:55:40Z",
        "closed_at": "2020-09-25T02:03:48Z",
        "merged_at": null,
        "body": "I have modified `InvertedBottleneckBlock` and `SqueezeExcitation` to prepare for the Mobilenet migration.\r\n\r\n1.  factor out make_divisible function and move round_filters to nn_layers\r\n2.  modify SqueezeExcitation to add two additional parameter: divisible_by and gating_activation, and remove expand_ratio\r\n3. modify InvertedBottleneckBlock to: include `use_depthwise`, `use_residual`, `regularize_depthwise` boolean flag; Add control for depthwise activation and regularizer.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 25,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-09-18T21:55:27Z",
        "closed_at": "2020-09-25T19:42:59Z",
        "merged_at": "2020-09-25T19:42:59Z",
        "body": "This is config is created for auto assignment issues for tf-dev-support\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-09-15T21:43:51Z",
        "closed_at": "2020-09-22T17:19:08Z",
        "merged_at": "2020-09-22T17:19:08Z",
        "body": "# Description\r\n\r\nThis PR adds the following Intel-optimized, TF2-compatible NLP and Recommender models to the community README:\r\n- BERT\r\n- GNMT\r\n- Transformer-LT\r\n- Wide & Deep\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 12,
        "changed_files": 1,
        "created_at": "2020-09-15T16:50:57Z",
        "closed_at": "2020-09-16T00:16:18Z",
        "merged_at": "2020-09-16T00:16:18Z",
        "body": "# Description\r\n\r\nFix a small typo on DELG's extractor.py.\r\n\r\n## Type of change\r\n\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\n\r\nNone. The typo wasn't a breaking issue, but an extra unnecessary `if` statement.\r\n\r\n## Checklist\r\n\r\n- [X] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [X] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [X] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [X] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [X] I have commented my code, particularly in hard-to-understand areas.\r\n- [X] I have made corresponding changes to the documentation.\r\n- [X] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 62,
        "deletions": 6,
        "changed_files": 4,
        "created_at": "2020-09-14T20:52:42Z",
        "closed_at": "2020-09-15T16:02:56Z",
        "merged_at": "2020-09-15T16:02:56Z",
        "body": "# Description\r\n\r\nDELG: adding models pre-trained on GLDv2-clean. This will be included in an arXiv update of our paper, which will go live in the next few days.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [X] Documentation update\r\n- [X] New feature (non-breaking change which adds functionality)\r\n\r\n## Tests\r\n\r\nNone\r\n\r\n## Checklist\r\n\r\n- [X] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [X] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [X] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [X] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [X] I have commented my code, particularly in hard-to-understand areas.\r\n- [X] I have made corresponding changes to the documentation.\r\n- [X] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 16,
        "deletions": 13,
        "changed_files": 3,
        "created_at": "2020-09-10T15:46:51Z",
        "closed_at": "2020-09-30T00:05:33Z",
        "merged_at": "2020-09-30T00:05:33Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [x] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2020-09-10T00:54:48Z",
        "closed_at": "2020-09-10T03:51:47Z",
        "merged_at": "2020-09-10T03:51:47Z",
        "body": "# Description\r\n\r\nUpdated the DELF documentation to include hyperparameter guidelines.\r\n\r\n## Type of change\r\n\r\n- [x] Documentation update\r\n\r\n## Tests\r\n\r\nN/A\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-09-08T08:51:06Z",
        "closed_at": "2021-04-20T20:08:46Z",
        "merged_at": "2021-04-20T20:08:46Z",
        "body": "# Description\r\n\r\n> :memo: The previous url led to 404 errors. This commit uses the correct URL.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [X] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Checklist\r\n\r\n- [X] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [X] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [X] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [X] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [X] I have made corresponding changes to the documentation.\r\n- [X] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-09-07T17:05:01Z",
        "closed_at": "2020-09-18T21:14:26Z",
        "merged_at": "2020-09-18T21:14:26Z",
        "body": "The previous `base_url` led to 404 errors. This commit uses the correct base URL.\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\nMy motivation for this change arose from answering [this StackOverflow question](https://stackoverflow.com/q/63728740/5666087).\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration. \r\n\r\n**Test Configuration**:\r\n\r\nI have not provided tests.\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 39,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-09-03T20:31:58Z",
        "closed_at": "2020-09-08T17:41:35Z",
        "merged_at": "2020-09-08T17:41:35Z",
        "body": "\r\n\r\n## Type of change\r\nStale bot needs this file for configuration.\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 71,
        "deletions": 19,
        "changed_files": 5,
        "created_at": "2020-09-02T20:41:26Z",
        "closed_at": "2020-09-03T22:25:12Z",
        "merged_at": "2020-09-03T22:25:12Z",
        "body": "# Description\r\n\r\nExporting code for DELG global feature, together with documentation explaining its use.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [X] Documentation update\r\n- [X] New feature (non-breaking change which adds functionality)\r\n\r\n## Tests\r\n\r\nModel was successfully exported and used with the codebase instructions to obtain good results in the Oxford/Paris datasets.\r\n\r\n## Checklist\r\n\r\n- [X] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [X] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [X] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [X] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [X] I have commented my code, particularly in hard-to-understand areas.\r\n- [X] I have made corresponding changes to the documentation.\r\n- [X] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1288,
        "deletions": 10,
        "changed_files": 5,
        "created_at": "2020-09-02T06:45:55Z",
        "closed_at": "2020-09-09T16:34:41Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\nresearch/street does not exist in master branch, so some url is not available.\r\nAnd we should not rely on that model, so I copy file \"fsns_urls.txt\" here.\r\n\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2923,
        "deletions": 0,
        "changed_files": 6,
        "created_at": "2020-08-31T17:45:02Z",
        "closed_at": "2020-10-02T19:37:18Z",
        "merged_at": null,
        "body": "# Only BatchNorm\r\n  \r\n[![Paper](http://img.shields.io/badge/paper-arXiv.2003.00152-B3181B.svg)](https://arxiv.org/pdf/2003.00152.pdf) \r\n<!-- [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Vishal-V/tf-models/blob/master/...)   -->\r\n\r\nThis repository is the unofficial implementation of the following [[Paper]](https://arxiv.org/pdf/2003.00152.pdf).\r\n\r\n* Training BatchNorm and Only BatchNorm: On the Expressivity of Random Features in CNNs\r\n\r\n## Description/Abstract\r\n\r\nBatch normalization (BatchNorm) has become an indispensable tool for training\r\ndeep neural networks, yet it is still poorly understood. Although previous work\r\nhas typically focused on studying its normalization component, BatchNorm also\r\nadds two per-feature trainable parameters\u2014a coefficient and a bias\u2014whose role\r\nand expressive power remain unclear. To study this question, we investigate the\r\nperformance achieved when training only these parameters and freezing all others\r\nat their random initializations. We find that doing so leads to surprisingly high\r\nperformance. For example, sufficiently deep ResNets reach 82% (CIFAR-10) and\r\n32% (ImageNet, top-5) accuracy in this configuration, far higher than when training\r\nan equivalent number of randomly chosen parameters elsewhere in the network.\r\nBatchNorm achieves this performance in part by naturally learning to disable\r\naround a third of the random features. Not only do these results highlight the\r\nunder-appreciated role of the affine parameters in BatchNorm, but\u2014in a broader\r\nsense\u2014they characterize the expressive power of neural networks constructed\r\nsimply by shifting and rescaling random features.\r\n\r\n \r\n  \r\n<!-- ## History\r\n\r\n> :memo: Provide a changelog. -->\r\n  \r\n## Key Features\r\n\r\n- [x] TensorFlow 2.3.0\r\n- [x] Inference example (Colab Demo)\r\n- [x] Graph mode training with `model.fit`\r\n- [x] Functional model with `tf.keras.layers`\r\n- [x] Input pipeline using `tf.data` and `tfds`\r\n- [x] GPU accelerated\r\n- [ ] Fully integrated with `absl-py` from [abseil.io](https://abseil.io)\r\n- [x] Clean implementation\r\n- [x] Following the best practices\r\n- [x] Apache 2.0 License\r\n\r\n## Requirements\r\n\r\n[![TensorFlow 2.3](https://img.shields.io/badge/tensorflow-2.3-brightgreen)](https://github.com/tensorflow/tensorflow/releases/tag/v2.3.0)\r\n[![Python 3.7](https://img.shields.io/badge/python-3.8-blue.svg)](https://www.python.org/downloads/release/python-382/)\r\n\r\n\r\nTo install requirements:\r\n\r\n```setup\r\npip install -r requirements.txt\r\n```\r\n\r\n## Results\r\n#\r\n### Image Classification (Only BatchNorm weights) \r\n \r\n| Model name | Download | Top 1 Accuracy |\r\n|------------|----------|----------------|\r\n| ResNet-14 (N=2)| [Checkpoint](https://drive.google.com/...) | 46.67% |\r\n| ResNet-32 (N=5)| [Checkpoint](https://drive.google.com/...) | 51.29% |\r\n| ResNet-56 (N=9)| [Checkpoint](https://drive.google.com/...) | 55.21% |\r\n| ResNet-110 (N=18)| [Checkpoint](https://drive.google.com/...) | 65.19% |\r\n| ResNet-218 (N=36)| [Checkpoint](https://drive.google.com/...) | 70.09% |\r\n| ResNet-434 (N=72)| [Checkpoint](https://drive.google.com/...) | 73.67% |\r\n| ResNet-866 (N=144)| [Checkpoint](https://drive.google.com/...) | 77.83% |\r\n#  \r\n## Dataset\r\n\r\n`CIFAR10` dataset - 10 classes with 50,000 images in the train set and 10,000 images in the test set.\r\n  \r\n\r\n## Training\r\n\r\n> :memo: Provide training information.  \r\n>  \r\n> * Provide details for preprocessing, hyperparameters, random seeds, and environment.  \r\n> * Provide a command line example for training.  \r\n\r\nPlease run this command line for training.\r\n\r\n```shell\r\npython3 resnet_cifar.py\r\n```\r\nThis trains the OnlyBN model for the ResNet-14 architecture. Replace `num_blocks` with the appropriate value for 'N' from the results table above to train the respective ResNet architecture.  \r\n  \r\n## Evaluation\r\n<!-- \r\n> :memo: Provide an evaluation script with details of how to reproduce results.  \r\n>  \r\n> * Describe data preprocessing / postprocessing steps.  \r\n> * Provide a command line example for evaluation.   -->\r\n\r\nPlease run this command line for evaluation.\r\n\r\n```shell\r\npython3 ...\r\n```\r\n\r\n## References\r\n\r\n> :memo: Provide links to references.  \r\n\r\n## Citation\r\n\r\n> :memo: Make your repository citable.  \r\n>  \r\n> * Reference: [Making Your Code Citable](https://guides.github.com/activities/citable-code/)  \r\n\r\nIf you want to cite this repository in your research paper, please use the following information.\r\n\r\n## Authors or Maintainers\r\n\r\n* Vishal Vinod ([@Vishal-V](https://github.com/Vishal-V))\r\n  \r\nThis project is licensed under the terms of the **Apache License 2.0**.\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1170,
        "deletions": 0,
        "changed_files": 11,
        "created_at": "2020-08-31T16:05:21Z",
        "closed_at": "2020-10-02T19:38:49Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Implement Hierarchical Disentanglement for Fine-Grained Object Generation - FineGAN. \r\n>  \r\n> * State-of-the-art for CUB 200, CUB 128x128, Stanford Cars and Stanford Dogs datasets.  \r\n> * Hierarchical Deep Generative Model (Several moving parts trained end-to-end).  \r\n> * Reproduce the paper results and benchmark it on the 3 datasets.  \r\n> * Publish documentation and prepare Colab demo.  \r\n> * Publish pre-trained SavedModel files at TensorFlow Hub.  \r\n> * Completed implementation and merge solves #8705\r\n\r\n## Type of change\r\n- [x] A new research paper code implementation  \r\n  \r\n  \r\n## Key Features\r\n  \r\n- [x] TensorFlow 2.3.0\r\n- [ ] Inference example (Demo)\r\n- [x] Eager mode training with `tf.GradientTape` [If Required]\r\n- [ ] [Default] Graph mode training with `model.train_on_batch`\r\n- [x] Functional model with `tf.keras.layers.Layer`\r\n- [x] Subclassing model with `tf.keras.Model`\r\n- [x] Input pipeline using `tf.data` and `tfds`\r\n- [ ] Tensorflow Serving\r\n- [x] Vectorized transformations\r\n- [x] GPU accelerated\r\n- [x] Clean implementation\r\n- [x] Following the best practices\r\n- [x] Apache 2.0 License\r\n  \r\n## Tests\r\n\r\n> :memo: [WIP] Code Reviews and Tests Pending.\r\n>  \r\n> * [WIP] Provide instructions so we can reproduce.  \r\n> * [WIP] Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n> * Config `.yml` files and Config class included.\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2020-08-29T10:58:10Z",
        "closed_at": "2020-08-31T21:58:34Z",
        "merged_at": "2020-08-31T21:58:34Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  When I run script:\r\n``` bash\r\npython pretrain.py \\\r\n    --train_dir=$PRETRAIN_DIR \\\r\n    --data_dir=$IMDB_DATA_DIR \\\r\n    --vocab_size=86934 \\\r\n    --embedding_dims=256 \\\r\n    --rnn_cell_size=1024 \\\r\n    --num_candidate_samples=1024 \\\r\n    --batch_size=256 \\\r\n    --learning_rate=0.001 \\\r\n    --learning_rate_decay_factor=0.9999 \\\r\n    --max_steps=100000 \\\r\n    --max_grad_norm=1.0 \\\r\n    --num_timesteps=400 \\\r\n    --keep_prob_emb=0.5 \\\r\n    --normalize_embeddings\r\n```\r\nI will get error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"pretrain.py\", line 46, in <module>\r\n    tf.app.run()\r\n  File \"/home/luke/miniconda3/lib/python3.7/site-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/home/luke/miniconda3/lib/python3.7/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/home/luke/miniconda3/lib/python3.7/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"pretrain.py\", line 40, in main\r\n    model = graphs.get_model()\r\n  File \"/home/luke/Download/models/research/adversarial_text/graphs.py\", line 100, in get_model\r\n    return VatxtModel()\r\n  File \"/home/luke/Download/models/research/adversarial_text/graphs.py\", line 122, in __init__\r\n    self.vocab_freqs = _get_vocab_freqs()\r\n  File \"/home/luke/Download/models/research/adversarial_text/graphs.py\", line 661, in _get_vocab_freqs\r\n    (len(freqs), FLAGS.vocab_size))\r\nValueError: Frequency file length 87007 != vocab size 86934\r\n```\r\n\r\n\r\n## Type of change\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 8977,
        "deletions": 0,
        "changed_files": 69,
        "created_at": "2020-08-25T23:37:17Z",
        "closed_at": "2020-08-26T21:34:57Z",
        "merged_at": "2020-08-26T21:34:57Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 83,
        "deletions": 33,
        "changed_files": 7,
        "created_at": "2020-08-24T20:37:32Z",
        "closed_at": "2020-08-25T00:53:02Z",
        "merged_at": "2020-08-25T00:53:02Z",
        "body": "# Description\r\n\r\n- Refactor DELG extraction, which allows faster feature extraction than previously reported on the paper (need to update it on arXiv later)\r\n- Release latest DELG paper models\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [X] New feature (non-breaking change which adds functionality)\r\n\r\n## Tests\r\n\r\n- All tests continue to pass\r\n- Re-ran experiments on ROxf/RPar datasets and obtained same results as before\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [X] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [X] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [X] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [X] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [X] I have commented my code, particularly in hard-to-understand areas.\r\n- [X] I have made corresponding changes to the documentation.\r\n- [X] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-08-21T02:18:18Z",
        "closed_at": "2020-11-13T01:07:34Z",
        "merged_at": null,
        "body": "see line 145\r\nadd missing import box_list_ops\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-08-18T06:20:10Z",
        "closed_at": "2020-09-01T12:07:17Z",
        "merged_at": null,
        "body": "Added \"Open in Colab\" button for the Google Colab projects.\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-08-17T20:27:49Z",
        "closed_at": "2020-08-17T22:42:13Z",
        "merged_at": "2020-08-17T22:42:13Z",
        "body": "Another bugfix, missed this in the first bugfix.\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 16,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-08-15T04:40:00Z",
        "closed_at": "2020-08-18T16:07:46Z",
        "merged_at": "2020-08-18T16:07:46Z",
        "body": "# Description\r\n\r\nREADME update for training DELG global feature.\r\n\r\n## Type of change\r\n\r\n- [x] Documentation update\r\n\r\n## Tests\r\n\r\n- N/A\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2020-08-14T20:17:52Z",
        "closed_at": "2020-09-18T19:47:02Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: transformer_main.py to run Seq2SeqTransformer\r\n>  \r\n> * This is the main program file to run Seq2SeqTransformer model in nlp/modeling/models\r\n> * Follow the instructions in nlp/transformer/README.md to run\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] TensorFlow 2 migration\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 95,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-08-14T00:26:13Z",
        "closed_at": "2020-08-14T22:13:47Z",
        "merged_at": "2020-08-14T22:13:47Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * This pull request adds a forward pass test file to guard the correctness of refactoring Transformer model. The original Transformer model is in nlp/transformer/transformer.py. The refactored model is in nlp/modeling/models/seq2seq_transformer.py. This forward pass test file can test whether the original model and refactored model have the same output after one forward pass, given that:\r\n> ** Inputs are the same.\r\n> ** Weights are the same.\r\n> ** Dropout randomness is avoided.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] TensorFlow 2 migration\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Test cases in this file can be passed. \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 400,
        "deletions": 107,
        "changed_files": 7,
        "created_at": "2020-08-13T09:20:02Z",
        "closed_at": "2020-08-18T00:44:50Z",
        "merged_at": "2020-08-18T00:44:50Z",
        "body": "\r\n- Added a TF-Lite compatible feature extractor. With the latest TF-Lite,\r\n  that involves a DFT-multiplication replacement for tf.abs(tf.signal.stft())\r\n  and not a lot else. Note that TF-Lite now allows variable-length inputs.\r\n- Added a YAMNet exporter that produces TF2 SavedModels, TF-Lite models,\r\n  and TF-JS models.\r\n- Cleanups: switched hyperparameters to a dataclass, got rid of\r\n  some lingering cruft in yamnet_test.\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\nRan VGGish exporter, YAMNet {test, inference demo, exporter}\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2020-08-13T07:03:37Z",
        "closed_at": "2020-08-13T19:05:49Z",
        "merged_at": "2020-08-13T19:05:49Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 406,
        "deletions": 49,
        "changed_files": 14,
        "created_at": "2020-08-13T05:40:11Z",
        "closed_at": "2020-08-14T03:48:34Z",
        "merged_at": "2020-08-14T03:48:34Z",
        "body": "# Description\r\n\r\n- Support local feature matching using ratio test.\r\n- Option to measure DELG latency taking binarization into account.\r\n- DELG global features training.\r\n\r\n## Type of change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n## Tests\r\n\r\n- Training of DELG global features successfully on 8xP100 GPUs\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 344,
        "deletions": 241,
        "changed_files": 5,
        "created_at": "2020-08-11T23:34:43Z",
        "closed_at": "2020-08-12T13:08:58Z",
        "merged_at": "2020-08-12T13:08:58Z",
        "body": "- Waveform input for YAMNet is now padded so that we get at least\r\n  one patch of log mel spectrogram. The VGGish TF-Hub exporter\r\n  uses YAMNet's feature computation so the VGGish export will\r\n  also pad waveform input similarly.\r\n- Added a 1024-D embedding output to YAMNet so we now produce\r\n  predicted scores, log mel spectrogram features, and embeddings,\r\n  to satisfy a variety of uses: class prediction, acoustic\r\n  feature visualization, semantic feature extraction.\r\n- Simplified usage of YAMNet in inference mode. Instead of trying\r\n  to work around implicit batch size issues in the Model.predict()\r\n  API, we simply __call__() the Model.\r\n- Switched inference.py to TF 2 and Eager execution.\r\n- Updated the visualization notebook: now uses TF2/Eager and\r\n  can be loaded and run in Google Colab.\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] TensorFlow 2 migration\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\nRan inference.py and vggish_tfhub_export.py with TF2.\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2020-08-11T21:20:16Z",
        "closed_at": "2020-08-13T22:40:24Z",
        "merged_at": "2020-08-13T22:40:23Z",
        "body": "Project name seems that have changed to project ID. Just changed the project names to project Id.\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 812,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2020-08-11T15:53:03Z",
        "closed_at": "2020-08-13T23:40:24Z",
        "merged_at": "2020-08-13T23:40:24Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * The Seq2SeqTransformer model in this pull request, is a refactored version of Transformer model in nlp/transformer/transformer.py. \r\n> * The difference is that Seq2SeqTransformer model uses layers in nlp/modeling/layers to implement encoder, decoder and embedding layer.\r\n> * We can still follow instructions in nlp/transformer/README.md to run Seq2SeqTransformer model. Before running, we only need to make the following changes in nlp/transformer/transformer_main.py:\r\n> ** In the package import process, add `from official.nlp.modeling.models import seq2seq_transformer`\r\n> ** In Line 201, 381, 397, change `transformer.create_model` to `seq2seq_transformer.create_model`\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] TensorFlow 2 migration\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Seq2SeqTransformer model in my test reached benchmark performance.\r\n> * Seq2SeqTransformer model passed test cases in seq2seq_transformer_test.py.\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 8,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-08-11T14:26:51Z",
        "closed_at": "2020-08-14T07:22:40Z",
        "merged_at": null,
        "body": "# Description\r\nSupport fine_tune for all CenterNet feature extractors.\r\nFixes\r\nhttps://github.com/tensorflow/models/issues/8967#issuecomment-665082686\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 187,
        "deletions": 18,
        "changed_files": 3,
        "created_at": "2020-08-10T22:36:23Z",
        "closed_at": "2020-08-13T19:32:11Z",
        "merged_at": "2020-08-13T19:32:10Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 127,
        "deletions": 3,
        "changed_files": 4,
        "created_at": "2020-08-10T03:45:49Z",
        "closed_at": "2020-08-10T21:53:31Z",
        "merged_at": "2020-08-10T21:53:31Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\nRan vggish_export_tfhub.py, which self-checks the generated exports in TF1 and TF2.\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 27,
        "deletions": 39,
        "changed_files": 4,
        "created_at": "2020-08-10T02:55:13Z",
        "closed_at": "2020-08-10T13:29:09Z",
        "merged_at": "2020-08-10T13:29:09Z",
        "body": "Fixed a long-standing bug where the released VGGish model used\r\npost-activation embedding output while the released embeddings\r\nwere pre-activation. There are still discrepancies due to\r\nother reasons: differences in choice of YouTube transcode,\r\nrepeated resamplings with different resamplers, slight differences\r\nin feature computation, etc.\r\n\r\nThis can break existing code that assumes post-activation embedding\r\nvalues, but those can be easily fixed by passing the embeddings\r\nthrough a ReLU.\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [x] TensorFlow 2 migration\r\n- [x] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\nRan vggish_{smoke_test, inference_demo, train_demo}.py\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 27,
        "deletions": 32,
        "changed_files": 6,
        "created_at": "2020-08-09T05:08:56Z",
        "closed_at": "2020-08-09T17:17:14Z",
        "merged_at": "2020-08-09T17:17:13Z",
        "body": "Allowed TF2 behavior and allowed passing in a features tensor into the\r\nVGGish model definition. Both of these changes are needed for making\r\nTF-Hub exports of these models. Lifted constraints on TF versions since\r\ntf_slim has been updated to work with TF 2.\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Documentation update\r\n- [x] TensorFlow 2 migration\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\nVGGish: Ran vggish_smoke_test.py and vggish_inference_demo.py with latest TF1 and TF2\r\nYAMNet: Only documentation change.\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 749,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2020-08-07T19:58:54Z",
        "closed_at": "2022-11-15T04:34:02Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 7,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-08-07T19:38:44Z",
        "closed_at": "2020-08-10T04:23:21Z",
        "merged_at": null,
        "body": "extending iou loss options\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 42,
        "deletions": 8,
        "changed_files": 2,
        "created_at": "2020-08-07T18:30:57Z",
        "closed_at": "2020-08-07T22:41:21Z",
        "merged_at": "2020-08-07T22:41:21Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * attention_initializer argument is added to Transformer, TransformerDecoderLayer. This way, via attention_initializer, we can specify kernel_initializer for attention layers.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] TensorFlow 2 migration\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * All test cases in transformer_test.py can be passed.\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2020-08-07T14:49:31Z",
        "closed_at": "2020-08-17T19:20:52Z",
        "merged_at": "2020-08-17T19:20:52Z",
        "body": "# Description\r\n\r\nThe key `input_meta_data['num_labels']` doesn't always exist, it is defaulted to 1 when the Bert model is a regression model. In both modes `train_and_eval` and `export`, the \"default to 1\" setting is considered but not in `predict` mode.\r\n\r\nAnother issue this PR tries to solve is the unnecessary softmax applied to logit for regression model.\r\n\r\n## Type of change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\n\r\nCreate a customized `DataProcessor` class with attribute `is_regression = True`, the output meta data will look something like follows where key `num_labels` is absent.\r\n\r\n```\r\n{\r\n    \"processor_type\": \"RegressionDataProcessor\",\r\n    \"train_data_size\": 19765218,\r\n    \"max_seq_length\": 128,\r\n    \"task_type\": \"bert_regression\",\r\n    \"label_type\": \"int\",\r\n    \"eval_data_size\": 1260452\r\n}\r\n```\r\n\r\nThis lets the finetuning process to create a regression Bert model. Finetuning finished without issue, prediction ran fine too after the proposed change, otherwise prediction will raise exception as follows.\r\n\r\n```\r\nKeyError: 'num_labels'\r\n```\r\n\r\n**Test Configuration**:\r\n\r\nWith `tf_models_nightly-2.2.0.dev20200720`\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-08-07T11:42:55Z",
        "closed_at": "2020-08-08T05:42:05Z",
        "merged_at": "2020-08-08T05:42:05Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  add a note about creating fine-tuning data with SQUAD 2.0 in bert README\r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-08-06T10:49:32Z",
        "closed_at": "2022-04-16T15:45:40Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nChanged link address to point to correct notebook location, previous link resulted in page not found error\r\n\r\n## Type of change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n\r\n## Tests\r\n\r\nAccessed object_detection_tutorial.ipynb through new link\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 172,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-08-05T19:34:12Z",
        "closed_at": "2020-08-11T15:23:53Z",
        "merged_at": "2020-08-11T15:23:53Z",
        "body": "# Description\r\n\r\n> :memo: add config file for faster rcnn resnet 50 fpn on dataset coco17 using tpu-8\r\n\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [x] Other (New config file)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2020-08-05T14:12:35Z",
        "closed_at": "2021-09-29T19:42:54Z",
        "merged_at": null,
        "body": "\r\n\r\n# Description\r\nsets `clip_boxes=False`, as it makes `tf.image.combined_non_max_suppression` coordinate agnostic after https://github.com/tensorflow/tensorflow/commit/35e39cd3f102d663d198074e95ff77197d2e0a1d\r\n\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [x] Other\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 311,
        "deletions": 2,
        "changed_files": 6,
        "created_at": "2020-08-04T20:09:34Z",
        "closed_at": "2020-08-06T21:05:25Z",
        "merged_at": "2020-08-06T21:05:25Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 40,
        "deletions": 6,
        "changed_files": 2,
        "created_at": "2020-08-03T23:25:26Z",
        "closed_at": "2020-08-04T03:10:51Z",
        "merged_at": "2020-08-04T03:10:51Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Add intermediate_dropout argument in Transformer, TransformerDecoderLayer to enable intermediate_dropout_layer\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] TensorFlow 2 migration\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 143,
        "deletions": 13,
        "changed_files": 3,
        "created_at": "2020-08-03T20:41:55Z",
        "closed_at": "2020-08-11T19:03:17Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 757,
        "deletions": 3776,
        "changed_files": 70,
        "created_at": "2020-08-03T01:10:50Z",
        "closed_at": "2020-08-05T00:03:45Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 28,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2020-07-31T21:37:03Z",
        "closed_at": "2020-08-02T06:54:10Z",
        "merged_at": "2020-08-02T06:54:10Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * `use_scale` argument in added in __int__ to enable scaling of output embeddings.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] TensorFlow 2 migration\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-07-31T19:00:33Z",
        "closed_at": "2020-08-01T06:24:09Z",
        "merged_at": "2020-08-01T06:24:09Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 8,
        "changed_files": 2,
        "created_at": "2020-07-31T14:34:48Z",
        "closed_at": "2020-07-31T18:20:05Z",
        "merged_at": "2020-07-31T18:20:05Z",
        "body": "# Description\r\nFixed doc strings and typos\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-07-30T22:40:54Z",
        "closed_at": "2020-08-14T20:34:10Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nThe comment says \"select the last self.beam_size\", but `[:-self.beam_size]` actually means the opposite, i.e., removing the last self.beam_size.\r\n\r\n## Type of change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\n\r\nBefore the bugfix, the output was not a sentence:\r\n\r\n```\r\nCaptions for image COCO_val2014_000000224477.jpg:\r\n  0)  (p=0.000001)\r\n  1) surfer (p=0.000000)\r\n  2) two (p=0.000000)\r\n```\r\n\r\nAfter the bugfix, the output looks good:\r\n\r\n```\r\nCaptions for image COCO_val2014_000000224477.jpg:\r\n  0) a man riding a wave on top of a surfboard . (p=0.035869)\r\n  1) a person riding a surf board on a wave (p=0.018637)\r\n  2) a man riding a wave on a surfboard in the ocean . (p=0.004625)\r\n```\r\n\r\n**Test Configuration**:\r\n\r\n* Python 3.6\r\n* TensorFlow 1.0\r\n* Pretrained model from [KranthiGV/Pretrained-Show-and-Tell-model](https://github.com/KranthiGV/Pretrained-Show-and-Tell-model)\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2020-07-30T07:42:28Z",
        "closed_at": "2020-07-30T21:01:26Z",
        "merged_at": "2020-07-30T21:01:26Z",
        "body": "PiperOrigin-RevId: 323948101\r\n\r\n# Description\r\nCherry pick for Master branch to fix NCF performance regression on GPUs and TPU donuts.\r\n\r\n## Type of change\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\nRun on a TPU pod.\r\n\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-07-29T21:49:52Z",
        "closed_at": "2020-08-02T21:50:39Z",
        "merged_at": "2020-08-02T21:50:39Z",
        "body": "There's an extraneous `colab_tutorials/` in there.\r\n\r\n# Description\r\n\r\nJust a simple typo fix.\r\n\r\n## Type of change\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [X] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\nN/A\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [X] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [X] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [X] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [X] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [X] I have commented my code, particularly in hard-to-understand areas.\r\n- [X] I have made corresponding changes to the documentation.\r\n- [X] My changes generate no new warnings.\r\n- [X] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 195,
        "deletions": 16,
        "changed_files": 3,
        "created_at": "2020-07-29T21:01:02Z",
        "closed_at": "2020-07-30T23:04:43Z",
        "merged_at": "2020-07-30T23:04:43Z",
        "body": "# Description\r\n\r\n> :memo: Changes in transformer and attention layer\r\n>  \r\n> * This change is to  to help with performance of Seq2SeqTransformer model.\r\n> * Arguments in layer class `__init__` are added to meet different needs of using layers.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] TensorFlow 2 migration\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * This change passes layers/transformer_test.py\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-07-28T14:19:02Z",
        "closed_at": "2020-08-02T20:43:29Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: fix links for research/object_detection/colab_tutorials/object_detection_tutorial.ipynb  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-07-28T13:46:07Z",
        "closed_at": "2020-08-08T22:42:02Z",
        "merged_at": "2020-08-08T22:42:02Z",
        "body": "# Description\r\n\r\n> :memo: Update documentation for research/object_detection/g3doc/tf1_detection_zoo.md\r\n>  \r\n> * frozen inference graphs are generated using the [v1.12.0](https://github.com/tensorflow/tensorflow/tree/v1.12.0) release\r\n    version of TensorFlow\r\n> * remove \u201cwe do not guarantee that these will work with other versions\u201d\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2020-07-27T21:13:13Z",
        "closed_at": "2020-07-27T23:07:30Z",
        "merged_at": "2020-07-27T23:07:30Z",
        "body": "PiperOrigin-RevId: 322844988\r\n\r\n# Description\r\n\r\nThis is [a cherry pick](https://github.com/tensorflow/models/commit/a829e6480d88bc19ac6f25fe6cbc3da702eb1bfa) from a master branch.\r\n\r\nChanged eval_input_dataset not to use experimental_distribute_dataset as it was failing on TPU pods\r\n\r\n## Type of change\r\n\r\n\r\n-  Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\n\r\nAdded to our tests for TPU and GPUs.\r\n\r\n\r\n## Checklist\r\n\r\nA [cherry pick](https://github.com/tensorflow/models/commit/a829e6480d88bc19ac6f25fe6cbc3da702eb1bfa) from master branch.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 403,
        "deletions": 151,
        "changed_files": 11,
        "created_at": "2020-07-27T15:35:16Z",
        "closed_at": "2020-07-28T04:22:22Z",
        "merged_at": "2020-07-28T04:22:22Z",
        "body": "- Add Mobilenet v3 Edge TPU implementation\r\n- Fix a few bugs",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-07-27T00:43:59Z",
        "closed_at": "2023-05-14T15:38:05Z",
        "merged_at": null,
        "body": "Fixed several minor typos.\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 316,
        "deletions": 2,
        "changed_files": 4,
        "created_at": "2020-07-24T20:46:36Z",
        "closed_at": "2020-09-15T16:26:49Z",
        "merged_at": "2020-09-15T16:26:49Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2020-07-24T15:42:53Z",
        "closed_at": "2020-07-28T04:26:40Z",
        "merged_at": "2020-07-28T04:26:40Z",
        "body": "> :memo: Fixed typos in anchor.py\r\n\r\n## Type of change\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-07-24T00:38:04Z",
        "closed_at": "2020-07-25T18:14:24Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: remove unused import within image_resizer.proto\r\n> fix warning: object_detection/protos/input_reader.proto:5:1: warning: Import object_detection/protos/image_resizer.proto is unused.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 167,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2020-07-23T00:22:44Z",
        "closed_at": "2020-08-03T16:54:33Z",
        "merged_at": "2020-08-03T16:54:33Z",
        "body": "# Hungarian Matcher in TF 2, for Detection Transformer\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  Used a very similar set of tests to the other matchers.\r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 231878,
        "changed_files": 877,
        "created_at": "2020-07-22T00:12:54Z",
        "closed_at": "2020-07-31T04:14:22Z",
        "merged_at": "2020-07-31T04:14:22Z",
        "body": "# Description\r\nDeprecate old research models as we announced several months ago.\r\n\r\nPeople can still access archived models in the archive branch.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [x] Other (Specify)\r\n\r\n## Tests\r\nN/A\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 51,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2020-07-19T23:34:12Z",
        "closed_at": "2020-07-20T22:08:41Z",
        "merged_at": "2020-07-20T22:08:41Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-07-18T00:45:47Z",
        "closed_at": "2020-07-18T03:55:22Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 247,
        "deletions": 71,
        "changed_files": 7,
        "created_at": "2020-07-17T05:38:16Z",
        "closed_at": "2020-08-07T04:22:14Z",
        "merged_at": "2020-08-07T04:22:14Z",
        "body": "# Description\r\n\r\n> :memo: Adjust frcnn meta arch to multilevel rpn feature.\r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 68,
        "deletions": 48,
        "changed_files": 3,
        "created_at": "2020-07-17T04:59:07Z",
        "closed_at": "2020-08-02T20:35:05Z",
        "merged_at": "2020-08-02T20:35:05Z",
        "body": "# Description\r\n\r\n> :memo: moving fpn message to fpn.proto\r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [x] Other (Adjust proto file for faster rcnn fpn feature extractor)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 98,
        "deletions": 41,
        "changed_files": 3,
        "created_at": "2020-07-17T04:43:14Z",
        "closed_at": "2020-08-03T18:02:33Z",
        "merged_at": "2020-08-03T18:02:32Z",
        "body": "# Description\r\n\r\n> :memo: Return keras layers instead of keras models for fasterrcnn fpn keras feature extractor\r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [x] Other (Fix 'unknow graph' error)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 313,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-07-16T19:56:30Z",
        "closed_at": "2020-07-18T02:54:11Z",
        "merged_at": "2020-07-18T02:54:11Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 115,
        "created_at": "2020-07-16T19:29:13Z",
        "closed_at": "2020-08-14T20:53:45Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-07-16T10:51:06Z",
        "closed_at": "2020-07-26T15:10:22Z",
        "merged_at": "2020-07-26T15:10:22Z",
        "body": "Add notebook link to readme",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2020-07-15T05:47:15Z",
        "closed_at": "2020-07-16T16:29:05Z",
        "merged_at": "2020-07-16T16:29:05Z",
        "body": "# Description\r\n\r\nRefactoring, follow-up for https://github.com/tensorflow/models/pull/8866\r\n\r\n## Type of change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\n\r\n```\r\npython deeplab/train.py \\\r\n    --logtostderr \\\r\n    --training_number_of_steps=100 \\\r\n    --train_split=\"train_fine\" \\\r\n    --model_variant=\"xception_65\" \\\r\n    --fine_tune_batch_norm=False \\\r\n    --atrous_rates=6 \\\r\n    --atrous_rates=12 \\\r\n    --atrous_rates=18 \\\r\n    --output_stride=16 \\\r\n    --decoder_output_stride=4 \\\r\n    --train_crop_size=\"769,769\" \\\r\n    --train_batch_size=1 \\\r\n    --dataset=\"cityscapes\" \\\r\n    --tf_initial_checkpoint=${PATH_TO_INITIAL_CHECKPOINT} \\\r\n    --train_logdir=${PATH_TO_TRAIN_DIR} \\\r\n    --dataset_dir=${PATH_TO_DATASET}\r\n```\r\n\r\n```\r\npython deeplab/eval.py \\\r\n    --logtostderr \\\r\n    --eval_split=\"val_fine\" \\\r\n    --model_variant=\"xception_65\" \\\r\n    --atrous_rates=6 \\\r\n    --atrous_rates=12 \\\r\n    --atrous_rates=18 \\\r\n    --output_stride=16 \\\r\n    --decoder_output_stride=4 \\\r\n    --eval_crop_size=\"1025,2049\" \\\r\n    --dataset=\"cityscapes\" \\\r\n    --max_number_of_evaluations=1 \\\r\n    --checkpoint_dir=${PATH_TO_CHECKPOINT} \\\r\n    --eval_logdir=${PATH_TO_EVAL_DIR} \\\r\n    --dataset_dir=${PATH_TO_DATASET}\r\n```\r\n\r\n```\r\npython deeplab/vis.py \\\r\n    --logtostderr \\\r\n    --vis_split=\"val_fine\" \\\r\n    --model_variant=\"xception_65\" \\\r\n    --atrous_rates=6 \\\r\n    --atrous_rates=12 \\\r\n    --atrous_rates=18 \\\r\n    --output_stride=16 \\\r\n    --decoder_output_stride=4 \\\r\n    --vis_crop_size=\"1025,2049\" \\\r\n    --dataset=\"cityscapes\" \\\r\n    --max_number_of_iterations=1 \\\r\n    --colormap_type=\"cityscapes\" \\\r\n    --checkpoint_dir=${PATH_TO_CHECKPOINT} \\\r\n    --vis_logdir=${PATH_TO_VIS_DIR} \\\r\n    --dataset_dir=${PATH_TO_DATASET}\r\n```\r\n\r\n- Ubuntu 18.04.4\r\n- CUDA 10.2\r\n- Tensorflow 1.15.2\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-07-14T22:01:04Z",
        "closed_at": "2020-07-15T23:09:24Z",
        "merged_at": "2020-07-15T23:09:24Z",
        "body": "# Description\r\n\r\nAdds links to the community README for three TF2-compatible object detection models from the Model Zoo for Intel\u00ae Architecture.\r\n\r\n## Type of change\r\n\r\n- [x] Documentation update\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 293,
        "deletions": 223,
        "changed_files": 20,
        "created_at": "2020-07-12T05:05:56Z",
        "closed_at": "2020-07-21T15:33:29Z",
        "merged_at": "2020-07-21T15:33:29Z",
        "body": "# Description\r\n\r\nThis PR aims to migrate the TensorFlow code from 1.x to 2.x for the AttentionOCR model in the `research` folder.\r\n\r\nThe changes will partly address #8703 but there is more work to do.\r\n\r\nFurther work will include\r\n* Consolidating documentation\r\n* Providing tutorials\r\n\r\n## Type of change\r\n\r\n- [x] Documentation update\r\n- [x] TensorFlow 2 migration\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-07-12T00:26:55Z",
        "closed_at": "2020-08-02T20:46:13Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 7129,
        "deletions": 235849,
        "changed_files": 1071,
        "created_at": "2020-07-11T15:14:28Z",
        "closed_at": "2020-08-03T17:52:28Z",
        "merged_at": null,
        "body": "Check https://colab.research.google.com/drive/1b7iIzHw6m9lCcNqR1EMjp_rbu0icIZ-K?usp=sharing for more information.This is the content for this PR.\r\n\r\n# Description\r\n\r\nOn running the given notebook tutorial for object tutorial on Colab I found bugs on two places .\r\nOne at the the masking_model plotting , other at the model was not assigned a serving_default signature for the same.\r\nFor better understanding of where the issue was, please run the original NB on colab. \r\nAlso solves #8839 \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 10
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-07-10T16:25:23Z",
        "closed_at": "2020-07-10T18:01:42Z",
        "merged_at": "2020-07-10T18:01:42Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 4839,
        "deletions": 0,
        "changed_files": 32,
        "created_at": "2020-07-10T16:24:10Z",
        "closed_at": "2020-07-11T01:01:48Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nWe provide the full model building codes for [MobileNetV1], [MobileNetV2] and [MobilenetV3] \r\nnetworks using [TensorFlow 2 with the Keras API](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/keras).\r\n\r\nIn particular, this module consists of\r\n- Architectural definition of various MobileNet versions in \r\n[configs/archs.py].\r\n- Complete model building codes for\r\n    - MobilenetV1 in [mobilenet_v1.py]\r\n    - MobilenetV2 in [mobilenet_v2.py]\r\n    - MobilenetV3 in [mobilenet_v3.py]\r\n- Utilities helping load the pre-trained \r\n[TF1.X checkpoints](../slim/nets/mobilenet) into TensorFlow 2 Keras defined versions.\r\n    - MobilenetV1 TF1 checkpoint loader in [tf1_loader/v1_loader.py]\r\n    - MobilenetV2 TF1 checkpoint loader in [tf1_loader/v2_loader.py]\r\n    - MobilenetV3 TF1 checkpoint loader in [tf1_loader/v3_loader.py]\r\n- A sample training pipeline for image classification problem defined in\r\n[mobilenet_trainer.py], which also includes\r\n    - pre-configured datasets: [ImageNet] and [Imagenette], \r\n    in [dataset.py]\r\n    - dataset loading and preprocessing pipeline defined \r\n    in [dataset_loader.py]\r\n- A set of bash scripts in folder [scripts/]to help launch training\r\njobs for various MobileNet versions.\r\n\r\n## Type of change\r\n\r\n- [x] TensorFlow 2 migration\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 82,
        "deletions": 89,
        "changed_files": 1,
        "created_at": "2020-07-10T08:49:27Z",
        "closed_at": "2020-07-10T18:55:12Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 644,
        "deletions": 82,
        "changed_files": 2,
        "created_at": "2020-07-10T07:20:27Z",
        "closed_at": "2020-07-10T09:17:16Z",
        "merged_at": "2020-07-10T09:17:16Z",
        "body": "# Description\r\nInteractive Ducks Colab\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 49,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2020-07-10T00:12:34Z",
        "closed_at": "2020-07-10T01:58:36Z",
        "merged_at": "2020-07-10T01:58:35Z",
        "body": "# Description\r\nInference colab with keypoints\r\n> :memo: Please include a summary of the change. \r\n>  Adding keypoint support to inference colab\r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 331,
        "deletions": 161,
        "changed_files": 13,
        "created_at": "2020-07-08T17:26:14Z",
        "closed_at": "2020-07-08T21:12:41Z",
        "merged_at": "2020-07-08T21:12:41Z",
        "body": "- Change some of the file names to simplify\r\n- Modify readme to align with template",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 605,
        "deletions": 0,
        "changed_files": 55,
        "created_at": "2020-07-07T17:56:34Z",
        "closed_at": "2020-07-08T19:55:20Z",
        "merged_at": "2020-07-08T19:55:20Z",
        "body": "# Description\r\nRetinanet colab tutorial with rubber ducks test data created by @jch1, modified to work externally\r\n> :memo: Please include a summary of the change. \r\n>  Adding the colab, test images, and config\r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  The colab notebook runs end-to-end.\r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**: Colab CPU & GPU environments\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 26,
        "changed_files": 1,
        "created_at": "2020-07-07T13:45:57Z",
        "closed_at": "2020-07-11T02:14:49Z",
        "merged_at": null,
        "body": "Hi! I would like to ask, does Keras Neural Networks do predictions in real time?\r\nI see, that one of your parameters in prediction is array of data. But when you need to predict future data, you don't have an array of data - you have only previous data and time interval for prediction and nothing more.\r\nAs I undestand, you simply checked the prediction because to predict future data I need to give to a function predict a time interval in future, not a previous data trainX as necessary in this function predict\r\n\r\nHere is my Neuro Network:\r\n**look_back = 3\r\nmodel = Sequential()\r\nmodel.add(LSTM(4, input_shape=(look_back, 1)))\r\nmodel.add(Dense(1))\r\nmodel.compile(loss='mean_squared_error', optimizer='adam')\r\nmodel.fit(trainX, trainY, epochs=20, batch_size=1, verbose=2)\r\ntrainPredict = model.predict(trainX)**\r\n\r\nCan you show an example of predicting in real time?",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2020-07-06T17:37:46Z",
        "closed_at": "2020-07-06T21:59:47Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nSmall documentation update to mention DELG acceptance into ECCV'20.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [X] Documentation update\r\n\r\n## Tests\r\n\r\nN/A\r\n\r\n## Checklist\r\n\r\n- [X] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [X] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [X] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [X] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [X] I have commented my code, particularly in hard-to-understand areas.\r\n- [X] I have made corresponding changes to the documentation.\r\n- [X] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 55,
        "deletions": 28,
        "changed_files": 1,
        "created_at": "2020-07-06T02:15:26Z",
        "closed_at": "2021-03-14T20:01:06Z",
        "merged_at": null,
        "body": "update to tf.version >= 2.0 of tf.name_scope and tf.image.draw_bounding_boxes\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-07-04T09:29:30Z",
        "closed_at": "2023-02-10T21:10:11Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nThe original order of preprocessing in `preprocess_for_train` consists of doing mean_subtraction and standardisation first and then applying augmentation. \r\n\r\nThis order might result in issue. Mean subtraction and standardisation make some value in the image tensor negative. Then the image tensor will be first clipped to 0 to 255 inside `augmenter.distort` method, and then converted to `tf.uint8` dtype. This might result in loss of image content. For example, imagine mean subtraction and standardisation make all pixel values have the range of -5.0 to 5.0 and `augmenter.distort` convert those values to `tf.uint8` dtype. The content of image is completely changed even before any augmentation (such as affine transform, brightness, etc) is applied.\r\n\r\nTherefore mean subtraction and standardisation should be done after augmentation, as changed in this PR.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 244,
        "deletions": 33,
        "changed_files": 10,
        "created_at": "2020-07-04T00:59:36Z",
        "closed_at": "2020-07-04T02:18:01Z",
        "merged_at": "2020-07-04T02:18:01Z",
        "body": "319539052  by rathodv:\r\n\r\n    Internal Change.\r\n\r\n--\r\n319537186  by rathodv:\r\n\r\n    Internal Change\r\n\r\n--\r\n319320800  by jonathanhuang:\r\n\r\n    Internal changes.\r\n\r\n--\r\n319260368  by ronnyvotel:\r\n\r\n    Adding a target assigner for DensePose.\r\n\r\n--\r\n319240476  by sbeery:\r\n\r\n    switching to main() for argparse\r\n\r\n--\r\n\r\nPiperOrigin-RevId: 319539052\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 590,
        "deletions": 9,
        "changed_files": 4,
        "created_at": "2020-07-01T19:14:00Z",
        "closed_at": "2020-08-27T18:28:28Z",
        "merged_at": "2020-08-27T18:28:27Z",
        "body": "# Description\r\n\r\n> :memo: Added bash + python scripts to generate TF records from AVA actions data. \r\n>  \r\n> * There was no unified tool for doing this for AVA beforehand.  \r\n> * Works in TF 1.15  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n## Tests\r\n\r\n> :memo: Running the script, and doing visual sanity checks on a metadata example, will need to conduct more extensive testing though. Holding off on testing right now at instruction of @tombstone \r\n>  \r\n> * Run the bash script, then the python script.\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 91,
        "deletions": 120,
        "changed_files": 4,
        "created_at": "2020-07-01T17:07:06Z",
        "closed_at": "2020-07-01T23:00:51Z",
        "merged_at": "2020-07-01T23:00:51Z",
        "body": "# Description\r\n\r\n* Centralizing installation instructions\r\n* Requesting TF2.2+\r\n* Refactoring verbose \"Code overview\" README section\r\n* Acknowledging recent contributors\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [X] Documentation update\r\n- [X] TensorFlow 2 migration\r\n\r\n## Tests\r\n\r\nNone, only minor/documentation changes.\r\n\r\n## Checklist\r\n\r\n- [X] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [X] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [X] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [X] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [X] I have commented my code, particularly in hard-to-understand areas.\r\n- [X] I have made corresponding changes to the documentation.\r\n- [X] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-07-01T16:44:25Z",
        "closed_at": "2020-07-07T19:46:11Z",
        "merged_at": "2020-07-07T19:46:11Z",
        "body": "# Description\r\n\r\nSimple typo correction.\r\n -  supportted --> supported\r\n\r\n## Type of change\r\n\r\n- Other (Typo in code)\r\n\r\n## Tests\r\n\r\nNo testing required\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [y] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [y] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [y] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [y] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [n/a] I have commented my code, particularly in hard-to-understand areas.\r\n- [n/a] I have made corresponding changes to the documentation.\r\n- [n/a] My changes generate no new warnings.\r\n- [n/a] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 210,
        "deletions": 64,
        "changed_files": 12,
        "created_at": "2020-07-01T15:31:24Z",
        "closed_at": "2020-08-26T06:15:56Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Adjust faster rcnn meta arch rpn feature to multilevel feature.\r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [x] Other (Change meta arch file.)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-07-01T07:16:43Z",
        "closed_at": "2020-07-01T18:58:17Z",
        "merged_at": "2020-07-01T18:58:17Z",
        "body": "# Description\r\n\r\n> :memo: Remove extraneous spaces in FasterRCNN Resnet fpn Keras feature extractor\r\n\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [x] Other (Format)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 283,
        "deletions": 214,
        "changed_files": 3,
        "created_at": "2020-07-01T00:26:26Z",
        "closed_at": "2020-07-01T04:05:33Z",
        "merged_at": "2020-07-01T04:05:33Z",
        "body": "# Description\r\n\r\n* TF2 version for global feature model exporting\r\n* Small edits to the training README (small reformatting and fixes)\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [X] Documentation update\r\n- [X] TensorFlow 2 migration\r\n\r\n## Tests\r\n\r\nRe-exported global feature model and made sure it works.\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [X] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [X] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [X] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [X] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [X] I have commented my code, particularly in hard-to-understand areas.\r\n- [X] I have made corresponding changes to the documentation.\r\n- [X] My changes generate no new warnings.\r\n- [X] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 843,
        "deletions": 160,
        "changed_files": 11,
        "created_at": "2020-06-30T21:01:46Z",
        "closed_at": "2020-07-06T19:39:42Z",
        "merged_at": "2020-07-06T19:39:42Z",
        "body": "# Description\r\n\r\nAdd code to export model into SavedModel format. This code has the same functionality as PR #5378, but add endpoints for sequence confidence and predicted text. The code also incorporate several changes to allow running inference with batches of dynamic sizes.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n## Tests\r\n\r\nAdded model_export_test.py. Ran all test to verify that nothing is broken.\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-06-30T18:23:00Z",
        "closed_at": "2020-06-30T20:43:23Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nFix broken link in README.md for attention_ocr model.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Documentation update\r\n\r\n## Tests\r\n\r\nN/A\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1374,
        "deletions": 351,
        "changed_files": 15,
        "created_at": "2020-06-30T17:47:02Z",
        "closed_at": "2020-06-30T19:19:35Z",
        "merged_at": "2020-06-30T19:19:35Z",
        "body": "319052168  by rathodv:\r\n\r\n    Change assertAllEqual to assertAllClose for Position Sensitive Crop and Resize to avoid flaky tests.\r\n\r\n--\r\n319044492  by rathodv:\r\n\r\n    Internal change.\r\n\r\n--\r\n319039033  by ronnyvotel:\r\n\r\n    Preprocessor ops for DensePose.\r\n\r\n--\r\n319035440  by sbeery:\r\n\r\n    External beam code with DataFlow Support\r\n\r\n--\r\n318899436  by ronnyvotel:\r\n\r\n    DensePose library for common operations like scaling, coordinate transformations, and flipping.\r\n\r\n--\r\n318833308  by Vivek Rathod:\r\n\r\n      Internal Change\r\n\r\n--\r\n\r\nPiperOrigin-RevId: 319052168\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 506,
        "deletions": 130,
        "changed_files": 12,
        "created_at": "2020-06-30T11:12:56Z",
        "closed_at": "2020-06-30T15:18:43Z",
        "merged_at": "2020-06-30T15:18:43Z",
        "body": "# Description\r\n- Export model migration to TF2.\r\n- Removed unnecessary cast from feature_aggregation_extraction.py\r\n- Fixed clustering script\r\n- Loaded pretrained ImageNet weights to initialize the ResNet backbone. Changed the defaults of the batch size and initial learning rate to increase convergence on the GLDv2 dataset. Made the evaluation batch size dynamic depending on the global batch size.\r\n- Additional shuffling when generating the TRAIN and VALIDATION datasets to increase variance of labels across batches. Possibility to load pretrained weights for the ResNet backbone.\r\n\r\n## Type of change\r\n\r\n- [x] TensorFlow 2 migration\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1093,
        "deletions": 0,
        "changed_files": 12,
        "created_at": "2020-06-29T19:04:40Z",
        "closed_at": "2020-08-14T20:56:12Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Implement Hierarchical Disentanglement for Fine-Grained Object Generation - FineGAN. \r\n>  \r\n> * State-of-the-art for CUB 200, CUB 128x128, Stanford Cars and Stanford Dogs datasets.  \r\n> * Hierarchical Deep Generative Model (Several moving parts trained end-to-end).  \r\n> * Reproduce the paper results and benchmark it on the 3 datasets.  \r\n> * Publish documentation and prepare Colab demo.  \r\n> * Publish pre-trained SavedModel files at TensorFlow Hub.  \r\n> * Completed implementation and merge solves #8705\r\n\r\n## Type of change\r\n- [x] A new research paper code implementation  \r\n  \r\n  \r\n## Key Features\r\n  \r\n- [x] TensorFlow 2.2.0\r\n- [ ] Inference example (Colab Demo)\r\n- [ ] Transfer learning example (Inception-ResNet Backbone)\r\n- [x] Eager mode training with `tf.GradientTape` [If Required]\r\n- [ ] [Default] Graph mode training with `model.train_on_batch`\r\n- [x] Functional model with `tf.keras.layers.Layer`\r\n- [x] Subclassing model with `tf.keras.Model`\r\n- [x] Input pipeline using `tf.data` and `tfds`\r\n- [ ] Tensorflow Serving\r\n- [x] Vectorized transformations\r\n- [x] GPU accelerated\r\n- [ ] Fully integrated with `absl-py` from [abseil.io](https://abseil.io)\r\n- [x] Clean implementation\r\n- [x] Following the best practices\r\n- [x] Apache 2.0 License\r\n  \r\n## Tests\r\n\r\n> :memo: [WIP] Code Reviews and Tests Pending.\r\n>  \r\n> * [WIP] Provide instructions so we can reproduce.  \r\n> * [WIP] Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n> * Config `.yml` files and Config class included.\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 370,
        "deletions": 15,
        "changed_files": 6,
        "created_at": "2020-06-29T18:43:25Z",
        "closed_at": "2020-07-23T16:31:15Z",
        "merged_at": "2020-07-23T16:31:14Z",
        "body": "# Description\r\nAdd support for Context R-CNN in TF 2.0. Still passes the TF 1.0 tests.\r\n\r\n> :memo: Change projection layers to keras custom layer rather than tf slim. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [x] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  The context_rcnn unit tests in meta_architectures.\r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1728,
        "deletions": 142,
        "changed_files": 22,
        "created_at": "2020-06-29T16:30:39Z",
        "closed_at": "2020-06-30T01:37:33Z",
        "merged_at": "2020-06-30T01:37:33Z",
        "body": "This is part of effort addressing issue #8537 but not complete.\r\n\r\n1. Add trainer to train mobilenet; \r\n2. Add loader to load tf1 checkpoints;\r\n3. Perform evaluation with loaded tf1 checkpoints;\r\n4. Fix various bugs;\r\n\r\nCurrent result is of evaluation on loaded tf1 checkpoints:\r\n\r\nCheckpoint | Evaluation Top1 Accuracy\r\n-- | --\r\nmobilenet_v1_1.0_224 | 0.710099995136261\r\nmobilenet_v2_1.0_224 | 0.7184000015258789\r\nmobilenet_v3_large_224_1.0_float | 0.7521799802780151",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 175,
        "deletions": 10,
        "changed_files": 7,
        "created_at": "2020-06-28T19:02:13Z",
        "closed_at": "2020-07-20T20:39:21Z",
        "merged_at": "2020-07-20T20:39:21Z",
        "body": "# Description\r\n\r\n> :memo: Add funtions to perform multilevel crop and resize. \r\n>  \r\n> * Add multilevel_native_crop_and_resize.\r\n> * Add multilevel_matmul_crop_and_resize\r\n> * Change faster rcnn meta arch function that use _crop_and_resize_fn\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [x] Other (Add functions support faster rcnn fpn feature extractor)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Simple unittest for both functions.\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 17,
        "deletions": 18,
        "changed_files": 3,
        "created_at": "2020-06-23T21:46:44Z",
        "closed_at": "2020-06-29T19:25:03Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\nWas able to train a model whereas previously unable, but the Unit Test needs to still be fixed.\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2604,
        "deletions": 12119,
        "changed_files": 123,
        "created_at": "2020-06-23T20:11:12Z",
        "closed_at": "2020-06-24T20:55:48Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2020-06-22T14:29:15Z",
        "closed_at": "2020-06-25T00:44:58Z",
        "merged_at": "2020-06-25T00:44:58Z",
        "body": "Fix a small spelling error\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 468,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2020-06-22T07:12:42Z",
        "closed_at": "2020-06-30T21:41:57Z",
        "merged_at": "2020-06-30T21:41:57Z",
        "body": "# Description\r\n\r\n> :memo: Add faster RCNN Resnet V1 FPN Keras feature extractor\r\n>  \r\n> * Add faster RCNN Resnet {50, 101, 152} FPN Keras feature extractor.\r\n> * Add unit test to ensure the size for proposal and box classifier features are correct.\r\n> * Add model to model_builder.py\r\n> * Need to further modify faster_rcnn_meta_arch.py to make the extractor work\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 54,
        "deletions": 78,
        "changed_files": 4,
        "created_at": "2020-06-18T11:17:50Z",
        "closed_at": "2020-08-14T19:43:38Z",
        "merged_at": "2020-08-14T19:43:38Z",
        "body": "2. compatible with tf1.14\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [x] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 10
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 15,
        "changed_files": 1,
        "created_at": "2020-06-18T05:00:11Z",
        "closed_at": "2020-06-18T19:20:33Z",
        "merged_at": "2020-06-18T19:20:33Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 49645,
        "deletions": 22266,
        "changed_files": 612,
        "created_at": "2020-06-18T00:23:12Z",
        "closed_at": "2020-07-19T23:01:02Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-06-17T18:03:33Z",
        "closed_at": "2020-08-14T22:17:43Z",
        "merged_at": "2020-08-14T22:17:43Z",
        "body": "Documentation update.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 19143,
        "deletions": 3290,
        "changed_files": 162,
        "created_at": "2020-06-17T05:48:31Z",
        "closed_at": "2020-06-17T07:59:18Z",
        "merged_at": "2020-06-17T07:59:18Z",
        "body": "Internal changes.\r\n\r\n--\r\n\r\nPiperOrigin-RevId: 316825723\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [x] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-06-17T04:56:26Z",
        "closed_at": "2020-06-18T04:55:11Z",
        "merged_at": "2020-06-18T04:55:11Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2020-06-15T04:23:11Z",
        "closed_at": "2020-06-17T15:39:55Z",
        "merged_at": "2020-06-17T15:39:55Z",
        "body": "# Description\r\n\r\nAdds the WikiTableQuestions link. The old dropbox link was outdated, also put in some details about the current version of the data against the one used by the original authors. **No further maintenance intended.**\r\n\r\n> Fixes #8531 \r\n\r\n## Type of change\r\n\r\n- [x] Documentation update\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 517,
        "deletions": 410,
        "changed_files": 10,
        "created_at": "2020-06-12T20:45:16Z",
        "closed_at": "2020-06-12T23:45:03Z",
        "merged_at": "2020-06-12T23:45:03Z",
        "body": "# Description\r\n\r\nPush to Github of changes to DELF package:\r\n- Performance optimization in generating the TRAIN and VALIDATION splits per label.\r\n- Tiny fix to char limit in extractor.py.\r\n- Script to measure DELG latency.\r\n- Pre-load PCA parameters, if using them when extracting DELF/G features.\r\n- Code migration from TF1 to TF2 for:\r\n    - loading the models using  in extractor.py and detector.py using tf.saved_model.load\r\n    - removed tf.compat.v1.Session for the extractor and detector model usage\r\n\r\n## Type of change\r\n\r\n- [x] Documentation update\r\n- [x] TensorFlow 2 migration\r\n\r\n## Tests\r\n\r\n## Checklist\r\n\r\n- [x ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ x] I have made corresponding changes to the documentation.\r\n- [ x] My changes generate no new warnings.\r\n- [ x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 119,
        "deletions": 20,
        "changed_files": 1,
        "created_at": "2020-06-11T07:27:01Z",
        "closed_at": "2020-06-12T05:21:24Z",
        "merged_at": "2020-06-12T05:21:24Z",
        "body": "# Description\r\n\r\nUpdated the DELF training documentation with the following steps:\r\n- Installation of the DELF library.\r\n- Download of the GLDv2 dataset.\r\n- Generation of the TFRecord files for training.\r\n\r\n## Type of change\r\n\r\n- [x ] Documentation update\r\n\r\n## Tests\r\n\r\nN/A\r\n\r\n## Checklist\r\n\r\n- [x ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ x] I have made corresponding changes to the documentation.\r\n- [ x] My changes generate no new warnings.\r\n- [ x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2020-06-11T06:00:49Z",
        "closed_at": "2020-06-12T02:43:28Z",
        "merged_at": "2020-06-12T02:43:28Z",
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  update a3c_cartpole.py to tf2.x\r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Documentation update\r\n- [x] TensorFlow 2 migration\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  python a3c_cartpole.py --train\r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 68,
        "deletions": 68,
        "changed_files": 1,
        "created_at": "2020-06-10T20:27:53Z",
        "closed_at": "2020-06-19T07:07:23Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2020-06-09T06:26:50Z",
        "closed_at": "2020-06-09T21:47:41Z",
        "merged_at": "2020-06-09T21:47:41Z",
        "body": "fixes #8647\r\n\r\n# Description\r\n\r\nUpdated a few links, not too sure about `quantize`. The link added has two implementations and corresponding use cases.  \r\n\r\n## Type of change\r\n\r\n- [x] Documentation update\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 582,
        "deletions": 28,
        "changed_files": 9,
        "created_at": "2020-06-08T21:35:47Z",
        "closed_at": "2020-06-23T18:41:03Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Added bash + python scripts to generate TF records from AVA actions data. \r\n>  \r\n> * There was no unified tool for doing this for AVA beforehand.  \r\n> * Works in TF 1.15  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n## Tests\r\n\r\n> :memo: Running the script, and doing visual sanity checks on a metadata example, will need to conduct more extensive testing though. Holding off on testing right now at instruction of @tombstone \r\n>  \r\n> * Run the bash script, then the python script.\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-06-07T07:41:54Z",
        "closed_at": "2021-06-20T01:15:56Z",
        "merged_at": null,
        "body": "The time has come to systematically ___find and eliminate Python syntax errors___ from tensorflow/models.  Output: https://github.com/cclauss/models/actions > 10 Python syntax errors.\r\n```\r\n./research/cognitive_planning/viz_active_vision_dataset_main.py:98:11: E999 SyntaxError: invalid syntax\r\n    print world\r\n          ^\r\n./research/cognitive_planning/train_supervised_active_vision.py:185:9: E999 SyntaxError: invalid syntax\r\n  print inputs\r\n        ^\r\n./research/cognitive_planning/envs/active_vision_dataset_env.py:940:13: E999 SyntaxError: invalid syntax\r\n      print 'path not found, image_id = ', self._cur_world, self._cur_image_id\r\n            ^\r\n./research/swivel/text2bin.py:53:3: F633 use of >> is invalid with print function\r\n  print >> sys.stderr, e\r\n  ^\r\n./research/swivel/text2bin.py:74:9: F633 use of >> is invalid with print function\r\n        print >> vocab_out, token\r\n        ^\r\n./research/swivel/prep.py:133:9: F633 use of >> is invalid with print function\r\n        print >> vocab_out, tok\r\n        ^\r\n./research/swivel/prep.py:134:9: F633 use of >> is invalid with print function\r\n        print >> sums_out, cnt\r\n        ^\r\n./research/learning_unsupervised_learning/variable_replace.py:94:11: E999 SyntaxError: invalid syntax\r\n    print \"Didn't use all replacements\"\r\n          ^\r\n./research/learning_unsupervised_learning/meta_objective/sklearn.py:116:20: E999 SyntaxError: invalid syntax\r\n      def blackbox((trX, trY, teX, teY)):\r\n                   ^\r\n./research/lexnet_nc/extract_paths.py:83:18: E999 SyntaxError: invalid syntax\r\n          lambda (head, mod): head)}\r\n                 ^\r\n6     E999 SyntaxError: invalid syntax\r\n4     F633 use of >> is invalid with print function\r\n10\r\n```\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Find syntax errors in Python code\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\nflake8 . --count --show-source --statistics  --select=E9,F63  # ,F7,F82\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\nflake8 . --count --show-source --statistics  --select=E9,F63  # ,F7,F82\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-06-07T07:28:49Z",
        "closed_at": "2021-08-03T21:44:40Z",
        "merged_at": null,
        "body": "`box_list_ops` is an _undefined name_ in this context which has the potential raise NameError at runtime.\r\n\r\n[flake8](http://flake8.pycqa.org) testing of https://github.com/tensorflow/models on Python 3.8.3\r\n\r\n$ __flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics__\r\n```\r\n./official/vision/detection/utils/object_detection/preprocessor.py:143:21: F821 undefined name 'box_list_ops'\r\n    new_keypoints = box_list_ops.scale(keypoints - [window[0], window[1]],\r\n                    ^\r\n```\r\nhttps://flake8.pycqa.org/en/latest/user/error-codes.html\r\n\r\nOn the flake8 test selection, this PR does _not_ focus on \"_style violations_\" (the majority of flake8 error codes that [__psf/black__](https://github.com/psf/black) can autocorrect).  Instead these tests are focus on runtime safety and correctness:\r\n* E9 tests are about Python syntax errors usually raised because flake8 can not build an Abstract Syntax Tree (AST).  Often these issues are a sign of unused code or code that has not been ported to Python 3.  These would be compile-time errors in a compiled language but in a dynamic language like Python they result in the script halting/crashing on the user.\r\n* F63 tests are usually about the confusion between identity and equality in Python.  Use ==/!= to compare str, bytes, and int literals is the classic case.  These are areas where __a == b__ is True but __a is b__ is False (or vice versa).  Python >= 3.8 will raise SyntaxWarnings on these instances.\r\n* F7 tests logic errors and syntax errors in type hints\r\n* F82 tests are almost always _undefined names_ which are usually a sign of a typo, missing imports, or code that has not been ported to Python 3.  These also would be compile-time errors in a compiled language but in Python a __NameError__ is raised which will halt/crash the script on the user.\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-06-05T19:24:07Z",
        "closed_at": "2020-06-12T19:46:19Z",
        "merged_at": "2020-06-12T19:46:18Z",
        "body": "Install slim to fix this notebook.\r\n\r\nhttps://colab.sandbox.google.com/github/MarkDaoust/models/blob/tf_slim-2/research/object_detection/object_detection_tutorial.ipynb",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2335,
        "deletions": 0,
        "changed_files": 16,
        "created_at": "2020-06-05T00:37:48Z",
        "closed_at": "2020-06-05T23:41:22Z",
        "merged_at": "2020-06-05T23:41:22Z",
        "body": "In this PR, the Mobilenet V1, V2 and V3 have been migrated to TF2. All the code is stored in research/mobilenet folder. The code has been reviewed by the SME @marksandler2 .\r\n\r\nThis is the first milestone of addressing issue #8573 but not complete. Further work includes\r\n- Replicate the training result\r\n- Consolidate documentations",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-06-04T17:30:35Z",
        "closed_at": "2020-06-04T19:09:21Z",
        "merged_at": "2020-06-04T19:09:21Z",
        "body": "# Description\r\n\r\nThis change adds to the community models README a table of CPU-optimized image recognition models from the Model Zoo for Intel\u00ae Architecture.\r\n\r\n## Type of change\r\n\r\n- [x] Documentation update\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 123,
        "deletions": 11,
        "changed_files": 3,
        "created_at": "2020-06-03T18:41:12Z",
        "closed_at": "2020-06-04T07:05:01Z",
        "merged_at": "2020-06-04T07:05:01Z",
        "body": "Reverts tensorflow/models#8619",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 123,
        "deletions": 11,
        "changed_files": 3,
        "created_at": "2020-06-03T13:33:23Z",
        "closed_at": "2020-06-03T17:32:25Z",
        "merged_at": "2020-06-03T17:32:25Z",
        "body": "# Description\r\n\r\n> :memo: I added the RelativePositionEmbedding class to layers/position_embedding.py. This class generates sine cosine relative positional embedding. Such embedding is defined and formulized in \"Attention is All You Need\", section 3.5.\r\n>  \r\n> * In this way, nlp/transformer can directly use RelativePositionEmbedding under KerasBERT library.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] TensorFlow 2 migration\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * I added two test functions in layers/position_embedding_test.py. Tests were successful.\r\n> * nlp/transformer_main_test.py was changed to call RelativePositionEmbedding(). This test file was run without errors.\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 314,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2020-06-03T08:00:33Z",
        "closed_at": "2020-06-04T17:17:46Z",
        "merged_at": "2020-06-04T17:17:46Z",
        "body": "# Description\r\n\r\n> :memo: Scripts to download GLDv2 data for DELF training and to install DELF package. \r\n\r\n## Type of change\r\n\r\n- [ x] Documentation update\r\n\r\n## Tests\r\n\r\n- Tested downloading 1 file per dataset from the GLDv2 dataset\r\n- Tested downloading 5 files in parallel per dataset from the GLDv2 dataset  \r\n- Tested downloading 10 files in parallel per dataset from the GLDv2 dataset \r\n- Tested individually each step of the DELF package installation and added error handling\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ x] I have made corresponding changes to the documentation.\r\n- [ x] My changes generate no new warnings.\r\n- [ x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 124,
        "deletions": 11,
        "changed_files": 4,
        "created_at": "2020-06-01T22:31:25Z",
        "closed_at": "2020-06-02T22:41:10Z",
        "merged_at": "2020-06-02T22:41:10Z",
        "body": "# Description\r\n\r\n> :memo: I added the RelativePositionEmbedding class to layers/position_embedding.py. This class generates sine cosine relative positional embedding. Such embedding is defined and formulized in \"Attention is All You Need\", section 3.5.\r\n>  \r\n> * In this way, nlp/transformer can directly use RelativePositionEmbedding under KerasBERT library.\r\n\r\n## Type of change\r\n\r\n- [x] TensorFlow 2 migration\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * I added two test functions in layers/position_embedding_test.py. Tests were successful.\r\n> * nlp/transformer_main_test.py was changed to call RelativePositionEmbedding(). This test file was run without errors.\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 215,
        "deletions": 26,
        "changed_files": 6,
        "created_at": "2020-06-01T16:55:56Z",
        "closed_at": "2020-09-02T22:34:48Z",
        "merged_at": "2020-09-02T22:34:48Z",
        "body": "# Description\r\n\r\nThis change adds an example test for clustering mobilenet_v1 in resnet_imagenet_main.py as well as flags changes in common.py. It can demonstrate how clustering APIs in tensorflow/model-optimization work on the last three conv2d layers of mobilenet_v1. \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n\r\n## Tests\r\nThe test is currently not dependent on any other benchmark code. To run it, we can set: \r\n\r\n**Test Configuration**:\r\nTensorflow == 2.1.0\r\nKeras-Applications == 1.0.8\r\nPython == 3.7.7\r\ncudatoolkit == 10.1.243\r\ncudnn == 7.6.5\r\n\r\n**Test Command line example**:\r\npython resnet_imagenet_main.py --data_dir=your_path_to_imagenet --model='mobilenet_pretrained' --train_epochs=1 --batch_size=64 --optimizer='mobilenet_fine_tune' --distribution_strategy='mirrored' --num_gpus=4 --save_files_to='./exp_folder' --clustering_method='selective_clustering'\r\n(make sure the --data_dir flag is set to the same one needed by the previous resnet test.)\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 16
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 12,
        "changed_files": 1,
        "created_at": "2020-05-31T11:01:30Z",
        "closed_at": "2020-06-18T17:50:40Z",
        "merged_at": null,
        "body": "# Description\r\nThe OD API is dependent on `tf_slim` which is not pre-installed on colab, as shown in #8598.\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 91,
        "deletions": 136,
        "changed_files": 11,
        "created_at": "2020-05-29T15:42:14Z",
        "closed_at": "2020-05-29T22:01:10Z",
        "merged_at": "2020-05-29T22:01:10Z",
        "body": "# Description\r\n\r\nCode migration from TF1 to TF2 for:\r\n- logging (replaced usage of tf.compat.v1.logging.info)\r\n- testing directories (replaced usage of tf.compat.v1.test.get_temp_dir())\r\n- feature/object extraction scripts (replaced usage of tf.compat.v1.train.string_input_producer and tf.compat.v1.train.start_queue_runners with PIL)  \r\n\r\n## Type of change\r\n\r\n- [x] TensorFlow 2 migration\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-05-24T06:32:37Z",
        "closed_at": "2020-06-06T00:22:06Z",
        "merged_at": "2020-06-06T00:22:06Z",
        "body": "# Description\r\n\r\nSee the change. The two tf.cast calls are repeated.\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 10483,
        "deletions": 5596,
        "changed_files": 407,
        "created_at": "2020-05-22T07:39:38Z",
        "closed_at": "2020-05-26T23:20:00Z",
        "merged_at": "2020-05-26T23:20:00Z",
        "body": "# Description\r\n\r\nUpdate models/slim to use tf_slim instead of contrib.slim, \r\n\r\nRelease MobileDet code and model in Object Detection API.\r\ntf_slim is now required to be installed for OD API.\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-05-21T20:26:50Z",
        "closed_at": "2020-05-21T22:03:38Z",
        "merged_at": "2020-05-21T22:03:38Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 18469,
        "deletions": 7082,
        "changed_files": 520,
        "created_at": "2020-05-21T19:39:21Z",
        "closed_at": "2020-10-12T19:39:59Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-05-20T11:59:27Z",
        "closed_at": "2020-05-20T17:02:17Z",
        "merged_at": "2020-05-20T17:02:17Z",
        "body": "The source code works only on Python v2.7 and is not compatible with Python v3.x versions.\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-05-20T07:53:15Z",
        "closed_at": "2020-05-25T06:50:03Z",
        "merged_at": "2020-05-25T06:50:03Z",
        "body": "# Description\r\nthere is a bug that assigns test data files to `train_files` variable. Also, currently, test data are downloaded only (unprocessed and unused), so there is no need for a variable to keep track of those files.\r\n\r\n## Type of change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-05-19T18:04:07Z",
        "closed_at": "2021-10-01T19:08:55Z",
        "merged_at": null,
        "body": "\r\n\r\n# Description\r\n\r\nTensorflow functions have changed after the release of tensorflow 2.0 \r\nSo installing the tensorflow 1.15 will be advised\r\nChange pip install tensorflow to pip install tensorflow==1.15.\r\nBegginers find it difficult to figure out the problem when it arises\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n\r\n\r\n## Tests\r\n\r\nTry to use contrib libraries\r\n\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2020-05-19T05:15:27Z",
        "closed_at": "2020-07-16T17:22:30Z",
        "merged_at": "2020-07-16T17:22:30Z",
        "body": "# Description\r\n\r\nUse 'bash' instead of 'sh' in `deeplab/local_test.sh`:\r\n\r\n- Make it consistent with '/bin/bash' shebang\r\n- Fix \"Bad substitution\" error in BASH_SOURCE[0]\r\n\r\n## Type of change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\n\r\n```\r\n[research/deeplab]> bash local_test.sh\r\n```\r\n\r\n**Test Configuration**:\r\n\r\n- Tensorflow 1.15.2\r\n- Ubuntu 18.04.4 LTS\r\n- CUDA 10.1\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] My changes generate no new warnings.\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-05-18T22:39:28Z",
        "closed_at": "2020-05-19T07:38:10Z",
        "merged_at": "2020-05-19T07:38:09Z",
        "body": "# Description\r\n\r\nThis PR fixes typos in vision/detection README.md\r\n\r\n\r\n## Type of change\r\n\r\n- [x] Documentation update\r\n\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 24,
        "deletions": 29,
        "changed_files": 6,
        "created_at": "2020-05-18T16:04:16Z",
        "closed_at": "2020-05-18T17:24:28Z",
        "merged_at": "2020-05-18T17:24:28Z",
        "body": "# Description\r\n\r\nDocumentation instructions update to become Python3 specific\r\n\r\n## Type of change\r\n\r\n- [x] Documentation update\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-05-18T10:59:51Z",
        "closed_at": "2020-05-19T05:03:42Z",
        "merged_at": null,
        "body": "# Description\r\n\r\n- Fix error `Missing value for flag -v`\r\n\r\n## Type of change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\n\r\n```\r\n[research/deeplab]> bash local_test.sh\r\n```\r\n\r\n**Test Configuration**:\r\n\r\n- Tensorflow 1.15.2\r\n- Ubuntu 18.04.4 LTS\r\n- CUDA 10.1\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] My changes generate no new warnings.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-05-16T16:03:48Z",
        "closed_at": "2020-05-18T18:46:45Z",
        "merged_at": "2020-05-18T18:46:45Z",
        "body": "# Description\r\nmodel_test.py doesn't support -v (--verbose) parameter. Removed -v param while calling this script.\r\nTo fix the following error:\r\nFile \"/usr/local/lib/python3.6/dist-packages/absl/flags/_flagvalues.py\", line 698, in get_value raise _exceptions.Error('Missing value for flag ' + arg) # pylint: disable=undefined-loop-variable absl.flags._exceptions.Error: Missing value for flag -\r\n## Type of change\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n## Tests\r\nFrom tensorflow/models/research/deeplab\r\nsh local_test.sh\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-05-14T23:59:19Z",
        "closed_at": "2020-05-15T16:46:01Z",
        "merged_at": "2020-05-15T16:46:01Z",
        "body": "# Description\r\n\r\nIn paragraph [Train and evaluate model](https://github.com/tensorflow/models/tree/master/official/recommendation#train-and-evaluate-model), there is a description about training/evaluation with GPU.\r\nHowever, there is no clue how to specify the number of GPUs used for training/evaluation the model.\r\n\r\nThis PR adds the description about the option 'num_gpus' in reference to [Transformer model](https://github.com/tensorflow/models/tree/master/official/nlp/transformer#using-multiple-gpus).\r\n\r\n## Type of change\r\n\r\n- [x] Documentation update\r\n\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-05-14T23:36:35Z",
        "closed_at": "2020-05-15T05:07:00Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nExample command in README raises error, which is also mentioned at #8388.\r\nI think an example command in README should not raise any errors because many users may execute this command as is.\r\nThis PR fixes the example command not to raise error.\r\n\r\n## Type of change\r\n\r\n- [x] Documentation update\r\n\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-05-14T22:32:31Z",
        "closed_at": "2020-05-15T21:23:57Z",
        "merged_at": "2020-05-15T21:23:57Z",
        "body": "# Description\r\n\r\nCurrent README.md in bert model does not include an instruction about using a checkpoint on local storage.\r\nI think this makes some users confused.\r\n\r\nThis PR adds a supplemental explanation when users use checkpoint located on local storage.\r\n\r\n\r\n## Type of change\r\n\r\n- [x] Documentation update\r\n\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 0,
        "changed_files": 0,
        "created_at": "2020-05-13T03:19:01Z",
        "closed_at": "2020-05-13T15:34:55Z",
        "merged_at": null,
        "body": "\u66f4\u65b0\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [ ] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [ ] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [ ] My changes generate no new warnings.\r\n- [ ] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1594,
        "deletions": 1230,
        "changed_files": 84,
        "created_at": "2020-05-12T18:27:44Z",
        "closed_at": "2020-05-27T00:01:05Z",
        "merged_at": null,
        "body": "# Description\r\nBringing in internal changes. Moves slim from contrib.slim to tf_slim, updates some internal implementation details in MobilenetV3. \r\n\r\n## Type of change\r\n\r\nUpgrading research.slim to eliminate most dependencies on contrib.slim - a few are still lingering particularly in some dusty corners of quantization and training. \r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Documentation update\r\n- [x] TensorFlow 2 migration\r\n- [x] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 125,
        "deletions": 88,
        "changed_files": 6,
        "created_at": "2020-05-12T06:45:22Z",
        "closed_at": "2020-05-12T15:48:46Z",
        "merged_at": "2020-05-12T15:48:46Z",
        "body": "# Description\r\n\r\n* Revise issue templates for readability improvement\r\n* Add prerequisites\r\n\r\n## Type of change\r\n\r\n- [x] Other (Specify): Template update\r\n\r\n## Tests\r\nN/A\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-05-11T17:32:23Z",
        "closed_at": "2020-05-13T01:39:06Z",
        "merged_at": "2020-05-13T01:39:06Z",
        "body": "# Description\r\n\r\n> :memo: The cifar dataset links are changed to download python version of files. Downloading binary files will throw an error with the current code\r\n```\r\ntensorflow.python.framework.errors_impl.NotFoundError: $DATA_DIR/cifar10/data_batch_1; No such file or directory\r\n```\r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Documentation update\r\n\r\n## Tests\r\nTested on python2.7 and tensorflow1.15\r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] My changes generate no new warnings.\r\n\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 15670,
        "deletions": 7109,
        "changed_files": 202,
        "created_at": "2020-05-09T04:46:58Z",
        "closed_at": "2020-05-12T18:41:08Z",
        "merged_at": "2020-05-12T18:41:08Z",
        "body": "310447280  by lzc:\r\n\r\n    Internal change\r\n\r\n310420845  by Zhichao Lu:\r\n\r\n    Open source the internal Context RCNN code.\r\n\r\n--\r\n310362339  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n310259448  by lzc:\r\n\r\n    Update required TF version for OD API.\r\n\r\n--\r\n310252159  by Zhichao Lu:\r\n\r\n    Port patch_ops_test to TF1/TF2 as TPUs.\r\n\r\n--\r\n310247180  by Zhichao Lu:\r\n\r\n    Ignore keypoint heatmap loss in the regions/bounding boxes with target keypoint\r\n    class but no valid keypoint annotations.\r\n\r\n--\r\n310178294  by Zhichao Lu:\r\n\r\n    Opensource MnasFPN\r\n    https://arxiv.org/abs/1912.01106\r\n\r\n--\r\n310094222  by lzc:\r\n\r\n    Internal changes.\r\n\r\n--\r\n310085250  by lzc:\r\n\r\n    Internal Change.\r\n\r\n--\r\n310016447  by huizhongc:\r\n\r\n    Remove unrecognized classes from labeled_classes.\r\n\r\n--\r\n310009470  by rathodv:\r\n\r\n    Mark batcher.py as TF1 only.\r\n\r\n--\r\n310001984  by rathodv:\r\n\r\n    Update core/preprocessor.py to be compatible with TF1/TF2..\r\n\r\n--\r\n309455035  by Zhichao Lu:\r\n\r\n    Makes the freezable_batch_norm_test run w/ v2 behavior.\r\n\r\n    The main change is in v2 updates will happen right away when running batchnorm in training mode. So, we need to restore the weights between batchnorm calls to make sure the numerical checks all start from the same place.\r\n\r\n--\r\n309425881  by Zhichao Lu:\r\n\r\n    Make TF1/TF2 optimizer builder tests explicit.\r\n\r\n--\r\n309408646  by Zhichao Lu:\r\n\r\n    Make dataset builder tests TF1 and TF2 compatible.\r\n\r\n--\r\n309246305  by Zhichao Lu:\r\n\r\n    Added the functionality of combining the person keypoints and object detection\r\n    annotations in the binary that converts the COCO raw data to TfRecord.\r\n\r\n--\r\n309125076  by Zhichao Lu:\r\n\r\n    Convert target_assigner_utils to TF1/TF2.\r\n\r\n--\r\n308966359  by huizhongc:\r\n\r\n    Support SSD training with partially labeled groundtruth.\r\n\r\n--\r\n308937159  by rathodv:\r\n\r\n    Update core/target_assigner.py to be compatible with TF1/TF2.\r\n\r\n--\r\n308774302  by Zhichao Lu:\r\n\r\n    Internal\r\n\r\n--\r\n308732860  by rathodv:\r\n\r\n    Make core/prefetcher.py  compatible with TF1 only.\r\n\r\n--\r\n308726984  by rathodv:\r\n\r\n    Update core/multiclass_nms_test.py to be TF1/TF2 compatible.\r\n\r\n--\r\n308714718  by rathodv:\r\n\r\n    Update core/region_similarity_calculator_test.py to be TF1/TF2 compatible.\r\n\r\n--\r\n308707960  by rathodv:\r\n\r\n    Update core/minibatch_sampler_test.py to be TF1/TF2 compatible.\r\n\r\n--\r\n308700595  by rathodv:\r\n\r\n    Update core/losses_test.py to be TF1/TF2 compatible and remove losses_test_v2.py\r\n\r\n--\r\n308361472  by rathodv:\r\n\r\n    Update core/matcher_test.py to be TF1/TF2 compatible.\r\n\r\n--\r\n308335846  by Zhichao Lu:\r\n\r\n    Updated the COCO evaluation logics and populated the groundturth area\r\n    information through. This change matches the groundtruth format expected by the\r\n    COCO keypoint evaluation.\r\n\r\n--\r\n308256924  by rathodv:\r\n\r\n    Update core/keypoints_ops_test.py to be TF1/TF2 compatible.\r\n\r\n--\r\n308256826  by rathodv:\r\n\r\n    Update class_agnostic_nms_test.py to be TF1/TF2 compatible.\r\n\r\n--\r\n308256112  by rathodv:\r\n\r\n    Update box_list_ops_test.py to be TF1/TF2 compatible.\r\n\r\n--\r\n308159360  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n308145008  by Zhichao Lu:\r\n\r\n    Added 'image/class/confidence' field in the TFExample decoder.\r\n\r\n--\r\n307651875  by rathodv:\r\n\r\n    Refactor core/box_list.py to support TF1/TF2.\r\n\r\n--\r\n307651798  by rathodv:\r\n\r\n    Modify box_coder.py base class to work with with TF1/TF2\r\n\r\n--\r\n307651652  by rathodv:\r\n\r\n    Refactor core/balanced_positive_negative_sampler.py to support TF1/TF2.\r\n\r\n--\r\n307651571  by rathodv:\r\n\r\n    Modify BoxCoders tests to use test_case:execute method to allow testing with TF1.X and TF2.X\r\n\r\n--\r\n307651480  by rathodv:\r\n\r\n    Modify Matcher tests to use test_case:execute method to allow testing with TF1.X and TF2.X\r\n\r\n--\r\n307651409  by rathodv:\r\n\r\n    Modify AnchorGenerator tests to use test_case:execute method to allow testing with TF1.X and TF2.X\r\n\r\n--\r\n307651314  by rathodv:\r\n\r\n    Refactor model_builder to support TF1 or TF2 models based on TensorFlow version.\r\n\r\n--\r\n307092053  by Zhichao Lu:\r\n\r\n    Use manager to save checkpoint.\r\n\r\n--\r\n307071352  by ronnyvotel:\r\n\r\n    Fixing keypoint visibilities. Now by default, the visibility is marked True if the keypoint is labeled (regardless of whether it is visible or not).\r\n    Also, if visibilities are not present in the dataset, they will be created based on whether the keypoint coordinates are finite (vis = True) or NaN (vis = False).\r\n\r\n--\r\n307069557  by Zhichao Lu:\r\n\r\n    Internal change to add few fields related to postprocessing parameters in\r\n    center_net.proto and populate those parameters to the keypoint postprocessing\r\n    functions.\r\n\r\n--\r\n307012091  by Zhichao Lu:\r\n\r\n    Make Adam Optimizer's epsilon proto configurable.\r\n\r\n    Potential issue: tf.compat.v1's AdamOptimizer has a default epsilon on 1e-08 ([doc-link](https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/AdamOptimizer))  whereas tf.keras's AdamOptimizer has default epsilon 1e-07 ([doc-link](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam))\r\n\r\n--\r\n306858598  by Zhichao Lu:\r\n\r\n    Internal changes to update the CenterNet model:\r\n    1) Modified eval job loss computation to avoid averaging over batches with zero loss.\r\n    2) Updated CenterNet keypoint heatmap target assigner to apply box size to heatmap Guassian standard deviation.\r\n    3) Updated the CenterNet meta arch keypoint losses computation to apply weights outside of loss function.\r\n\r\n--\r\n306731223  by jonathanhuang:\r\n\r\n    Internal change.\r\n\r\n--\r\n306549183  by rathodv:\r\n\r\n    Internal Update.\r\n\r\n--\r\n306542930  by rathodv:\r\n\r\n    Internal Update\r\n\r\n--\r\n306322697  by rathodv:\r\n\r\n    Internal.\r\n\r\n--\r\n305345036  by Zhichao Lu:\r\n\r\n    Adding COCO Camera Traps Json to tf.Example beam code\r\n\r\n--\r\n304104869  by lzc:\r\n\r\n    Internal changes.\r\n\r\n--\r\n304068971  by jonathanhuang:\r\n\r\n    Internal change.\r\n\r\n--\r\n304050469  by Zhichao Lu:\r\n\r\n    Internal change.\r\n\r\n--\r\n303880642  by huizhongc:\r\n\r\n    Support parsing partially labeled groundtruth.\r\n\r\n--\r\n303841743  by Zhichao Lu:\r\n\r\n    Deprecate nms_on_host in SSDMetaArch.\r\n\r\n--\r\n303803204  by rathodv:\r\n\r\n    Internal change.\r\n\r\n--\r\n303793895  by jonathanhuang:\r\n\r\n    Internal change.\r\n\r\n--\r\n303467631  by rathodv:\r\n\r\n    Py3 update for detection inference test.\r\n\r\n--\r\n303444542  by rathodv:\r\n\r\n    Py3 update to metrics module\r\n\r\n--\r\n303421960  by rathodv:\r\n\r\n    Update json_utils to python3.\r\n\r\n--\r\n302787583  by ronnyvotel:\r\n\r\n    Coco results generator for submission to the coco test server.\r\n\r\n--\r\n302719091  by Zhichao Lu:\r\n\r\n    Internal change to add the ResNet50 image feature extractor for CenterNet model.\r\n\r\n--\r\n302116230  by Zhichao Lu:\r\n\r\n    Added the functions to overlay the heatmaps with images in visualization util\r\n    library.\r\n\r\n--\r\n301888316  by Zhichao Lu:\r\n\r\n    Fix checkpoint_filepath not defined error.\r\n\r\n--\r\n301840312  by ronnyvotel:\r\n\r\n    Adding keypoint_scores to visualizations.\r\n\r\n--\r\n301683475  by ronnyvotel:\r\n\r\n    Introducing the ability to preprocess `keypoint_visibilities`.\r\n\r\n    Some data augmentation ops such as random crop can filter instances and keypoints. It's important to also filter keypoint visibilities, so that the groundtruth tensors are always in alignment.\r\n\r\n--\r\n301532344  by Zhichao Lu:\r\n\r\n    Don't use tf.divide since \"Quantization not yet supported for op: DIV\"\r\n\r\n--\r\n301480348  by ronnyvotel:\r\n\r\n    Introducing keypoint evaluation into model lib v2.\r\n    Also, making some fixes to coco keypoint evaluation.\r\n\r\n--\r\n301454018  by Zhichao Lu:\r\n\r\n    Added the image summary to visualize the train/eval input images and eval's\r\n    prediction/groundtruth side-by-side image.\r\n\r\n--\r\n301317527  by Zhichao Lu:\r\n\r\n    Updated the random_absolute_pad_image function in the preprocessor library to\r\n    support the keypoints argument.\r\n\r\n--\r\n301300324  by Zhichao Lu:\r\n\r\n    Apply name change(experimental_run_v2 -> run) for all callers in Tensorflow.\r\n\r\n--\r\n301297115  by ronnyvotel:\r\n\r\n    Utility function for setting keypoint visibilities based on keypoint coordinates.\r\n\r\n--\r\n301248885  by Zhichao Lu:\r\n\r\n    Allow MultiworkerMirroredStrategy(MWMS) use by adding checkpoint handling with temporary directories in model_lib_v2. Added missing WeakKeyDictionary cfer_fn_cache field in CollectiveAllReduceStrategyExtended.\r\n\r\n--\r\n301224559  by Zhichao Lu:\r\n\r\n    ...1) Fixes model_lib to also use keypoints while preparing model groundtruth.\r\n    ...2) Tests model_lib with newly added keypoint metrics config.\r\n\r\n--\r\n300836556  by Zhichao Lu:\r\n\r\n    Internal changes to add keypoint estimation parameters in CenterNet proto.\r\n\r\n--\r\n300795208  by Zhichao Lu:\r\n\r\n    Updated the eval_util library to populate the keypoint groundtruth to\r\n    eval_dict.\r\n\r\n--\r\n299474766  by Zhichao Lu:\r\n\r\n    ...Modifies eval_util to create Keypoint Evaluator objects when configured in eval config.\r\n\r\n--\r\n299453920  by Zhichao Lu:\r\n\r\n    Add swish activation as a hyperperams option.\r\n\r\n--\r\n299240093  by ronnyvotel:\r\n\r\n    Keypoint postprocessing for CenterNetMetaArch.\r\n\r\n--\r\n299176395  by Zhichao Lu:\r\n\r\n    Internal change.\r\n\r\n--\r\n299135608  by Zhichao Lu:\r\n\r\n    Internal changes to refactor the CenterNet model in preparation for keypoint estimation tasks.\r\n\r\n--\r\n298915482  by Zhichao Lu:\r\n\r\n    Make dataset_builder aware of input_context for distributed training.\r\n\r\n--\r\n298713595  by Zhichao Lu:\r\n\r\n    Handling data with negative size boxes.\r\n\r\n--\r\n298695964  by Zhichao Lu:\r\n\r\n    Expose change_coordinate_frame as a config parameter; fix multiclass_scores optional field.\r\n\r\n--\r\n298492150  by Zhichao Lu:\r\n\r\n    Rename optimizer_builder_test_v2.py -> optimizer_builder_v2_test.py\r\n\r\n--\r\n298476471  by Zhichao Lu:\r\n\r\n    Internal changes to support CenterNet keypoint estimation.\r\n\r\n--\r\n298365851  by ronnyvotel:\r\n\r\n    Fixing a bug where groundtruth_keypoint_weights were being padded with a dynamic dimension.\r\n\r\n--\r\n297843700  by Zhichao Lu:\r\n\r\n    Internal change.\r\n\r\n--\r\n297706988  by lzc:\r\n\r\n    Internal change.\r\n\r\n--\r\n297705287  by ronnyvotel:\r\n\r\n    Creating the \"snapping\" behavior in CenterNet, where regressed keypoints are refined with updated candidate keypoints from a heatmap.\r\n\r\n--\r\n297700447  by Zhichao Lu:\r\n\r\n    Improve checkpoint checking logic with TF2 loop.\r\n\r\n--\r\n297686094  by Zhichao Lu:\r\n\r\n    Convert \"import tensorflow as tf\" to \"import tensorflow.compat.v1\".\r\n\r\n--\r\n297670468  by lzc:\r\n\r\n    Internal change.\r\n\r\n--\r\n297241327  by Zhichao Lu:\r\n\r\n    Convert \"import tensorflow as tf\" to \"import tensorflow.compat.v1\".\r\n\r\n--\r\n297205959  by Zhichao Lu:\r\n\r\n    Internal changes to support refactored the centernet object detection target assigner into a separate library.\r\n\r\n--\r\n297143806  by Zhichao Lu:\r\n\r\n    Convert \"import tensorflow as tf\" to \"import tensorflow.compat.v1\".\r\n\r\n--\r\n297129625  by Zhichao Lu:\r\n\r\n    Explicitly replace \"import tensorflow\" with \"tensorflow.compat.v1\" for TF2.x migration\r\n\r\n--\r\n297117070  by Zhichao Lu:\r\n\r\n    Explicitly replace \"import tensorflow\" with \"tensorflow.compat.v1\" for TF2.x migration\r\n\r\n--\r\n297030190  by Zhichao Lu:\r\n\r\n    Add configuration options for visualizing keypoint edges\r\n\r\n--\r\n296359649  by Zhichao Lu:\r\n\r\n    Support DepthwiseConv2dNative (of separable conv) in weight equalization loss.\r\n\r\n--\r\n296290582  by Zhichao Lu:\r\n\r\n    Internal change.\r\n\r\n--\r\n296093857  by Zhichao Lu:\r\n\r\n    Internal changes to add general target assigner utilities.\r\n\r\n--\r\n295975116  by Zhichao Lu:\r\n\r\n    Fix visualize_boxes_and_labels_on_image_array to show max_boxes_to_draw correctly.\r\n\r\n--\r\n295819711  by Zhichao Lu:\r\n\r\n    Adds a flag to visualize_boxes_and_labels_on_image_array to skip the drawing of axis aligned bounding boxes.\r\n\r\n--\r\n295811929  by Zhichao Lu:\r\n\r\n    Keypoint support in random_square_crop_by_scale.\r\n\r\n--\r\n295788458  by rathodv:\r\n\r\n    Remove unused checkpoint to reduce repo size on github\r\n\r\n--\r\n295787184  by Zhichao Lu:\r\n\r\n    Enable visualization of edges between keypoints\r\n\r\n--\r\n295763508  by Zhichao Lu:\r\n\r\n    [Context RCNN] Add an option to enable / disable cropping feature in the post\r\n    process step in the meta archtecture.\r\n\r\n--\r\n295605344  by Zhichao Lu:\r\n\r\n    internal change.\r\n\r\n--\r\n294926050  by ronnyvotel:\r\n\r\n    Adding per-keypoint groundtruth weights. These weights are intended to be used as multipliers in a keypoint loss function.\r\n\r\n    Groundtruth keypoint weights are constructed as follows:\r\n    - Initialize the weight for each keypoint type based on user-specified weights in the input_reader proto\r\n    - Mask out (i.e. make zero) all keypoint weights that are not visible.\r\n\r\n--\r\n294829061  by lzc:\r\n\r\n    Internal change.\r\n\r\n--\r\n294566503  by Zhichao Lu:\r\n\r\n    Changed internal CenterNet Model configuration.\r\n\r\n--\r\n294346662  by ronnyvotel:\r\n\r\n    Using NaN values in keypoint coordinates that are not visible.\r\n\r\n--\r\n294333339  by Zhichao Lu:\r\n\r\n    Change experimetna_distribute_dataset -> experimental_distribute_dataset_from_function\r\n\r\n--\r\n293928752  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n--\r\n293909384  by Zhichao Lu:\r\n\r\n    Add capabilities to train 1024x1024 CenterNet models.\r\n\r\n--\r\n293637554  by ronnyvotel:\r\n\r\n    Adding keypoint visibilities to TfExampleDecoder.\r\n\r\n--\r\n293501558  by lzc:\r\n\r\n    Internal change.\r\n\r\n--\r\n293252851  by Zhichao Lu:\r\n\r\n    Change tf.gfile.GFile to tf.io.gfile.GFile.\r\n\r\n--\r\n292730217  by Zhichao Lu:\r\n\r\n    Internal change.\r\n\r\n--\r\n292456563  by lzc:\r\n\r\n    Internal changes.\r\n\r\n--\r\n292355612  by Zhichao Lu:\r\n\r\n    Use tf.gather and tf.scatter_nd instead of matrix ops.\r\n\r\n--\r\n292245265  by rathodv:\r\n\r\n    Internal\r\n\r\n--\r\n291989323  by richardmunoz:\r\n\r\n    Refactor out building a DataDecoder from building a tf.data.Dataset.\r\n\r\n--\r\n291950147  by Zhichao Lu:\r\n\r\n    Flip bounding boxes in arbitrary shaped tensors.\r\n\r\n--\r\n291401052  by huizhongc:\r\n\r\n    Fix multiscale grid anchor generator to allow fully convolutional inference. When exporting model with identity_resizer as image_resizer, there is an incorrect box offset on the detection results. We add the anchor offset to address this problem.\r\n\r\n--\r\n291298871  by Zhichao Lu:\r\n\r\n    Py3 compatibility changes.\r\n\r\n--\r\n290957957  by Zhichao Lu:\r\n\r\n    Hourglass feature extractor for CenterNet.\r\n\r\n--\r\n290564372  by Zhichao Lu:\r\n\r\n    Internal change.\r\n\r\n--\r\n290155278  by rathodv:\r\n\r\n    Remove Dataset Explorer.\r\n\r\n--\r\n290155153  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n--\r\n290122054  by Zhichao Lu:\r\n\r\n    Unify the format in the faster_rcnn.proto\r\n\r\n--\r\n290116084  by Zhichao Lu:\r\n\r\n    Deprecate tensorflow.contrib.\r\n\r\n--\r\n290100672  by Zhichao Lu:\r\n\r\n    Update MobilenetV3 SSD candidates\r\n\r\n--\r\n289926392  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n--\r\n289553440  by Zhichao Lu:\r\n\r\n    [Object Detection API] Fix the comments about the dimension of the rpn_box_encodings from 4-D to 3-D.\r\n\r\n--\r\n288994128  by lzc:\r\n\r\n    Internal changes.\r\n\r\n--\r\n288942194  by lzc:\r\n\r\n    Internal change.\r\n\r\n--\r\n288746124  by Zhichao Lu:\r\n\r\n    Configurable channel mean/std. dev in CenterNet feature extractors.\r\n\r\n--\r\n288552509  by rathodv:\r\n\r\n    Internal.\r\n\r\n--\r\n288541285  by rathodv:\r\n\r\n    Internal update.\r\n\r\n--\r\n288396396  by Zhichao Lu:\r\n\r\n    Make object detection import contrib explicitly\r\n\r\n--\r\n288255791  by rathodv:\r\n\r\n    Internal\r\n\r\n--\r\n288078600  by Zhichao Lu:\r\n\r\n    Fix model_lib_v2 test\r\n\r\n--\r\n287952244  by rathodv:\r\n\r\n    Internal\r\n\r\n--\r\n287921774  by Zhichao Lu:\r\n\r\n    internal change\r\n\r\n--\r\n287906173  by Zhichao Lu:\r\n\r\n    internal change\r\n\r\n--\r\n287889407  by jonathanhuang:\r\n\r\n    PY3 compatibility\r\n\r\n--\r\n287889042  by rathodv:\r\n\r\n    Internal\r\n\r\n--\r\n287876178  by Zhichao Lu:\r\n\r\n    Internal change.\r\n\r\n--\r\n287770490  by Zhichao Lu:\r\n\r\n    Add CenterNet proto and builder\r\n\r\n--\r\n287694213  by Zhichao Lu:\r\n\r\n    Support for running multiple steps per tf.function call.\r\n\r\n--\r\n287377183  by jonathanhuang:\r\n\r\n    PY3 compatibility\r\n\r\n--\r\n287371344  by rathodv:\r\n\r\n    Support loading keypoint labels and ids.\r\n\r\n--\r\n287368213  by rathodv:\r\n\r\n    Add protos supporting keypoint evaluation.\r\n\r\n--\r\n286673200  by rathodv:\r\n\r\n    dataset_tools PY3 migration\r\n\r\n--\r\n286635106  by Zhichao Lu:\r\n\r\n    Update code for upcoming tf.contrib removal\r\n\r\n--\r\n286479439  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n--\r\n286311711  by Zhichao Lu:\r\n\r\n    Skeleton of context model within TFODAPI\r\n\r\n--\r\n286005546  by Zhichao Lu:\r\n\r\n    Fix Faster-RCNN training when using keep_aspect_ratio_resizer with pad_to_max_dimension\r\n\r\n--\r\n285906400  by derekjchow:\r\n\r\n    Internal change\r\n\r\n--\r\n285822795  by Zhichao Lu:\r\n\r\n    Add CenterNet meta arch target assigners.\r\n\r\n--\r\n285447238  by Zhichao Lu:\r\n\r\n    Internal changes.\r\n\r\n--\r\n285016927  by Zhichao Lu:\r\n\r\n    Make _dummy_computation a tf.function. This fixes breakage caused by\r\n    cl/284256438\r\n\r\n--\r\n284827274  by Zhichao Lu:\r\n\r\n    Convert to python 3.\r\n\r\n--\r\n284645593  by rathodv:\r\n\r\n    Internal change\r\n\r\n--\r\n284639893  by rathodv:\r\n\r\n    Add missing documentation for keypoints in eval_util.py.\r\n\r\n--\r\n284323712  by Zhichao Lu:\r\n\r\n    Internal changes.\r\n\r\n--\r\n284295290  by Zhichao Lu:\r\n\r\n    Updating input config proto and dataset builder to include context fields\r\n\r\n    Updating standard_fields and tf_example_decoder to include context features\r\n\r\n--\r\n284226821  by derekjchow:\r\n\r\n    Update exporter.\r\n\r\n--\r\n284211030  by Zhichao Lu:\r\n\r\n    API changes in CenterNet informed by the experiments with hourlgass network.\r\n\r\n--\r\n284190451  by Zhichao Lu:\r\n\r\n    Add support for CenterNet losses in protos and builders.\r\n\r\n--\r\n284093961  by lzc:\r\n\r\n    Internal changes.\r\n\r\n--\r\n284028174  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n--\r\n284014719  by derekjchow:\r\n\r\n    Do not pad top_down feature maps unnecessarily.\r\n\r\n--\r\n284005765  by Zhichao Lu:\r\n\r\n    Add new pad_to_multiple_resizer\r\n\r\n--\r\n283858233  by Zhichao Lu:\r\n\r\n    Make target assigner work when under tf.function.\r\n\r\n--\r\n283836611  by Zhichao Lu:\r\n\r\n    Make config getters more general.\r\n\r\n--\r\n283808990  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n--\r\n283754588  by Zhichao Lu:\r\n\r\n    Internal changes.\r\n\r\n--\r\n282460301  by Zhichao Lu:\r\n\r\n    Add ability to restore v2 style checkpoints.\r\n\r\n--\r\n281605842  by lzc:\r\n\r\n    Add option to disable loss computation in OD API eval job.\r\n\r\n--\r\n280298212  by Zhichao Lu:\r\n\r\n    Add backwards compatible change\r\n\r\n--\r\n280237857  by Zhichao Lu:\r\n\r\n    internal change\r\n\r\n--\r\n\r\nPiperOrigin-RevId: 310447280\r\n\r\n# Description\r\n\r\n> :memo: Please include a summary of the change. \r\n>  \r\n> * Please also include relevant motivation and context.  \r\n> * List any dependencies that are required for this change.  \r\n\r\n## Type of change\r\n\r\nFor a new feature or function, please create an issue first to discuss it\r\nwith us before submitting a pull request.\r\n\r\nNote: Please delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] Documentation update\r\n- [ ] TensorFlow 2 migration\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] A new research paper code implementation\r\n- [x] Other (Specify)\r\n\r\n## Tests\r\n\r\n> :memo: Please describe the tests that you ran to verify your changes.\r\n>  \r\n> * Provide instructions so we can reproduce.  \r\n> * Please also list any relevant details for your test configuration.  \r\n\r\n**Test Configuration**:\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [x] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 0,
        "changed_files": 0,
        "created_at": "2020-05-07T18:17:32Z",
        "closed_at": "2020-05-07T22:27:35Z",
        "merged_at": null,
        "body": "310362339  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n310259448  by lzc:\r\n\r\n    Update required TF version for OD API.\r\n\r\n--\r\n310252159  by Zhichao Lu:\r\n\r\n    Port patch_ops_test to TF1/TF2 as TPUs.\r\n\r\n--\r\n310247180  by Zhichao Lu:\r\n\r\n    Ignore keypoint heatmap loss in the regions/bounding boxes with target keypoint\r\n    class but no valid keypoint annotations.\r\n\r\n--\r\n310178294  by Zhichao Lu:\r\n\r\n    Opensource MnasFPN\r\n    https://arxiv.org/abs/1912.01106\r\n\r\n--\r\n310094222  by lzc:\r\n\r\n    Internal changes.\r\n\r\n--\r\n310085250  by lzc:\r\n\r\n    Internal Change.\r\n\r\n--\r\n310016447  by huizhongc:\r\n\r\n    Remove unrecognized classes from labeled_classes.\r\n\r\n--\r\n310009470  by rathodv:\r\n\r\n    Mark batcher.py as TF1 only.\r\n\r\n--\r\n310001984  by rathodv:\r\n\r\n    Update core/preprocessor.py to be compatible with TF1/TF2..\r\n\r\n--\r\n309455035  by Zhichao Lu:\r\n\r\n    Makes the freezable_batch_norm_test run w/ v2 behavior.\r\n\r\n    The main change is in v2 updates will happen right away when running batchnorm in training mode. So, we need to restore the weights between batchnorm calls to make sure the numerical checks all start from the same place.\r\n\r\n--\r\n309425881  by Zhichao Lu:\r\n\r\n    Make TF1/TF2 optimizer builder tests explicit.\r\n\r\n--\r\n309408646  by Zhichao Lu:\r\n\r\n    Make dataset builder tests TF1 and TF2 compatible.\r\n\r\n--\r\n309246305  by Zhichao Lu:\r\n\r\n    Added the functionality of combining the person keypoints and object detection\r\n    annotations in the binary that converts the COCO raw data to TfRecord.\r\n\r\n--\r\n309125076  by Zhichao Lu:\r\n\r\n    Convert target_assigner_utils to TF1/TF2.\r\n\r\n--\r\n308966359  by huizhongc:\r\n\r\n    Support SSD training with partially labeled groundtruth.\r\n\r\n--\r\n308937159  by rathodv:\r\n\r\n    Update core/target_assigner.py to be compatible with TF1/TF2.\r\n\r\n--\r\n308774302  by Zhichao Lu:\r\n\r\n    Internal\r\n\r\n--\r\n308732860  by rathodv:\r\n\r\n    Make core/prefetcher.py  compatible with TF1 only.\r\n\r\n--\r\n308726984  by rathodv:\r\n\r\n    Update core/multiclass_nms_test.py to be TF1/TF2 compatible.\r\n\r\n--\r\n308714718  by rathodv:\r\n\r\n    Update core/region_similarity_calculator_test.py to be TF1/TF2 compatible.\r\n\r\n--\r\n308707960  by rathodv:\r\n\r\n    Update core/minibatch_sampler_test.py to be TF1/TF2 compatible.\r\n\r\n--\r\n308700595  by rathodv:\r\n\r\n    Update core/losses_test.py to be TF1/TF2 compatible and remove losses_test_v2.py\r\n\r\n--\r\n308361472  by rathodv:\r\n\r\n    Update core/matcher_test.py to be TF1/TF2 compatible.\r\n\r\n--\r\n308335846  by Zhichao Lu:\r\n\r\n    Updated the COCO evaluation logics and populated the groundturth area\r\n    information through. This change matches the groundtruth format expected by the\r\n    COCO keypoint evaluation.\r\n\r\n--\r\n308330634  by Zhichao Lu:\r\n\r\n    Support float input/output in exporter.\r\n\r\n--\r\n308256924  by rathodv:\r\n\r\n    Update core/keypoints_ops_test.py to be TF1/TF2 compatible.\r\n\r\n--\r\n308256826  by rathodv:\r\n\r\n    Update class_agnostic_nms_test.py to be TF1/TF2 compatible.\r\n\r\n--\r\n308256112  by rathodv:\r\n\r\n    Update box_list_ops_test.py to be TF1/TF2 compatible.\r\n\r\n--\r\n308159360  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n308145008  by Zhichao Lu:\r\n\r\n    Added 'image/class/confidence' field in the TFExample decoder.\r\n\r\n--\r\n307651875  by rathodv:\r\n\r\n    Refactor core/box_list.py to support TF1/TF2.\r\n\r\n--\r\n307651798  by rathodv:\r\n\r\n    Modify box_coder.py base class to work with with TF1/TF2\r\n\r\n--\r\n307651652  by rathodv:\r\n\r\n    Refactor core/balanced_positive_negative_sampler.py to support TF1/TF2.\r\n\r\n--\r\n307651571  by rathodv:\r\n\r\n    Modify BoxCoders tests to use test_case:execute method to allow testing with TF1.X and TF2.X\r\n\r\n--\r\n307651480  by rathodv:\r\n\r\n    Modify Matcher tests to use test_case:execute method to allow testing with TF1.X and TF2.X\r\n\r\n--\r\n307651409  by rathodv:\r\n\r\n    Modify AnchorGenerator tests to use test_case:execute method to allow testing with TF1.X and TF2.X\r\n\r\n--\r\n307651314  by rathodv:\r\n\r\n    Refactor model_builder to support TF1 or TF2 models based on TensorFlow version.\r\n\r\n--\r\n307092053  by Zhichao Lu:\r\n\r\n    Use manager to save checkpoint.\r\n\r\n--\r\n307071352  by ronnyvotel:\r\n\r\n    Fixing keypoint visibilities. Now by default, the visibility is marked True if the keypoint is labeled (regardless of whether it is visible or not).\r\n    Also, if visibilities are not present in the dataset, they will be created based on whether the keypoint coordinates are finite (vis = True) or NaN (vis = False).\r\n\r\n--\r\n307069557  by Zhichao Lu:\r\n\r\n    Internal change to add few fields related to postprocessing parameters in\r\n    center_net.proto and populate those parameters to the keypoint postprocessing\r\n    functions.\r\n\r\n--\r\n307012091  by Zhichao Lu:\r\n\r\n    Make Adam Optimizer's epsilon proto configurable.\r\n\r\n    Potential issue: tf.compat.v1's AdamOptimizer has a default epsilon on 1e-08 ([doc-link](https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/AdamOptimizer))  whereas tf.keras's AdamOptimizer has default epsilon 1e-07 ([doc-link](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam))\r\n\r\n--\r\n306947114  by Zhichao Lu:\r\n\r\n    Updated the refine_keypoints in CenterNetMetaArch to support different\r\n    criterias to select the refine the keypoint location.\r\n\r\n--\r\n306937457  by Zhichao Lu:\r\n\r\n    Updated the CenterNetMetaArch's\r\n    convert_strided_predictions_to_normalized_keypoints function such that the\r\n    caller can choose to clip the out-of-frame keypoints to image boundary instead\r\n    of pruning them.\r\n\r\n--\r\n306858598  by Zhichao Lu:\r\n\r\n    Internal changes to update the CenterNet model:\r\n    1) Modified eval job loss computation to avoid averaging over batches with zero loss.\r\n    2) Updated CenterNet keypoint heatmap target assigner to apply box size to heatmap Guassian standard deviation.\r\n    3) Updated the CenterNet meta arch keypoint losses computation to apply weights outside of loss function.\r\n\r\n--\r\n306731223  by jonathanhuang:\r\n\r\n    Internal change.\r\n\r\n--\r\n306549183  by rathodv:\r\n\r\n    Internal Update.\r\n\r\n--\r\n306542930  by rathodv:\r\n\r\n    Internal Update\r\n\r\n--\r\n306446355  by rathodv:\r\n\r\n    Internal Update\r\n\r\n--\r\n306322697  by rathodv:\r\n\r\n    Internal.\r\n\r\n--\r\n305833518  by Zhichao Lu:\r\n\r\n    Fixed bug in top_k_feature_map_locations function to select the top k scores\r\n    from feature_map_peak as opposed to feature_map.\r\n\r\n--\r\n305345036  by Zhichao Lu:\r\n\r\n    Adding COCO Camera Traps Json to tf.Example beam code\r\n\r\n--\r\n304439507  by Zhichao Lu:\r\n\r\n    Fix exporter_lib_v2 test to use different input types.\r\n\r\n--\r\n304104869  by lzc:\r\n\r\n    Internal changes.\r\n\r\n--\r\n304068971  by jonathanhuang:\r\n\r\n    Internal change.\r\n\r\n--\r\n304050469  by Zhichao Lu:\r\n\r\n    Internal change.\r\n\r\n--\r\n304012139  by ronnyvotel:\r\n\r\n    Updating centernet keypoints to output 0.0 instead of NaN, which plays nicer with other tools.\r\n\r\n--\r\n303880642  by huizhongc:\r\n\r\n    Support parsing partially labeled groundtruth.\r\n\r\n--\r\n303841743  by Zhichao Lu:\r\n\r\n    Deprecate nms_on_host in SSDMetaArch.\r\n\r\n--\r\n303803204  by rathodv:\r\n\r\n    Internal change.\r\n\r\n--\r\n303793895  by jonathanhuang:\r\n\r\n    Internal change.\r\n\r\n--\r\n303774233  by Zhichao Lu:\r\n\r\n    Internal changes to update the CenterNetMetaArch functions to handle the error when the keypoint postprocessing tries to call \"scatter_nd\" with empty indices and updates with zero dimensions.\r\n\r\n    This came out when training the object detection and keypoint tasks on full COCO dataset with object detection/keypoint annotations where some images do not contain any \"person\" annotation and no \"keypoint\" to predict.\r\n\r\n--\r\n303561606  by ronnyvotel:\r\n\r\n    Updating the exported model classes output datatype to float, to agree with V1 exporter\r\n\r\n--\r\n303467631  by rathodv:\r\n\r\n    Py3 update for detection inference test.\r\n\r\n--\r\n303444542  by rathodv:\r\n\r\n    Py3 update to metrics module\r\n\r\n--\r\n303421960  by rathodv:\r\n\r\n    Update json_utils to python3.\r\n\r\n--\r\n303300597  by Zhichao Lu:\r\n\r\n    Fixed bug/crash in center net model creation.\r\n\r\n--\r\n302787583  by ronnyvotel:\r\n\r\n    Coco results generator for submission to the coco test server.\r\n\r\n--\r\n302719091  by Zhichao Lu:\r\n\r\n    Internal change to add the ResNet50 image feature extractor for CenterNet model.\r\n\r\n--\r\n302116230  by Zhichao Lu:\r\n\r\n    Added the functions to overlay the heatmaps with images in visualization util\r\n    library.\r\n\r\n--\r\n301888316  by Zhichao Lu:\r\n\r\n    Fix checkpoint_filepath not defined error.\r\n\r\n--\r\n301840312  by ronnyvotel:\r\n\r\n    Adding keypoint_scores to visualizations.\r\n\r\n--\r\n301683475  by ronnyvotel:\r\n\r\n    Introducing the ability to preprocess `keypoint_visibilities`.\r\n\r\n    Some data augmentation ops such as random crop can filter instances and keypoints. It's important to also filter keypoint visibilities, so that the groundtruth tensors are always in alignment.\r\n\r\n--\r\n301532344  by Zhichao Lu:\r\n\r\n    Don't use tf.divide since \"Quantization not yet supported for op: DIV\"\r\n\r\n--\r\n301480348  by ronnyvotel:\r\n\r\n    Introducing keypoint evaluation into model lib v2.\r\n    Also, making some fixes to coco keypoint evaluation.\r\n\r\n--\r\n301454018  by Zhichao Lu:\r\n\r\n    Added the image summary to visualize the train/eval input images and eval's\r\n    prediction/groundtruth side-by-side image.\r\n\r\n--\r\n301317527  by Zhichao Lu:\r\n\r\n    Updated the random_absolute_pad_image function in the preprocessor library to\r\n    support the keypoints argument.\r\n\r\n--\r\n301300324  by Zhichao Lu:\r\n\r\n    Apply name change(experimental_run_v2 -> run) for all callers in Tensorflow.\r\n\r\n--\r\n301297115  by ronnyvotel:\r\n\r\n    Utility function for setting keypoint visibilities based on keypoint coordinates.\r\n\r\n--\r\n301248885  by Zhichao Lu:\r\n\r\n    Allow MultiworkerMirroredStrategy(MWMS) use by adding checkpoint handling with temporary directories in model_lib_v2. Added missing WeakKeyDictionary cfer_fn_cache field in CollectiveAllReduceStrategyExtended.\r\n\r\n--\r\n301224559  by Zhichao Lu:\r\n\r\n    ...1) Fixes model_lib to also use keypoints while preparing model groundtruth.\r\n    ...2) Tests model_lib with newly added keypoint metrics config.\r\n\r\n--\r\n300836556  by Zhichao Lu:\r\n\r\n    Internal changes to add keypoint estimation parameters in CenterNet proto.\r\n\r\n--\r\n300795208  by Zhichao Lu:\r\n\r\n    Updated the eval_util library to populate the keypoint groundtruth to\r\n    eval_dict.\r\n\r\n--\r\n300113487  by Zhichao Lu:\r\n\r\n    Internal changes to allow CenterNet model to learn keypoint estimation tasks.\r\n\r\n--\r\n300086313  by ronnyvotel:\r\n\r\n    Updating _get_shape() in center_net_meta_arch.py so that integers are returned for static shapes, rather than Tensors.\r\n\r\n--\r\n299474766  by Zhichao Lu:\r\n\r\n    ...Modifies eval_util to create Keypoint Evaluator objects when configured in eval config.\r\n\r\n--\r\n299453920  by Zhichao Lu:\r\n\r\n    Add swish activation as a hyperperams option.\r\n\r\n--\r\n299240093  by ronnyvotel:\r\n\r\n    Keypoint postprocessing for CenterNetMetaArch.\r\n\r\n--\r\n299176395  by Zhichao Lu:\r\n\r\n    Internal change.\r\n\r\n--\r\n299135608  by Zhichao Lu:\r\n\r\n    Internal changes to refactor the CenterNet model in preparation for keypoint estimation tasks.\r\n\r\n--\r\n298915482  by Zhichao Lu:\r\n\r\n    Make dataset_builder aware of input_context for distributed training.\r\n\r\n--\r\n298732566  by Zhichao Lu:\r\n\r\n    Internal changes to add util functions to support multi-task CenterNet model training.\r\n\r\n--\r\n298713595  by Zhichao Lu:\r\n\r\n    Handling data with negative size boxes.\r\n\r\n--\r\n298710411  by ronnyvotel:\r\n\r\n    Adding two CenterNet utility functions. These functions help construct full keypoint coordinate/score tensors, from keypoint estimates on individual classes.\r\n\r\n--\r\n298697053  by ronnyvotel:\r\n\r\n    Adding a CenterNet function to convert strided keypoint predictions to normalized (input space) coordinates.\r\n\r\n--\r\n298695964  by Zhichao Lu:\r\n\r\n    Expose change_coordinate_frame as a config parameter; fix multiclass_scores optional field.\r\n\r\n--\r\n298650858  by Zhichao Lu:\r\n\r\n    Internal changes to add util function and parameters for CenterNet keypoint estimation\r\n\r\n--\r\n298492150  by Zhichao Lu:\r\n\r\n    Rename optimizer_builder_test_v2.py -> optimizer_builder_v2_test.py\r\n\r\n--\r\n298476471  by Zhichao Lu:\r\n\r\n    Internal changes to support CenterNet keypoint estimation.\r\n\r\n--\r\n298365851  by ronnyvotel:\r\n\r\n    Fixing a bug where groundtruth_keypoint_weights were being padded with a dynamic dimension.\r\n\r\n--\r\n297843700  by Zhichao Lu:\r\n\r\n    Internal change.\r\n\r\n--\r\n297706988  by lzc:\r\n\r\n    Internal change.\r\n\r\n--\r\n297705287  by ronnyvotel:\r\n\r\n    Creating the \"snapping\" behavior in CenterNet, where regressed keypoints are refined with updated candidate keypoints from a heatmap.\r\n\r\n--\r\n297700447  by Zhichao Lu:\r\n\r\n    Improve checkpoint checking logic with TF2 loop.\r\n\r\n--\r\n297686094  by Zhichao Lu:\r\n\r\n    Convert \"import tensorflow as tf\" to \"import tensorflow.compat.v1\".\r\n\r\n--\r\n297670468  by lzc:\r\n\r\n    Internal change.\r\n\r\n--\r\n297241327  by Zhichao Lu:\r\n\r\n    Convert \"import tensorflow as tf\" to \"import tensorflow.compat.v1\".\r\n\r\n--\r\n297205959  by Zhichao Lu:\r\n\r\n    Internal changes to support refactored the centernet object detection target assigner into a separate library.\r\n\r\n--\r\n297143806  by Zhichao Lu:\r\n\r\n    Convert \"import tensorflow as tf\" to \"import tensorflow.compat.v1\".\r\n\r\n--\r\n297129625  by Zhichao Lu:\r\n\r\n    Explicitly replace \"import tensorflow\" with \"tensorflow.compat.v1\" for TF2.x migration\r\n\r\n--\r\n297117070  by Zhichao Lu:\r\n\r\n    Explicitly replace \"import tensorflow\" with \"tensorflow.compat.v1\" for TF2.x migration\r\n\r\n--\r\n297030190  by Zhichao Lu:\r\n\r\n    Add configuration options for visualizing keypoint edges\r\n\r\n--\r\n296359649  by Zhichao Lu:\r\n\r\n    Support DepthwiseConv2dNative (of separable conv) in weight equalization loss.\r\n\r\n--\r\n296290582  by Zhichao Lu:\r\n\r\n    Internal change.\r\n\r\n--\r\n296278526  by ronnyvotel:\r\n\r\n    Updating regressed_keypoints_at_object_centers() in center_net_meta_arch.py so that the regressed keypoints are returned in absolute coordinates (in output coordinate frame), not relative.\r\n\r\n--\r\n296093857  by Zhichao Lu:\r\n\r\n    Internal changes to add general target assigner utilities.\r\n\r\n--\r\n296066476  by ronnyvotel:\r\n\r\n    In center_net_meta_arch.py, allowing the ability to return the top k feature map values **per channel**. This will be used to retrieve an equal number of candidates per keypoint type. This avoids the possibility that a disproportionate number of candidates comes from a few keypoint types.\r\n\r\n--\r\n295975116  by Zhichao Lu:\r\n\r\n    Fix visualize_boxes_and_labels_on_image_array to show max_boxes_to_draw correctly.\r\n\r\n--\r\n295819711  by Zhichao Lu:\r\n\r\n    Adds a flag to visualize_boxes_and_labels_on_image_array to skip the drawing of axis aligned bounding boxes.\r\n\r\n--\r\n295811929  by Zhichao Lu:\r\n\r\n    Keypoint support in random_square_crop_by_scale.\r\n\r\n--\r\n295788458  by rathodv:\r\n\r\n    Remove unused checkpoint to reduce repo size on github\r\n\r\n--\r\n295787184  by Zhichao Lu:\r\n\r\n    Enable visualization of edges between keypoints\r\n\r\n--\r\n295763508  by Zhichao Lu:\r\n\r\n    [Context RCNN] Add an option to enable / disable cropping feature in the post\r\n    process step in the meta archtecture.\r\n\r\n--\r\n295605344  by Zhichao Lu:\r\n\r\n    internal change.\r\n\r\n--\r\n295252797  by ronnyvotel:\r\n\r\n    Adding a function to gather regressed keypoints at specified locations.\r\n\r\n--\r\n295139603  by ronnyvotel:\r\n\r\n    This CL updates two parts of the CenterNet meta architecture:\r\n    - refactors the peak-finding functionality, since it is useful for both box centers and keypoints.\r\n    - adding a post-processing utility function to get the locations and scores from the keypoint heatmap and offset feature maps.\r\n\r\n--\r\n294926050  by ronnyvotel:\r\n\r\n    Adding per-keypoint groundtruth weights. These weights are intended to be used as multipliers in a keypoint loss function.\r\n\r\n    Groundtruth keypoint weights are constructed as follows:\r\n    - Initialize the weight for each keypoint type based on user-specified weights in the input_reader proto\r\n    - Mask out (i.e. make zero) all keypoint weights that are not visible.\r\n\r\n--\r\n294829061  by lzc:\r\n\r\n    Internal change.\r\n\r\n--\r\n294566503  by Zhichao Lu:\r\n\r\n    Changed internal CenterNet Model configuration.\r\n\r\n--\r\n294346662  by ronnyvotel:\r\n\r\n    Using NaN values in keypoint coordinates that are not visible.\r\n\r\n--\r\n294333339  by Zhichao Lu:\r\n\r\n    Change experimetna_distribute_dataset -> experimental_distribute_dataset_from_function\r\n\r\n--\r\n293928752  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n--\r\n293909384  by Zhichao Lu:\r\n\r\n    Add capabilities to train 1024x1024 CenterNet models.\r\n\r\n--\r\n293889713  by jonathanhuang:\r\n\r\n    Internal changes.\r\n\r\n--\r\n293637554  by ronnyvotel:\r\n\r\n    Adding keypoint visibilities to TfExampleDecoder.\r\n\r\n--\r\n293501558  by lzc:\r\n\r\n    Internal change.\r\n\r\n--\r\n293252851  by Zhichao Lu:\r\n\r\n    Change tf.gfile.GFile to tf.io.gfile.GFile.\r\n\r\n--\r\n292730217  by Zhichao Lu:\r\n\r\n    Internal change.\r\n\r\n--\r\n292456563  by lzc:\r\n\r\n    Internal changes.\r\n\r\n--\r\n292355612  by Zhichao Lu:\r\n\r\n    Use tf.gather and tf.scatter_nd instead of matrix ops.\r\n\r\n--\r\n292245265  by rathodv:\r\n\r\n    Internal\r\n\r\n--\r\n291989323  by richardmunoz:\r\n\r\n    Refactor out building a DataDecoder from building a tf.data.Dataset.\r\n\r\n--\r\n291950147  by Zhichao Lu:\r\n\r\n    Flip bounding boxes in arbitrary shaped tensors.\r\n\r\n--\r\n291401052  by huizhongc:\r\n\r\n    Fix multiscale grid anchor generator to allow fully convolutional inference. When exporting model with identity_resizer as image_resizer, there is an incorrect box offset on the detection results. We add the anchor offset to address this problem.\r\n\r\n--\r\n291298871  by Zhichao Lu:\r\n\r\n    Py3 compatibility changes.\r\n\r\n--\r\n290957957  by Zhichao Lu:\r\n\r\n    Hourglass feature extractor for CenterNet.\r\n\r\n--\r\n290564372  by Zhichao Lu:\r\n\r\n    Internal change.\r\n\r\n--\r\n290155278  by rathodv:\r\n\r\n    Remove Dataset Explorer.\r\n\r\n--\r\n290155153  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n--\r\n290122054  by Zhichao Lu:\r\n\r\n    Unify the format in the faster_rcnn.proto\r\n\r\n--\r\n290116084  by Zhichao Lu:\r\n\r\n    Deprecate tensorflow.contrib.\r\n\r\n--\r\n290100672  by Zhichao Lu:\r\n\r\n    Update MobilenetV3 SSD candidates\r\n\r\n--\r\n289926392  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n--\r\n289553440  by Zhichao Lu:\r\n\r\n    [Object Detection API] Fix the comments about the dimension of the rpn_box_encodings from 4-D to 3-D.\r\n\r\n--\r\n288994128  by lzc:\r\n\r\n    Internal changes.\r\n\r\n--\r\n288942194  by lzc:\r\n\r\n    Internal change.\r\n\r\n--\r\n288746124  by Zhichao Lu:\r\n\r\n    Configurable channel mean/std. dev in CenterNet feature extractors.\r\n\r\n--\r\n288552509  by rathodv:\r\n\r\n    Internal.\r\n\r\n--\r\n288541285  by rathodv:\r\n\r\n    Internal update.\r\n\r\n--\r\n288396396  by Zhichao Lu:\r\n\r\n    Make object detection import contrib explicitly\r\n\r\n--\r\n288255791  by rathodv:\r\n\r\n    Internal\r\n\r\n--\r\n288078600  by Zhichao Lu:\r\n\r\n    Fix model_lib_v2 test\r\n\r\n--\r\n287952244  by rathodv:\r\n\r\n    Internal\r\n\r\n--\r\n287921774  by Zhichao Lu:\r\n\r\n    internal change\r\n\r\n--\r\n287906173  by Zhichao Lu:\r\n\r\n    internal change\r\n\r\n--\r\n287889407  by jonathanhuang:\r\n\r\n    PY3 compatibility\r\n\r\n--\r\n287889042  by rathodv:\r\n\r\n    Internal\r\n\r\n--\r\n287876178  by Zhichao Lu:\r\n\r\n    Internal change.\r\n\r\n--\r\n287770490  by Zhichao Lu:\r\n\r\n    Add CenterNet proto and builder\r\n\r\n--\r\n287694213  by Zhichao Lu:\r\n\r\n    Support for running multiple steps per tf.function call.\r\n\r\n--\r\n287377183  by jonathanhuang:\r\n\r\n    PY3 compatibility\r\n\r\n--\r\n287371344  by rathodv:\r\n\r\n    Support loading keypoint labels and ids.\r\n\r\n--\r\n287368213  by rathodv:\r\n\r\n    Add protos supporting keypoint evaluation.\r\n\r\n--\r\n287225346  by Zhichao Lu:\r\n\r\n    Add CenterNet postprocess methods.\r\n\r\n--\r\n286673200  by rathodv:\r\n\r\n    dataset_tools PY3 migration\r\n\r\n--\r\n286635106  by Zhichao Lu:\r\n\r\n    Update code for upcoming tf.contrib removal\r\n\r\n--\r\n286513155  by Zhichao Lu:\r\n\r\n    Add Center Net meta arch losses.\r\n\r\n--\r\n286479439  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n--\r\n286311711  by Zhichao Lu:\r\n\r\n    Skeleton of context model within TFODAPI\r\n\r\n--\r\n286009924  by Zhichao Lu:\r\n\r\n    Add CenterNet meta-architecture predict functions.\r\n\r\n--\r\n286005546  by Zhichao Lu:\r\n\r\n    Fix Faster-RCNN training when using keep_aspect_ratio_resizer with pad_to_max_dimension\r\n\r\n--\r\n285906400  by derekjchow:\r\n\r\n    Internal change\r\n\r\n--\r\n285822795  by Zhichao Lu:\r\n\r\n    Add CenterNet meta arch target assigners.\r\n\r\n--\r\n285447238  by Zhichao Lu:\r\n\r\n    Internal changes.\r\n\r\n--\r\n285016927  by Zhichao Lu:\r\n\r\n    Make _dummy_computation a tf.function. This fixes breakage caused by\r\n    cl/284256438\r\n\r\n--\r\n284827274  by Zhichao Lu:\r\n\r\n    Convert to python 3.\r\n\r\n--\r\n284645593  by rathodv:\r\n\r\n    Internal change\r\n\r\n--\r\n284639893  by rathodv:\r\n\r\n    Add missing documentation for keypoints in eval_util.py.\r\n\r\n--\r\n284323712  by Zhichao Lu:\r\n\r\n    Internal changes.\r\n\r\n--\r\n284295290  by Zhichao Lu:\r\n\r\n    Updating input config proto and dataset builder to include context fields\r\n\r\n    Updating standard_fields and tf_example_decoder to include context features\r\n\r\n--\r\n284226821  by derekjchow:\r\n\r\n    Update exporter.\r\n\r\n--\r\n284211030  by Zhichao Lu:\r\n\r\n    API changes in CenterNet informed by the experiments with hourlgass network.\r\n\r\n--\r\n284190451  by Zhichao Lu:\r\n\r\n    Add support for CenterNet losses in protos and builders.\r\n\r\n--\r\n284093961  by lzc:\r\n\r\n    Internal changes.\r\n\r\n--\r\n284028174  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n--\r\n284014719  by derekjchow:\r\n\r\n    Do not pad top_down feature maps unnecessarily.\r\n\r\n--\r\n284005765  by Zhichao Lu:\r\n\r\n    Add new pad_to_multiple_resizer\r\n\r\n--\r\n283858233  by Zhichao Lu:\r\n\r\n    Make target assigner work when under tf.function.\r\n\r\n--\r\n283836611  by Zhichao Lu:\r\n\r\n    Make config getters more general.\r\n\r\n--\r\n283808990  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n--\r\n283754588  by Zhichao Lu:\r\n\r\n    Internal changes.\r\n\r\n--\r\n282460301  by Zhichao Lu:\r\n\r\n    Add ability to restore v2 style checkpoints.\r\n\r\n--\r\n281605842  by lzc:\r\n\r\n    Add option to disable loss computation in OD API eval job.\r\n\r\n--\r\n280298212  by Zhichao Lu:\r\n\r\n    Add backwards compatible change\r\n\r\n--\r\n280237857  by Zhichao Lu:\r\n\r\n    internal change\r\n\r\n--\r\n\r\nPiperOrigin-RevId: 310362339",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 587015,
        "deletions": 477,
        "changed_files": 777,
        "created_at": "2020-05-07T15:43:14Z",
        "closed_at": "2020-05-07T17:09:02Z",
        "merged_at": null,
        "body": "Please ignore",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2020-05-07T14:09:29Z",
        "closed_at": "2020-05-08T06:47:44Z",
        "merged_at": "2020-05-08T06:47:44Z",
        "body": "Delete two files no longer used (.gitmodules, WORKSPACE)",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 31,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-05-07T07:45:35Z",
        "closed_at": "2021-08-03T21:45:12Z",
        "merged_at": null,
        "body": "Now that [`TensorFlow has dropped support for Python 2`](https://github.com/tensorflow/tensorflow/releases), let's look for Python 3 syntax errors.\r\n```\r\n./research/cognitive_planning/train_supervised_active_vision.py:185:9: E999 SyntaxError: invalid syntax\r\n  print inputs\r\n        ^\r\n./research/cognitive_planning/viz_active_vision_dataset_main.py:98:11: E999 SyntaxError: invalid syntax\r\n    print world\r\n          ^\r\n./research/cognitive_planning/envs/active_vision_dataset_env.py:940:13: E999 SyntaxError: invalid syntax\r\n      print 'path not found, image_id = ', self._cur_world, self._cur_image_id\r\n            ^\r\n./research/learning_unsupervised_learning/variable_replace.py:94:11: E999 SyntaxError: invalid syntax\r\n    print \"Didn't use all replacements\"\r\n          ^\r\n./research/learning_unsupervised_learning/meta_objective/sklearn.py:116:20: E999 SyntaxError: invalid syntax\r\n      def blackbox((trX, trY, teX, teY)):\r\n                   ^\r\n./research/object_detection/core/matcher_test.py:192:16: F632 use ==/!= to compare str, bytes, and int literals\r\n          all([op.name is not 'Gather' for op in sess.graph.get_operations()]))\r\n               ^\r\n./research/lexnet_nc/extract_paths.py:83:18: E999 SyntaxError: invalid syntax\r\n          lambda (head, mod): head)}\r\n                 ^\r\n./research/swivel/prep.py:133:9: F633 use of >> is invalid with print function\r\n        print >> vocab_out, tok\r\n        ^\r\n./research/swivel/prep.py:134:9: F633 use of >> is invalid with print function\r\n        print >> sums_out, cnt\r\n        ^\r\n./research/swivel/text2bin.py:53:3: F633 use of >> is invalid with print function\r\n  print >> sys.stderr, e\r\n  ^\r\n./research/swivel/text2bin.py:74:9: F633 use of >> is invalid with print function\r\n        print >> vocab_out, token\r\n        ^\r\n6     E999 SyntaxError: invalid syntax\r\n1     F632 use ==/!= to compare str, bytes, and int literals\r\n4     F633 use of >> is invalid with print function\r\n11\r\n```",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2020-05-06T16:58:25Z",
        "closed_at": "2020-05-06T18:01:00Z",
        "merged_at": "2020-05-06T18:01:00Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 331,
        "deletions": 160,
        "changed_files": 7,
        "created_at": "2020-05-05T04:57:38Z",
        "closed_at": "2020-05-05T17:00:26Z",
        "merged_at": "2020-05-05T17:00:26Z",
        "body": "Add templates \r\n\r\n- README_TEMPLATE.md\r\n- pull_request_template.md\r\n\r\nUpdate\r\n\r\n- README files for official, research, and community\r\n- CONTRIBUTING.md\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 801,
        "deletions": 690,
        "changed_files": 1,
        "created_at": "2020-05-03T10:08:32Z",
        "closed_at": "2020-05-07T06:00:05Z",
        "merged_at": null,
        "body": "I added real-time Object detection and Segmentation function using a webcam on the tutorial notebook.\r\n\r\n**What I added:**\r\n1. Opencv installation\r\n2. run_inference function\r\n\r\nThank you.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 2752,
        "deletions": 438,
        "changed_files": 42,
        "created_at": "2020-04-30T00:51:46Z",
        "closed_at": "2020-05-02T03:51:52Z",
        "merged_at": "2020-05-02T03:51:52Z",
        "body": "- Updated library to be fully compatible with TF2.1.\r\n- New training code included.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 22,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2020-04-26T17:22:10Z",
        "closed_at": "2020-05-01T02:38:22Z",
        "merged_at": "2020-05-01T02:38:21Z",
        "body": "Add a new \"Community\" directory\r\nAdd description for a new \"Community\" directory",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-04-25T22:45:29Z",
        "closed_at": "2020-04-27T06:09:26Z",
        "merged_at": "2020-04-27T06:09:26Z",
        "body": "This fix handles situations when `sys.stdout` doesn't have `encoding` field at all. For me this is the case where I pipe script's stdout into a report generator.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 13634,
        "deletions": 0,
        "changed_files": 35,
        "created_at": "2020-04-25T06:33:01Z",
        "closed_at": "2020-05-07T05:52:16Z",
        "merged_at": null,
        "body": "These codes will help directly in colab local or working through local-colab.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2020-04-25T03:56:06Z",
        "closed_at": "2020-04-26T05:58:35Z",
        "merged_at": "2020-04-26T05:58:35Z",
        "body": "Issue :  #8435",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 13634,
        "deletions": 0,
        "changed_files": 35,
        "created_at": "2020-04-23T07:16:11Z",
        "closed_at": "2020-04-25T06:30:04Z",
        "merged_at": null,
        "body": "need to work on colab or locally, get these notebooks into implementation",
        "comments": 10
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-04-21T21:46:55Z",
        "closed_at": "2020-09-19T00:15:13Z",
        "merged_at": "2020-09-19T00:15:13Z",
        "body": "With kernel=[3, 3] in all entries of MOBILENETV1_CONV_DEFS, the latent index error (likely due to copy-paste) did not cause problems.\r\nFix is needed to ensure proper padding with non-square kernels.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-04-21T18:38:30Z",
        "closed_at": "2020-05-20T05:37:45Z",
        "merged_at": "2020-05-20T05:37:44Z",
        "body": "Example of incorrect visualization: actual scores below\r\n```\r\n{'id': 1, 'name': 'person'} - 0.9168785214424133\r\n{'id': 38, 'name': 'kite'} - 0.8294453620910645\r\n{'id': 1, 'name': 'person'} - 0.7785056233406067\r\n{'id': 38, 'name': 'kite'} - 0.7699868083000183\r\n{'id': 38, 'name': 'kite'} - 0.7555397152900696\r\n{'id': 1, 'name': 'person'} - 0.6342337727546692\r\n{'id': 38, 'name': 'kite'} - 0.6074063777923584\r\n{'id': 1, 'name': 'person'} - 0.5891015529632568\r\n{'id': 1, 'name': 'person'} - 0.5123766660690308\r\n{'id': 1, 'name': 'person'} - 0.5014634728431702\r\n```\r\nBut on the image person has 91% and kite has 82%.\r\n![screen](https://user-images.githubusercontent.com/37259322/79901104-2709be00-83c4-11ea-9617-6f5e3b8b4d6d.png)",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 124,
        "deletions": 61,
        "changed_files": 1,
        "created_at": "2020-04-20T19:31:38Z",
        "closed_at": "2020-04-21T05:41:55Z",
        "merged_at": null,
        "body": "- Migrated the shake_shake.py to Tensorflow 2.x",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 30,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-04-18T12:47:12Z",
        "closed_at": "2020-04-18T23:56:11Z",
        "merged_at": "2020-04-18T23:56:11Z",
        "body": "fix error as below:\r\n'''\r\n\r\nTraceback (most recent call last):\r\n  File \"deep_speech.py\", line 416, in <module>\r\n    absl_app.run(main)\r\n  File \"/home/luke/miniconda3/lib/python3.7/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/home/luke/miniconda3/lib/python3.7/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"deep_speech.py\", line 409, in main\r\n    run_deep_speech(flags_obj)\r\n  File \"deep_speech.py\", line 260, in run_deep_speech\r\n    per_replica_batch_size = distribution_utils.per_replica_batch_size(\r\nAttributeError: module 'official.utils.misc.distribution_utils' has no attribute 'per_replica_batch_size'\r\n'''",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 13,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2020-04-16T15:56:08Z",
        "closed_at": "2020-04-27T17:35:01Z",
        "merged_at": "2020-04-27T17:35:01Z",
        "body": "This PR would allow writing BERT pretraining models completely in a functional style. Currently, TrnaformerEncoder should be a custom layer, providing `get_embedding_table()` method. With this PR, we could use arbitrary `tf.keras.Model` for this.\r\n\r\nNote, that I among TF warnings I now see the following:\r\n```\r\nWARNING:tensorflow:                                          \r\nThe following Variables were used a Lambda layer's call (lambda_1), but                                                   \r\nare not present in its tracked objects:                      \r\n  <tf.Variable 'BERT/word_embeddings/embeddings:0' shape=(30522, 768) dtype=float32>                                      \r\nIt is possible that this is intended behavior, but it is more likely                                                      \r\nan omission. This is a strong indication that this layer should be                                                        \r\nformulated as a subclassed Layer rather than a Lambda layer.  \r\n```\r\n\r\nI'm struggling to develop a style which could help to re-use as much code as possible so given the attitude towards functional style API in Keras I decided to propose this change. But I think it's OK to postone/cancel it if developers think this issue is a serious one.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 153,
        "deletions": 2,
        "changed_files": 40,
        "created_at": "2020-04-12T05:04:07Z",
        "closed_at": "2020-04-13T04:37:11Z",
        "merged_at": "2020-04-13T04:37:11Z",
        "body": "Added TensorFlow requirement\r\nAdded \"No Maintenance Intended\" for deprecated models",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-04-11T08:14:09Z",
        "closed_at": "2020-04-13T17:44:15Z",
        "merged_at": "2020-04-13T17:44:15Z",
        "body": "In pip package `tf-models-nightly`, below import throws a ModuleNotFoundError\r\n\r\n```python\r\n>>> import official.vision.detection.ops\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nModuleNotFoundError: No module named 'official.vision.detection.ops'\r\n```\r\nThis is because of the fact that the `official.vision.detection.ops` module didn't have an `__init__.py` file.\r\n\r\nThis is fixed in this PR by adding an empty `__init__.py` file inside official/vision/detection/ops. ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-04-10T14:53:16Z",
        "closed_at": "2020-04-13T18:35:44Z",
        "merged_at": "2020-04-13T18:35:44Z",
        "body": "Installing tensorflow1.14 instead of 2.X\r\n\r\npython3 -c \"import delf\" crashed because of call to tf.contrib.slim\r\ncontrib module has been deprecated in tf 2.0",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-04-08T11:10:45Z",
        "closed_at": "2020-04-09T18:37:44Z",
        "merged_at": "2020-04-09T18:37:44Z",
        "body": "It seems that `num_summed_dimensions` is missing in the config dict for serialization.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-04-06T07:53:58Z",
        "closed_at": "2020-04-06T17:32:26Z",
        "merged_at": "2020-04-06T17:32:26Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 34,
        "deletions": 31,
        "changed_files": 2,
        "created_at": "2020-04-04T03:06:08Z",
        "closed_at": "2020-04-04T04:41:27Z",
        "merged_at": "2020-04-04T04:41:27Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 16,
        "deletions": 10,
        "changed_files": 1,
        "created_at": "2020-04-02T16:45:23Z",
        "closed_at": "2020-04-03T05:13:55Z",
        "merged_at": "2020-04-03T05:13:55Z",
        "body": "With this change applied we could import and reuse lower-level functions like `create_training_instances` from thirdparty scripts.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2020-04-02T13:55:11Z",
        "closed_at": "2020-04-24T15:32:36Z",
        "merged_at": "2020-04-24T15:32:36Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 94,
        "deletions": 4,
        "changed_files": 3,
        "created_at": "2020-04-01T23:58:07Z",
        "closed_at": "2020-04-02T19:24:11Z",
        "merged_at": "2020-04-02T19:24:11Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2020-04-01T20:31:37Z",
        "closed_at": "2020-04-23T16:01:23Z",
        "merged_at": "2020-04-23T16:01:23Z",
        "body": "\u2026nd-to-end",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-03-31T16:31:04Z",
        "closed_at": "2020-03-31T19:01:30Z",
        "merged_at": "2020-03-31T19:01:30Z",
        "body": "Python 2 is deprecated. Tested by running the notebook in a Python 3 runtime.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 9,
        "changed_files": 1,
        "created_at": "2020-03-31T15:33:44Z",
        "closed_at": "2020-04-01T17:00:33Z",
        "merged_at": "2020-04-01T17:00:32Z",
        "body": "The output shape of the position embedding layer should be the same as the word embeddings, which is `[batch_size, sequence_length, hidden_size]`, instead of `[1, sequence_length, hidden_size]`.\r\n\r\nThis PR explicitly calls `tf.broadcast_to()` to ensure the tf.keras.layers.Add() layer on [L133](https://github.com/tensorflow/models/blob/651677f5645831fe748a7eb7fe59a8b05c921a52/official/nlp/modeling/networks/transformer_encoder.py#L133) won't complain about merging tensors with different batch sizes.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 17,
        "changed_files": 2,
        "created_at": "2020-03-31T05:48:07Z",
        "closed_at": "2020-03-31T17:35:35Z",
        "merged_at": "2020-03-31T17:35:35Z",
        "body": "Added owners for official and research model folders\r\nRemoved owners of removed folders",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 891,
        "deletions": 2,
        "changed_files": 8,
        "created_at": "2020-03-30T22:23:07Z",
        "closed_at": "2020-06-26T23:50:37Z",
        "merged_at": null,
        "body": "",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 78,
        "deletions": 82,
        "changed_files": 1,
        "created_at": "2020-03-30T06:49:13Z",
        "closed_at": "2020-03-30T18:16:53Z",
        "merged_at": "2020-03-30T18:16:53Z",
        "body": "Created a table to organize models\r\nAdded paper names\r\nAdded maintainer information",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 7,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2020-03-27T13:32:36Z",
        "closed_at": "2020-04-27T17:40:43Z",
        "merged_at": null,
        "body": "Issue : #8280 \r\n\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-03-20T13:51:34Z",
        "closed_at": "2020-04-29T19:31:46Z",
        "merged_at": null,
        "body": "Issue: #8320 ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-03-19T13:21:03Z",
        "closed_at": "2020-03-19T23:58:54Z",
        "merged_at": "2020-03-19T23:58:54Z",
        "body": "A small PR improving the error message",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 88,
        "deletions": 68,
        "changed_files": 25,
        "created_at": "2020-03-17T18:38:09Z",
        "closed_at": "2020-03-20T16:39:09Z",
        "merged_at": "2020-03-20T16:39:09Z",
        "body": "Issue : #8289 \r\n\r\n\r\ntf.compat.v1.logging implemented with absl module on suggestion by the maintainer of the project.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 8,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-03-17T08:12:41Z",
        "closed_at": "2020-03-17T14:08:52Z",
        "merged_at": null,
        "body": "Fix for install google-cloud-sdk package in Dockerfile. Change order of installation and add omitted apt packages before install google-cloud-sdk.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2020-03-14T19:40:21Z",
        "closed_at": "2020-03-17T04:16:39Z",
        "merged_at": "2020-03-17T04:16:39Z",
        "body": "Issue: #8293 ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-03-14T18:55:00Z",
        "closed_at": "2020-03-15T05:52:18Z",
        "merged_at": "2020-03-15T05:52:18Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 64,
        "deletions": 40,
        "changed_files": 18,
        "created_at": "2020-03-13T14:24:15Z",
        "closed_at": "2020-03-27T03:59:51Z",
        "merged_at": null,
        "body": "I am migrating more files with the lastest API for logging in tensorflow. Currently , updated a few files.\r\nIssue : #8289 ",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 10,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2020-03-13T13:49:32Z",
        "closed_at": "2020-03-22T17:48:08Z",
        "merged_at": null,
        "body": "Issue: #8287 ",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 27,
        "deletions": 22,
        "changed_files": 1,
        "created_at": "2020-03-13T13:29:13Z",
        "closed_at": "2020-06-21T04:17:09Z",
        "merged_at": null,
        "body": "Issue : #8285 ",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 14,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-03-13T11:29:36Z",
        "closed_at": "2020-04-20T04:01:35Z",
        "merged_at": null,
        "body": "@sherrym  & @shlens please have a look. Create README.md file for helping others what is inside directories.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-03-13T11:15:07Z",
        "closed_at": "2020-03-20T16:40:57Z",
        "merged_at": null,
        "body": "@ebrevdo   please approve this, update broken link.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 8,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2020-03-13T10:19:53Z",
        "closed_at": "2020-04-27T23:44:46Z",
        "merged_at": null,
        "body": "Issue : #8280 ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 7110,
        "changed_files": 49,
        "created_at": "2020-03-12T18:48:21Z",
        "closed_at": "2020-03-17T20:53:51Z",
        "merged_at": "2020-03-17T20:53:51Z",
        "body": "I've archived a copy of [the code with history in tensorflow_examples](https://github.com/tensorflow/examples/tree/master/community/en/r1/tutorials)\r\n\r\nNothing on  tensorflow.org refers to this directory anymore.\r\nNobody is maintaining this.\r\nIt's confusing for people landing here looking for models/official. \r\nThe copybara sync is off. \r\nLet's delete this. \r\n\r\nWe don't have good replacements for the `word2vec` or `quickdraw` tutorials, I've added them to our list for the next round of tutorials refresh. ",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 61,
        "deletions": 17,
        "changed_files": 8,
        "created_at": "2020-03-12T00:08:44Z",
        "closed_at": "2020-03-12T22:51:47Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-03-11T22:51:59Z",
        "closed_at": "2020-04-17T06:46:51Z",
        "merged_at": "2020-04-17T06:46:51Z",
        "body": "Thanks to @wooters!\r\n\r\nFixes #8267\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 47271,
        "deletions": 45424,
        "changed_files": 296,
        "created_at": "2020-03-09T10:43:10Z",
        "closed_at": "2021-01-31T07:27:29Z",
        "merged_at": null,
        "body": "This PR resolves #8248 in a way that it provides a `yapf` style file `official/.style.yapf` so that python files within the `official` directory (and all subdirectories) can be formatted in a consistent way.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 47271,
        "deletions": 45424,
        "changed_files": 296,
        "created_at": "2020-03-09T08:51:27Z",
        "closed_at": "2020-03-09T10:22:05Z",
        "merged_at": null,
        "body": "This PR will resolve #8248 by providing a `yapf` style file located in the `models/official` directory and formatting all python files using this setting.\r\n\r\nTo reproduce how I formatted code call\r\n```bash\r\nfind official/ -name '*.py' -print0 | xargs -0 yapf -i\r\n```\r\nfrom the `models` directory.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 35,
        "deletions": 16,
        "changed_files": 1,
        "created_at": "2020-03-07T15:56:01Z",
        "closed_at": "2020-03-20T03:13:47Z",
        "merged_at": "2020-03-20T03:13:47Z",
        "body": "By this PR I propose several improvements to the tokenizer found in transformer model:\r\n\r\n1. Unhardcode alphanumeric charset (it is still the default). This help me to use tokenizer in tasks which require a different charsets\r\n2. Safety check before inserting EOL. The check detects the situation where users don't include default `RESERVE_TOKENS` list into their custom `reserved_tokens` argument.\r\n3. ~~(updated)  Debug-print the status of long-runnning token counting~~",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 77,
        "deletions": 31,
        "changed_files": 1,
        "created_at": "2020-03-06T01:15:54Z",
        "closed_at": "2021-08-30T15:46:12Z",
        "merged_at": null,
        "body": "Using a combined (bigger) embedding table followed by tensor slicing\r\nresults in an extra write and read operation, which can be completely\r\navoided if we maintain separate embedding tables. This results in a\r\nsignificant performance improvement on the GPU.\r\n\r\nAs a sanity check, when I fixed the weights of the embedding to a\r\nconstant, and the weights were the same for all other layers before the\r\ntraining, the value of the logits were the same after one step. After\r\nthe 1st step, the values will differ due to non-determinism in gradient\r\ncalculations.\r\n\r\nFor the following experiment, I used\r\n  batch size = 99000\r\n  synthetic data\r\n  xla (on / off)\r\n\r\nWithout XLA\r\n  Original: ~ 7.0 M examples/sec\r\n  Modified: ~ 7.9 M examples/sec (12.8 % improvement)\r\n\r\nWith XLA:\r\n  Original: ~ 9.2 M examples/sec\r\n  Modified: ~ 9.5 M examples/sec (3.2 % improvement)\r\n\r\npython ncf_keras_main.py \\\r\n    --model_dir /tmp/ \\\r\n    --data_dir data \\\r\n    --dataset ml-20m \\\r\n    --hooks --clean \\\r\n    --seed 3 \\\r\n    --train_epochs 3 \\\r\n    --batch_size 99000 \\\r\n    --eval_batch_size 99000 \\\r\n    --layers 256,256,128,64 \\\r\n    --num_factors 64 \\\r\n    --hr_threshold 0.635 \\\r\n    --ml_perf \\\r\n    --num_gpus 1 \\\r\n    --keras_use_ctl \\\r\n    --enable_xla \\\r\n    --use_synthetic_data\r\n\r\nNote that since NCF is very sensitive, the number of epochs to convergence can change.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 26,
        "deletions": 26,
        "changed_files": 1,
        "created_at": "2020-03-05T16:40:31Z",
        "closed_at": "2020-03-20T16:42:08Z",
        "merged_at": null,
        "body": "Issue: #8249 \r\n\r\nAlexnet in tutorials folder was modifed 3 years ago hence did not support the latest Tensorflow's API. \r\nI thought updating it to TF2.x will help keep this repo updated. Hence, this PR. ",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-03-05T12:47:57Z",
        "closed_at": "2020-04-13T21:47:39Z",
        "merged_at": null,
        "body": "Issue: #8246\r\n\r\nCurrent Results: \r\n![Screenshot from 2020-03-05 18-07-15](https://user-images.githubusercontent.com/41910134/75982953-a07d4800-5f0d-11ea-8822-3c5d36824a11.png)\r\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-03-05T07:07:49Z",
        "closed_at": "2020-03-06T00:10:35Z",
        "merged_at": null,
        "body": "samples models have been deleted.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-03-04T11:55:29Z",
        "closed_at": "2020-03-06T00:09:12Z",
        "merged_at": "2020-03-06T00:09:12Z",
        "body": "Remove non existing samples folder mention",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-03-04T11:53:42Z",
        "closed_at": "2020-03-06T00:10:17Z",
        "merged_at": "2020-03-06T00:10:16Z",
        "body": "Remove non existing samples folder mention",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-03-03T16:28:16Z",
        "closed_at": "2020-03-03T21:13:46Z",
        "merged_at": null,
        "body": "Issue :  #8231\r\n\r\nSince the aim of the Repo is to convert most of their models compatible with TF 2.x so, i made this example compatible with TF 2.x. ",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 73,
        "deletions": 48,
        "changed_files": 3,
        "created_at": "2020-03-02T20:46:58Z",
        "closed_at": "2020-04-17T00:19:29Z",
        "merged_at": "2020-04-17T00:19:29Z",
        "body": "PiperOrigin-RevId: 298380851",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-03-02T05:45:29Z",
        "closed_at": "2020-04-24T15:36:29Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-03-01T22:27:04Z",
        "closed_at": "2020-04-24T06:32:30Z",
        "merged_at": "2020-04-24T06:32:29Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2020-03-01T00:13:43Z",
        "closed_at": "2020-04-24T06:43:05Z",
        "merged_at": "2020-04-24T06:43:05Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-02-28T21:15:28Z",
        "closed_at": "2020-02-28T23:38:58Z",
        "merged_at": "2020-02-28T23:38:58Z",
        "body": "creating config.yml to disable blank issues",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2020-02-25T04:28:22Z",
        "closed_at": "2020-02-25T18:21:11Z",
        "merged_at": "2020-02-25T18:21:11Z",
        "body": "Issue: #8190 ",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 7,
        "changed_files": 2,
        "created_at": "2020-02-24T17:11:05Z",
        "closed_at": "2020-02-25T05:24:57Z",
        "merged_at": null,
        "body": "Issue : #8187 ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-02-24T07:46:59Z",
        "closed_at": "2020-02-24T18:07:49Z",
        "merged_at": "2020-02-24T18:07:49Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-02-23T16:56:06Z",
        "closed_at": "2020-04-25T22:29:16Z",
        "merged_at": null,
        "body": "Issue #8024 Done.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 28,
        "deletions": 15,
        "changed_files": 1,
        "created_at": "2020-02-21T23:41:18Z",
        "closed_at": "2020-04-23T11:48:44Z",
        "merged_at": null,
        "body": "(Retry of pull request).",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 28,
        "deletions": 15,
        "changed_files": 1,
        "created_at": "2020-02-21T16:09:04Z",
        "closed_at": "2020-02-22T01:24:05Z",
        "merged_at": "2020-02-22T01:24:04Z",
        "body": "Update example notebook for YAMNet to work with wav files with any sampling rate.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 56,
        "deletions": 56,
        "changed_files": 4,
        "created_at": "2020-02-21T01:47:44Z",
        "closed_at": "2020-06-15T09:43:20Z",
        "merged_at": null,
        "body": "1. update to tf2.0 for deep_speech, by tf_upgrade_v2\r\n2. compatible with tf1.15",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 730768,
        "changed_files": 501,
        "created_at": "2020-02-21T00:11:37Z",
        "closed_at": "2020-02-21T01:12:22Z",
        "merged_at": "2020-02-21T01:12:22Z",
        "body": "delete syntax net to reduce repo size as syntax net is going to move to google-research/",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-02-20T22:21:09Z",
        "closed_at": "2020-02-21T01:12:10Z",
        "merged_at": "2020-02-21T01:12:10Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 23,
        "deletions": 12,
        "changed_files": 1,
        "created_at": "2020-02-19T23:31:33Z",
        "closed_at": "2020-02-20T03:00:28Z",
        "merged_at": "2020-02-20T03:00:28Z",
        "body": "Somehow explicitly setting a tensor flow graph context manager fixed the batch-size problem that appeared for tensorflow 2.0.",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 35,
        "deletions": 14,
        "changed_files": 2,
        "created_at": "2020-02-19T23:26:03Z",
        "closed_at": "2020-02-20T01:53:36Z",
        "merged_at": null,
        "body": "Somehow explicitly initializing the tf graph fixed the batching problem.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 346,
        "deletions": 3,
        "changed_files": 11,
        "created_at": "2020-02-19T22:40:55Z",
        "closed_at": "2020-02-20T19:26:36Z",
        "merged_at": "2020-02-20T19:26:36Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 21,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-02-19T21:29:33Z",
        "closed_at": "2020-02-20T01:30:48Z",
        "merged_at": "2020-02-20T01:30:48Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-02-19T05:14:56Z",
        "closed_at": "2020-04-24T07:20:30Z",
        "merged_at": "2020-04-24T07:20:30Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 12,
        "changed_files": 1,
        "created_at": "2020-02-17T20:16:22Z",
        "closed_at": "2020-02-18T03:44:45Z",
        "merged_at": "2020-02-18T03:44:45Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 14196,
        "deletions": 715,
        "changed_files": 58,
        "created_at": "2020-02-17T06:40:39Z",
        "closed_at": "2020-04-24T05:04:58Z",
        "merged_at": null,
        "body": "my mistake...",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-02-14T00:33:56Z",
        "closed_at": "2020-02-19T21:36:44Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 53,
        "deletions": 37,
        "changed_files": 14,
        "created_at": "2020-02-13T21:43:40Z",
        "closed_at": "2020-02-13T23:41:22Z",
        "merged_at": "2020-02-13T23:41:22Z",
        "body": "This change contains multiple minor changes to make the Attention OCR model compatible with Python 3 as well decreases size of fsns-00000-of-00001 file from 7.6mb to 632kb.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 3367,
        "changed_files": 31,
        "created_at": "2020-02-08T04:48:52Z",
        "closed_at": "2020-02-12T07:09:07Z",
        "merged_at": "2020-02-12T07:09:07Z",
        "body": "Remove differential_privacy and morph_net from research folder because they have been migrated to google-research/ for a while",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-02-05T00:01:32Z",
        "closed_at": "2022-06-19T18:15:13Z",
        "merged_at": null,
        "body": "**The name tf.gfile.GFile is deprecated.  I have replaced it with updated tf.io.gfile.GFile instead. To avoid unnecessary warnings**",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-02-02T23:25:29Z",
        "closed_at": "2020-05-09T01:25:03Z",
        "merged_at": null,
        "body": "untar option is deprecated, per https://www.tensorflow.org/api_docs/python/tf/keras/utils/get_file",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-02-02T13:18:29Z",
        "closed_at": "2020-04-25T01:10:23Z",
        "merged_at": "2020-04-25T01:10:23Z",
        "body": "resolves #8073 ",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-01-30T14:34:05Z",
        "closed_at": "2020-01-30T16:19:28Z",
        "merged_at": "2020-01-30T16:19:28Z",
        "body": "Commit https://github.com/tensorflow/models/commit/4dcd5116adf2b4d657858060396f8ce8a0127fab removed the GAN part of the repo, hence it can be removed from the list in the README file. Thanks.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2020-01-29T20:42:17Z",
        "closed_at": "2020-01-29T22:35:54Z",
        "merged_at": "2020-01-29T22:35:54Z",
        "body": "Binary write mode W might cause problems for Python 3 and Windows.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 778,
        "changed_files": 7,
        "created_at": "2020-01-29T02:50:18Z",
        "closed_at": "2020-01-30T07:47:50Z",
        "merged_at": "2020-01-30T07:47:50Z",
        "body": "Delete legacy research/resnet as there is no maintenance.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 6,
        "changed_files": 2,
        "created_at": "2020-01-27T17:30:32Z",
        "closed_at": "2020-02-04T18:21:56Z",
        "merged_at": "2020-02-04T18:21:56Z",
        "body": "I am updating the code according to the recommendation in the deprecation message.\r\n\r\n```python\r\n@tf_export(\"while_loop\", v1=[])\r\n@deprecation.deprecated_arg_values(\r\n    None,\r\n    \"\"\"back_prop=False is deprecated. Consider using tf.stop_gradient instead.\r\nInstead of:\r\nresults = tf.while_loop(c, b, vars, back_prop=False)\r\nUse:\r\nresults = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\"\"\",\r\n```",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2020-01-27T15:10:46Z",
        "closed_at": "2020-04-25T04:41:34Z",
        "merged_at": "2020-04-25T04:41:34Z",
        "body": "There is a simple typo in usage.\r\n\r\n```bash\r\npython export_inference_graph\r\n```\r\ncan not execute python.\r\n\r\nI changed this to\r\n\r\n```bash\r\npython export_inference_graph.py\r\n```\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-01-23T14:06:18Z",
        "closed_at": "2020-01-24T01:58:05Z",
        "merged_at": "2020-01-24T01:58:05Z",
        "body": "The colab and github link were in wrong hrefs.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2583,
        "changed_files": 24,
        "created_at": "2020-01-22T22:19:52Z",
        "closed_at": "2020-01-24T19:52:10Z",
        "merged_at": "2020-01-24T19:52:10Z",
        "body": "These are being moved to github.com/tensorflow/java\r\n\r\nSee tensorflow/java#22",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1436,
        "deletions": 1071,
        "changed_files": 58,
        "created_at": "2020-01-21T22:44:13Z",
        "closed_at": "2020-01-22T02:08:14Z",
        "merged_at": "2020-01-22T02:08:14Z",
        "body": "Internal cleanup (py2->py3) plus the following changes:\r\n289455329 by Sergio Guadarrama:\r\n  Adds warmup_epochs to train_image_classifier\r\n\r\n285513318  by Sergio Guadarrama:\r\n\r\n    Adds a script for post-training quantization\r\n\r\n284222305  by Sergio Guadarrama:\r\n\r\n    Modified squeeze-excite operation to accommodate tensors of undefined (Nonetype) H/W.\r\n\r\n282028343  by Sergio Guadarrama:\r\n\r\n    Add MobilenetV3 and MobilenetEdgeTPU to the slim/nets_factory.\r\n\r\nPiperOrigin-RevId: 289455329",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2020-01-21T14:08:55Z",
        "closed_at": "2020-01-21T19:42:40Z",
        "merged_at": "2020-01-21T19:42:40Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-01-19T02:27:33Z",
        "closed_at": "2020-01-21T22:24:29Z",
        "merged_at": null,
        "body": "This pr fixs bug of class DenseEinsum.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 31,
        "deletions": 35,
        "changed_files": 7,
        "created_at": "2020-01-18T06:50:16Z",
        "closed_at": "2020-01-18T15:30:35Z",
        "merged_at": "2020-01-18T15:30:35Z",
        "body": "- Made code work with either TF v1.x or TF v2.x, while explicitly\r\n  enabling v1.x behavior.l\r\n- Pulled slim from tf_slim package instead of through tensorflow\r\n  contrib. Note that tf_slim itself uses tensorflow contrib so\r\n  it requires using TF v1.x for now (referenced a relevant PR\r\n  which should remove this limitation once it gets merged).\r\n- Removed all mention of scipy. Switched wav writing to soundfile.\r\n- Switched package name to soundfile instead of pysoundfile. The\r\n  former is the newer name.\r\n- Updated installation instructions for both vggish and yamnet to\r\n  reflect these changes.\r\n- Tested new installation procedures. vggish works with TF v1.15,\r\n  yamnet works with TF v1.15.0 as well as TF v2.1.0.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-01-16T18:25:24Z",
        "closed_at": "2020-04-25T22:59:53Z",
        "merged_at": "2020-04-25T22:59:53Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-01-15T07:42:48Z",
        "closed_at": "2020-01-25T07:36:14Z",
        "merged_at": null,
        "body": "Link to google colab fixed",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-01-13T22:14:10Z",
        "closed_at": "2020-01-14T03:34:52Z",
        "merged_at": "2020-01-14T03:34:52Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2020-01-13T15:53:08Z",
        "closed_at": "2020-01-13T21:21:15Z",
        "merged_at": "2020-01-13T21:21:15Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-01-13T14:45:25Z",
        "closed_at": "2020-04-26T00:53:47Z",
        "merged_at": null,
        "body": "Change the current URL in Google Colab link (https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb) for the correct one URL",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 9769,
        "deletions": 0,
        "changed_files": 26,
        "created_at": "2020-01-12T21:42:12Z",
        "closed_at": "2020-04-24T15:34:04Z",
        "merged_at": null,
        "body": "From https://github.com/google-research/ALBERT",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 0,
        "changed_files": 0,
        "created_at": "2020-01-08T20:29:13Z",
        "closed_at": "2020-04-25T03:52:09Z",
        "merged_at": null,
        "body": "fix means to take list [mean_r, mean_g, mean_b] e.g. [ 109.8 , 109.8 , 109.8 ] in subtract_channel_mean in config file for objection detection module",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 118,
        "deletions": 89,
        "changed_files": 9,
        "created_at": "2020-01-08T03:40:18Z",
        "closed_at": "2020-01-08T05:31:24Z",
        "merged_at": "2020-01-08T05:31:24Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2020-01-08T03:38:16Z",
        "closed_at": "2020-08-11T05:33:31Z",
        "merged_at": null,
        "body": "PiperOrigin-RevId: 285447238",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2020-01-06T15:03:28Z",
        "closed_at": "2020-04-26T00:55:06Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2020-01-01T21:23:20Z",
        "closed_at": "2020-01-02T17:51:29Z",
        "merged_at": "2020-01-02T17:51:29Z",
        "body": "The prediction returned in `predict_labels_multi_scale()` is `outputs_to_predictions` instead of `predictions`.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-12-24T23:50:35Z",
        "closed_at": "2020-04-24T07:22:04Z",
        "merged_at": "2020-04-24T07:22:04Z",
        "body": "typo fixed",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-12-22T18:10:57Z",
        "closed_at": "2019-12-30T21:00:57Z",
        "merged_at": "2019-12-30T21:00:57Z",
        "body": "distribution strategy should be `mirrored`",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-12-19T21:42:48Z",
        "closed_at": "2020-01-23T07:09:32Z",
        "merged_at": "2020-01-23T07:09:32Z",
        "body": "\u2026_Execution.ipynb\r\n\r\nColab will soon update the default version of tensorflow to 2.1.0. In order for this notebook to continue to work, I'm adding a line magic that will ensure this notebook continues to use tensorflow 1.x and execute without errors.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-12-19T05:19:40Z",
        "closed_at": "2019-12-22T04:46:52Z",
        "merged_at": "2019-12-22T04:46:52Z",
        "body": "tensorflow 2.0 cannot run a3c example",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-12-18T18:23:37Z",
        "closed_at": "2020-01-02T18:44:27Z",
        "merged_at": "2020-01-02T18:44:27Z",
        "body": "As in the Keras compile/fit mode (https://github.com/tensorflow/models/blob/master/official/vision/image_classification/resnet_imagenet_main.py#L62), this PR enables the persistent CUDNN batch norm by default for better performance in CTL ResNet50.\r\n\r\nfyi @nluehr ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-12-16T12:40:23Z",
        "closed_at": "2020-04-25T03:31:54Z",
        "merged_at": "2020-04-25T03:31:54Z",
        "body": " to prevent crash when running data_sampler.\r\n\r\nRunning `example_main.py` would result in:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"example_main.py\", line 453, in <module>\r\n    app.run(main)\r\n  File \"/usr/local/anaconda3/envs/tf/lib/python3.6/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/anaconda3/envs/tf/lib/python3.6/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"example_main.py\", line 237, in main\r\n    sampled_vals = sample_data(data_type, num_contexts)\r\n  File \"example_main.py\", line 127, in sample_data\r\n    dataset, opt_mushroom = sample_mushroom_data(file_name, num_contexts)\r\n  File \"/Users/tmo/Nodes/tf-models/research/deep_contextual_bandits/bandits/data/data_sampler.py\", line 74, in sample_mushroom_data\r\n    eat_reward = eat_reward.reshape((num_contexts, 1))\r\n  File \"/usr/local/anaconda3/envs/tf/lib/python3.6/site-packages/pandas/core/generic.py\", line 5179, in __getattr__\r\n    return object.__getattribute__(self, name)\r\nAttributeError: 'Series' object has no attribute 'reshape'\r\n```",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-12-14T19:04:35Z",
        "closed_at": "2019-12-20T07:59:16Z",
        "merged_at": "2019-12-20T07:59:15Z",
        "body": "The flag needed is not `-h` or `--help` it's `--helpfull`. ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-12-13T06:30:31Z",
        "closed_at": "2019-12-14T00:59:11Z",
        "merged_at": "2019-12-14T00:59:11Z",
        "body": "Nit, needs new line",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 342,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2019-12-12T06:11:13Z",
        "closed_at": "2021-07-13T06:48:37Z",
        "merged_at": null,
        "body": "This commit adds a terminal parameter so that users can decide whether they want to include masks or not. In the previous version, there was no optional argument for including masks if they want to execute the script from the terminal and the default value for include_masks was false. With this commit users can include masks in their tf records ",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-12-09T18:56:56Z",
        "closed_at": "2020-04-26T00:57:17Z",
        "merged_at": null,
        "body": "Use otherwise unused variable",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 560,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-12-09T05:09:20Z",
        "closed_at": "2019-12-10T18:13:14Z",
        "merged_at": null,
        "body": "Hi @all, \r\n\r\nThis is my first ever contribution to TensorFlow repo. I have created a notebook having a way to do transfer learning using Function API in **TensorFlow 2.0** and with the TensorBorad plugin in the notebook. It will really help people who just started in TensorFlow to how to build a neural network using Transfer Learning with the latest TensorFlow Version 2.0 using Python.\r\n\r\nKindly merge this pull request to the actual repo if you see it can give value to the local community. \r\n\r\nThanks.",
        "comments": 9
    },
    {
        "merged": false,
        "additions": 10,
        "deletions": 9,
        "changed_files": 6,
        "created_at": "2019-12-08T04:30:57Z",
        "closed_at": "2020-04-27T23:02:27Z",
        "merged_at": null,
        "body": "",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 197,
        "deletions": 44,
        "changed_files": 4,
        "created_at": "2019-12-06T06:27:02Z",
        "closed_at": "2020-01-16T06:37:55Z",
        "merged_at": null,
        "body": "This reverts commit f079ed2ec359bc0f011bf5d48fc77a6900f360e2.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-12-04T13:59:54Z",
        "closed_at": "2020-04-26T00:58:45Z",
        "merged_at": null,
        "body": "These two links were pointing to the inverted paths.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2019-12-02T23:02:23Z",
        "closed_at": "2020-04-25T04:46:49Z",
        "merged_at": "2020-04-25T04:46:48Z",
        "body": "The current Dockerfile is not functional anymore. This commit fixes it by the following changes:\r\n - install gpg-agent, update google-cloud-sdk installation from https://cloud.google.com/sdk/docs/quickstart-debian-ubuntu\r\n - use non-interactive front end to set default tzdata configuration (required for TF object detection installation)\r\n - fix the tensorflow configuration\r\n\r\nLeaving the base image untouched, although nightly-devel is no longer actively maintained. It may be worth upgrading as a separate effort later.\r\n\r\nResolves https://github.com/tensorflow/models/issues/7710, https://github.com/tensorflow/models/issues/6068",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2019-11-29T14:54:22Z",
        "closed_at": "2022-08-08T19:33:04Z",
        "merged_at": null,
        "body": "Currently Tensorflow 2.0 is not supported in this codebase.\r\n\r\nModified the installation instructions to suggest installing the latest Tensorflow 1.X version that passes the installation verification tests.\r\n\r\nThis should be changed once the code is migrated to Tensorflow 2.0, but in the meantime this will make for a much better experience for anyone trying to install and use this library.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-11-29T13:22:47Z",
        "closed_at": "2019-11-30T06:11:37Z",
        "merged_at": "2019-11-30T06:11:37Z",
        "body": "Before that, it called __tensorflow.compat.v1.compat.v1.io.tf_record_iterator__ function, which does not exist, instead of __tensorflow.compat.v1.io.tf_record_iterator__.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-11-29T05:04:31Z",
        "closed_at": "2019-11-30T05:55:21Z",
        "merged_at": "2019-11-30T05:55:21Z",
        "body": "The wget command for the KITTI dataset in the currently downloads the html for GitHub's fancy display of the text file. This change fixes that so it instead downloads the raw txt file (no more trying to resolve host '<')",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 10,
        "deletions": 10,
        "changed_files": 1,
        "created_at": "2019-11-28T23:58:06Z",
        "closed_at": "2020-04-24T05:12:23Z",
        "merged_at": null,
        "body": "I wanted to have a look at an ImageNet example and came across this. However, it was full of deprecation warnings, so I've dropped in the suggested functions in their stead. There's still one warning left, however:\r\n\r\n```\r\n2019-11-29 00:50:28.988072: W tensorflow/core/framework/op_def_util.cc:370] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef \r\nversion 9. Use tf.nn.batch_normalization().\r\n```\r\n\r\nI wasn't as sure as to how to respond to this one, as there's no mention of BatchNormWithGlobalNormalization anywhere in the example, so I've left that one.\r\n\r\nRegardless, this set of changes I've made is at least an improvement. Now both 2.0 and 1.15 users can use this example; beforehand only 1.15 users could.\r\n\r\nI have signed the contributors agreement.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-11-28T01:04:27Z",
        "closed_at": "2020-04-24T05:40:28Z",
        "merged_at": "2020-04-24T05:40:28Z",
        "body": "Add notice about implementation discrepancy.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1646,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2019-11-25T08:06:30Z",
        "closed_at": "2020-03-10T01:40:19Z",
        "merged_at": null,
        "body": "Add autoaugment compatible with tensorflow2.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-11-22T07:21:46Z",
        "closed_at": "2020-04-26T00:59:27Z",
        "merged_at": null,
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1231,
        "deletions": 0,
        "changed_files": 8,
        "created_at": "2019-11-21T14:08:21Z",
        "closed_at": "2019-11-21T20:12:21Z",
        "merged_at": "2019-11-21T20:12:21Z",
        "body": "We are publishing a pertained audio event model based on the AudioSet data.\r\n@plakal : I'd be grateful for an independent test before a merge.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 22,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-11-21T07:27:27Z",
        "closed_at": "2019-11-22T20:52:21Z",
        "merged_at": "2019-11-22T20:52:21Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 18,
        "deletions": 10,
        "changed_files": 1,
        "created_at": "2019-11-21T07:26:29Z",
        "closed_at": "2019-11-21T20:56:28Z",
        "merged_at": "2019-11-21T20:56:28Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 11,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2019-11-20T18:18:39Z",
        "closed_at": "2019-11-21T07:24:06Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 12,
        "changed_files": 1,
        "created_at": "2019-11-20T10:47:21Z",
        "closed_at": "2019-11-21T00:50:10Z",
        "merged_at": "2019-11-21T00:50:10Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-11-18T23:34:18Z",
        "closed_at": "2019-11-21T22:59:57Z",
        "merged_at": "2019-11-21T22:59:57Z",
        "body": "Note that during the transition period tstring is typedef'ed to\r\nstd::string.\r\n\r\nSee: https://github.com/tensorflow/community/pull/91",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-11-15T15:12:44Z",
        "closed_at": "2023-03-01T01:19:50Z",
        "merged_at": null,
        "body": "Current shard calculation produces tfrecord files with greatly differing filesizes - 100 shard test produced files ranging form 45% to 0% of the total dataset.\r\n\r\nTo fix the problem, I copied over the shard calculation logic from create_coco_tf_record.py",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1193,
        "deletions": 117,
        "changed_files": 67,
        "created_at": "2019-11-13T09:58:56Z",
        "closed_at": "2019-11-13T18:36:48Z",
        "merged_at": "2019-11-13T18:36:48Z",
        "body": "280142968  by Zhichao Lu:\r\n\r\n    Opensource MobilenetEdgeTPU + ssdlite into third-party object detection APIs on EdgeTPU.\r\n\r\n--\r\n280134001  by Zhichao Lu:\r\n\r\n    Adds MobilenetEdgeTpu + ssdlite into internal object detection APIs on EdgeTPU.\r\n\r\n--\r\n278941778  by Zhichao Lu:\r\n\r\n    Add support for fixed input shapes for 'encoded_image_string_tensor' and 'tf_example' inputs.\r\n\r\n--\r\n278933274  by Zhichao Lu:\r\n\r\n      Adding fool proof check to avoid using 1x1 depthwise conv op.\r\n\r\n--\r\n278762192  by Zhichao Lu:\r\n\r\n    Ensure correct number of iterations after training resumes.\r\n\r\n--\r\n278746440  by Zhichao Lu:\r\n\r\n    Internal change.\r\n\r\n--\r\n278006953  by Zhichao Lu:\r\n\r\n    Internal changes to tf.contrib symbols\r\n\r\n--\r\n278006330  by Zhichao Lu:\r\n\r\n    Internal changes to tf.contrib symbols\r\n\r\n--\r\n277593959  by Zhichao Lu:\r\n\r\n      Make the ssd_feature_extractor_test.py PY3 compatible. The \"six.zip\" will use \"itertools.izip\" in Python 2 and \"zip\" in Python 3.\r\n\r\n--\r\n277344551  by Zhichao Lu:\r\n\r\n    Internal change.\r\n\r\n--\r\n277154953  by Zhichao Lu:\r\n\r\n    Conditionally use keras based optimizers so that check-pointing works correctly.\r\n    This change also enables summaries on TPU which were previously not enabled\r\n    due to a bug.\r\n\r\n--\r\n277087572  by Zhichao Lu:\r\n\r\n    Fix resizing boxes when using keep_aspect_ratio_rezier with padding.\r\n\r\n--\r\n275898543  by Zhichao Lu:\r\n\r\n    Support label_map_proto as input in label_map_util.\r\n\r\n--\r\n275891248  by Zhichao Lu:\r\n\r\n    Fix top-k computation logic for boxes to consider all classes per location.\r\n\r\n--\r\n275347137  by Zhichao Lu:\r\n\r\n    Add force_no_resize flag in eval.proto which replaces\r\n    the resize config with identity resizer. This is useful\r\n    when we want to test at the original image resolution.\r\n\r\n--\r\n\r\nPiperOrigin-RevId: 280142968",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-11-12T18:54:41Z",
        "closed_at": "2019-11-19T00:27:16Z",
        "merged_at": "2019-11-19T00:27:16Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-11-12T11:42:19Z",
        "closed_at": "2020-04-24T15:06:41Z",
        "merged_at": null,
        "body": "changed the link for kitti_archives_to_download.txt to point to the raw file rather than just the github URL.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-11-12T02:04:40Z",
        "closed_at": "2020-04-26T00:59:54Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 251,
        "deletions": 0,
        "changed_files": 4,
        "created_at": "2019-11-10T14:20:19Z",
        "closed_at": "2019-11-11T19:54:16Z",
        "merged_at": null,
        "body": "",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 12,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2019-11-07T13:16:53Z",
        "closed_at": "2020-03-19T13:18:20Z",
        "merged_at": null,
        "body": "Hi. Let me suggest 2 patches that would make BERT model more customizable:\r\n1. Allows users to pass custom `get_bert_model`.\r\n2. Builds BERT's components as early as possible.\r\n\r\nThe particular problem I'm trying to solve is following: Currently Keras calls `build`s  from `__call__` which doesn't left any space for model modifications. This PR (the 2nd patch) adds `build()` calls to constructors whenever possible to offer user an opportunity to change some of the model's components before hard-wiring things with `__call__`s. This approach should reduce time/efforts required to prepare model experiments. Please check an example below.\r\n\r\nNote that some time ago I started a related topic in TFdev mailing list:  https://groups.google.com/a/tensorflow.org/forum/#!topic/developers/B57l_ygjBPU\r\n\r\n\r\n```py\r\nfrom mytweaks import CustomTransformerBlock\r\n\r\ndef get_custom_bert_model(input_word_ids, input_mask, input_type_ids, config=None, name=None, float_type=tf.float32):\r\n  bert_model_layer = BertModel(config=config, float_type=float_type, name=name)\r\n  \r\n  # Added part: update some (in this case all) layers of encoder. Wouldn't be possible wothout patch\r\n  new_layers = []  \r\n  for i,tb in enumerate(bert_model_layer.encoder.layers):\r\n    self=tb\r\n    new_layers.append(CustomTransformerBlock(\r\n          hidden_size=self.hidden_size,\r\n          num_attention_heads=self.num_attention_heads,\r\n          intermediate_size=self.intermediate_size,\r\n          intermediate_activation=self.intermediate_activation,\r\n          hidden_dropout_prob=self.hidden_dropout_prob,\r\n          attention_probs_dropout_prob=self.attention_probs_dropout_prob,\r\n          initializer_range=self.initializer_range,\r\n          backward_compatible=self.backward_compatible,\r\n          float_type=self.float_type,\r\n          name=(\"custom_layer_%d\" % i)))\r\n  bert_model_layer.encoder.layers = new_layers\r\n\r\n  pooled_output, sequence_output = bert_model_layer(input_word_ids, input_mask,\r\n                                                    input_type_ids)\r\n  bert_model = tf.keras.Model(\r\n      inputs=[input_word_ids, input_mask, input_type_ids],\r\n      outputs=[pooled_output, sequence_output])\r\n  return bert_model\r\n\r\ndef run():\r\n  ...\r\n  model,_ = classifier_model(bert_config, tf.float32, num_labels, max_seq_length,\r\n                                              custom_bert_model=get_custom_bert_model)\r\n  model.compile(...)\r\n  model.fit(...)\r\n\r\n```",
        "comments": 13
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-11-07T12:58:22Z",
        "closed_at": "2019-11-07T19:01:07Z",
        "merged_at": "2019-11-07T19:01:07Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-11-06T19:05:56Z",
        "closed_at": "2019-11-24T23:45:52Z",
        "merged_at": "2019-11-24T23:45:52Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-11-06T06:57:19Z",
        "closed_at": "2020-04-25T03:41:33Z",
        "merged_at": null,
        "body": "Interchanging Colab and Git Links",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-11-01T19:12:16Z",
        "closed_at": "2019-11-02T03:15:33Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-11-01T10:03:44Z",
        "closed_at": "2019-11-01T16:41:40Z",
        "merged_at": null,
        "body": "API changed \r\nhttps://www.tensorflow.org/api_docs/python/tf/data/experimental/DistributeOptions",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 84,
        "deletions": 84,
        "changed_files": 42,
        "created_at": "2019-10-31T18:52:55Z",
        "closed_at": "2020-04-24T06:17:15Z",
        "merged_at": null,
        "body": "It is quite confusing that `GFile` and `FastGFile` co-exists in this repo although their implementations are the very same.\r\nThus for consistency reasons, I would follow https://github.com/tensorflow/tensorflow/issues/12663 's conclusion to favor of `GFile` here as well.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-10-29T14:05:06Z",
        "closed_at": "2020-04-26T01:00:48Z",
        "merged_at": null,
        "body": "The Colab and Github links were switched.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 350,
        "deletions": 350,
        "changed_files": 189,
        "created_at": "2019-10-27T12:39:12Z",
        "closed_at": "2019-10-27T14:07:46Z",
        "merged_at": null,
        "body": "to avoid depcaration warning",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 11316,
        "deletions": 8961,
        "changed_files": 195,
        "created_at": "2019-10-26T09:51:57Z",
        "closed_at": "2019-10-28T20:47:04Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 10,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2019-10-25T07:49:18Z",
        "closed_at": "2019-10-26T06:48:50Z",
        "merged_at": null,
        "body": "This is an updated version, with conflict fixing of https://github.com/tensorflow/models/pull/5144\r\n\r\nAll credits must go to @bleqdyce\r\n\r\n_NB: I've tried to merge directly in his branch on https://github.com/bleqdyce/models/pull/1 , no news so it might be better to do it directly here_",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 26,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2019-10-25T05:40:38Z",
        "closed_at": "2020-06-21T03:19:38Z",
        "merged_at": "2020-06-21T03:19:37Z",
        "body": "Added model save option once we train the model on IMDB Data set \r\n1. Save model checkpoint with best accuracy while training (epoch based)\r\n2. Save the whole model (big file)\r\n\r\nLet me know if any changes needed further I have trained and tested the same and used the model for inferencing as well \r\nwhile using the saved model for prediction create CNN with same voc_size as you have set while training the model.",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-10-24T17:10:24Z",
        "closed_at": "2020-04-26T01:03:19Z",
        "merged_at": null,
        "body": "Change to use the new website where the Open Images dataset is hosted",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-10-24T11:03:55Z",
        "closed_at": "2019-10-25T03:23:44Z",
        "merged_at": "2019-10-25T03:23:44Z",
        "body": "Using this code on GPU, was not logging \"learning_rate\" and \"gradient norm\" etc, basically items in metric_dict. We need to use simple \"tf.summary.scalar\" instead of contrib one to log these params when \"use_tpu\" is False. Function \"record_scalars\" gets called on in case when \"use_tpu\" is False. So this change helped tensors in metric dict properly show up in Tensorboard summary. Tested on Tensorflow 1.14.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-10-23T12:36:24Z",
        "closed_at": "2019-10-23T22:14:07Z",
        "merged_at": "2019-10-23T22:14:07Z",
        "body": "Minor change to make git ignore .mypy_cache folders",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2019-10-22T12:46:48Z",
        "closed_at": "2019-10-23T01:02:37Z",
        "merged_at": "2019-10-23T01:02:36Z",
        "body": "Change one_hot+matmul on gather. It's important for conversion to tflite because one_hot+matmul seriously change model predictions after conversion in tflite format. Gather does the same operations and doesn't have the same effect.\r\n\r\nIt is related to problem in tflite. Issue: https://github.com/tensorflow/tensorflow/issues/33613.\r\nMy fix allow to convert model to tflite before this problem will be solved",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-10-21T19:16:44Z",
        "closed_at": "2019-10-21T21:22:47Z",
        "merged_at": "2019-10-21T21:22:47Z",
        "body": "arparse -> argparse",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-10-21T19:00:11Z",
        "closed_at": "2022-06-30T14:18:46Z",
        "merged_at": null,
        "body": "So as to match that of eval_util.py, i.e.\r\n\r\nhttps://github.com/bgalvao/models/blob/6766e6ddfabefbd1003d5275fa5cc32f18196c11/research/object_detection/eval_util.py#L65",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 117,
        "deletions": 33,
        "changed_files": 11,
        "created_at": "2019-10-19T01:25:18Z",
        "closed_at": "2019-10-21T18:13:24Z",
        "merged_at": "2019-10-21T18:13:24Z",
        "body": "275538818  by Sergio Guadarrama:\r\n\r\n    Support grayscale input images in Slim model training\r\n\r\n--\r\n275355841  by Sergio Guadarrama:\r\n\r\n    Fixed cases where tf.TensorShape was constructed with float dimensions\r\n\r\n    This is a prerequisite for making TensorShape and Dimension more strict\r\n    about the types of their arguments.\r\n\r\n--\r\n275131829  by Sergio Guadarrama:\r\n\r\n    updates mobilenet/README.md to be github compatible adds V2+ reference to mobilenet_v1.md file and fixes invalid markdown\r\n\r\n--\r\n\r\nPiperOrigin-RevId: 275538818",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-10-17T19:36:13Z",
        "closed_at": "2019-10-17T21:10:09Z",
        "merged_at": "2019-10-17T21:10:09Z",
        "body": "people are commonly having issues configuring paths for running python scripts. The README has a typo in it. ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4651,
        "deletions": 752,
        "changed_files": 92,
        "created_at": "2019-10-17T00:25:00Z",
        "closed_at": "2019-10-17T22:55:29Z",
        "merged_at": "2019-10-17T22:55:29Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 21,
        "deletions": 18,
        "changed_files": 3,
        "created_at": "2019-10-17T00:22:53Z",
        "closed_at": "2019-10-18T03:39:56Z",
        "merged_at": "2019-10-18T03:39:56Z",
        "body": "Use compat.v1 in official/mnist and official/dataset.py to support TF2.0\r\n\r\nHere is a log when I tried to run mnist.py with tensorflow version 2.0\r\n<img width=\"630\" alt=\"Screen Shot 2019-10-16 at 5 14 05 PM\" src=\"https://user-images.githubusercontent.com/40487883/66968108-6384e780-f038-11e9-861c-ee1edcb7dab8.png\">\r\n\r\n\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-10-16T18:46:29Z",
        "closed_at": "2019-10-17T03:31:00Z",
        "merged_at": "2019-10-17T03:31:00Z",
        "body": "After Eager was moved to core Tensorflow, this notebook gives the error:\r\nAttributeError: module 'tensorflow.contrib.eager' has no attribute 'Variable'\r\nI just fixed it.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 13926,
        "deletions": 0,
        "changed_files": 108,
        "created_at": "2019-10-16T14:50:46Z",
        "closed_at": "2020-04-25T03:44:08Z",
        "merged_at": null,
        "body": "SSD & YOLO \uc218\uac15\uc790\uc785\ub2c8\ub2e4.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 718,
        "deletions": 117,
        "changed_files": 14,
        "created_at": "2019-10-15T16:28:14Z",
        "closed_at": "2019-10-17T16:57:27Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 1333118,
        "changed_files": 2737,
        "created_at": "2019-10-15T08:41:35Z",
        "closed_at": "2019-10-15T21:56:53Z",
        "merged_at": null,
        "body": "KM",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 453,
        "deletions": 0,
        "changed_files": 5,
        "created_at": "2019-10-13T17:24:56Z",
        "closed_at": "2020-04-24T06:24:41Z",
        "merged_at": null,
        "body": "",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 11,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2019-10-13T15:03:01Z",
        "closed_at": "2020-04-24T07:03:43Z",
        "merged_at": null,
        "body": "Hey, Google's engineers. I studied the STN (spatial transform network) for some time, and I found three are some errors in the bilinear interpolation method of the STN code.\r\nThe test code is as follows:\r\n\r\nimport tensorflow as tf\r\nfrom spatial_transformer import transformer\r\nimport numpy as np\r\nU = tf.reshape(tf.range(9), [1, 3, 3, 1])\r\ntheta = np.array([[1, 0, 0], [0, 1, 0]])\r\nout_size = (3, 3)\r\ny = transformer(U, theta, out_size)\r\nsess = tf.Session()\r\nprint(sess.run(y))\r\n\r\nIt's obvious that the output y should be identical to the input U because it's a identity transform with the theta value above. However, the output y is :\r\n[[[[0. ]\r\n[1.5]\r\n[0. ]]\r\n\r\n[[4.5]\r\n[6. ]\r\n[0. ]]\r\n\r\n[[0. ]\r\n[0. ]\r\n[0. ]]]]\r\nTherefore there are some mistakes. I have fixed it, and please check it out.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 9,
        "changed_files": 4,
        "created_at": "2019-10-11T22:27:37Z",
        "closed_at": "2019-10-11T23:37:24Z",
        "merged_at": "2019-10-11T23:37:24Z",
        "body": "Reverts tensorflow/models#7650",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-10-11T22:15:18Z",
        "closed_at": "2019-10-11T23:20:44Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 22,
        "changed_files": 9,
        "created_at": "2019-10-11T17:42:16Z",
        "closed_at": "2019-10-11T22:27:03Z",
        "merged_at": "2019-10-11T22:27:03Z",
        "body": "`tf.contrib` has been removed in TF 2.0, so this change upgrades the `tf.data`-using parts of tensorflow/models to TF 2.0 compatibility. (Note that these symbols are also available in recent versions of TF 1.x.)",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2019-10-07T21:04:35Z",
        "closed_at": "2021-07-28T03:26:42Z",
        "merged_at": null,
        "body": "Remove \"-of\" from the regex pattern for the input path at line 207 since the output files from the code in lines 178-192 doesn't actually produce files with \"of-\" in their names (as listed in lines 196-201).",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-10-02T20:06:10Z",
        "closed_at": "2023-04-08T01:48:31Z",
        "merged_at": null,
        "body": "The AutoAugment paper has been posted online. We can now remove the `TODO` concerning this change",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-10-02T03:02:40Z",
        "closed_at": "2019-10-11T03:35:20Z",
        "merged_at": "2019-10-11T03:35:20Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 466,
        "deletions": 455,
        "changed_files": 1,
        "created_at": "2019-10-01T15:10:45Z",
        "closed_at": "2019-10-22T03:31:16Z",
        "merged_at": null,
        "body": "TkAgg should be running in backend of Matplotlib to show the output image. if \"Agg\" is running in backend it wont able to do so. so it is better to fix the backend of matplotlib as TkAgg.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2019-10-01T11:43:39Z",
        "closed_at": "2019-10-03T18:33:12Z",
        "merged_at": "2019-10-03T18:33:12Z",
        "body": "Minor fix making error messages look more clear.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-09-29T22:22:10Z",
        "closed_at": "2019-09-30T00:39:21Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-09-29T20:56:54Z",
        "closed_at": "2019-09-29T22:05:04Z",
        "merged_at": null,
        "body": "Testing",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 281,
        "deletions": 76,
        "changed_files": 19,
        "created_at": "2019-09-28T00:06:42Z",
        "closed_at": "2019-12-19T20:29:08Z",
        "merged_at": null,
        "body": "This is needed for a person detection model running on an MCU, which only has a grayscale camera.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 6234,
        "changed_files": 30,
        "created_at": "2019-09-25T17:43:42Z",
        "closed_at": "2019-09-25T20:43:19Z",
        "merged_at": "2019-09-25T20:43:19Z",
        "body": "The reference implementation can be found at\r\nhttps://github.com/tensorflow/minigo\r\n\r\nThis fork was originally created to experiment with performance upgrades\r\nfor MLPerf, but since MLPerf work is focused in the original repo,\r\nthis fork's existence only serves to confuse.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-09-23T05:03:49Z",
        "closed_at": "2019-09-23T23:57:47Z",
        "merged_at": "2019-09-23T23:57:47Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-09-21T01:02:50Z",
        "closed_at": "2019-10-11T03:36:05Z",
        "merged_at": "2019-10-11T03:36:05Z",
        "body": "ssd_inception_v3_pets.config and ssd_inception_v2_pets.config headers was same",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 210,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-09-20T21:01:19Z",
        "closed_at": "2019-09-23T04:34:51Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-09-20T15:04:53Z",
        "closed_at": "2020-04-24T07:08:14Z",
        "merged_at": null,
        "body": "If ptb_word_lm.py is executed with --num_gpus=0, initial_state and final_state are not imported. As a result, feed_dict is always empty.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-09-20T08:53:42Z",
        "closed_at": "2019-09-20T18:46:25Z",
        "merged_at": "2019-09-20T18:46:25Z",
        "body": "Just fixing the path to the helper file to download and process the Movielens dataset in the script `run.sh` after a recent move of this file within the repository",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-09-18T23:14:27Z",
        "closed_at": "2020-04-25T03:28:45Z",
        "merged_at": "2020-04-25T03:28:45Z",
        "body": "Just wanted to add documentation stating that users can pip install pycocotools.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2019-09-18T08:39:41Z",
        "closed_at": "2019-09-18T20:34:59Z",
        "merged_at": "2019-09-18T20:34:59Z",
        "body": "Ref. #7572 ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2019-09-17T17:14:39Z",
        "closed_at": "2019-09-17T20:15:15Z",
        "merged_at": "2019-09-17T20:15:15Z",
        "body": "For the auto mixed precision benchmarks in ResNet50 CTL, this PR doubles the batch sizes for better performance.\r\n\r\n@reedwm ",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 91,
        "deletions": 89,
        "changed_files": 1,
        "created_at": "2019-09-17T06:36:45Z",
        "closed_at": "2020-04-24T15:42:28Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 11,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2019-09-15T17:16:11Z",
        "closed_at": "2019-09-22T05:23:24Z",
        "merged_at": null,
        "body": "Hey, Google's engineers. I studied the STN (spatial transform network) for some time, and I found some following errors in the bilinear interpolation method of the STN code.\r\nThe test code is as follows:\r\n\r\nimport tensorflow as tf\r\nfrom spatial_transformer import transformer\r\nimport numpy as np\r\nU = tf.reshape(tf.range(9), [1, 3, 3, 1])\r\ntheta = np.array([[1, 0, 0], [0, 1, 0]])\r\nout_size = (3, 3)\r\ny = transformer(U, theta, out_size)\r\nsess = tf.Session()\r\nprint(sess.run(y))\r\n\r\nIt's obvious that the output y should be identical to the input U because it's a identity transform with the theta value above. However, the output y is :\r\n[[[[0. ]\r\n[1.5]\r\n[0. ]]\r\n\r\n[[4.5]\r\n[6. ]\r\n[0. ]]\r\n\r\n[[0. ]\r\n[0. ]\r\n[0. ]]]]\r\nTherefore there are some mistakes. I have fixed it, and please check it out.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 11,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2019-09-15T15:46:54Z",
        "closed_at": "2019-09-15T17:12:06Z",
        "merged_at": null,
        "body": "Hey, Google's engineers. I studied the STN (spatial transform network) for some time, and I found some following errors in your bilinear interpolation method of the STN code.\r\nThe test code is as follows:\r\n\r\nimport tensorflow as tf\r\nfrom spatial_transformer import transformer\r\nimport numpy as np\r\nU = tf.reshape(tf.range(9), [1, 3, 3, 1])\r\ntheta =  np.array([[1, 0, 0], [0, 1, 0]])\r\nout_size = (3, 3)\r\ny = transformer(U, theta, out_size)\r\nsess = tf.Session()\r\nprint(sess.run(y))\r\n\r\nIt's obvious that the output y should be identical to the input U because it's a identity transform with the theta value above. However, the output y is :\r\n[[[[0. ]\r\n   [1.5]\r\n   [0. ]]\r\n\r\n  [[4.5]\r\n   [6. ]\r\n   [0. ]]\r\n\r\n  [[0. ]\r\n   [0. ]\r\n   [0. ]]]]\r\nTherefore there are some mistakes. I have fixed it, and please check it out. ",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-09-11T12:48:35Z",
        "closed_at": "2019-09-12T01:37:07Z",
        "merged_at": "2019-09-12T01:37:06Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 38,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2019-09-11T09:05:04Z",
        "closed_at": "2019-09-16T20:07:07Z",
        "merged_at": "2019-09-16T20:07:07Z",
        "body": "This PR adds some more non-CTL benchmarks to NCF FP16 mode. ",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 47,
        "deletions": 6,
        "changed_files": 4,
        "created_at": "2019-09-06T15:32:19Z",
        "closed_at": "2019-09-11T08:56:43Z",
        "merged_at": null,
        "body": "In continuation of https://github.com/tensorflow/models/pull/7419 and https://github.com/tensorflow/models/pull/7531 this PR adds automatic mixed precision functionality to the NCF model. It can be enabled by running with `--dtype=fp16 --fp16_implementation=graph_rewrite`",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 83,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2019-09-05T16:37:24Z",
        "closed_at": "2019-09-06T22:30:25Z",
        "merged_at": "2019-09-06T22:30:25Z",
        "body": "This PR adds automatic mixed precision training to Resnet in CTL mode via setting the flag combination of --dtype=fp16 --fp16_implementation=graph_rewrite.\r\n\r\nCorresponding benchmarks are added as well.",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 98,
        "deletions": 1,
        "changed_files": 6,
        "created_at": "2019-09-05T02:27:30Z",
        "closed_at": "2019-09-06T17:49:01Z",
        "merged_at": "2019-09-06T17:49:01Z",
        "body": "Automatic Mixed Precision for TensorFlow has recently been introduced:\r\nhttps://medium.com/tensorflow/automatic-mixed-precision-in-tensorflow-for-faster-ai-training-on-nvidia-gpus-6033234b2540\r\n\r\nIn continuation of https://github.com/tensorflow/models/pull/7419, this PR adds automatic mixed precision training to  BERT pretraining & fine-tuning tasks via setting the flag combo `--dtype=fp16 --fp16_implementation=graph_rewrite`.\r\n\r\nFor example:\r\n\r\n```\r\npython3 run_pretraining.py --dtype=fp16 --fp16_implementation=graph_rewrite\r\npython3 run_classifier.py --dtype=fp16 --fp16_implementation=graph_rewrite\r\npython3 run_squad.py --dtype=fp16 --fp16_implementation=graph_rewrite\r\n```\r\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 7,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2019-08-29T15:27:48Z",
        "closed_at": "2019-08-31T05:31:21Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 19,
        "deletions": 23,
        "changed_files": 2,
        "created_at": "2019-08-28T12:20:48Z",
        "closed_at": "2019-08-31T05:35:33Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-08-22T15:41:49Z",
        "closed_at": "2020-04-24T06:36:05Z",
        "merged_at": null,
        "body": "Requires to handle the expected type of the proto in py2 and 3.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 20,
        "changed_files": 3,
        "created_at": "2019-08-21T19:29:08Z",
        "closed_at": "2019-08-22T22:52:22Z",
        "merged_at": null,
        "body": "The old infer_float32_policies policy will be removed from TensorFlow soon.\r\n\r\nTo test, I ran the TransformerBigKerasAccuracy.benchmark_8_gpu_fp16 PerfZero benchmark. The max BLEU score was 28.63 on epoch 10. Unfortunately, the run crashed during Epoch 11, but I tried doing a clean run and it also crashed, so I don't think it was caused by this PR",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-08-21T02:32:51Z",
        "closed_at": "2022-01-14T01:58:29Z",
        "merged_at": null,
        "body": "Hi, everyone. \r\n\r\ni wanted to etimate inference time. then, i modify batch size is '1'.\r\n\r\nbut, i met under the error.\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/yoohj/anaconda3/envs/tensorpack/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1567, in _create_c_op\r\n    c_op = c_api.TF_FinishOperation(op_desc)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Shape must be rank 1 but is rank 0 for 'in_top_k/InTopKV2' (op: 'InTopKV2') with input shapes: [1,1001], [], [].\r\n```\r\n\r\nso, I looked for a problem. And, i find it.because of tf.squeeze().\r\nif you use tf.squeeze() in shape of variables (1,), shape of variables is no shape.\r\n\r\nFinally, I solve the problem to add a conditional statement.\r\n\r\nThank you for reading!",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-08-21T00:52:59Z",
        "closed_at": "2020-04-24T07:23:04Z",
        "merged_at": null,
        "body": "Also test to see if the tests pass.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-08-21T00:47:42Z",
        "closed_at": "2019-08-21T03:10:16Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 42,
        "deletions": 26,
        "changed_files": 5,
        "created_at": "2019-08-20T18:21:12Z",
        "closed_at": "2019-09-12T07:20:25Z",
        "merged_at": null,
        "body": "The old infer_float32_policies policy will be removed from TensorFlow soon.\r\n\r\nTo test convergence, I ran the Resnet50KerasAccuracy.benchmark_8_gpu_fp16 benchmark. I got an accuracy of 0.76037 and an exp_per_second of 6908.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 10,
        "changed_files": 3,
        "created_at": "2019-08-19T20:50:14Z",
        "closed_at": "2019-08-20T16:02:21Z",
        "merged_at": "2019-08-20T16:02:21Z",
        "body": "- Increased NCF because we have seen one .64, and that is not a fail\r\n- Increased Transformer to 29+ as that has occured and is not a fail even if rare.  \r\n- Lower the min Transformer for FP32 to 27.9 because that is a documented acceptable number that does happen from time to time; and it not actionable.  \r\n- Increased Shakespeare as the higher number is acceptable.\r\n- Decreased Shakespeare as .91 is still not actionable on the lower end and is a false positive. This may need to be be lowered even more; but for now this should reduce noise.  \r\n\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 115,
        "deletions": 95,
        "changed_files": 8,
        "created_at": "2019-08-19T18:10:20Z",
        "closed_at": "2019-08-19T21:55:39Z",
        "merged_at": "2019-08-19T21:55:39Z",
        "body": "263863588  by yongzhe:\r\n\r\n    Fix a bug that the SetExternalContext for EdgeTPU wasn't called when initializing LSTD client.\r\n\r\n--\r\n263370193  by yongzhe:\r\n\r\n    Internal change.\r\n\r\n--\r\n\r\nPiperOrigin-RevId: 263863588",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 70,
        "deletions": 70,
        "changed_files": 9,
        "created_at": "2019-08-16T21:29:21Z",
        "closed_at": "2019-11-02T03:49:10Z",
        "merged_at": null,
        "body": "Adding support of TF 2.0 to and older commit.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-08-15T06:24:37Z",
        "closed_at": "2019-08-15T08:14:45Z",
        "merged_at": null,
        "body": "possible to run 1.X code in TensorFlow 2.0:",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 15,
        "changed_files": 1,
        "created_at": "2019-08-13T22:59:10Z",
        "closed_at": "2019-08-14T01:44:09Z",
        "merged_at": "2019-08-14T01:44:08Z",
        "body": "The benchmark fails and XLA is not ready to work on it yet.  Easy to add back later.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 218,
        "changed_files": 1,
        "created_at": "2019-08-13T22:20:16Z",
        "closed_at": "2019-08-14T01:00:51Z",
        "merged_at": "2019-08-14T01:00:51Z",
        "body": "These tests are not monitored closely.  In realty all the \"graph\" tests should also be removed; but I need a few more days to think about them.  ",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 33,
        "deletions": 1,
        "changed_files": 3,
        "created_at": "2019-08-13T20:51:30Z",
        "closed_at": "2019-08-24T00:04:01Z",
        "merged_at": "2019-08-24T00:04:01Z",
        "body": "adding support for fp16 using the TF1.x API",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 32,
        "deletions": 8,
        "changed_files": 9,
        "created_at": "2019-08-12T00:52:43Z",
        "closed_at": "2019-08-13T18:10:50Z",
        "merged_at": null,
        "body": "Testing",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 119,
        "deletions": 5,
        "changed_files": 7,
        "created_at": "2019-08-09T07:30:32Z",
        "closed_at": "2019-08-28T17:31:30Z",
        "merged_at": "2019-08-28T17:31:30Z",
        "body": "Automatic Mixed Precision for TensorFlow has recently been introduced:\r\nhttps://medium.com/tensorflow/automatic-mixed-precision-in-tensorflow-for-faster-ai-training-on-nvidia-gpus-6033234b2540\r\n\r\nThis PR adds automatic mixed precision training to Resnet and Transformer model via setting the flag combo `--dtype=fp16 --fp16_implementation=graph_rewrite`.\r\n\r\nFor example:\r\n\r\n```\r\npython3 keras_imagenet_main.py --dtype=fp16 --fp16_implementation=graph_rewrite\r\npython3 transformer_main.py --dtype=fp16 --fp16_implementation=graph_rewrite\r\n```\r\n",
        "comments": 15
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-08-08T22:17:04Z",
        "closed_at": "2019-10-28T22:17:23Z",
        "merged_at": null,
        "body": "This is a workaround to avoid tf.cond() in LossScaleOptimizer.\r\nFor fp16, single GPU step time (3072 static batch) reduces ~5ms and 8 GPU step time (3072 x 8 static batch, without XLA) reduces ~35ms.\r\n\r\nset --loss_scale=256 and dynamic batching can yield similar Bleu scores as LossScaleOptimizer, reaching {28.45, 27.95} at 200000 steps for {uncased, cased} Bleu.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-08-08T00:48:16Z",
        "closed_at": "2019-08-08T05:20:48Z",
        "merged_at": null,
        "body": "",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 37,
        "deletions": 11,
        "changed_files": 3,
        "created_at": "2019-08-07T23:43:17Z",
        "closed_at": "2019-11-24T23:47:01Z",
        "merged_at": null,
        "body": "\u2026tilization on GPUs\r\n\r\nThe original vocab list length is 33708, which is not multiples of 8, so the TensorCore is not used when training with fp16 on Volta GPUs or newer. Padding dummy tokens at the end of the vocab list and making its length 33712 solve this performance issue. The step time sees ~35 ms saving for fp16. ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 90,
        "deletions": 30,
        "changed_files": 5,
        "created_at": "2019-08-07T20:12:09Z",
        "closed_at": "2019-08-08T22:54:22Z",
        "merged_at": "2019-08-08T22:54:22Z",
        "body": "Also, do Transformer inference in fp16, as well as training, when --dtype=fp16. In TF 2, layers now cannot run in multiple different dtypes, so we must use the same dtype for training and inference.",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 69,
        "changed_files": 3,
        "created_at": "2019-08-07T04:39:34Z",
        "closed_at": "2019-08-07T20:11:59Z",
        "merged_at": "2019-08-07T20:11:59Z",
        "body": "Merged commit includes the following changes:\n262039434  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Internal change\n\n262024241  by hongkuny<hongkuny@google.com>:\n    \n    Adds __init__.py\n    \n--\n262021128  by isaprykin<isaprykin@google.com>:",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-08-06T21:24:52Z",
        "closed_at": "2019-08-07T01:03:03Z",
        "merged_at": "2019-08-07T01:03:03Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 89,
        "deletions": 144,
        "changed_files": 7,
        "created_at": "2019-08-05T23:03:56Z",
        "closed_at": "2019-08-06T03:42:55Z",
        "merged_at": "2019-08-06T03:42:55Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 870,
        "deletions": 66,
        "changed_files": 10,
        "created_at": "2019-08-05T13:38:50Z",
        "closed_at": "2019-08-12T22:16:41Z",
        "merged_at": "2019-08-12T22:16:41Z",
        "body": "I am interested in getting this project setup up to have an easier walkthrough from tfrecord creation to having a model running on android, specifically for the SSD Interleaved v2 model. These updates are steps in that direction:\r\n\r\n- replaces `google3.pylib` module with `tf` and `absl` (321b085)\r\n- adds example pipeline config for SSD Interleaved v2 model (231e65e)\r\n- removes incorrect and unused tfrecords creation in unittest (ae5b330)\r\n- corrects docstrings (e5810f9)\r\n- adds frozen graph exporter (181119e)\r\n- adds tflite model exporter (3f5de09)\r\n- adds scripts to test tflite model (b613257)",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 160,
        "changed_files": 5,
        "created_at": "2019-08-02T00:53:27Z",
        "closed_at": "2019-08-05T21:40:38Z",
        "merged_at": "2019-08-05T21:40:38Z",
        "body": "Seeing if the tests will pass and putting this here so I do not forget.  Will wait for Haoyu to finish the grand refactor/move.  ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 47,
        "deletions": 10,
        "changed_files": 5,
        "created_at": "2019-08-01T22:18:04Z",
        "closed_at": "2019-08-02T07:18:31Z",
        "merged_at": "2019-08-02T07:18:31Z",
        "body": "261196859  by yongzhe:\r\n\r\n    Integrate EdgeTPU API into the Mobile SSD tflite client.\r\n\r\n    Build command with EdgeTPU enabled:\r\n    bazel build mobile_ssd_tflite_client  --define enable_edgetpu=true\r\n\r\n    Build command with EdgeTPU disabled:\r\n    bazel build mobile_ssd_tflite_client\r\n\r\n--\r\n259096620  by Menglong Zhu:\r\n\r\n    Remove unused proto imports.\r\n\r\n--\r\n\r\nPiperOrigin-RevId: 261196859",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 24,
        "changed_files": 5,
        "created_at": "2019-08-01T21:54:15Z",
        "closed_at": "2019-08-01T23:17:34Z",
        "merged_at": "2019-08-01T23:17:34Z",
        "body": "Merged commit includes the following changes:\n261202754  by hongkuny<hongkuny@google.com>:\n    \n    Use enable_xla flag for classifier and squad, so xla option is exposed to users.\n    \n--",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 69,
        "deletions": 21,
        "changed_files": 8,
        "created_at": "2019-08-01T21:52:45Z",
        "closed_at": "2019-08-02T17:31:29Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 210,
        "deletions": 167,
        "changed_files": 14,
        "created_at": "2019-08-01T20:06:02Z",
        "closed_at": "2019-08-01T22:50:18Z",
        "merged_at": "2019-08-01T22:50:18Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 17,
        "changed_files": 5,
        "created_at": "2019-08-01T17:59:47Z",
        "closed_at": "2019-08-01T20:20:15Z",
        "merged_at": "2019-08-01T20:20:15Z",
        "body": "Merged commit includes the following changes:\n261153520  by haoyuzhang<haoyuzhang@google.com>:\n\n    Internal change",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 46,
        "deletions": 23,
        "changed_files": 2,
        "created_at": "2019-07-31T23:45:34Z",
        "closed_at": "2019-08-01T02:04:06Z",
        "merged_at": "2019-08-01T02:04:06Z",
        "body": "Merged commit includes the following changes:\n260862396  by A. Unique TensorFlower<gardener@tensorflow.org>:\n    \n    Fix BERT pretraining input pipeline to shuffle and shard dataset properly for multi-worker training.\n    \n--",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 25,
        "deletions": 22,
        "changed_files": 4,
        "created_at": "2019-07-31T16:03:34Z",
        "closed_at": "2019-07-31T17:34:50Z",
        "merged_at": "2019-07-31T17:34:50Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-07-31T15:24:49Z",
        "closed_at": "2020-04-24T06:55:21Z",
        "merged_at": "2020-04-24T06:55:21Z",
        "body": "The original version does not apply normalization to the `input_image` even if `self.imagenet_norm` is `True`.\r\nIn the original version when line 772 is reached and `self.imagenet_norm == True` the variable `input_image` holds the tensor `depth_prediction/truediv:0`, i.e. the output of the normalization operation. When a value is fed in [line 840](https://github.com/tensorflow/models/blob/master/research/struct2depth/model.py#L840) the normalization operation is not run on this tensor.\r\nWith the change `self.input_image` is the tensor `depth_prediction/raw_input:0` which I think is the intended behavior.\r\n\r\nI have opened an issue with more information: https://github.com/tensorflow/models/issues/7343 .\r\n\r\nI hope that this is a valid bug and apologize if I made a mistake.\r\nBests\r\n-Lukas",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2019-07-31T06:13:20Z",
        "closed_at": "2020-04-25T03:56:49Z",
        "merged_at": "2020-04-25T03:56:48Z",
        "body": "Referred #881 and #982\r\nThis is a very easy fix for the modern style.\r\nThis change following this repositorys' most files that are using `contrib.rnn` instead of `rnn.nn`.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-07-30T21:28:46Z",
        "closed_at": "2019-07-30T22:31:32Z",
        "merged_at": "2019-07-30T22:31:32Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 29,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-07-30T21:14:24Z",
        "closed_at": "2019-07-30T22:31:24Z",
        "merged_at": "2019-07-30T22:31:24Z",
        "body": "\u2026pile = True.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2019-07-30T20:51:45Z",
        "closed_at": "2019-08-02T02:36:29Z",
        "merged_at": null,
        "body": "- uses `tf.app` instead of `google3.pyglib.app`\r\n- uses `absl.flags` (already imported) instead if instead of `google3.pyglib.flags`\r\n\r\nThis removes the need for the `google3` module for the entire project, and also matches `train.py`'s use.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 768,
        "changed_files": 4,
        "created_at": "2019-07-30T15:55:22Z",
        "closed_at": "2019-10-02T17:20:08Z",
        "merged_at": "2019-10-02T17:20:08Z",
        "body": "Fix #4988. @pooyadavoodi.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-07-29T23:18:37Z",
        "closed_at": "2019-07-30T01:02:32Z",
        "merged_at": "2019-07-30T01:02:32Z",
        "body": "Merged commit includes the following changes:\n260601376  by hongkuny<hongkuny@google.com>:\n    \n    reorder Q,K to make TPU faster.\n    \n--",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 145,
        "deletions": 35,
        "changed_files": 1,
        "created_at": "2019-07-29T19:13:03Z",
        "closed_at": "2020-04-24T06:21:07Z",
        "merged_at": null,
        "body": "Add in ml-100k preprocessing in `dataset`.\r\n    \r\n `README.MD` and `ncf_keras_main.py` in `official/recommendation` need to be updated accordingly.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-07-26T12:33:45Z",
        "closed_at": "2020-02-03T13:31:16Z",
        "merged_at": null,
        "body": "While the links in the text are correct, the file names in the commands for instance segmentation refer to the bbox and labels files for object detection, which contain labels that are not part of the 300 supported labels for instance segmentation.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-07-26T07:32:57Z",
        "closed_at": "2019-07-31T00:29:29Z",
        "merged_at": null,
        "body": "Guard the unsafe `tf.exp` to prevent NAN cost. We are able to find a failing test given a trained network. See the MNIST-like image below.\r\n![nan](https://user-images.githubusercontent.com/18027197/61934322-9d56cc80-afba-11e9-9b74-80bdc55d8d11.png)\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 137,
        "deletions": 10,
        "changed_files": 6,
        "created_at": "2019-07-26T05:55:49Z",
        "closed_at": "2019-07-26T17:19:49Z",
        "merged_at": "2019-07-26T17:19:49Z",
        "body": "Merged commit includes the following changes:\n260060237  by zongweiz<zongweiz@google.com>:\n    \n    [BERT SQuAD] Enable mixed precision training\n    \n    Add mixed precision training support for BERT SQuAD model. Using the experimental Keras mixed precision API. For numeric stability, use fp32 for layer normalization, dense layers with GELU activation, etc.\n    \n--",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-07-26T00:26:29Z",
        "closed_at": "2019-07-26T02:11:34Z",
        "merged_at": "2019-07-26T02:11:34Z",
        "body": "Merged commit includes the following changes:\n260052674  by hongkuny<hongkuny@google.com>:\n    \n    Add expect_partial()\n    \n--",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-07-25T09:46:05Z",
        "closed_at": "2020-04-25T03:45:12Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 44,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-07-25T07:30:59Z",
        "closed_at": "2019-08-05T21:42:01Z",
        "merged_at": "2019-08-05T21:42:01Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-07-25T07:24:43Z",
        "closed_at": "2019-07-25T15:49:48Z",
        "merged_at": "2019-07-25T15:49:48Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 105,
        "deletions": 33,
        "changed_files": 3,
        "created_at": "2019-07-25T01:49:13Z",
        "closed_at": "2019-07-25T03:56:12Z",
        "merged_at": null,
        "body": "Merged commit includes the following changes:\n259861112  by hongkuny<hongkuny@google.com>:\n    \n    Add no ds and xla perfzero tests\n    ",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 29,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-07-24T22:17:40Z",
        "closed_at": "2019-07-25T00:45:19Z",
        "merged_at": "2019-07-25T00:45:19Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-07-24T22:16:28Z",
        "closed_at": "2019-07-25T00:45:34Z",
        "merged_at": "2019-07-25T00:45:34Z",
        "body": "MLPerf tests are not for accuracy, but I want to record the number just to have it.  I set the error bars really wide so only something horrible would get caught.  We have the \"early stop\" tests which are used to watch accuracy.  ",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2019-07-24T20:42:33Z",
        "closed_at": "2019-10-02T19:49:57Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-07-24T18:59:57Z",
        "closed_at": "2020-04-25T04:07:16Z",
        "merged_at": "2020-04-25T04:07:16Z",
        "body": "Updated website addresses for MS COCO and Open Images.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2019-07-24T15:24:39Z",
        "closed_at": "2019-07-24T16:34:33Z",
        "merged_at": "2019-07-24T16:34:33Z",
        "body": "Tests are failing.  I had a typo and was in a hurry.  :-(",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2019-07-23T23:48:22Z",
        "closed_at": "2019-07-24T05:06:22Z",
        "merged_at": "2019-07-24T05:06:22Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 42,
        "deletions": 35,
        "changed_files": 1,
        "created_at": "2019-07-23T22:23:49Z",
        "closed_at": "2019-07-24T05:06:06Z",
        "merged_at": "2019-07-24T05:06:06Z",
        "body": "I also did a small refactor.  I found this flow is easier to manage than the abstract class style where the extending class has to implement the method.  It was going to be hard to pull this off that way unless I made a new class.  If I made a new class for the MLPerf tests it would break my history.  \r\n\r\nA problem that I slightly created myself; but this resolves it and seems fine.  I hope you feel the same.  ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 231,
        "deletions": 86,
        "changed_files": 5,
        "created_at": "2019-07-23T04:30:25Z",
        "closed_at": "2019-07-23T05:56:11Z",
        "merged_at": "2019-07-23T05:56:11Z",
        "body": "Merged commit includes the following changes:\n259442882  by hongkuny<hongkuny@google.com>:\n    \n    Internal\n    \n--\n259377621  by A. Unique TensorFlower<gardener@tensorflow.org>:\n    \n    Fix NCF serialization/de-serialization logic in NCF input pipeline to use tf.FixedLenFeature instead of raw string/binary decoding.\n    \n--\n259373183  by A. Unique TensorFlower<gardener@tensorflow.org>:\n    \n    Create binary to generate NCF training/evaluation dataset offline.\n    \n--\n259026454  by isaprykin<isaprykin@google.com>:\n\n    Internal change\n\n258871624  by hongkuny<hongkuny@google.com>:\n\n    Internal change\n\n257285772  by haoyuzhang<haoyuzhang@google.com>:\n\n    Internal change\n\n256202287  by A. Unique TensorFlower<gardener@tensorflow.org>:\n    \n    Internal change.\n    \n--\n254069984  by hongkuny<hongkuny@google.com>:\n    Automated rollback of changelist 254060732.\n\n254060732  by yifeif<yifeif@google.com>:\n    Automated rollback of changelist 254027750.\n\n254027750  by hongkuny<hongkuny@google.com>:\n\n    Internal change\n\n253118910  by hongkuny<hongkuny@google.com>:\n\n    Internal change\n\n251906769  by hongkuny<hongkuny@google.com>:\n\n    Internal change\n\n251303452  by haoyuzhang<haoyuzhang@google.com>:",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 229,
        "deletions": 29,
        "changed_files": 12,
        "created_at": "2019-07-22T22:11:13Z",
        "closed_at": "2019-07-23T23:27:24Z",
        "merged_at": "2019-07-23T23:27:24Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2019-07-22T19:09:54Z",
        "closed_at": "2019-07-23T15:45:47Z",
        "merged_at": "2019-07-23T15:45:47Z",
        "body": "At larger batch-sizes we were not logging any examples/sec which resulted in an index out of bounds.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 62,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-07-20T01:51:57Z",
        "closed_at": "2019-07-21T21:15:59Z",
        "merged_at": "2019-07-21T21:15:59Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 183,
        "deletions": 2,
        "changed_files": 3,
        "created_at": "2019-07-19T22:58:21Z",
        "closed_at": "2019-07-22T16:13:39Z",
        "merged_at": "2019-07-22T16:13:39Z",
        "body": "This is going to replace current lint presubmit.\r\nAfter that, we can enforce correct lint rules. Now, in pylint.rcfile, there is a disable=W which disables most warning.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2019-07-19T18:10:39Z",
        "closed_at": "2019-07-20T00:15:34Z",
        "merged_at": "2019-07-20T00:15:34Z",
        "body": "Added back your change and the NCF fix.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 54,
        "deletions": 10,
        "changed_files": 1,
        "created_at": "2019-07-19T05:46:28Z",
        "closed_at": "2019-07-19T19:04:20Z",
        "merged_at": null,
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 41,
        "changed_files": 5,
        "created_at": "2019-07-19T05:26:11Z",
        "closed_at": "2019-07-24T02:03:11Z",
        "merged_at": "2019-07-24T02:03:11Z",
        "body": "model.add_loss is (1) simpler (2) works in both 1.x and 2.0 with distribution strategy.\r\n\r\nNOTE: the change was approved in https://github.com/tensorflow/models/pull/7077 previously but that PR got a bit messed up so re-doing it in a fresh client",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2019-07-19T01:23:49Z",
        "closed_at": "2019-07-19T05:13:43Z",
        "merged_at": "2019-07-19T05:13:43Z",
        "body": "This combination does not yet work. Fail early with an explicit message instead of throwing error later on.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2019-07-19T01:09:48Z",
        "closed_at": "2019-07-19T02:47:49Z",
        "merged_at": "2019-07-19T02:47:48Z",
        "body": "Merged commit includes the following changes:\n258881002  by hongkuny<hongkuny@google.com>:\n    \n    Fix lint.\n    \n--\n258874998  by hongkuny<hongkuny@google.com>:\n    \n    Internal\n    \n--\n258872662  by hongkuny<hongkuny@google.com>:\n    \n    Fix doc\n    \n--\n258871624  by hongkuny<hongkuny@google.com>:",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2019-07-19T00:54:58Z",
        "closed_at": "2019-07-19T05:03:58Z",
        "merged_at": "2019-07-19T05:03:58Z",
        "body": "The current approach checks for presence of contrib. Sometimes this is not sufficient (for e..g when testing TF 1 + enable_v2_behavior=True which is what internal tests currently do)",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 404,
        "deletions": 26,
        "changed_files": 3,
        "created_at": "2019-07-18T16:56:32Z",
        "closed_at": "2019-07-18T22:04:23Z",
        "merged_at": "2019-07-18T22:04:23Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 31,
        "deletions": 6,
        "changed_files": 2,
        "created_at": "2019-07-17T20:32:56Z",
        "closed_at": "2019-07-18T18:04:38Z",
        "merged_at": "2019-07-18T18:04:38Z",
        "body": "This change should bring Keras graph performance close to legacy graph. The major problem in current code is a large number of many H2D memory copies, and the main reason for that is in the normalization layer there's a cond op that triggers input_sizes being copied for each BN layer.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/normalization.py#L471\r\n\r\nSetting drop_remainder avoids triggering this logic and thus improves the performance.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 26,
        "changed_files": 1,
        "created_at": "2019-07-17T18:15:59Z",
        "closed_at": "2020-01-24T21:33:17Z",
        "merged_at": null,
        "body": "keras-cifar-main synthetic data generates sparse data, whereas the real data generates one-hot labels. The real data and model loss/metric are correct but the synthetic data is wrong with respect to this model parameters. We can convert the synthetic data to return one-hot labels but this synthetic data is shared across other models where sparse data is used. I figured it is best to convert keras-cifar-main to use sparse data as well.",
        "comments": 11
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2019-07-16T21:59:41Z",
        "closed_at": "2019-08-09T17:13:30Z",
        "merged_at": "2019-08-09T17:13:30Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-07-16T16:24:00Z",
        "closed_at": "2019-07-18T20:14:56Z",
        "merged_at": "2019-07-18T20:14:56Z",
        "body": null,
        "comments": 2
    },
    {
        "merged": true,
        "additions": 18,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2019-07-15T23:45:59Z",
        "closed_at": "2019-07-16T21:01:10Z",
        "merged_at": "2019-07-16T21:01:10Z",
        "body": "Merged commit includes the following changes:\n258208153  by hongkuny<hongkuny@google.com>:\n    \n    Adds run_eagerly option for bert.\n    \n--",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 3154,
        "deletions": 6,
        "changed_files": 28,
        "created_at": "2019-07-15T23:04:19Z",
        "closed_at": "2019-07-16T15:50:43Z",
        "merged_at": "2019-07-16T15:50:43Z",
        "body": "257930561  by yongzhe:\r\n\r\n    Mobile LSTD TfLite Client.\r\n\r\n--\r\n257928126  by yongzhe:\r\n\r\n    Mobile SSD Tflite client.\r\n\r\n--\r\n257921181  by menglong:\r\n\r\n    Fix discrepancy between pre_bottleneck = {true, false}\r\n\r\n--\r\n257561213  by yongzhe:\r\n\r\n    File utils.\r\n\r\n--\r\n257449226  by yongzhe:\r\n\r\n    Mobile SSD Client.\r\n\r\n--\r\n257264654  by yongzhe:\r\n\r\n    SSD utils.\r\n\r\n--\r\n257235648  by yongzhe:\r\n\r\n    Proto bazel build rules.\r\n\r\n--\r\n256437262  by Menglong Zhu:\r\n\r\n    Fix check for FusedBatchNorm op to only verify it as a prefix.\r\n\r\n--\r\n256283755  by yongzhe:\r\n\r\n    Bazel build and copybara changes.\r\n\r\n--\r\n251947295  by yinxiao:\r\n\r\n    Add missing interleaved option in checkpoint restore.\r\n\r\n--\r\n251513479  by yongzhe:\r\n\r\n    Conversion utils.\r\n\r\n--\r\n248783193  by yongzhe:\r\n\r\n    Branch protos needed for the lstd client.\r\n\r\n--\r\n248200507  by menglong:\r\n\r\n    Fix proto namespace in example config\r\n\r\n--\r\n\r\nPiperOrigin-RevId: 257930561",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 138,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-07-15T22:14:13Z",
        "closed_at": "2019-09-03T06:21:38Z",
        "merged_at": null,
        "body": "label_map_util.py shows an exception as string_int_label_map_pb2.py was absent.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 247,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2019-07-15T21:36:56Z",
        "closed_at": "2019-07-15T23:45:20Z",
        "merged_at": "2019-07-15T23:45:20Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-07-15T20:47:44Z",
        "closed_at": "2019-07-19T05:08:28Z",
        "merged_at": "2019-07-19T05:08:28Z",
        "body": "\u2026e full shape isn't passed to prefetch_queue contributed by mattmann.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 45,
        "deletions": 12,
        "changed_files": 1,
        "created_at": "2019-07-14T00:11:11Z",
        "closed_at": "2019-07-15T21:12:10Z",
        "merged_at": "2019-07-15T21:12:10Z",
        "body": "Merged commit includes the following changes:\n257883986  by hongkuny<hongkuny@google.com>:\n    \n    Adds tf.summary for bert training\n    \n--",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 7014,
        "deletions": 1027,
        "changed_files": 148,
        "created_at": "2019-07-13T04:11:01Z",
        "closed_at": "2019-07-15T16:50:59Z",
        "merged_at": "2019-07-15T16:50:59Z",
        "body": "257914648  by lzc:\r\n\r\n    Internal changes\r\n\r\n--\r\n257525973  by Zhichao Lu:\r\n\r\n    Fixes bug that silently prevents checkpoints from loading when training w/ eager + functions. Also sets up scripts to run training.\r\n\r\n--\r\n257296614  by Zhichao Lu:\r\n\r\n    Adding detection_features to model outputs\r\n\r\n--\r\n257234565  by Zhichao Lu:\r\n\r\n    Fix wrong order of `classes_with_max_scores` in class-agnostic NMS caused by\r\n    sorting in partitioned-NMS.\r\n\r\n--\r\n257232002  by ronnyvotel:\r\n\r\n    Supporting `filter_nonoverlapping` option in np_box_list_ops.clip_to_window().\r\n\r\n--\r\n257198282  by Zhichao Lu:\r\n\r\n    Adding the focal loss and l1 loss from the Objects as Points paper.\r\n\r\n--\r\n257089535  by Zhichao Lu:\r\n\r\n    Create Keras based ssd + resnetv1 + fpn.\r\n\r\n--\r\n257087407  by Zhichao Lu:\r\n\r\n    Make object_detection/data_decoders Python3-compatible.\r\n\r\n--\r\n257004582  by Zhichao Lu:\r\n\r\n    Updates _decode_raw_data_into_masks_and_boxes to the latest binary masks-to-string encoding format.\r\n\r\n--\r\n257002124  by Zhichao Lu:\r\n\r\n    Make object_detection/utils Python3-compatible, except json_utils.\r\n\r\n    The patching trick used in json_utils is not going to work in Python 3.\r\n\r\n--\r\n256795056  by lzc:\r\n\r\n    Add a detection_anchor_indices field to detection outputs.\r\n\r\n--\r\n256477542  by Zhichao Lu:\r\n\r\n    Make object_detection/core Python3-compatible.\r\n\r\n--\r\n256387593  by Zhichao Lu:\r\n\r\n    Edit class_id_function_approximations builder to skip class ids not present in label map.\r\n\r\n--\r\n256259039  by Zhichao Lu:\r\n\r\n    Move NMS to TPU for FasterRCNN.\r\n\r\n--\r\n256071360  by rathodv:\r\n\r\n    When multiclass_scores is empty, add one-hot encoding of groundtruth_classes as multiclass scores so that data_augmentation ops that expect the presence of multiclass_scores don't have to individually handle this case.\r\n\r\n    Also copy input tensor_dict to out_tensor_dict first to avoid inplace modification.\r\n\r\n--\r\n256023645  by Zhichao Lu:\r\n\r\n    Adds the first WIP iterations of TensorFlow v2 eager + functions style custom training & evaluation loops.\r\n\r\n--\r\n255980623  by Zhichao Lu:\r\n\r\n    Adds a new data augmentation operation \"remap_labels\" which remaps a set of labels to a new label.\r\n\r\n--\r\n255753259  by Zhichao Lu:\r\n\r\n    Announcement of the released evaluation tutorial for Open Images Challenge\r\n    2019.\r\n\r\n--\r\n255698776  by lzc:\r\n\r\n    Fix rewrite_nn_resize_op function which was broken by tf forward compatibility movement.\r\n\r\n--\r\n255623150  by Zhichao Lu:\r\n\r\n    Add Keras-based ResnetV1 models.\r\n\r\n--\r\n255504992  by Zhichao Lu:\r\n\r\n    Fixing the typo in specifying label expansion for ground truth segmentation\r\n    file.\r\n\r\n--\r\n255470768  by Zhichao Lu:\r\n\r\n    1. Fixing Python bug with parsed arguments.\r\n    2. Adding capability to parse relevant columns from CSV header.\r\n    3. Fixing bug with duplicated labels expansion.\r\n\r\n--\r\n255462432  by Zhichao Lu:\r\n\r\n    Adds a new data augmentation operation \"drop_label_probabilistically\" which drops a given label with the given probability. This supports experiments on training in the presence of label noise.\r\n\r\n--\r\n255441632  by rathodv:\r\n\r\n    Fallback on groundtruth classes when multiclass_scores tensor is empty.\r\n\r\n--\r\n255434899  by Zhichao Lu:\r\n\r\n    Ensuring evaluation binary can run even with big files by synchronizing\r\n    processing of ground truth and predictions: in this way, ground truth is not stored but immediatly\r\n    used for evaluation. In case gt of object masks, this allows to run\r\n    evaluations on relatively large sets.\r\n\r\n--\r\n255337855  by lzc:\r\n\r\n    Internal change.\r\n\r\n--\r\n255308908  by Zhichao Lu:\r\n\r\n    Add comment to clarify usage of calibration parameters proto.\r\n\r\n--\r\n255266371  by Zhichao Lu:\r\n\r\n    Ensuring correct processing of the case, when no groundtruth masks are provided\r\n    for an image.\r\n\r\n--\r\n255236648  by Zhichao Lu:\r\n\r\n    Refactor model_builder in faster_rcnn.py to a util_map, so that it's possible to be overwritten.\r\n\r\n--\r\n255093285  by Zhichao Lu:\r\n\r\n    Updating capability to subsample data during evaluation\r\n\r\n--\r\n255081222  by rathodv:\r\n\r\n    Convert groundtruth masks to be of type float32 before its used in the loss function.\r\n\r\n    When using mixed precision training, masks are represented using bfloat16 tensors in the input pipeline for performance reasons. We need to convert them to float32 before using it in the loss function.\r\n\r\n--\r\n254788436  by Zhichao Lu:\r\n\r\n    Add forward_compatible to non_max_suppression_with_scores to make it is\r\n    compatible with older tensorflow version.\r\n\r\n--\r\n254442362  by Zhichao Lu:\r\n\r\n    Add num_layer field to ssd feature extractor proto.\r\n\r\n--\r\n253911582  by jonathanhuang:\r\n\r\n    Plumbs Soft-NMS options (using the new tf.image.non_max_suppression_with_scores op) into the TF Object Detection API.  It adds a `soft_nms_sigma` field to the postprocessing proto file and plumbs this through to both the multiclass and class_agnostic versions of NMS. Note that there is no effect on behavior of NMS when soft_nms_sigma=0 (which it is set to by default).\r\n\r\n    See also \"Soft-NMS -- Improving Object Detection With One Line of Code\" by Bodla et al (https://arxiv.org/abs/1704.04503)\r\n\r\n--\r\n253703949  by Zhichao Lu:\r\n\r\n    Internal test fixes.\r\n\r\n--\r\n253151266  by Zhichao Lu:\r\n\r\n    Fix the op type check for FusedBatchNorm, given that we introduced\r\n    FusedBatchNormV3 in a previous change.\r\n\r\n--\r\n252718956  by Zhichao Lu:\r\n\r\n    Customize activation function to enable relu6 instead of relu for saliency\r\n    prediction model seastarization\r\n\r\n--\r\n252158593  by Zhichao Lu:\r\n\r\n    Make object_detection/core Python3-compatible.\r\n\r\n--\r\n252150717  by Zhichao Lu:\r\n\r\n    Make object_detection/core Python3-compatible.\r\n\r\n--\r\n251967048  by Zhichao Lu:\r\n\r\n    Make GraphRewriter proto extensible.\r\n\r\n--\r\n251950039  by Zhichao Lu:\r\n\r\n    Remove experimental_export_device_assignment from TPUEstimator.export_savedmodel(), so as to remove rewrite_for_inference().\r\n\r\n    As a replacement, export_savedmodel() V2 API supports device_assignment where user call tpu.rewrite in model_fn and pass in device_assigment there.\r\n\r\n--\r\n251890697  by rathodv:\r\n\r\n    Updated docstring to include new output nodes.\r\n\r\n--\r\n251662894  by Zhichao Lu:\r\n\r\n    Add autoaugment augmentation option to objection detection api codebase. This\r\n    is an available option in preprocessor.py.\r\n\r\n    The intended usage of autoaugment is to be done along with random flipping and\r\n    cropping for best results.\r\n\r\n--\r\n251532908  by Zhichao Lu:\r\n\r\n    Add TrainingDataType enum to track whether class-specific or agnostic data was used to fit the calibration function.\r\n\r\n    This is useful, since classes with few observations may require a calibration function fit on all classes.\r\n\r\n--\r\n251511339  by Zhichao Lu:\r\n\r\n    Add multiclass isotonic regression to the calibration builder.\r\n\r\n--\r\n251317769  by pengchong:\r\n\r\n    Internal Change.\r\n\r\n--\r\n250729989  by Zhichao Lu:\r\n\r\n    Fixing bug in gt statistics count in case of mask and box annotations.\r\n\r\n--\r\n250729627  by Zhichao Lu:\r\n\r\n    Label expansion for segmentation.\r\n\r\n--\r\n250724905  by Zhichao Lu:\r\n\r\n    Fix use_depthwise in fpn and test it with fpnlite on ssd + mobilenet v2.\r\n\r\n--\r\n250670379  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n250630364  by lzc:\r\n\r\n    Fix detection_model_zoo footnotes\r\n\r\n--\r\n250560654  by Zhichao Lu:\r\n\r\n    Fix static shape issue in matmul_crop_and_resize.\r\n\r\n--\r\n250534857  by Zhichao Lu:\r\n\r\n    Edit class agnostic calibration function docstring to more accurately describe the function's outputs.\r\n\r\n--\r\n250533277  by Zhichao Lu:\r\n\r\n    Edit the multiclass messages to use class ids instead of labels.\r\n\r\n--\r\n\r\nPiperOrigin-RevId: 257914648",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2019-07-12T20:41:47Z",
        "closed_at": "2019-07-16T17:34:12Z",
        "merged_at": "2019-07-16T17:34:12Z",
        "body": "Ncf perf changes 1)exclude metric layer from CTL train step 2) Dataset optimization to fix size of the sample_weights, preventing a costly broadcast during loss calculation for multi-gpu case",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 19,
        "changed_files": 1,
        "created_at": "2019-07-12T19:19:47Z",
        "closed_at": "2019-07-20T01:42:46Z",
        "merged_at": "2019-07-20T01:42:46Z",
        "body": "Tensorflow softmax GPU internally internally performs math operations using float32 for numeric stability. So in mixed-precision training, we can keep the input and output of softmax in float16 for better performance (without manual casting and also save memory bandwidth).",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 0,
        "changed_files": 0,
        "created_at": "2019-07-11T21:02:03Z",
        "closed_at": "2019-07-13T03:48:11Z",
        "merged_at": null,
        "body": "257525973  by Zhichao Lu:\r\n\r\n    Fixes bug that silently prevents checkpoints from loading when training w/ eager + functions. Also sets up scripts to run training.\r\n\r\n--\r\n257296614  by Zhichao Lu:\r\n\r\n    Adding detection_features to model outputs\r\n\r\n--\r\n257234565  by Zhichao Lu:\r\n\r\n    Fix wrong order of `classes_with_max_scores` in class-agnostic NMS caused by\r\n    sorting in partitioned-NMS.\r\n\r\n--\r\n257232002  by ronnyvotel:\r\n\r\n    Supporting `filter_nonoverlapping` option in np_box_list_ops.clip_to_window().\r\n\r\n--\r\n257198282  by Zhichao Lu:\r\n\r\n    Adding the focal loss and l1 loss from the Objects as Points paper.\r\n\r\n--\r\n257089535  by Zhichao Lu:\r\n\r\n    Create Keras based ssd + resnetv1 + fpn.\r\n\r\n--\r\n257087407  by Zhichao Lu:\r\n\r\n    Make object_detection/data_decoders Python3-compatible.\r\n\r\n--\r\n257004582  by Zhichao Lu:\r\n\r\n    Updates _decode_raw_data_into_masks_and_boxes to the latest binary masks-to-string encoding format.\r\n\r\n--\r\n257002124  by Zhichao Lu:\r\n\r\n    Make object_detection/utils Python3-compatible, except json_utils.\r\n\r\n    The patching trick used in json_utils is not going to work in Python 3.\r\n\r\n--\r\n256795056  by lzc:\r\n\r\n    Add a detection_anchor_indices field to detection outputs.\r\n\r\n--\r\n256477542  by Zhichao Lu:\r\n\r\n    Make object_detection/core Python3-compatible.\r\n\r\n--\r\n256387593  by Zhichao Lu:\r\n\r\n    Edit class_id_function_approximations builder to skip class ids not present in label map.\r\n\r\n--\r\n256259039  by Zhichao Lu:\r\n\r\n    Move NMS to TPU for FasterRCNN.\r\n\r\n--\r\n256071360  by rathodv:\r\n\r\n    When multiclass_scores is empty, add one-hot encoding of groundtruth_classes as multiclass scores so that data_augmentation ops that expect the presence of multiclass_scores don't have to individually handle this case.\r\n\r\n    Also copy input tensor_dict to out_tensor_dict first to avoid inplace modification.\r\n\r\n--\r\n256023645  by Zhichao Lu:\r\n\r\n    Adds the first WIP iterations of TensorFlow v2 eager + functions style custom training & evaluation loops.\r\n\r\n--\r\n255980623  by Zhichao Lu:\r\n\r\n    Adds a new data augmentation operation \"remap_labels\" which remaps a set of labels to a new label.\r\n\r\n--\r\n255753259  by Zhichao Lu:\r\n\r\n    Announcement of the released evaluation tutorial for Open Images Challenge\r\n    2019.\r\n\r\n--\r\n255698776  by lzc:\r\n\r\n    Fix rewrite_nn_resize_op function which was broken by tf forward compatibility movement.\r\n\r\n--\r\n255623150  by Zhichao Lu:\r\n\r\n    Add Keras-based ResnetV1 models.\r\n\r\n--\r\n255504992  by Zhichao Lu:\r\n\r\n    Fixing the typo in specifying label expansion for ground truth segmentation\r\n    file.\r\n\r\n--\r\n255470768  by Zhichao Lu:\r\n\r\n    1. Fixing Python bug with parsed arguments.\r\n    2. Adding capability to parse relevant columns from CSV header.\r\n    3. Fixing bug with duplicated labels expansion.\r\n\r\n--\r\n255462432  by Zhichao Lu:\r\n\r\n    Adds a new data augmentation operation \"drop_label_probabilistically\" which drops a given label with the given probability. This supports experiments on training in the presence of label noise.\r\n\r\n--\r\n255441632  by rathodv:\r\n\r\n    Fallback on groundtruth classes when multiclass_scores tensor is empty.\r\n\r\n--\r\n255434899  by Zhichao Lu:\r\n\r\n    Ensuring evaluation binary can run even with big files by synchronizing\r\n    processing of ground truth and predictions: in this way, ground truth is not stored but immediatly\r\n    used for evaluation. In case gt of object masks, this allows to run\r\n    evaluations on relatively large sets.\r\n\r\n--\r\n255337855  by lzc:\r\n\r\n    Internal change.\r\n\r\n--\r\n255308908  by Zhichao Lu:\r\n\r\n    Add comment to clarify usage of calibration parameters proto.\r\n\r\n--\r\n255266371  by Zhichao Lu:\r\n\r\n    Ensuring correct processing of the case, when no groundtruth masks are provided\r\n    for an image.\r\n\r\n--\r\n255236648  by Zhichao Lu:\r\n\r\n    Refactor model_builder in faster_rcnn.py to a util_map, so that it's possible to be overwritten.\r\n\r\n--\r\n255093285  by Zhichao Lu:\r\n\r\n    Updating capability to subsample data during evaluation\r\n\r\n--\r\n255081222  by rathodv:\r\n\r\n    Convert groundtruth masks to be of type float32 before its used in the loss function.\r\n\r\n    When using mixed precision training, masks are represented using bfloat16 tensors in the input pipeline for performance reasons. We need to convert them to float32 before using it in the loss function.\r\n\r\n--\r\n254788436  by Zhichao Lu:\r\n\r\n    Add forward_compatible to non_max_suppression_with_scores to make it is\r\n    compatible with older tensorflow version.\r\n\r\n--\r\n254442362  by Zhichao Lu:\r\n\r\n    Add num_layer field to ssd feature extractor proto.\r\n\r\n--\r\n253911582  by jonathanhuang:\r\n\r\n    Plumbs Soft-NMS options (using the new tf.image.non_max_suppression_with_scores op) into the TF Object Detection API.  It adds a `soft_nms_sigma` field to the postprocessing proto file and plumbs this through to both the multiclass and class_agnostic versions of NMS. Note that there is no effect on behavior of NMS when soft_nms_sigma=0 (which it is set to by default).\r\n\r\n    See also \"Soft-NMS -- Improving Object Detection With One Line of Code\" by Bodla et al (https://arxiv.org/abs/1704.04503)\r\n\r\n--\r\n253703949  by Zhichao Lu:\r\n\r\n    Internal test fixes.\r\n\r\n--\r\n253151266  by Zhichao Lu:\r\n\r\n    Fix the op type check for FusedBatchNorm, given that we introduced\r\n    FusedBatchNormV3 in a previous change.\r\n\r\n--\r\n252718956  by Zhichao Lu:\r\n\r\n    Customize activation function to enable relu6 instead of relu for saliency\r\n    prediction model seastarization\r\n\r\n--\r\n252158593  by Zhichao Lu:\r\n\r\n    Make object_detection/core Python3-compatible.\r\n\r\n--\r\n252150717  by Zhichao Lu:\r\n\r\n    Make object_detection/core Python3-compatible.\r\n\r\n--\r\n251967048  by Zhichao Lu:\r\n\r\n    Make GraphRewriter proto extensible.\r\n\r\n--\r\n251950039  by Zhichao Lu:\r\n\r\n    Remove experimental_export_device_assignment from TPUEstimator.export_savedmodel(), so as to remove rewrite_for_inference().\r\n\r\n    As a replacement, export_savedmodel() V2 API supports device_assignment where user call tpu.rewrite in model_fn and pass in device_assigment there.\r\n\r\n--\r\n251890697  by rathodv:\r\n\r\n    Updated docstring to include new output nodes.\r\n\r\n--\r\n251662894  by Zhichao Lu:\r\n\r\n    Add autoaugment augmentation option to objection detection api codebase. This\r\n    is an available option in preprocessor.py.\r\n\r\n    The intended usage of autoaugment is to be done along with random flipping and\r\n    cropping for best results.\r\n\r\n--\r\n251532908  by Zhichao Lu:\r\n\r\n    Add TrainingDataType enum to track whether class-specific or agnostic data was used to fit the calibration function.\r\n\r\n    This is useful, since classes with few observations may require a calibration function fit on all classes.\r\n\r\n--\r\n251511339  by Zhichao Lu:\r\n\r\n    Add multiclass isotonic regression to the calibration builder.\r\n\r\n--\r\n251317769  by pengchong:\r\n\r\n    Internal Change.\r\n\r\n--\r\n250729989  by Zhichao Lu:\r\n\r\n    Fixing bug in gt statistics count in case of mask and box annotations.\r\n\r\n--\r\n250729627  by Zhichao Lu:\r\n\r\n    Label expansion for segmentation.\r\n\r\n--\r\n250724905  by Zhichao Lu:\r\n\r\n    Fix use_depthwise in fpn and test it with fpnlite on ssd + mobilenet v2.\r\n\r\n--\r\n250670379  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n250630364  by lzc:\r\n\r\n    Fix detection_model_zoo footnotes\r\n\r\n--\r\n250560654  by Zhichao Lu:\r\n\r\n    Fix static shape issue in matmul_crop_and_resize.\r\n\r\n--\r\n250534857  by Zhichao Lu:\r\n\r\n    Edit class agnostic calibration function docstring to more accurately describe the function's outputs.\r\n\r\n--\r\n250533277  by Zhichao Lu:\r\n\r\n    Edit the multiclass messages to use class ids instead of labels.\r\n\r\n--\r\n\r\nPiperOrigin-RevId: 257525973",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 24,
        "deletions": 9,
        "changed_files": 2,
        "created_at": "2019-07-11T17:47:46Z",
        "closed_at": "2019-07-11T19:46:11Z",
        "merged_at": "2019-07-11T19:46:11Z",
        "body": "This records the highest bleu score found along with which iteration it occurred on.  It is possible the issues with our variance can be resolved; but for now this will give us a better indication as to if we have an issue.  \r\n\r\nMy knowledge is not complete, but the paper mentioned it took the average of the parameters of the last 5 checkpoints.  This suggest to me the result is not as stable as say ResNet.  Currently running the test and taking a reading at a predefined epoch gives results that are not conclusive or actionable.  \r\n\r\nI also record the final bleu uncased in a different field so that is also tracked.  ",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 156,
        "deletions": 1,
        "changed_files": 3,
        "created_at": "2019-07-11T15:24:47Z",
        "closed_at": "2022-06-19T18:15:29Z",
        "merged_at": null,
        "body": "model_main is extended by a runconfig_overrides command line parameter\r\nthat allows to overwrite individual attributes of the default RunConfig\r\nin a similar manner as hparams_overrides allows to overwrite\r\nhyperparameters on command line.\r\n\r\nCloses #5246\r\n\r\nThis is just a proposal. I am not sure if it makes sense to _reuse_ `parse_values` from `contrib.training`. Please advise if the implementation and the feature makes sense to you.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 29,
        "deletions": 28,
        "changed_files": 2,
        "created_at": "2019-07-11T03:48:43Z",
        "closed_at": "2019-07-11T06:24:21Z",
        "merged_at": "2019-07-11T06:24:21Z",
        "body": "**Waiting on final test result to finish: ResNet50 XLA+FP16.**\r\n\r\nThis changes ResNet50 and ResNet56.  The detailed comments below cover each situation. The change was first made to ResNet50 to aligned with TPUs and was tested on TPU to reduce variance and help push to .764 more often. I decided to apply it to ResNet56 as well as make the dense layers match. \r\n\r\n**ResNet56**\r\nIn a 6 run test this has make ResNet56 much more stable and should allow us to reduce the error bars for the test to better detect regressions.  We currently have to accept values as low as .924 as possibly ok.  \r\n\r\n**Before:**  Min: .924  Max: .938  Median: .931\r\n**After:**   Min  .929  MAX .934  Median: .932\r\n\r\nRaw numbers:\r\n0.9324919581\r\n0.9309895635\r\n0.9342948794\r\n0.9292868376\r\n0.9331930876\r\n0.9320913553\r\n\r\n**ResNet50**\r\nI just did one run given the change was minor and I believe I have seen us set this in tf_cnn_benchmarks or maybe not.  Either way I did XLA + FP16 because it runs fast and if that works we should be good to go. \r\n625/625 - 244s - loss: 1.3501 - sparse_categorical_accuracy: 0.7797 - val_loss: 1.3821 - val_sparse_categorical_accuracy: **0.7638** <-- looks good.\r\n\r\nhttps://sponge.corp.google.com/target?id=c09a85d7-28a1-46e0-a3c4-eebd49dbc6cc&target=tensorflow_models/perfzero/manual/v100_8_gpu/v100_8_gpu&searchFor=&show=ALL&sortBy=STATUS\r\n\r\n\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 153,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2019-07-10T20:26:14Z",
        "closed_at": "2019-07-11T02:39:07Z",
        "merged_at": null,
        "body": "Merged commit includes the following changes:\n257314238  by hongkuny<hongkuny@google.com>:\n    \n    Creates transformer v2 README.\n    Remove contents that are not implemented.\n    \n--",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 21,
        "changed_files": 2,
        "created_at": "2019-07-10T17:49:49Z",
        "closed_at": "2019-07-11T04:00:40Z",
        "merged_at": "2019-07-11T04:00:40Z",
        "body": "I did local testing and the results of 5+ runs look to have the same variance as before.  Here is what I believe changed so the reviewer can check my logic:\r\n\r\n- PerfZero uses the `self.timestamp_log` and I believe my change is a no-op for that code path  `self.timestamp_log.append(BatchTimestamp(self.global_steps, timestamp))` \r\n- Examples per second print out might be slightly lower because I no longer allow a gap between `on_batch_end` and `on_batch_begin`.  I made the start_time the end_time, which is how perfzero calculates the examples/second anyway.\r\n\r\nNote that I do not think the estimator hook does this.  It looks like it used the step time taken from inside TensorFlow and I very much doubt that included the time between steps.  It should be minor based on the results I saw but I did not attempt to measure it.  \r\n\r\nThe improvement:\r\n\r\n- Global step runs through epochs and does not reset like using `batch`.  Uneven batches resulted in the first log of each epoch after the first being incorrect and making it look like there was some issue at the epoch boundary.  I tested that if you do not do any eval between epochs it just keeps going and prints as expected with zero slow down.  If you do eval between epochs you will see the first measurement as slower as it will include that time.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-07-10T04:22:29Z",
        "closed_at": "2019-07-11T21:35:02Z",
        "merged_at": "2019-07-11T21:35:02Z",
        "body": "Early results indicate FP16 trains with the same or maybe less steps than FP32. No need for the 20 epochs which takes \"forever\" and has no added value.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-07-10T03:04:32Z",
        "closed_at": "2020-04-24T05:27:41Z",
        "merged_at": "2020-04-24T05:27:41Z",
        "body": "tiny typing error: prerprocessiing -> preprocessing",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 13,
        "changed_files": 1,
        "created_at": "2019-07-09T23:21:55Z",
        "closed_at": "2020-05-09T01:25:38Z",
        "merged_at": null,
        "body": "Rename to AI Platform",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 10,
        "changed_files": 1,
        "created_at": "2019-07-09T15:48:21Z",
        "closed_at": "2019-07-09T19:26:40Z",
        "merged_at": "2019-07-09T19:26:39Z",
        "body": "Needed additional expand for conv2d. \r\n\r\nSuppress compat warnings by moving to compat.v1 versions of some functions.\r\n\r\nNote that this code is not 2.0 compatible yet - that will be a future set of changes.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-07-09T13:03:13Z",
        "closed_at": "2019-09-03T06:20:19Z",
        "merged_at": null,
        "body": "well, when i use to models/research/object_detection, i usually needed bounding boxes location,\r\nso, i suggest this merge.\r\nthank you!",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 20,
        "deletions": 8,
        "changed_files": 2,
        "created_at": "2019-07-09T01:32:48Z",
        "closed_at": "2022-07-30T22:54:39Z",
        "merged_at": null,
        "body": "try and except for unicode NameError and dict.iteritems AttributeError",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 61,
        "deletions": 54,
        "changed_files": 1,
        "created_at": "2019-07-08T21:28:42Z",
        "closed_at": "2019-07-08T22:48:17Z",
        "merged_at": "2019-07-08T22:48:17Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 32,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2019-07-08T18:43:02Z",
        "closed_at": "2019-07-08T20:29:11Z",
        "merged_at": "2019-07-08T20:29:11Z",
        "body": "See internal email with distribution of results and pivot tables for details.\r\n\r\nFP16 dynamic batch is to compare with FP32 number. Static batch is not as well tested and without the updated packing algo it may not be worth testing yet.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-07-07T16:54:42Z",
        "closed_at": "2019-07-08T01:59:47Z",
        "merged_at": "2019-07-08T01:59:47Z",
        "body": "Changed dataset name from PASCAL VOC 2012 to ADE20K in description. ",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-07-07T07:53:28Z",
        "closed_at": "2019-07-08T17:58:18Z",
        "merged_at": "2019-07-08T17:58:18Z",
        "body": "Related with issue [7156](https://github.com/tensorflow/models/issues/7156)",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-07-04T19:02:19Z",
        "closed_at": "2019-07-10T22:51:19Z",
        "merged_at": "2019-07-10T22:51:19Z",
        "body": "There is an error in step3 of maskGAN.\r\n\r\nNotFoundError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\r\n\r\nKey critic/rnn/biases not found in checkpoint\r\n[[node save/RestoreV2 (defined at train_mask_gan.py:431) ]]\r\n\r\nThis is an issue with seq2seq model because it uses the attention mechanism.\r\nThe issue arises if you saved the model with an earlier version (seq2seq is old) and restore with a recent one (saver.restore got updated).\r\nThe naming convention for LSTM parameters changed, e.g. cell_0/basic_lstm_cell/weights became cell_0/basic_lstm_cell/kernel.\r\nWhich is why you cannot restore them if you try to restore old checkpoints with recent TF.\r\nPlease edit the original maskGAN readme file and add this information.\r\nThe below script will help rename the variables and everything will work as expected.\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/tools/checkpoint_convert.py\r\n\r\nI tested and it worked for me, please confirm if it does for you.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-07-04T16:08:16Z",
        "closed_at": "2020-04-25T04:08:00Z",
        "merged_at": "2020-04-25T04:08:00Z",
        "body": "Small spelling fix: Common -> Commons",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 59,
        "deletions": 57,
        "changed_files": 5,
        "created_at": "2019-07-02T18:28:23Z",
        "closed_at": "2019-07-02T23:07:12Z",
        "merged_at": "2019-07-02T23:07:11Z",
        "body": "Merged commit includes the following changes:\n256204636  by hongkuny<hongkuny@google.com>:\n    \n    Internal\n    ",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-07-02T06:49:07Z",
        "closed_at": "2020-04-24T15:25:44Z",
        "merged_at": null,
        "body": "When rading ImageNet data, allow files to be read in non-determinstic\r\norder. This greatly improves performance when reading from some cloud\r\nstorage backends (e.g. Google Cloud Storage).",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-07-02T00:53:49Z",
        "closed_at": "2019-07-02T18:11:34Z",
        "merged_at": "2019-07-02T18:11:34Z",
        "body": "when there are multiple workers.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-07-02T00:46:25Z",
        "closed_at": "2019-07-02T20:18:53Z",
        "merged_at": "2019-07-02T20:18:53Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 54,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-06-28T18:28:09Z",
        "closed_at": "2019-06-28T19:28:16Z",
        "merged_at": "2019-06-28T19:28:16Z",
        "body": "Tests are failing due to an issue with checkpointing and loading, but we should still accept the tests so we can work through the issues.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 281,
        "deletions": 6,
        "changed_files": 3,
        "created_at": "2019-06-27T21:06:37Z",
        "closed_at": "2019-06-28T00:14:49Z",
        "merged_at": "2019-06-28T00:14:49Z",
        "body": "Merged commit includes the following changes:\n255470372  by dmchen<dmchen@google.com>:\n    \n    Slightly expand expected range for F1 score in BERT SQuAD accuracy test\n    \n--\n255109240  by hongkuny<hongkuny@google.com>:\n    \n    Update eval/predict batch sizes.\n    ",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 339,
        "deletions": 133,
        "changed_files": 3,
        "created_at": "2019-06-27T02:51:12Z",
        "closed_at": "2021-07-15T18:49:57Z",
        "merged_at": null,
        "body": "I'd like to modify and commit jupyter code.\r\n\r\n1) preprocessing model wrapped key-object type.\r\n2) 'load_batch' function can received parameter to save all preprocessed image files and to load preprocessing model using key-object model.\r\n\r\nso, can i make the branch your repo? how can i do that?",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2019-06-26T02:34:03Z",
        "closed_at": "2019-06-28T17:36:37Z",
        "merged_at": "2019-06-28T17:36:37Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 233,
        "deletions": 124,
        "changed_files": 29,
        "created_at": "2019-06-25T20:52:10Z",
        "closed_at": "2019-07-03T16:51:15Z",
        "merged_at": "2019-07-03T16:51:15Z",
        "body": "Ready for Review.  \r\n\r\nOpen to revisit tests that are skipped for TF 2.0. The TF 2.0 presubmit server will be dual GPU.",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 72,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-06-25T04:52:57Z",
        "closed_at": "2019-09-03T06:15:06Z",
        "merged_at": null,
        "body": "This script will solve the variable file saving in variable folder problem in Tensorflow. User can run this script to save variable wherever he/she want to store variable file in their local system.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-06-24T16:42:52Z",
        "closed_at": "2019-06-24T18:09:40Z",
        "merged_at": "2019-06-24T18:09:40Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 62,
        "deletions": 47,
        "changed_files": 4,
        "created_at": "2019-06-22T04:17:52Z",
        "closed_at": "2019-06-22T13:25:08Z",
        "merged_at": "2019-06-22T13:25:08Z",
        "body": "*  Updated tests that were failing\r\n   *  mostly to skip GPU tests when on GPU\r\n   *  Reset flags in setup\r\n   *  Use correct set eager if _v2.0\r\n* What looks like needless changes to the presubmit.sh make it easy to swap in `-m unittest` which may be a hopeless dream.  I can be talked into reverting them.\r\n\r\nI really wanted to use python3 -m unittest.  But this skips the main and requires a different approach to loading the flags which I fear would mess up the internal testing.  The benefit to -m unittest is that if a test file has a bad module/import you get a clear failure with the test method failing because the module is missing vs. the current method where test are run with python3 dir/dir/blah_test.py and the error is just like running a script with a missing module or bad import.  Maybe there is a better method but none-the-less this is better and the script update to kokoro gives a decent summary.  \r\n\r\nWe will see....  \r\n\r\nTest pass CPU local with Python3.  I am testing GPU and then hoping to changing kokoro to use GPUs for a bigger range of tests.  ",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-06-22T00:34:11Z",
        "closed_at": "2019-06-24T18:09:53Z",
        "merged_at": null,
        "body": "Merged commit includes the following changes:\n254497647  by hongkuny<hongkuny@google.com>:\n    \n    Fix device placement for TPU export model.\n    \n--",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 8,
        "changed_files": 3,
        "created_at": "2019-06-21T21:59:19Z",
        "closed_at": "2019-06-22T19:24:34Z",
        "merged_at": "2019-06-22T19:24:34Z",
        "body": "- updated URL to CNN tutorial page\r\n- minor refactor in order of imports ",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 40,
        "deletions": 6,
        "changed_files": 3,
        "created_at": "2019-06-21T15:31:15Z",
        "closed_at": "2019-06-21T16:43:33Z",
        "merged_at": null,
        "body": "- URL in readme was no longer valid\r\n- Added missing function maybe_download_and_extract, once it was part of the repo but it was removed and there is a function call to non existent func",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2019-06-21T11:15:02Z",
        "closed_at": "2019-06-21T17:04:30Z",
        "merged_at": "2019-06-21T17:04:30Z",
        "body": "Fix help print error when stdout/stderr not use utf-8 encoding, like https://github.com/tensorflow/models/issues/5637\r\n\r\nMain reason is the help wrap did not check the stdout encoding, even the system have installed utf-8 locale package",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 10,
        "deletions": 42,
        "changed_files": 5,
        "created_at": "2019-06-21T06:12:44Z",
        "closed_at": "2019-07-19T05:31:51Z",
        "merged_at": null,
        "body": "model.add_loss is (1) simpler (2) works in both 1.x and 2.0 with distribution strategy.\r\nUsing the loss layer has a bug with 1.x + distribution strategy that we do not have an easy way to fix. ",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 1,
        "changed_files": 3,
        "created_at": "2019-06-21T02:11:10Z",
        "closed_at": "2019-06-21T17:47:48Z",
        "merged_at": "2019-06-21T17:47:48Z",
        "body": "Custom metrics during training seem to have a reasonable overhead, so making them optional with a flag. \r\nFor 1 GPU, base, it increases ex/s from 16.8k to 19k/s\r\nFor 8 GPU, base, it increases from 111k to 125k/s. ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 11,
        "changed_files": 2,
        "created_at": "2019-06-20T23:29:45Z",
        "closed_at": "2019-06-21T03:06:03Z",
        "merged_at": "2019-06-21T03:06:03Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 118,
        "deletions": 27,
        "changed_files": 1,
        "created_at": "2019-06-20T20:18:16Z",
        "closed_at": "2019-06-21T16:03:23Z",
        "merged_at": "2019-06-21T16:03:23Z",
        "body": "Tested locally nothing blows up.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 130,
        "deletions": 73,
        "changed_files": 13,
        "created_at": "2019-06-20T17:35:03Z",
        "closed_at": "2019-06-21T14:22:11Z",
        "merged_at": "2019-06-21T14:22:11Z",
        "body": "First: I am sorry this got big.  What happened is to move run_eagerly as a based flag Resnet flag usage needed refactored.  And I wanted to do it anyway to reduce our calls to resnet_run_loop from the TF 2.0/Keras code.\r\n\r\nI have run ResNet50 and ResNet56 1 GPU tests  benchmark.*1_gpu and for ResNet50 benchmark.*8_gpu and then the NCF tests.\r\n\r\nVery soon I will factor out the rest of the calls to imagenet_main.py from the v2 folder so we can more easily move the v1 code into some archive folder.  I think only the constants are left.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-06-20T07:38:35Z",
        "closed_at": "2019-06-21T23:34:32Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 140,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-06-20T02:03:13Z",
        "closed_at": "2019-06-20T03:19:28Z",
        "merged_at": "2019-06-20T03:19:28Z",
        "body": "FP16 test are failing.\r\n\r\nTypeError: in converted code:\r\n\r\n   /workspace/benchmarks/perfzero/workspace/site-packages/models/official/transformer/v2/transformer.py:127 call  *\r\n       logits = self.decode(targets, encoder_outputs, attention_bias, training)\r\n   /workspace/benchmarks/perfzero/workspace/site-packages/models/official/transformer/v2/transformer.py:206 decode  *\r\n       logits = self.embedding_softmax_layer(outputs, mode=\"linear\")\r\n   /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py:699 __call__\r\n       outputs = call_fn(inputs, *args, **kwargs)\r\n   /workspace/benchmarks/perfzero/workspace/site-packages/models/official/transformer/v2/embedding_layer.py:73 call  *\r\n       return self._linear(inputs)\r\n   /workspace/benchmarks/perfzero/workspace/site-packages/models/official/transformer/v2/embedding_layer.py:102 _linear  *\r\n       logits = tf.matmul(x, self.shared_weights, transpose_b=True)\r\n   /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/dispatch.py:180 wrapper\r\n       return target(*args, **kwargs)\r\n   /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_ops.py:2661 matmul\r\n       a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\r\n   /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_math_ops.py:5982 mat_mul\r\n       name=name)\r\n   /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py:563 _apply_op_helper\r\n       inferred_from[input_arg.type_attr]))\r\n\r\n   TypeError: Input 'b' of 'MatMul' Op has type float32 that does not match type float16 of argument 'a'.\r\nhttps://sponge.corp.google.com/target?id=db890010-cb81-44ce-a74e-2a33cc500e74&target=tensorflow_models/perfzero/manual/v100_1_gpu/v100_1_gpu&searchFor=&show=ALL&sortBy=STATUS\r\nchecking to see if I did anything wrong.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 22,
        "deletions": 10,
        "changed_files": 1,
        "created_at": "2019-06-20T01:00:59Z",
        "closed_at": "2019-06-20T05:20:22Z",
        "merged_at": "2019-06-20T05:20:22Z",
        "body": "Merged commit includes the following changes:\n254069984  by hongkuny<hongkuny@google.com>:\n    Automated rollback of changelist 254060732.\n\n254061429  by hongkuny<hongkuny@google.com>:\n    \n    Use host while loop for training steps.\n    \n--\n254060732  by yifeif<yifeif@google.com>:\n    Automated rollback of changelist 254027750.\n\n254027750  by hongkuny<hongkuny@google.com>:",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2019-06-19T21:49:02Z",
        "closed_at": "2019-06-20T02:37:47Z",
        "merged_at": "2019-06-20T02:37:47Z",
        "body": "Fix trailing whitespace lint error.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 65,
        "deletions": 2,
        "changed_files": 5,
        "created_at": "2019-06-19T15:15:17Z",
        "closed_at": "2019-06-20T17:54:59Z",
        "merged_at": "2019-06-20T17:54:59Z",
        "body": "Setting the learning phase for some reason negatively affect the performance when not using distribution strategy. We observe additional FusedBachnorm Grad ops in the backward pass if the learning phase here is set to 1. The root cause is still unclear.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 13,
        "deletions": 36,
        "changed_files": 1,
        "created_at": "2019-06-19T03:15:18Z",
        "closed_at": "2019-06-19T14:06:09Z",
        "merged_at": "2019-06-19T14:06:09Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 141,
        "deletions": 109,
        "changed_files": 11,
        "created_at": "2019-06-18T20:11:07Z",
        "closed_at": "2019-06-19T20:48:56Z",
        "merged_at": "2019-06-19T20:48:56Z",
        "body": "- Moved config logic to keras_utils\r\n- Added enable_xla flag to _performance flags\r\n- refactored flags for keras resnet\r\n- created common set_session_config",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-06-18T18:13:40Z",
        "closed_at": "2019-06-18T21:04:07Z",
        "merged_at": "2019-06-18T21:04:07Z",
        "body": "Resolves: https://github.com/tensorflow/models/issues/6970",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 67,
        "deletions": 45,
        "changed_files": 1,
        "created_at": "2019-06-18T00:24:45Z",
        "closed_at": "2019-06-18T01:31:00Z",
        "merged_at": "2019-06-18T01:31:00Z",
        "body": "253636854  by dmchen<dmchen@google.com>:\r\n\r\n    Run only training in BERT SQuAD performance test\r\n\r\n--\r\n253118910  by hongkuny<hongkuny@google.com>:\r\n\r\n    Internal change\r\n\r\nPiperOrigin-RevId: 253636854",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 47,
        "deletions": 11,
        "changed_files": 2,
        "created_at": "2019-06-17T17:35:23Z",
        "closed_at": "2019-06-18T20:44:54Z",
        "merged_at": "2019-06-18T20:44:54Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 96,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-06-15T04:36:16Z",
        "closed_at": "2020-04-25T03:46:49Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 13,
        "changed_files": 3,
        "created_at": "2019-06-14T16:46:52Z",
        "closed_at": "2019-06-14T19:02:53Z",
        "merged_at": "2019-06-14T19:02:53Z",
        "body": "Sorry to double up, but I saw this flagged as unused and I am risking doing both changes at one time.  Running some test in kokoro to ensure I am not blowing anything up.  ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2019-06-13T20:15:15Z",
        "closed_at": "2019-06-13T22:59:41Z",
        "merged_at": "2019-06-13T22:59:41Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 102,
        "deletions": 16,
        "changed_files": 7,
        "created_at": "2019-06-13T18:59:34Z",
        "closed_at": "2019-06-19T22:49:50Z",
        "merged_at": "2019-06-19T22:49:50Z",
        "body": "To test convergence, I ran the following command on a DGX-1:\r\n\r\n```\r\npython transformer_main.py --num_gpus=8 --distribution_strategy=mirrored --data_dir ~/transformer_data2 --vocab_file ~/transformer_data2/vocab.ende.32768 --bleu_source ~/transformer_data2/newstest2014.en --bleu_ref ~/transformer_data2/newstest2014.de --param_set=base --batch_size=32768 --train_steps=300000 --steps_between_evals=20000 --log_steps=1000 --static_batch --max_length=64  --model_dir ~/transformer_model_dir_accuracy_fp16 --clean --dtype=fp16\r\n```\r\n\r\nI ran the convergence test on a slightly older version of the PR (67a4bdfc689a7e530663fd40614cccf25bd2df24) before doing some cleanup.\r\n\r\nThe results: BLEU: uncased=27.7248412371, cased=27.1868109703.\r\n\r\nEDIT:\r\n\r\nAnd the fp32 results: BLEU: uncased=27.6445806026, cased=27.1022170782\r\nSo fp16 does not harm accuracy with the command I tried.",
        "comments": 13
    },
    {
        "merged": true,
        "additions": 191,
        "deletions": 208,
        "changed_files": 10,
        "created_at": "2019-06-13T01:58:46Z",
        "closed_at": "2019-06-13T15:23:33Z",
        "merged_at": "2019-06-13T15:23:33Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-06-11T21:51:31Z",
        "closed_at": "2019-06-14T09:08:35Z",
        "merged_at": null,
        "body": "fix AttributeError: module 'tensorflow._api.v1.distribute' has no attribute 'OneDeviceStrategy' when running models/official/mnist/mnist.py",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 248,
        "deletions": 44,
        "changed_files": 5,
        "created_at": "2019-06-11T21:50:54Z",
        "closed_at": "2019-06-12T00:24:42Z",
        "merged_at": "2019-06-12T00:24:42Z",
        "body": "252697519 by dmchen<dmchen@google.com>:\r\n\r\n        BERT SQuAD accuracy test\r\n\r\n25266352 by hongjunchoi<hongjunchoi@google.com>:\r\n\r\n        Internal change\r\n\r\n252647871 by hongjunchoi<hongjunchoi@google.com>:\r\n\r\n        Enable multi worker TPU training for BERT pretraining.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 64,
        "deletions": 42,
        "changed_files": 4,
        "created_at": "2019-06-11T20:59:28Z",
        "closed_at": "2019-06-13T05:09:09Z",
        "merged_at": "2019-06-13T05:09:09Z",
        "body": "A number of changes are combined in this PR:\r\n- Clean up some dist strat related flags\r\n- Fix non dist strat version \r\n- use tf.keras.losses instead of tf.losses (temporary issue but might as well use the keras alias)\r\n- Fix loss scaling with dist strat \r\n- Fix metric name in early stopping callback\r\n- Added more test coverage for no strategy and CTL cases. ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2019-06-11T02:37:31Z",
        "closed_at": "2019-06-11T04:35:29Z",
        "merged_at": "2019-06-11T04:35:29Z",
        "body": "Merged commit includes the following changes:\r\n252534787  by hongkuny<hongkuny@google.com>:\r\n    \r\n    Transformer vocab fix to strip correctly in py2\r\n    \r\n\r\n    ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 14,
        "changed_files": 1,
        "created_at": "2019-06-10T16:46:19Z",
        "closed_at": "2019-06-10T18:48:42Z",
        "merged_at": "2019-06-10T18:48:42Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-06-10T11:04:06Z",
        "closed_at": "2019-10-24T06:56:30Z",
        "merged_at": null,
        "body": "There's a type mismatch when using `use_class_agnostic_nms: True` in your pipeline configuration.\r\nEven though the function class_agnostic_non_max_suppression works fine (see the [test](https://github.com/tensorflow/models/blob/master/research/object_detection/core/class_agnostic_nms_test.py)), it returns the nmsed classes with int type, while its [batch version](https://github.com/tensorflow/models/blob/master/research/object_detection/core/post_processing.py#L729) expects a float32 tensor.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-06-09T19:33:39Z",
        "closed_at": "2019-06-13T22:25:57Z",
        "merged_at": "2019-06-13T22:25:57Z",
        "body": "The super `__init__` call was overriding steps_per_epoch and num_epochs to None, so this moves them after.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 693,
        "deletions": 0,
        "changed_files": 5,
        "created_at": "2019-06-07T06:12:45Z",
        "closed_at": "2019-06-19T19:01:22Z",
        "merged_at": "2019-06-19T19:01:22Z",
        "body": "Add benchmarks for running ResNet50 on the ImageNet dataset using custom training loops.\r\n- Benchmarks(accuracy and examples_per_second) added for 1 GPU, 8 GPUs and no distrat\r\n- real and synthetic data use cases\r\n- This does not include benchmarks for the no_function case due to an existing OOM error\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 280,
        "deletions": 91,
        "changed_files": 5,
        "created_at": "2019-06-06T20:33:28Z",
        "closed_at": "2019-06-07T00:33:34Z",
        "merged_at": "2019-06-07T00:33:34Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2019-06-06T04:26:33Z",
        "closed_at": "2020-04-24T07:03:10Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 280,
        "deletions": 91,
        "changed_files": 5,
        "created_at": "2019-06-06T01:57:27Z",
        "closed_at": "2019-06-07T00:34:11Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 13,
        "deletions": 31,
        "changed_files": 1,
        "created_at": "2019-06-05T22:04:17Z",
        "closed_at": "2019-06-06T02:50:45Z",
        "merged_at": "2019-06-06T02:50:45Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 25,
        "changed_files": 4,
        "created_at": "2019-06-05T18:36:34Z",
        "closed_at": "2019-06-05T22:00:19Z",
        "merged_at": "2019-06-05T22:00:19Z",
        "body": "Merged commit includes the following changes:\n251681245  by hongkuny<hongkuny@google.com>:\n    \n    Update bert to use the new tf.distribute APIs \n    ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 47,
        "deletions": 41,
        "changed_files": 4,
        "created_at": "2019-06-05T05:40:18Z",
        "closed_at": "2019-06-05T23:44:30Z",
        "merged_at": "2019-06-05T23:44:30Z",
        "body": "The underlying issue has been fixed so we can now create and update metrics in cross replica context. \r\n\r\nAlso fixed existing unit tests and added more tests which test distribution strategy codepaths as well. ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 24,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2019-06-05T05:32:02Z",
        "closed_at": "2019-06-05T19:32:48Z",
        "merged_at": "2019-06-05T19:32:48Z",
        "body": "Separate 1 GPU transformer benchmarks into those with distribution strategy (will use OneDeviceStrategy) and those without strategy. ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2019-06-05T05:27:12Z",
        "closed_at": "2019-06-05T19:38:39Z",
        "merged_at": "2019-06-05T19:38:39Z",
        "body": "The original max was low (63.5) as some runs would exceed that and fail. ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-06-05T01:52:05Z",
        "closed_at": "2019-06-06T23:43:38Z",
        "merged_at": "2019-06-06T23:43:38Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2019-06-05T01:47:05Z",
        "closed_at": "2019-06-05T04:32:11Z",
        "merged_at": "2019-06-05T04:32:10Z",
        "body": "two things in this PR:\r\n- Loss needs to be scaled by global batch size. \r\n- Training input was being handled differently in fit vs CTL case. made them the same. will observe the difference in convergence from this change and decide which version to keep. ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 40,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-06-05T01:34:18Z",
        "closed_at": "2019-06-05T03:07:36Z",
        "merged_at": "2019-06-05T03:07:36Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 11,
        "changed_files": 2,
        "created_at": "2019-06-03T22:55:59Z",
        "closed_at": "2019-06-04T00:01:59Z",
        "merged_at": "2019-06-04T00:01:59Z",
        "body": "Merged commit includes the following changes:\n251325964  by hongkuny<hongkuny@google.com>:\n    \n    Improve flags\n    \n--\n250942274  by tobyboyd<tobyboyd@google.com>:",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 80,
        "deletions": 15,
        "changed_files": 1,
        "created_at": "2019-06-03T15:59:44Z",
        "closed_at": "2019-06-04T16:10:17Z",
        "merged_at": "2019-06-04T16:10:17Z",
        "body": "This change refactors Resnet50EstimatorBenchmark into a base class and subclasses for single worker and multiple worker benchmarks.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-06-03T07:10:50Z",
        "closed_at": "2020-04-25T03:27:46Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 68,
        "deletions": 71,
        "changed_files": 2,
        "created_at": "2019-06-03T05:40:53Z",
        "closed_at": "2019-06-03T20:24:24Z",
        "merged_at": "2019-06-03T20:24:24Z",
        "body": "Added custom loss (using model.add_loss) and custom metrics (using custom layer) so that we can account for weights in those computations.\r\nThe results with this change seem similar to those with custom training loop:\r\n\r\n```\r\nEpoch 1/10\r\n994/994 [==============================] - 46s 47ms/step - loss: 0.2469 - HR_METRIC: 0.0104 - val_loss: 0.0000e+00 - val_HR_METRIC: 0.5334\r\nEpoch 2/10\r\n994/994 [==============================] - 29s 29ms/step - loss: 0.1873 - HR_METRIC: 0.0100 - val_loss: 0.0000e+00 - val_HR_METRIC: 0.5875\r\nEpoch 3/10\r\n994/994 [==============================] - 29s 29ms/step - loss: 0.1689 - HR_METRIC: 0.0098 - val_loss: 0.0000e+00 - val_HR_METRIC: 0.6166\r\nEpoch 4/10\r\n994/994 [==============================] - 29s 29ms/step - loss: 0.1569 - HR_METRIC: 0.0101 - val_loss: 0.0000e+00 - val_HR_METRIC: 0.6203\r\nEpoch 5/10\r\n994/994 [==============================] - 27s 27ms/step - loss: 0.1487 - HR_METRIC: 0.0100 - val_loss: 0.0000e+00 - val_HR_METRIC: 0.6273\r\nEpoch 6/10\r\n994/994 [==============================] - 27s 27ms/step - loss: 0.1426 - HR_METRIC: 0.0103 - val_loss: 0.0000e+00 - val_HR_METRIC: 0.6305\r\nEpoch 7/10\r\n994/994 [==============================] - 26s 27ms/step - loss: 0.1383 - HR_METRIC: 0.0101 - val_loss: 0.0000e+00 - val_HR_METRIC: 0.6353\r\nEpoch 8/10\r\n994/994 [==============================] - 26s 27ms/step - loss: 0.1349 - HR_METRIC: 0.0106 - val_loss: 0.0000e+00 - val_HR_METRIC: 0.6347\r\nEpoch 9/10\r\n994/994 [==============================] - 27s 27ms/step - loss: 0.1322 - HR_METRIC: 0.0099 - val_loss: 0.0000e+00 - val_HR_METRIC: 0.6366\r\nEpoch 10/10\r\n994/994 [==============================] - 26s 27ms/step - loss: 0.1297 - HR_METRIC: 0.0098 - val_loss: 0.0000e+00 - val_HR_METRIC: 0.6361\r\n```\r\n\r\nAlso removed the cloning flag as cloning is False by default now.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2019-06-03T01:28:29Z",
        "closed_at": "2020-04-24T07:02:49Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 31,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2019-06-02T23:10:26Z",
        "closed_at": "2019-06-03T21:31:13Z",
        "merged_at": "2019-06-03T21:31:13Z",
        "body": "Added a benchmark for 1 and 2 GPUs. Also increased num epochs to 10. ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 52,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2019-06-02T21:04:15Z",
        "closed_at": "2019-06-03T16:02:21Z",
        "merged_at": "2019-06-03T16:02:21Z",
        "body": "Adds a benchmark that is pretty close to MLPerf.  Early results were about 144 minutes, which is pretty good.  I list the off the cuff reasons this is not to spec, but taking that into account I think our theory that if we had address startup issues we might have won last time is pretty valid.\r\n\r\nWe are much faster comparing total time than images/sec compared to our MLPerf numbers from 0.5.  I will setup this job to only run on 96vCPUs.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-05-31T23:11:41Z",
        "closed_at": "2019-06-03T16:02:51Z",
        "merged_at": "2019-06-03T16:02:51Z",
        "body": "After the change (https://github.com/tensorflow/models/pull/6846/files#diff-965780bf33f2aeca41a33f8eba197c79) I receive the following error:\r\n\r\nFile \"./models/official/mnist/mnist_tpu.py\", line 202, in <module>\r\n    absl_app.run()\r\nTypeError: run() missing 1 required positional argument: 'main'\r\n\r\nI added main as an argument and it seems to be working fine now.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 223,
        "deletions": 147,
        "changed_files": 1,
        "created_at": "2019-05-31T21:28:18Z",
        "closed_at": "2019-06-06T19:59:13Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-05-31T18:53:57Z",
        "closed_at": "2019-06-01T14:40:21Z",
        "merged_at": null,
        "body": "Re-batching currently doesn't happen when the batch size isn't constant as is the case with the dynamic batch.  There is an internal fix submitted, but until that makes its ways to nightly and gets verified this work around allows to prevent OOM.\r\n\r\nThe resulting model is still not as fast as it could be, because the underlying tf.function gets retraced for every unique shape of the dynamic batch size.  I'm looking into that now.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 42,
        "deletions": 40,
        "changed_files": 7,
        "created_at": "2019-05-31T18:37:29Z",
        "closed_at": "2019-05-31T19:47:18Z",
        "merged_at": "2019-05-31T19:47:18Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4764,
        "deletions": 1897,
        "changed_files": 77,
        "created_at": "2019-05-31T00:49:40Z",
        "closed_at": "2019-05-31T05:27:45Z",
        "merged_at": "2019-05-31T05:27:45Z",
        "body": "250447559  by Zhichao Lu:\r\n\r\n    Update expected files format for Instance Segmentation challenge:\r\n    - add fields ImageWidth, ImageHeight and store the values per prediction\r\n    - as mask, store only encoded image and assume its size is ImageWidth x ImageHeight\r\n\r\n--\r\n250402780  by rathodv:\r\n\r\n    Fix failing Mask R-CNN TPU convergence test.\r\n\r\n    Cast second stage prediction tensors from bfloat16 to float32 to prevent errors in third target assignment (Mask Prediction) - Concat with different types bfloat16 and bfloat32 isn't allowed.\r\n\r\n--\r\n250300240  by Zhichao Lu:\r\n\r\n    Addion Open Images Challenge 2019 object detection and instance segmentation\r\n    support into Estimator framework.\r\n\r\n--\r\n249944839  by rathodv:\r\n\r\n    Modify exporter.py to add multiclass score nodes in exported inference graphs.\r\n\r\n--\r\n249935201  by rathodv:\r\n\r\n    Modify postprocess methods to preserve multiclass scores after non max suppression.\r\n\r\n--\r\n249878079  by Zhichao Lu:\r\n\r\n    This CL slightly refactors some Object Detection helper functions for data creation, evaluation, and groundtruth providing.\r\n\r\n    This will allow the eager+function custom loops to share code with the existing estimator training loops.\r\n\r\n    Concretely we make the following changes:\r\n    1. In input creation we separate dataset-creation into top-level helpers, and allow it to optionally accept a pre-constructed model directly instead of always creating a model from the config just for feature preprocessing.\r\n\r\n    2. In coco evaluation we split the update_op creation into its own function, which the custom loops will call directly.\r\n\r\n    3. In model_lib we move groundtruth providing/ datastructure munging into a helper function\r\n\r\n    4. For now we put an escape hatch in `_summarize_target_assignment` when executing in tf v2.0 behavior because the summary apis used only work w/ tf 1.x\r\n\r\n--\r\n249673507  by rathodv:\r\n\r\n    Use explicit casts instead of tf.to_float and tf.to_int32 to avoid warnings.\r\n\r\n--\r\n249656006  by Zhichao Lu:\r\n\r\n    Add named \"raw_keypoint_locations\" node that corresponds with the \"raw_box_locations\" node.\r\n\r\n--\r\n249651674  by rathodv:\r\n\r\n    Keep proposal boxes in float format. MatMulCropAndResize can handle the type even when feature themselves are bfloat16s.\r\n\r\n--\r\n249568633  by rathodv:\r\n\r\n    Support q > 1 in class agnostic NMS.\r\n    Break post_processing_test.py into 3 separate files to avoid linter errors.\r\n\r\n--\r\n249535530  by rathodv:\r\n\r\n    Update some deprecated arguments to tf ops.\r\n\r\n--\r\n249368223  by rathodv:\r\n\r\n    Modify MatMulCropAndResize to use MultiLevelRoIAlign method and move the tests to spatial_transform_ops.py module.\r\n\r\n    This cl establishes that CropAndResize and RoIAlign are equivalent and only differ in the sampling point grid within the boxes. CropAndResize uses a uniform size x size point grid such that the corner points exactly overlap box corners, while RoiAlign divides boxes into size x size cells and uses their centers as sampling points. In this cl, we switch MatMulCropAndResize to use the MultiLevelRoIAlign implementation with `align_corner` option as MultiLevelRoIAlign implementation is more memory efficient on TPU when compared to the original MatMulCropAndResize.\r\n\r\n--\r\n249337338  by chowdhery:\r\n\r\n    Add class-agnostic non-max-suppression in post_processing\r\n\r\n--\r\n249139196  by Zhichao Lu:\r\n\r\n    Fix positional argument bug in export_tflite_ssd_graph\r\n\r\n--\r\n249120219  by Zhichao Lu:\r\n\r\n    Add evaluator for computing precision limited to a given recall range.\r\n\r\n--\r\n249030593  by Zhichao Lu:\r\n\r\n    Evaluation util to run segmentation and detection challenge evaluation.\r\n\r\n--\r\n248554358  by Zhichao Lu:\r\n\r\n    This change contains the auxiliary changes required for TF 2.0 style training with eager+functions+dist strat loops, but not the loops themselves.\r\n\r\n    It includes:\r\n    - Updates to shape usage to support both tensorshape v1 and tensorshape v2\r\n    - A fix to FreezableBatchNorm to not override the `training` arg in call when `None` was passed to the constructor (Not an issue in the estimator loops but it was in the custom loops)\r\n    - Puts some constants in init_scope so they work in eager + functions\r\n    - Makes learning rate schedules return a callable in eager mode (required so they update when the global_step changes)\r\n    - Makes DetectionModel a tf.module so it tracks variables (e.g. ones nested in layers)\r\n    - Removes some references to `op.name` for some losses and replaces it w/ explicit names\r\n    - A small part of the change to allow the coco evaluation metrics to work in eager mode\r\n\r\n--\r\n248271226  by rathodv:\r\n\r\n    Add MultiLevel RoIAlign op.\r\n\r\n--\r\n248229103  by rathodv:\r\n\r\n    Add functions to 1. pad features maps 2. ravel 5-D indices\r\n\r\n--\r\n248206769  by rathodv:\r\n\r\n    Add utilities needed to introduce RoI Align op.\r\n\r\n--\r\n248177733  by pengchong:\r\n\r\n    Internal changes\r\n\r\n--\r\n247742582  by Zhichao Lu:\r\n\r\n    Open Images Challenge 2019 instance segmentation metric: part 2\r\n\r\n--\r\n247525401  by Zhichao Lu:\r\n\r\n    Update comments on max_class_per_detection.\r\n\r\n--\r\n247520753  by rathodv:\r\n\r\n    Add multilevel crop and resize operation that builds on top of matmul_crop_and_resize.\r\n\r\n--\r\n247391600  by Zhichao Lu:\r\n\r\n    Open Images Challenge 2019 instance segmentation metric\r\n\r\n--\r\n247325813  by chowdhery:\r\n\r\n    Quantized MobileNet v2 SSD FPNLite config with depth multiplier 0.75\r\n\r\n--\r\n\r\nPiperOrigin-RevId: 250447559",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 16,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2019-05-30T23:49:30Z",
        "closed_at": "2019-05-31T03:33:11Z",
        "merged_at": "2019-05-31T03:33:11Z",
        "body": "Merged commit includes the following changes:\n250779087  by A. Unique TensorFlower<gardener@tensorflow.org>:\n    \n    Reduce BERT Perfzero benchmark test training steps.\n    \n--",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 50,
        "deletions": 35,
        "changed_files": 5,
        "created_at": "2019-05-30T23:38:28Z",
        "closed_at": "2019-06-06T23:45:22Z",
        "merged_at": "2019-06-06T23:45:22Z",
        "body": "Before, there was a global default loss scale for all models. Currently, only resnet uses loss scaling, but this will be useful once more models support it.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2019-05-30T22:33:42Z",
        "closed_at": "2019-05-31T00:05:14Z",
        "merged_at": "2019-05-31T00:05:14Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-05-30T20:10:36Z",
        "closed_at": "2019-07-08T20:28:45Z",
        "merged_at": "2019-07-08T20:28:45Z",
        "body": "line 120: changed from eval_data = FLAGS.eval_data == 'test'\r\nto: eval_data = FLAGS.eval_data\r\ncomment: the original code assigns 'true' to eval_data, when the script is being used to evaluate networks on the evaluation set, it DOES NOT load the evaluation set as intended, but actually loads the trainning set (line 105 of cifar10_input.py).",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 64,
        "deletions": 36,
        "changed_files": 4,
        "created_at": "2019-05-30T18:10:00Z",
        "closed_at": "2019-05-30T20:17:45Z",
        "merged_at": "2019-05-30T20:17:45Z",
        "body": "Merged commit includes the following changes:\n250713045  by hongkuny<hongkuny@google.com>:\n    \n    TPU util\n    \n--",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2019-05-30T17:03:50Z",
        "closed_at": "2020-04-24T07:02:21Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 206,
        "deletions": 60,
        "changed_files": 5,
        "created_at": "2019-05-30T01:12:35Z",
        "closed_at": "2019-05-30T02:26:11Z",
        "merged_at": "2019-05-30T02:26:11Z",
        "body": "Merged commit includes the following changes:\n250606180  by A. Unique TensorFlower<gardener@tensorflow.org>:\n    \n    Fix BERT benchamrk test errors.\n    \n--\n250589623  by A. Unique TensorFlower<gardener@tensorflow.org>:\n    \n    Change BERT benchmark test pretrained checkpoint url.\n    \n--\n250587892  by A. Unique TensorFlower<gardener@tensorflow.org>:\n    \n    Fix error in BERT custom training loop checkpoint restoration.\n    \n--\n250577163  by A. Unique TensorFlower<gardener@tensorflow.org>:\n    \n    Add logic to inject callback that measures performance in BERT custom training\n    loop.\n    \n--\n250529526  by hongkuny<hongkuny@google.com>:\n    \n    Internal clean up\n    \n--\n250428976  by hongkuny<hongkuny@google.com>:\n\n    Internal change\n\n250415383  by A. Unique TensorFlower<gardener@tensorflow.org>:\n    \n    Add min/max value to BERT classifier benchmark test.\n    ",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2019-05-30T00:28:16Z",
        "closed_at": "2020-04-24T07:01:28Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 198,
        "deletions": 58,
        "changed_files": 5,
        "created_at": "2019-05-29T23:27:49Z",
        "closed_at": "2019-05-30T00:58:14Z",
        "merged_at": null,
        "body": "Merged commit includes the following changes:\n250589623  by A. Unique TensorFlower<gardener@tensorflow.org>:\n    \n    Change BERT benchmark test pretrained checkpoint url.\n    \n--\n250587892  by A. Unique TensorFlower<gardener@tensorflow.org>:\n    \n    Fix error in BERT custom training loop checkpoint restoration.\n    \n--\n250577163  by A. Unique TensorFlower<gardener@tensorflow.org>:\n    \n    Add logic to inject callback that measures performance in BERT custom training\n    loop.\n    \n--\n250529526  by hongkuny<hongkuny@google.com>:\n    \n    Internal clean up\n    \n--\n250428976  by hongkuny<hongkuny@google.com>:\n\n    Internal change\n\n250415383  by A. Unique TensorFlower<gardener@tensorflow.org>:\n    \n    Add min/max value to BERT classifier benchmark test.\n    ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-05-29T21:51:16Z",
        "closed_at": "2019-05-31T21:59:41Z",
        "merged_at": "2019-05-31T21:59:41Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 188,
        "deletions": 50,
        "changed_files": 4,
        "created_at": "2019-05-29T20:35:25Z",
        "closed_at": "2019-06-13T19:50:47Z",
        "merged_at": null,
        "body": "Merged commit includes the following changes:\n250423625  by A. Unique TensorFlower<gardener@tensorflow.org>:\n    \n    Add logic to inject callback that measures performance in BERT custom training\n    loop.\n    \n--\n250529526  by hongkuny<hongkuny@google.com>:\n    \n    Internal clean up\n    \n--\n250428976  by hongkuny<hongkuny@google.com>:\n\n    Internal change\n\n250415383  by A. Unique TensorFlower<gardener@tensorflow.org>:\n    \n    Add min/max value to BERT classifier benchmark test.\n    ",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2019-05-29T14:36:41Z",
        "closed_at": "2019-10-05T08:31:40Z",
        "merged_at": null,
        "body": "Indexing a key object is invalid since python3. Replace line with enumeration of keys to obtain key and its index in the ordered dict.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 7,
        "changed_files": 4,
        "created_at": "2019-05-29T03:45:27Z",
        "closed_at": "2020-04-24T07:00:56Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 7,
        "changed_files": 2,
        "created_at": "2019-05-29T00:13:36Z",
        "closed_at": "2019-05-29T05:42:04Z",
        "merged_at": "2019-05-29T05:42:04Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2019-05-28T23:58:02Z",
        "closed_at": "2019-05-29T01:00:43Z",
        "merged_at": "2019-05-29T01:00:43Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 83,
        "deletions": 42,
        "changed_files": 7,
        "created_at": "2019-05-28T21:58:02Z",
        "closed_at": "2019-05-29T01:09:14Z",
        "merged_at": null,
        "body": "Because keeping it outside and iterating over it multiple times does not shuffle the data every iteration, which is what we ideally want.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 38,
        "deletions": 11,
        "changed_files": 3,
        "created_at": "2019-05-28T08:39:43Z",
        "closed_at": "2019-05-29T07:22:11Z",
        "merged_at": "2019-05-29T07:22:11Z",
        "body": "When static_batch is set to true, max_length needs to configure much smaller to improve data utilization.\r\n\r\nAlso some flag and logging configuration inside.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 83,
        "deletions": 15,
        "changed_files": 3,
        "created_at": "2019-05-28T07:10:13Z",
        "closed_at": "2020-04-24T07:00:10Z",
        "merged_at": null,
        "body": "Add custom training loop and eval in Transformer V2.\r\n\r\n- Tested with the following command for TF V1 and V2:\r\n```\r\npython official/transformer/v2/transformer_main.py \\\r\n  --data_dir=${DATA_DIR} \\\r\n  --model_dir=${MODEL_DIR} \\\r\n  --vocab_file=${VOCAB_FILE} \\\r\n  --param_set=${PARAM_SET} \\\r\n  --bleu_source=${BLEU_SOURCE} \\\r\n  --bleu_ref=${BLEU_REF} \\\r\n  --train_steps=10 \\\r\n  --steps_between_evals=5 \\\r\n  --batch_size=2048 \\\r\n  --mode=custom_train\r\n```\r\n- Tested with larger train_steps, which shows the decreasing loss.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 53,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2019-05-27T03:48:06Z",
        "closed_at": "2019-05-28T23:56:42Z",
        "merged_at": "2019-05-28T23:56:42Z",
        "body": "So we can distinguish how much static vs dynamic batch matter.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 202,
        "deletions": 15,
        "changed_files": 4,
        "created_at": "2019-05-25T02:27:56Z",
        "closed_at": "2019-05-28T21:08:45Z",
        "merged_at": "2019-05-28T21:08:45Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 45,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-05-24T22:13:36Z",
        "closed_at": "2019-05-28T19:57:23Z",
        "merged_at": "2019-05-28T19:57:23Z",
        "body": "Increase the number of warmup steps for 96 core platforms. Hope this can stabilize the reported performance.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 137,
        "deletions": 15,
        "changed_files": 10,
        "created_at": "2019-05-24T07:16:10Z",
        "closed_at": "2019-05-24T13:50:42Z",
        "merged_at": "2019-05-24T13:50:42Z",
        "body": "The change fixes Transformer's predict and eval related to Beam Search.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 57,
        "deletions": 4,
        "changed_files": 4,
        "created_at": "2019-05-24T01:46:35Z",
        "closed_at": "2019-05-24T20:44:12Z",
        "merged_at": "2019-05-24T20:44:12Z",
        "body": "This allows us to stop when we reach the desired hr, because there is high variance as you go past epoch 7/8. \r\nAlso change the default batch size to match the tuned hyperparams.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-05-23T21:13:43Z",
        "closed_at": "2019-05-28T18:46:20Z",
        "merged_at": "2019-05-28T18:46:20Z",
        "body": "The \".mat\" files loaded in the dataset are byte files. Python 3.7 requires them to be loaded using \"rb\".\r\n\r\n@andrefaraujo ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2019-05-23T21:06:56Z",
        "closed_at": "2019-05-29T20:46:25Z",
        "merged_at": "2019-05-29T20:46:25Z",
        "body": "This makes it easier to copy, paste & install all dependencies at once. In addition many users have custom setups (virtualenv, conda, .etc). Having it in one line easily allows to grap the dependencies.\r\n\r\n@andrefaraujo ",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2019-05-23T16:12:12Z",
        "closed_at": "2019-05-23T20:48:32Z",
        "merged_at": "2019-05-23T20:48:32Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-05-23T08:51:09Z",
        "closed_at": "2019-05-23T15:31:08Z",
        "merged_at": "2019-05-23T15:31:08Z",
        "body": "Adding validation every epoch allows us to view the progress during training instead of having to wait until the last eval. Mostly useful for manual runs.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-05-23T04:10:43Z",
        "closed_at": "2019-05-23T21:22:40Z",
        "merged_at": "2019-05-23T21:22:40Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 114,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-05-23T03:18:58Z",
        "closed_at": "2019-05-23T05:01:36Z",
        "merged_at": null,
        "body": "Merged commit includes the following changes:\n249566870  by A. Unique TensorFlower<gardener@tensorflow.org>:\n    \n    Set up BERT benchmark test.\n    \n--",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 544,
        "deletions": 180,
        "changed_files": 6,
        "created_at": "2019-05-23T03:10:44Z",
        "closed_at": "2019-05-24T19:20:57Z",
        "merged_at": "2019-05-24T19:20:57Z",
        "body": "This includes the refactor from my other PR.  I am not going to merge this until the other PR is merged.\r\n\r\nhttps://github.com/tensorflow/models/pull/6859",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 53,
        "deletions": 51,
        "changed_files": 2,
        "created_at": "2019-05-23T02:42:29Z",
        "closed_at": "2019-05-24T14:15:52Z",
        "merged_at": "2019-05-24T14:15:52Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2019-05-23T02:02:01Z",
        "closed_at": "2019-05-23T04:34:12Z",
        "merged_at": "2019-05-23T04:34:12Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-05-22T18:51:04Z",
        "closed_at": "2020-04-24T06:30:48Z",
        "merged_at": "2020-04-24T06:30:48Z",
        "body": "- Fixed typo in `models/research/video_prediction/prediction_train.py`\r\n@nealwu ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2614,
        "deletions": 29,
        "changed_files": 19,
        "created_at": "2019-05-22T03:24:00Z",
        "closed_at": "2019-05-22T15:52:02Z",
        "merged_at": "2019-05-22T15:52:02Z",
        "body": "Merge changes related to Transformer V2 to master.\r\n\r\n- Major changes are in official/transformer/model/v2/*",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 21,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-05-22T00:31:21Z",
        "closed_at": "2019-05-22T15:49:57Z",
        "merged_at": "2019-05-22T15:49:57Z",
        "body": "* Add tweaked fp32 test\r\n* Run accuracy tests with LR ops",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2404,
        "deletions": 26,
        "changed_files": 16,
        "created_at": "2019-05-22T00:00:16Z",
        "closed_at": "2019-05-22T14:50:56Z",
        "merged_at": null,
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 138,
        "deletions": 47,
        "changed_files": 1,
        "created_at": "2019-05-21T19:26:52Z",
        "closed_at": "2019-05-22T18:50:21Z",
        "merged_at": "2019-05-22T18:50:21Z",
        "body": "Main feature is adding Transformer Big, which will run the same basic tests as Transformer Base.\r\n\r\n- Added Transformer Big\r\n- Add FP16 tests\r\n- Updated batch-sizes to match final testing approach.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-05-21T18:22:43Z",
        "closed_at": "2019-05-21T21:08:06Z",
        "merged_at": "2019-05-21T21:08:06Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2608,
        "deletions": 27,
        "changed_files": 18,
        "created_at": "2019-05-21T14:25:32Z",
        "closed_at": "2019-05-21T15:58:50Z",
        "merged_at": null,
        "body": "Merge changes related to Transformer V2 to master\r\n\r\n- Major changes are in official/transformer/model/v2/*",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 223,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-05-21T04:10:08Z",
        "closed_at": "2019-05-21T15:43:12Z",
        "merged_at": "2019-05-21T15:43:12Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 42,
        "deletions": 27,
        "changed_files": 1,
        "created_at": "2019-05-20T20:12:01Z",
        "closed_at": "2019-05-22T04:53:12Z",
        "merged_at": "2019-05-22T04:53:12Z",
        "body": "In Tensorflow 1.14 a majority of the TensorRT python code was moved from contrib to python/compilers.\r\nAs part of this move, some of the API was changed.\r\n\r\nRunning this example without changes, using Tensorflow 1.14, and passing `--int8` will result an\r\n`AttributeError: module 'tensorflow.contrib.tensorrt' has no attribute 'calib_graph_to_infer_graph'`",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 8532,
        "deletions": 0,
        "changed_files": 17,
        "created_at": "2019-05-18T15:52:26Z",
        "closed_at": "2019-05-20T22:27:23Z",
        "merged_at": null,
        "body": "Should close [issue #26994](https://github.com/tensorflow/tensorflow/issues/26994) and [issue #26995](https://github.com/tensorflow/tensorflow/issues/26995).",
        "comments": 8
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-05-18T06:45:38Z",
        "closed_at": "2020-04-25T03:45:59Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-05-17T06:05:24Z",
        "closed_at": "2020-04-26T01:20:46Z",
        "merged_at": null,
        "body": "In file `export_tflite_ssd_graph.py` input argument `detections_per_class` was missed whereas there is a flag which indicates this argument. \r\n\r\nThis fix added missing input parameter",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 82,
        "deletions": 110,
        "changed_files": 2,
        "created_at": "2019-05-16T14:10:28Z",
        "closed_at": "2020-10-02T20:26:26Z",
        "merged_at": null,
        "body": "- Migrated the autoencoder_runner.py and Autoencoder.py to Tensorflow 2.0\r\n- The runner uses `tf.data.Dataset` pipeline to feed the batches and `tf.keras.datasets` to load the initial data and all necessary migrations in runner have been tested\r\n- The backpropagation is handled by `tf.GradientTape` and apply_gradients\r\n- Wrote the Encoder and Decoder as subclasses of `tf.keras.layers.Layer` and the Autoencoder as a subclass of `tf.keras.Model`\r\n- I working on and will upgrade the DenoisingAutoencoder and  VariationalAutoencoder.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 114,
        "deletions": 14,
        "changed_files": 1,
        "created_at": "2019-05-16T07:48:20Z",
        "closed_at": "2019-05-16T20:25:11Z",
        "merged_at": null,
        "body": "Tests are added for both Cifar10 and Imagenet datasets. This will make sure the tf.keras.layer works in Estimator model.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 6,
        "changed_files": 2,
        "created_at": "2019-05-15T20:18:37Z",
        "closed_at": "2019-05-15T21:23:23Z",
        "merged_at": "2019-05-15T21:23:23Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 38,
        "deletions": 67,
        "changed_files": 4,
        "created_at": "2019-05-14T20:38:51Z",
        "closed_at": "2019-05-15T20:02:28Z",
        "merged_at": "2019-05-15T20:02:28Z",
        "body": "",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-05-14T19:04:50Z",
        "closed_at": "2019-05-15T16:48:59Z",
        "merged_at": null,
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 137,
        "deletions": 56,
        "changed_files": 5,
        "created_at": "2019-05-10T14:58:10Z",
        "closed_at": "2019-05-11T00:15:35Z",
        "merged_at": "2019-05-11T00:15:35Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 142,
        "deletions": 20,
        "changed_files": 6,
        "created_at": "2019-05-09T20:20:38Z",
        "closed_at": "2019-05-15T19:00:05Z",
        "merged_at": "2019-05-15T19:00:05Z",
        "body": "- Adds benchmarks to keras_imagenet_benchmark (suffixed with `tfdata_exp`) that have tf_data_experimental_slack enabled, for both graph and eager mode benchmarks. \r\n- Adds flag `tf_data_experimental_slack` to resnet -- when True, enables tf.data's experimental_slack option on the input pipeline. \r\n- Renames old flag `data_prefetch_with_slack` to `data_delay_prefetch` (i.e. temporary hack) to better disambiguate the two flags.",
        "comments": 10
    },
    {
        "merged": false,
        "additions": 57,
        "deletions": 14,
        "changed_files": 7,
        "created_at": "2019-05-09T17:59:52Z",
        "closed_at": "2019-05-10T17:19:39Z",
        "merged_at": null,
        "body": "I tested XLA and FP16 accuracy benchmark on a separate GCE instance.  It depends on however on changelist 247454647 making it into the nightly, so tomorrow might be a good day to submit.\r\n\r\nThe plan is for no-cloning to become the default next week.  At that point I will remove all the no-cloning benchmarks.\r\n\r\nI also discovered that I forgot to create a pull request for renaming \"per device\" and \"per replica\" (see internal change 245843263).  I should really create branches for separate changes in the future.  But here it is.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 88,
        "deletions": 8,
        "changed_files": 2,
        "created_at": "2019-05-09T02:59:33Z",
        "closed_at": "2019-05-09T21:11:28Z",
        "merged_at": "2019-05-09T21:11:28Z",
        "body": "Create a piecewise learning rate schedule with warmup class and use it for in-graph learning rate computation. This change overlaps the learning rate calculation and assignment with other function execution and reduce the gaps between steps due to slow callbacks.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 10631,
        "deletions": 1246,
        "changed_files": 96,
        "created_at": "2019-05-08T23:08:56Z",
        "closed_at": "2019-05-22T17:29:22Z",
        "merged_at": "2019-05-22T17:29:22Z",
        "body": "247226201  by ronnyvotel:\r\n\r\n    Updating the visualization tools to accept unique_ids for color coding.\r\n\r\n--\r\n247067830  by Zhichao Lu:\r\n\r\n    Add box_encodings_clip_range options for the convolutional box predictor (for TPU compatibility).\r\n\r\n--\r\n246888475  by Zhichao Lu:\r\n\r\n    Remove unused _update_eval_steps function.\r\n\r\n--\r\n246163259  by lzc:\r\n\r\n    Add a gather op that can handle ignore indices (which are \"-1\"s in this case).\r\n\r\n--\r\n246084944  by Zhichao Lu:\r\n\r\n    Keras based implementation for SSD + MobilenetV2 + FPN.\r\n\r\n--\r\n245544227  by rathodv:\r\n\r\n    Add batch_get_targets method to target assigner module to gather any groundtruth tensors based on the results of target assigner.\r\n\r\n--\r\n245540854  by rathodv:\r\n\r\n    Update target assigner to return match tensor instead of a match object.\r\n\r\n--\r\n245434441  by Zhichao Lu:\r\n\r\n    Add README for tpu_exporters package.\r\n\r\n--\r\n245381834  by lzc:\r\n\r\n    Internal change.\r\n\r\n--\r\n245298983  by Zhichao Lu:\r\n\r\n    Add conditional_shape_resizer to config_util\r\n\r\n--\r\n245134666  by Zhichao Lu:\r\n\r\n    Adds ConditionalShapeResizer to the ImageResizer proto which enables resizing only if input image height or width is is greater or smaller than a certain size. Also enables specification of resize method in resize_to_{max, min}_dimension methods.\r\n\r\n--\r\n245093975  by Zhichao Lu:\r\n\r\n    Exporting SavedModel for Object Detection TPU inference. (faster-rcnn)\r\n\r\n--\r\n245072421  by Zhichao Lu:\r\n\r\n    Adds a new image resizing method \"resize_to_max_dimension\" which resizes images only if a dimension is greater than the maximum desired value while maintaining aspect ratio.\r\n\r\n--\r\n244946998  by lzc:\r\n\r\n    Internal Changes.\r\n\r\n--\r\n244943693  by Zhichao Lu:\r\n\r\n    Add a custom config to mobilenet v2 that makes it more detection friendly.\r\n\r\n--\r\n244754158  by derekjchow:\r\n\r\n    Internal change.\r\n\r\n--\r\n244699875  by Zhichao Lu:\r\n\r\n    Add check_range=False to box_list_ops.to_normalized_coordinates when training\r\n    for instance segmentation.  This is consistent with other calls when training\r\n    for object detection.  There could be wrongly annotated boxes in the dataset.\r\n\r\n--\r\n244507425  by rathodv:\r\n\r\n    Support bfloat16 for ssd models.\r\n\r\n--\r\n244399982  by Zhichao Lu:\r\n\r\n    Exporting SavedModel for Object Detection TPU inference. (ssd)\r\n\r\n--\r\n244209387  by Zhichao Lu:\r\n\r\n    Internal change.\r\n\r\n--\r\n243922296  by rathodv:\r\n\r\n    Change `raw_detection_scores` to contain softmax/sigmoid scores (not logits) for `raw_ detection_boxes`.\r\n\r\n--\r\n243883978  by Zhichao Lu:\r\n\r\n    Add a sample fully conv config.\r\n\r\n--\r\n243369455  by Zhichao Lu:\r\n\r\n    Fix regularization loss gap in Keras and Slim.\r\n\r\n--\r\n243292002  by lzc:\r\n\r\n    Internal changes.\r\n\r\n--\r\n243097958  by Zhichao Lu:\r\n\r\n    Exporting SavedModel for Object Detection TPU inference. (ssd model)\r\n\r\n--\r\n243007177  by Zhichao Lu:\r\n\r\n    Exporting SavedModel for Object Detection TPU inference. (ssd model)\r\n\r\n--\r\n242776550  by Zhichao Lu:\r\n\r\n    Make object detection pre-processing run on GPU.  tf.map_fn() uses\r\n    TensorArrayV3 ops, which have no int32 GPU implementation.  Cast to int64,\r\n    then cast back to int32.\r\n\r\n--\r\n242723128  by Zhichao Lu:\r\n\r\n    Using sorted dictionaries for additional heads in non_max_suppression to ensure tensor order\r\n\r\n--\r\n242495311  by Zhichao Lu:\r\n\r\n    Update documentation to reflect new TFLite examples repo location\r\n\r\n--\r\n242230527  by Zhichao Lu:\r\n\r\n    Fix Dropout bugs for WeightSharedConvolutionalBoxPred.\r\n\r\n--\r\n242226573  by Zhichao Lu:\r\n\r\n    Create Keras-based WeightSharedConvolutionalBoxPredictor.\r\n\r\n--\r\n241806074  by Zhichao Lu:\r\n\r\n    Add inference in unit tests of TFX OD template.\r\n\r\n--\r\n241641498  by lzc:\r\n\r\n    Internal change.\r\n\r\n--\r\n241637481  by Zhichao Lu:\r\n\r\n    matmul_crop_and_resize(): Switch to dynamic shaping, so that not all dimensions are required to be known.\r\n\r\n--\r\n241429980  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n--\r\n241167237  by Zhichao Lu:\r\n\r\n    Adds a faster_rcnn_inception_resnet_v2 Keras feature extractor, and updates the model builder to construct it.\r\n\r\n--\r\n241088616  by Zhichao Lu:\r\n\r\n    Make it compatible with different dtype, e.g. float32, bfloat16, etc.\r\n\r\n--\r\n240897364  by lzc:\r\n\r\n    Use image_np_expanded in object_detection_tutorial notebook.\r\n\r\n--\r\n240890393  by Zhichao Lu:\r\n\r\n    Disable multicore inference for OD template as its not yet compatible.\r\n\r\n--\r\n240352168  by Zhichao Lu:\r\n\r\n    Make SSDResnetV1FpnFeatureExtractor not protected to allow inheritance.\r\n\r\n--\r\n240351470  by lzc:\r\n\r\n    Internal change.\r\n\r\n--\r\n239878928  by Zhichao Lu:\r\n\r\n    Defines Keras box predictors for Faster RCNN and RFCN\r\n\r\n--\r\n239872103  by Zhichao Lu:\r\n\r\n    Delete duplicated inputs in test.\r\n\r\n--\r\n239714273  by Zhichao Lu:\r\n\r\n    Adding scope variable to all class heads\r\n\r\n--\r\n239698643  by Zhichao Lu:\r\n\r\n    Create FPN feature extractor for object detection.\r\n\r\n--\r\n239696657  by Zhichao Lu:\r\n\r\n    Internal Change.\r\n\r\n--\r\n239299404  by Zhichao Lu:\r\n\r\n    Allows the faster rcnn meta-architecture to support Keras subcomponents\r\n\r\n--\r\n238502595  by Zhichao Lu:\r\n\r\n    Lay the groundwork for symmetric quantization.\r\n\r\n--\r\n238496885  by Zhichao Lu:\r\n\r\n    Add flexible_grid_anchor_generator\r\n\r\n--\r\n238138727  by lzc:\r\n\r\n    Remove dead code.\r\n\r\n    _USE_C_SHAPES has been forced True in TensorFlow releases since\r\n    TensorFlow 1.9\r\n    (https://github.com/tensorflow/tensorflow/commit/1d74a69443f741e69f9f52cb6bc2940b4d4ae3b7)\r\n\r\n--\r\n238123936  by rathodv:\r\n\r\n    Add num_matched_groundtruth summary to target assigner in SSD.\r\n\r\n--\r\n238103345  by ronnyvotel:\r\n\r\n    Raising error if input file pattern does not match any files.\r\n    Also printing the number of evaluation images for coco metrics.\r\n\r\n--\r\n238044081  by Zhichao Lu:\r\n\r\n    Fix docstring to state the correct dimensionality of `class_predictions_with_background`.\r\n\r\n--\r\n237920279  by Zhichao Lu:\r\n\r\n    [XLA] Rework debug flags for dumping HLO.\r\n\r\n    The following flags (usually passed via the XLA_FLAGS envvar) are removed:\r\n\r\n      xla_dump_computations_to\r\n      xla_dump_executions_to\r\n      xla_dump_ir_to\r\n      xla_dump_optimized_hlo_proto_to\r\n      xla_dump_per_pass_hlo_proto_to\r\n      xla_dump_unoptimized_hlo_proto_to\r\n      xla_generate_hlo_graph\r\n      xla_generate_hlo_text_to\r\n      xla_hlo_dump_as_html\r\n      xla_hlo_graph_path\r\n      xla_log_hlo_text\r\n\r\n    The following new flags are added:\r\n\r\n      xla_dump_to\r\n      xla_dump_hlo_module_re\r\n      xla_dump_hlo_pass_re\r\n      xla_dump_hlo_as_text\r\n      xla_dump_hlo_as_proto\r\n      xla_dump_hlo_as_dot\r\n      xla_dump_hlo_as_url\r\n      xla_dump_hlo_as_html\r\n      xla_dump_ir\r\n      xla_dump_hlo_snapshots\r\n\r\n    The default is not to dump anything at all, but as soon as some dumping flag is\r\n    specified, we enable the following defaults (most of which can be overridden).\r\n\r\n     * dump to stdout (overridden by --xla_dump_to)\r\n     * dump HLO modules at the very beginning and end of the optimization pipeline\r\n     * don't dump between any HLO passes (overridden by --xla_dump_hlo_pass_re)\r\n     * dump all HLO modules (overridden by --xla_dump_hlo_module_re)\r\n     * dump in textual format (overridden by\r\n       --xla_dump_hlo_as_{text,proto,dot,url,html}).\r\n\r\n    For example, to dump optimized and unoptimized HLO text and protos to /tmp/foo,\r\n    pass\r\n\r\n      --xla_dump_to=/tmp/foo --xla_dump_hlo_as_text --xla_dump_hlo_as_proto\r\n\r\n    For details on these flags' meanings, see xla.proto.\r\n\r\n    The intent of this change is to make dumping both simpler to use and more\r\n    powerful.\r\n\r\n    For example:\r\n\r\n     * Previously there was no way to dump the HLO module during the pass pipeline\r\n       in HLO text format; the only option was --dump_per_pass_hlo_proto_to, which\r\n       dumped in proto format.\r\n\r\n       Now this is --xla_dump_pass_re=.* --xla_dump_hlo_as_text.  (In fact, the\r\n       second flag is not necessary in this case, as dumping as text is the\r\n       default.)\r\n\r\n     * Previously there was no way to dump HLO as a graph before and after\r\n       compilation; the only option was --xla_generate_hlo_graph, which would dump\r\n       before/after every pass.\r\n\r\n       Now this is --xla_dump_hlo_as_{dot,url,html} (depending on what format you\r\n       want the graph in).\r\n\r\n     * Previously, there was no coordination between the filenames written by the\r\n       various flags, so info about one module might be dumped with various\r\n       filename prefixes.  Now the filenames are consistent and all dumps from a\r\n       particular module are next to each other.\r\n\r\n    If you only specify some of these flags, we try to figure out what you wanted.\r\n    For example:\r\n\r\n     * --xla_dump_to implies --xla_dump_hlo_as_text unless you specify some\r\n       other --xla_dump_as_* flag.\r\n\r\n     * --xla_dump_hlo_as_text or --xla_dump_ir implies dumping to stdout unless you\r\n       specify a different --xla_dump_to directory.  You can explicitly dump to\r\n       stdout with --xla_dump_to=-.\r\n\r\n    As part of this change, I simplified the debugging code in the HLO passes for\r\n    dumping HLO modules.  Previously, many tests explicitly VLOG'ed the HLO module\r\n    before, after, and sometimes during the pass.  I removed these VLOGs.  If you\r\n    want dumps before/during/after an HLO pass, use --xla_dump_pass_re=<pass_name>.\r\n\r\n--\r\n237510043  by lzc:\r\n\r\n    Internal Change.\r\n\r\n--\r\n237469515  by Zhichao Lu:\r\n\r\n    Parameterize model_builder.build in inputs.py.\r\n\r\n--\r\n237293511  by rathodv:\r\n\r\n    Remove multiclass_scores from tensor_dict in transform_data_fn always.\r\n\r\n--\r\n237260333  by ronnyvotel:\r\n\r\n    Updating faster_rcnn_meta_arch to define prediction dictionary fields that are batched.\r\n\r\n--\r\n\r\nPiperOrigin-RevId: 247226201",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2019-05-08T16:25:40Z",
        "closed_at": "2019-05-08T22:36:45Z",
        "merged_at": "2019-05-08T22:36:45Z",
        "body": "This was causing the synthetic data tests to fail in TF 2.0.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 337,
        "deletions": 15,
        "changed_files": 6,
        "created_at": "2019-05-08T16:06:09Z",
        "closed_at": "2019-05-09T23:10:08Z",
        "merged_at": "2019-05-09T23:10:08Z",
        "body": "Transformer instrumented for benchmarking along with:\r\n\r\n- Fixed deprecation issue with gfile\r\n- Added benchmark for 1 GPU accuracy for base model and 1 GPU benchmark base model.  Accuracy cannot reach SOTA due to small batch-size.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2483,
        "deletions": 381,
        "changed_files": 51,
        "created_at": "2019-05-08T05:35:38Z",
        "closed_at": "2020-04-21T14:03:02Z",
        "merged_at": null,
        "body": "- Add new training mode: different meta-action periods for exploration and training\r\n- Plot q-value, context norm, log_prob, and other parameters during training and evaluation\r\n- Change interface. See quick_train.sh/quick_eval.sh/viz.sh for more comments.",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-05-08T01:55:52Z",
        "closed_at": "2020-09-19T00:16:15Z",
        "merged_at": null,
        "body": "",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 39,
        "deletions": 28,
        "changed_files": 7,
        "created_at": "2019-05-07T21:18:15Z",
        "closed_at": "2019-06-03T17:23:15Z",
        "merged_at": null,
        "body": "fp16 is added with the new `tf.train.experimental.enable_mixed_precision_graph_rewrite` function.\r\n\r\nNote: I moved the `get_loss_scale` function from _performance.py to resnet_run_loop.py, and added a similar function to the NCF model. This is because the default loss scale should be different for each model.\r\n\r\nTo test convergence, I ran:\r\n\r\n```\r\npython ncf_estimator_main.py --model_dir ~/ncf_model_dir --data_dir ~/ncf_data_dir --dataset=ml-20m --hooks= --num_gpus=1 --clean --train_epochs=14 --batch_size=98340 --learning_rate=0.00382059 --beta1=0.783529 --beta2=0.909003 --epsilon=1.45439e-07 --layers=256,256,128,64 --num_factors=64 --hr_threshold=0.635 --ml_perf --dtype=fp16\r\n```\r\nI got an HR of 0.6371 on epoch 8.\r\n\r\nPerformance gain is modest: From about 67 steps/sec to 75 steps/sec with a batch size of 98340 on a V100.\r\n\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-05-07T18:07:08Z",
        "closed_at": "2019-05-07T19:36:57Z",
        "merged_at": "2019-05-07T19:36:57Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 38,
        "deletions": 6026,
        "changed_files": 4,
        "created_at": "2019-05-06T19:12:24Z",
        "closed_at": "2019-05-07T01:56:16Z",
        "merged_at": "2019-05-07T01:56:16Z",
        "body": "Moving this to GCS removes a problem where the leaker file finds a word we do not want to share that happens to be in the test_data. This is blocking setting up the automated sync. It is also nice to not have test-data checked in.  ",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 243,
        "deletions": 43,
        "changed_files": 3,
        "created_at": "2019-05-06T03:37:11Z",
        "closed_at": "2020-03-06T02:45:51Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-05-02T18:11:32Z",
        "closed_at": "2019-05-03T02:03:29Z",
        "merged_at": "2019-05-03T02:03:29Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 25,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2019-05-02T00:38:02Z",
        "closed_at": "2019-05-04T00:00:37Z",
        "merged_at": "2019-05-04T00:00:36Z",
        "body": "* Enable CuDNN BatchNorm spatial persistent by default\r\n\r\n* Consistently set `scale=False` and `fused=True` in all the batchnorm layers.\r\n\r\n* Also, replace the zero padding layer with a padding attribute in max pooling layer. Zero padding adds both forward and backprop (Split) ops, each taking 1.5--2ms. Now the overhead is removed.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 38,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-05-01T22:47:52Z",
        "closed_at": "2019-05-02T18:05:53Z",
        "merged_at": "2019-05-02T18:05:53Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 28061,
        "deletions": 2,
        "changed_files": 40,
        "created_at": "2019-05-01T18:56:10Z",
        "closed_at": "2019-05-22T18:52:37Z",
        "merged_at": null,
        "body": "Updating Fork",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 47,
        "deletions": 7,
        "changed_files": 3,
        "created_at": "2019-05-01T00:38:27Z",
        "closed_at": "2019-05-01T22:19:04Z",
        "merged_at": "2019-05-01T22:19:04Z",
        "body": "This options allows the new tf.train.experimental.enable_mixed_precision_graph_rewrite() function to be used for fp16, instead of manual casts.\r\n\r\nTo test convergence, I ran\r\n```\r\npython imagenet_main.py --num_gpus=8 --data_dir=/data/imagenet/imagenet --batch_size=1024 --train_epochs=90 --epochs_between_evals=10 --model_dir ~/model_dir_amp --dtype=fp16 --hooks=ExamplesPerSecondHook --fp16_implementation=graph_rewrite\r\n```\r\n\r\nI got 76.26% accuracy.\r\n\r\nTo test performance, I ran\r\n\r\n```\r\npython imagenet_main.py --clean --synth --num_gpus=8 --batch_size=1024 --train_epochs=1 --model_dir ~/model_dir_test --dtype=fp16 --hooks=ExamplesPerSecondHook,ProfilerHook\r\n```\r\nI added --fp16_implementation=graph_rewrite to use enable_mixed_precision_graph_rewrite(), and I removed --synth and added --data_dir when using real data. Results (images/sec):\r\n\r\n| |casting|graph_rewrite|\r\n|--|--|--|\r\n|Real data|5104|4005|\r\n|Synthetic data|4682|4522|\r\n\r\nOn synthetic data, the graph rewrite is only 3.5% slower than manual casting. But on real data, it's 27% slower. And the fact that real data is faster than synthetic data with manual casting is very unusual.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-04-30T05:03:00Z",
        "closed_at": "2019-05-01T05:07:31Z",
        "merged_at": null,
        "body": "```\r\n  data_boxes = data[data.ConfidenceImageLabel.isnull()]\r\n  data_labels = data[data.XMin.isnull()]\r\n```\r\nIf this code want to get the data_boxes which is not null, u should use this follow:\r\n```\r\n  data_boxes = data[~data.ConfidenceImageLabel.isnull()]\r\n  data_labels = data[~data.XMin.isnull()]\r\n```",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-04-29T21:33:15Z",
        "closed_at": "2019-05-21T18:36:32Z",
        "merged_at": "2019-05-21T18:36:32Z",
        "body": "@guptapriya ",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-04-29T21:25:48Z",
        "closed_at": "2019-04-30T18:42:16Z",
        "merged_at": "2019-04-30T18:42:16Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 27,
        "deletions": 18,
        "changed_files": 1,
        "created_at": "2019-04-29T20:00:35Z",
        "closed_at": "2019-04-29T21:32:50Z",
        "merged_at": "2019-04-29T21:32:50Z",
        "body": "Add accuracy check and move to using metrics from extras.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 14,
        "changed_files": 6,
        "created_at": "2019-04-29T19:55:58Z",
        "closed_at": "2019-04-29T21:43:47Z",
        "merged_at": "2019-04-29T21:43:47Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-04-28T17:14:25Z",
        "closed_at": "2019-04-29T16:28:21Z",
        "merged_at": "2019-04-29T16:28:21Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 199,
        "deletions": 59,
        "changed_files": 10,
        "created_at": "2019-04-26T23:01:36Z",
        "closed_at": "2019-05-06T22:18:07Z",
        "merged_at": "2019-05-06T22:18:07Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 70,
        "deletions": 28,
        "changed_files": 3,
        "created_at": "2019-04-25T21:34:44Z",
        "closed_at": "2019-04-26T16:51:03Z",
        "merged_at": "2019-04-26T16:51:03Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 85,
        "deletions": 2,
        "changed_files": 7,
        "created_at": "2019-04-25T20:40:00Z",
        "closed_at": "2019-04-29T17:18:03Z",
        "merged_at": "2019-04-29T17:18:03Z",
        "body": "This PR adds essential correctness and performance benchmarks for the new --cloning=False code path.  The feature was added https://github.com/tensorflow/tensorflow/commit/22962228c29fe454522ee39e2154f0703f981e3b and probably haven't made its way into tf-nightly yet.  Quite a bit of the verification happened in that feature PR.  This PR hopefully represents a trivial change that still needs to be tested as part of the performance framework.  I will do that tomorrow once tf-nightly is ready.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 398,
        "deletions": 166,
        "changed_files": 4,
        "created_at": "2019-04-25T20:10:04Z",
        "closed_at": "2019-04-26T18:54:51Z",
        "merged_at": "2019-04-26T18:54:51Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 82,
        "deletions": 113,
        "changed_files": 2,
        "created_at": "2019-04-25T14:52:33Z",
        "closed_at": "2019-05-16T06:31:16Z",
        "merged_at": null,
        "body": "- Migrated the autoencoder_runner.py and Autoencoder.py to Tensorflow 2.0\r\n- The runner uses `tf.data.Dataset` pipeline to feed the batches and `tf.keras.datasets` to load the initial data and all necessary migrations in runner have been tested\r\n- The backpropagation is handled by `tf.GradientTape` and apply_gradients\r\n- Wrote the Encoder and Decoder as subclasses of `tf.keras.layers.Layer` and the Autoencoder as a subclass of `tf.keras.Model`\r\n- I have followed the best practices mentioned and will upgrade the DenoisingAutoencoder and  VariationalAutoencoder once this is reviewed and approved.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 877,
        "deletions": 29,
        "changed_files": 14,
        "created_at": "2019-04-24T22:23:36Z",
        "closed_at": "2019-04-26T18:27:43Z",
        "merged_at": "2019-04-26T18:27:43Z",
        "body": "244869387  by Sergio Guadarrama:\r\n\r\n    This CL adds script/code to generate Visual WakeWords Dataset annotation files and TF records starting from COCO dataset.\r\n\r\n--\r\n244866660  by Sergio Guadarrama:\r\n\r\n    Add VisualWakeWords Dataset to Slim dataset_factory to train MobileNets on it.\r\n\r\n--\r\n244836000  by Sergio Guadarrama:\r\n\r\n    n/a\r\n\r\n--\r\n244104396  by Sergio Guadarrama:\r\n\r\n    Add an option whether to enable / disable image cropping in inception_preprocessing.\r\n\r\n--\r\n242040128  by Sergio Guadarrama:\r\n\r\n    Internal change\r\n\r\n241793677  by Sergio Guadarrama:\r\n\r\n    Internal change\r\n\r\n241073081  by Sergio Guadarrama:\r\n\r\n    Internal change\r\n\r\n240131189  by Sergio Guadarrama:\r\n\r\n    Internal change\r\n\r\nPiperOrigin-RevId: 244869387",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-04-24T13:13:05Z",
        "closed_at": "2020-04-26T00:37:53Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-04-24T12:49:49Z",
        "closed_at": "2019-04-24T18:13:32Z",
        "merged_at": "2019-04-24T18:13:32Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1100,
        "deletions": 76,
        "changed_files": 18,
        "created_at": "2019-04-23T22:21:33Z",
        "closed_at": "2019-04-24T23:05:33Z",
        "merged_at": "2019-04-24T23:05:33Z",
        "body": "Includes many documentation updates, pointers to pre-trained models, more Detect-to-Retrieve code.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-04-23T13:51:53Z",
        "closed_at": "2020-04-24T07:07:56Z",
        "merged_at": null,
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-04-23T09:06:14Z",
        "closed_at": "2019-04-23T22:07:26Z",
        "merged_at": "2019-04-23T22:07:26Z",
        "body": "np.uint8 to np.int64 for detection class label index overflow when using OIDv4 labels",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-04-23T06:44:54Z",
        "closed_at": "2020-04-24T05:13:15Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2019-04-23T02:08:10Z",
        "closed_at": "2020-04-27T17:58:31Z",
        "merged_at": null,
        "body": "To edit these file, I can finally  use box model. But there still missing d2r_frcnn_20190411 .",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 9,
        "changed_files": 1,
        "created_at": "2019-04-22T22:04:42Z",
        "closed_at": "2019-05-22T14:51:48Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 85,
        "deletions": 4,
        "changed_files": 3,
        "created_at": "2019-04-22T20:59:42Z",
        "closed_at": "2019-04-24T00:55:53Z",
        "merged_at": "2019-04-24T00:55:53Z",
        "body": "Use a temporary hack to mimic the upcoming tf.data \"prefetch with slack\" feature. It help us bypass the blocking call to placeholder memcpy, and set the performance target for the prefetch with slack feature.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-04-22T07:22:51Z",
        "closed_at": "2019-04-26T03:29:24Z",
        "merged_at": null,
        "body": "When the font `arial.ttf` is not found it loads the default font and crashes whenever it finds Unicode characters on both Python 2 and 3. Filtering out non-printable characters for visualization only.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-04-21T15:56:55Z",
        "closed_at": "2020-04-25T04:10:20Z",
        "merged_at": "2020-04-25T04:10:20Z",
        "body": "The value of 'TF_OD_API_LABELS_FILE' in the documention should be changed since it has changed in source code 4 months ago.  Check the commit [here](https://github.com/tensorflow/tensorflow/commit/3b94c63e1b113b8504221c635c83a5477666605b).",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2019-04-20T06:08:53Z",
        "closed_at": "2019-04-22T20:42:06Z",
        "merged_at": "2019-04-22T20:42:06Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2019-04-19T22:20:24Z",
        "closed_at": "2019-04-24T17:41:38Z",
        "merged_at": "2019-04-24T17:41:38Z",
        "body": "There might be only one \"chief\" and not other workers.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 16,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2019-04-19T14:58:46Z",
        "closed_at": "2019-04-23T21:50:55Z",
        "merged_at": "2019-04-23T21:50:55Z",
        "body": "Added additional information on using the `SavedModel` for prediction purposes.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-04-18T09:44:48Z",
        "closed_at": "2019-04-22T06:54:26Z",
        "merged_at": null,
        "body": "When the font `arial.ttf` is not found it loads the default font and crashes whenever it finds Unicode characters on both Python 2 and 3. A warning should be shown first before filtering all non-ASCII characters in case the user used all-Unicode-labels. \r\n\r\nThe same error is shown when somebody tries `'\u767e'.encode('latin-1')` in a Python interpreter.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-04-18T02:53:07Z",
        "closed_at": "2019-04-22T20:46:16Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 534,
        "deletions": 42,
        "changed_files": 8,
        "created_at": "2019-04-17T23:41:48Z",
        "closed_at": "2019-04-18T18:04:54Z",
        "merged_at": "2019-04-18T18:04:54Z",
        "body": "- Small bug fixes\r\n- DELF extraction function refactoring\r\n- Initial D2R code with box extraction proto/library/scripts",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-04-17T17:51:11Z",
        "closed_at": "2019-04-18T17:49:12Z",
        "merged_at": "2019-04-18T17:49:11Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 542,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-04-16T23:30:02Z",
        "closed_at": "2019-04-17T17:17:33Z",
        "merged_at": "2019-04-17T17:17:33Z",
        "body": "Adds original MobileNetV2 keras implementation. Needs different imports.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 129,
        "deletions": 100,
        "changed_files": 9,
        "created_at": "2019-04-16T21:27:56Z",
        "closed_at": "2019-04-20T06:03:36Z",
        "merged_at": "2019-04-20T06:03:36Z",
        "body": "...and other stuff to make the model runs in TF 2.0",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 7,
        "deletions": 6,
        "changed_files": 3,
        "created_at": "2019-04-16T19:26:02Z",
        "closed_at": "2019-04-16T21:28:38Z",
        "merged_at": null,
        "body": "...so that this model can be run in TF2. ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-04-16T17:28:05Z",
        "closed_at": "2019-04-20T06:04:06Z",
        "merged_at": "2019-04-20T06:04:06Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-04-16T16:24:43Z",
        "closed_at": "2019-04-22T22:14:20Z",
        "merged_at": "2019-04-22T22:14:20Z",
        "body": "The evaluation crashes in python3 if iteritems() is used instead of items()",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 8,
        "changed_files": 4,
        "created_at": "2019-04-16T13:39:36Z",
        "closed_at": "2019-04-17T21:29:48Z",
        "merged_at": "2019-04-17T21:29:48Z",
        "body": "1. In python3, `dict.iteritems()` is gone, change it to `dict.items()`. And it also doesn't treat zip object as a list, so change zip to list type.\r\n2. Add encoding flag with open function to make it more compatible for Windows/Linux system.\r\n3. For newer tensorflow, it expected `int64` without giving a dtype parameter to embedding layer. We give it `float32` to solve it.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-04-16T12:50:04Z",
        "closed_at": "2020-04-24T06:22:09Z",
        "merged_at": null,
        "body": "When is_bidirectional == False, the original version passes the output tuple (output tensor and state tensor) of unidirectional RNN to the rnn_outputs. However, it should pass the exact output tensor instead of the tuple to the rnn_outputs.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2019-04-16T05:36:51Z",
        "closed_at": "2019-04-17T21:27:51Z",
        "merged_at": "2019-04-17T21:27:51Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-04-16T04:59:18Z",
        "closed_at": "2020-04-26T00:40:04Z",
        "merged_at": null,
        "body": "The command to compile on windows added",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2019-04-15T23:09:38Z",
        "closed_at": "2019-04-17T01:08:23Z",
        "merged_at": "2019-04-17T01:08:23Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-04-14T20:23:35Z",
        "closed_at": "2020-04-25T04:12:20Z",
        "merged_at": null,
        "body": "`eat_reward` is a Pandas DataFrame, as such it can't be `reshape` without first being converted to a Numpy array.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-04-11T23:53:11Z",
        "closed_at": "2019-04-12T02:22:18Z",
        "merged_at": "2019-04-12T02:22:18Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-04-11T22:30:35Z",
        "closed_at": "2019-06-26T20:09:34Z",
        "merged_at": "2019-06-26T20:09:34Z",
        "body": "Addresses #5033.\r\n\r\nThere was a PR for this previously but user didn't agree to cla it seems https://github.com/tensorflow/models/pull/5115",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 44,
        "deletions": 13,
        "changed_files": 5,
        "created_at": "2019-04-10T20:21:32Z",
        "closed_at": "2019-04-11T04:04:11Z",
        "merged_at": "2019-04-11T04:04:11Z",
        "body": "Reverts tensorflow/models#6517",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-04-10T18:58:09Z",
        "closed_at": "2019-04-11T03:50:30Z",
        "merged_at": "2019-04-11T03:50:30Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2019-04-10T15:06:53Z",
        "closed_at": "2019-07-30T15:26:23Z",
        "merged_at": "2019-07-30T15:26:23Z",
        "body": "",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-04-10T01:36:07Z",
        "closed_at": "2019-04-10T03:29:00Z",
        "merged_at": "2019-04-10T03:29:00Z",
        "body": "With trivial model, it improves the data input pipeline throughput from 12.5K to 15K on a DGX1 V100 machine.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 76,
        "changed_files": 2,
        "created_at": "2019-04-09T06:32:28Z",
        "closed_at": "2019-04-12T02:26:01Z",
        "merged_at": "2019-04-12T02:26:01Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2019-04-08T18:28:21Z",
        "closed_at": "2019-04-08T20:18:23Z",
        "merged_at": "2019-04-08T20:18:23Z",
        "body": "...for the purpose of using it as internal benchmarks as well. ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 472,
        "deletions": 21,
        "changed_files": 5,
        "created_at": "2019-04-06T20:29:47Z",
        "closed_at": "2019-04-17T23:11:23Z",
        "merged_at": "2019-04-17T23:11:23Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 675,
        "deletions": 718,
        "changed_files": 88,
        "created_at": "2019-04-05T23:27:27Z",
        "closed_at": "2019-04-17T22:31:24Z",
        "merged_at": null,
        "body": "This fixes #3137 #5369 and allows the use of ObjectDetectionEvaluator instances with evaluate_precision_recall=True\r\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 22,
        "deletions": 74,
        "changed_files": 2,
        "created_at": "2019-04-05T03:25:55Z",
        "closed_at": "2019-04-09T06:30:50Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 92,
        "deletions": 44,
        "changed_files": 3,
        "created_at": "2019-04-04T21:28:38Z",
        "closed_at": "2019-04-05T00:22:39Z",
        "merged_at": "2019-04-05T00:22:38Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-04-04T21:05:55Z",
        "closed_at": "2019-04-08T20:20:27Z",
        "merged_at": "2019-04-08T20:20:27Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 21,
        "deletions": 7,
        "changed_files": 5,
        "created_at": "2019-04-04T19:18:10Z",
        "closed_at": "2019-05-02T19:01:51Z",
        "merged_at": "2019-05-02T19:01:51Z",
        "body": "Fixes issue addressed in #5321, updating mujoco calls to `self.data` and TensorFlow calls to `tf.CriticalSection` to reflect 1.14/2.0 standard.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 5,
        "changed_files": 4,
        "created_at": "2019-04-04T04:45:53Z",
        "closed_at": "2020-03-30T03:27:09Z",
        "merged_at": null,
        "body": "When I try to train the `ssd_mobilenet_v1_coco` downloaded from object_detection model zoo,\r\nwith `samples/configs/ssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco14_sync.config`.\r\nThere occured an TypeError as mentioned above, so I use list() function to wrap the dict_keys object of the following line in `models/feature_map_generators.py`:\r\n```python\r\nimage_features = image_features[image_features.keys()[0]]           # problem solved !\r\n```\r\n\r\nThen I think, maybe there are some other similar problem which not have been fixed, so I use `grep` recursively search them and fix them. Hopefully, I have fixed most of that.",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 90,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-04-04T00:10:54Z",
        "closed_at": "2019-04-04T20:04:28Z",
        "merged_at": "2019-04-04T20:04:28Z",
        "body": "I add one convergence benchmark and five performance benchmarks.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 41,
        "deletions": 13,
        "changed_files": 5,
        "created_at": "2019-04-02T18:35:45Z",
        "closed_at": "2019-04-02T22:24:29Z",
        "merged_at": "2019-04-02T22:24:29Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1167,
        "deletions": 31,
        "changed_files": 14,
        "created_at": "2019-04-01T14:15:58Z",
        "closed_at": "2020-04-24T06:25:45Z",
        "merged_at": null,
        "body": "The model uses canned estimators. The tensorflow_estimators package obtainable from pip didn't work with Tf 2.0. Building the latest version of the estimators repository from source is required.\r\n\r\nHad to remove train hook from model training code. Keeping it raises a KeyError .\r\n\r\nExample error for deep model:\r\n`\"The name 'dnn/head/truediv:0' refers to a Tensor which does not exist. The operation, 'dnn/head/truediv', does not exist in the graph.\" `\r\n\r\nThe final accuracy for census model is in line with what is mentioned in the README.\r\nThe final evaluation for a census wide model:\r\n`I0401 18:03:14.976323 139656691826816 logger.py:147] Benchmark metric: {'name': 'accuracy', 'value': 0.8340396881103516, 'unit': None, 'global_step': 32580, 'timestamp': '2019-04-01T12:33:14.976269Z', 'extras': []}`\r\n\r\n`I0401 18:03:14.976451 139656691826816 logger.py:147] Benchmark metric: {'name': 'accuracy_baseline', 'value': 0.7637737393379211, 'unit': None, 'global_step': 32580, 'timestamp': '2019-04-01T12:33:14.976425Z', 'extras': []}`\r\n\r\n`I0401 18:03:14.976567 139656691826816 logger.py:147] Benchmark metric: {'name': 'auc', 'value': 0.8789075613021851, 'unit': None, 'global_step': 32580, 'timestamp': '2019-04-01T12:33:14.976542Z', 'extras': []}`\r\n\r\n`I0401 18:03:14.976674 139656691826816 logger.py:147] Benchmark metric: {'name': 'auc_precision_recall', 'value': 0.6867934465408325, 'unit': None, 'global_step': 32580, 'timestamp': '2019-04-01T12:33:14.976653Z', 'extras': []}`\r\n\r\n`I0401 18:03:14.976778 139656691826816 logger.py:147] Benchmark metric: {'name': 'average_loss', 'value': 0.359136164188385, 'unit': None, 'global_step': 32580, 'timestamp': '2019-04-01T12:33:14.976758Z', 'extras': []}`\r\n\r\n`I0401 18:03:14.976883 139656691826816 logger.py:147] Benchmark metric: {'name': 'label/mean', 'value': 0.23622627556324005, 'unit': None, 'global_step': 32580, 'timestamp': '2019-04-01T12:33:14.976863Z', 'extras': []}`\r\n\r\n`I0401 18:03:14.976987 139656691826816 logger.py:147] Benchmark metric: {'name': 'loss', 'value': 14.331116676330566, 'unit': None, 'global_step': 32580, 'timestamp': '2019-04-01T12:33:14.976967Z', 'extras': []}`\r\n\r\n`I0401 18:03:14.977092 139656691826816 logger.py:147] Benchmark metric: {'name': 'precision', 'value': 0.6924629807472229, 'unit': None, 'global_step': 32580, 'timestamp': '2019-04-01T12:33:14.977071Z', 'extras': []}`\r\n\r\n`I0401 18:03:14.977226 139656691826816 logger.py:147] Benchmark metric: {'name': 'prediction/mean', 'value': 0.22958678007125854, 'unit': None, 'global_step': 32580, 'timestamp': '2019-04-01T12:33:14.977175Z', 'extras': []}`\r\n\r\n`I0401 18:03:14.977340 139656691826816 logger.py:147] Benchmark metric: {'name': 'recall', 'value': 0.5351014137268066, 'unit': None, 'global_step': 32580, 'timestamp': '2019-04-01T12:33:14.977319Z', 'extras': []}`\r\n\r\n  ",
        "comments": 10
    },
    {
        "merged": true,
        "additions": 30,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2019-03-31T20:34:39Z",
        "closed_at": "2019-04-01T21:34:50Z",
        "merged_at": "2019-04-01T21:34:50Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 770,
        "deletions": 0,
        "changed_files": 7,
        "created_at": "2019-03-31T11:05:55Z",
        "closed_at": "2020-04-24T05:07:40Z",
        "merged_at": null,
        "body": "Preliminary work for GSoC\r\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1287,
        "deletions": 0,
        "changed_files": 12,
        "created_at": "2019-03-30T12:44:07Z",
        "closed_at": "2020-04-24T05:23:26Z",
        "merged_at": null,
        "body": "Preliminiary work for GSoC project - Core Model Migration to TensorFlow 2.0",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-03-30T03:28:00Z",
        "closed_at": "2021-03-29T04:56:26Z",
        "merged_at": null,
        "body": "The variable name at line 597 `train_`  is wrong, it should be `train_op`.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-03-30T03:07:49Z",
        "closed_at": "2019-04-02T23:56:54Z",
        "merged_at": "2019-04-02T23:56:54Z",
        "body": "Attempt to get the benchmark to hit the number that running the model alone would hit, which is 0.62xxx",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-03-29T00:12:35Z",
        "closed_at": "2019-03-29T01:26:44Z",
        "merged_at": "2019-03-29T01:26:44Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 7,
        "changed_files": 3,
        "created_at": "2019-03-28T21:52:08Z",
        "closed_at": "2019-03-28T23:29:01Z",
        "merged_at": "2019-03-28T23:29:01Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 107,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-03-28T01:04:36Z",
        "closed_at": "2019-03-29T17:47:55Z",
        "merged_at": "2019-03-29T17:47:55Z",
        "body": "These tests should be removed once data input bottleneck issue is fixed.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 45,
        "deletions": 2,
        "changed_files": 3,
        "created_at": "2019-03-27T22:55:43Z",
        "closed_at": "2019-03-28T00:38:46Z",
        "merged_at": "2019-03-28T00:38:46Z",
        "body": "Add a trivial model to test the pure performance of the data input pipeline.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-03-27T18:34:39Z",
        "closed_at": "2019-03-27T20:28:25Z",
        "merged_at": "2019-03-27T20:28:25Z",
        "body": "The type __NCFDataset__ is used in the type declaration on line 81 but it is never imported.\r\n\r\n[flake8](http://flake8.pycqa.org) testing of https://github.com/tensorflow/models on Python 3.7.1\r\n\r\n$ __flake8 . --count --select=E9,F63,F72,F82 --show-source --statistics__\r\n```\r\n./official/recommendation/data_preprocessing.py:180:3: F821 undefined name 'NCFDataset'\r\n  # type: (str, str, dict, typing.Optional[str], bool, typing.Optional[str]) -> (NCFDataset, typing.Callable)\r\n  ^\r\n1    F821 undefined name 'NCFDataset'\r\n1\r\n```\r\n__E901,E999,F821,F822,F823__ are the \"_showstopper_\" [flake8](http://flake8.pycqa.org) issues that can halt the runtime with a SyntaxError, NameError, etc. These 5 are different from most other flake8 issues which are merely \"style violations\" -- useful for readability but they do not effect runtime safety.\r\n* F821: undefined name `name`\r\n* F822: undefined name `name` in `__all__`\r\n* F823: local variable name referenced before assignment\r\n* E901: SyntaxError or IndentationError\r\n* E999: SyntaxError -- failed to compile a file into an Abstract Syntax Tree",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 2516,
        "deletions": 138,
        "changed_files": 17,
        "created_at": "2019-03-27T14:53:34Z",
        "closed_at": "2019-05-13T22:14:08Z",
        "merged_at": null,
        "body": "Migrated `resnet_model.py` to TF 2.0 and the training code for Cifar-10 to TF 2.0\r\n\r\nWrote two variants of the Model class, using keras functional API. One directly creates tf.keras.Model object while the other returns an object that can perform forward pass.\r\n\r\nRefactored the Cifar-10 code to use keras API calls instead of estimators. Tried to retain as much functionality of the original scripts as possible. I have not implemented fp16 support. I removed tf flags and used defined constants instead.",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 310,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2019-03-27T02:03:45Z",
        "closed_at": "2019-07-20T21:47:46Z",
        "merged_at": null,
        "body": "See [Issue #26997](https://github.com/tensorflow/tensorflow/issues/26997).\r\n\r\nThis is to make `tensorflow.keras.applications.mobilenet_v2` compatible with TF2.0 and TPUs.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 107,
        "deletions": 63,
        "changed_files": 7,
        "created_at": "2019-03-26T23:10:24Z",
        "closed_at": "2019-04-08T22:41:43Z",
        "merged_at": "2019-04-08T22:41:43Z",
        "body": "With the fix in distributed_training_utils (which is currently pending review), the NCF model converges with distribution strategies. ",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 30,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-03-26T15:55:41Z",
        "closed_at": "2019-03-27T03:25:15Z",
        "merged_at": "2019-03-27T03:25:15Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 13,
        "deletions": 13,
        "changed_files": 2,
        "created_at": "2019-03-26T01:00:24Z",
        "closed_at": "2019-03-26T06:22:26Z",
        "merged_at": "2019-03-26T06:22:26Z",
        "body": "It is required by multi-node collective ops in eager mode.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2019-03-25T14:10:25Z",
        "closed_at": "2019-03-25T15:48:45Z",
        "merged_at": null,
        "body": "One can pass loss weight per class as call arguments now.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 13,
        "deletions": 10,
        "changed_files": 3,
        "created_at": "2019-03-22T21:48:04Z",
        "closed_at": "2019-03-22T23:06:56Z",
        "merged_at": "2019-03-22T23:06:56Z",
        "body": "Tensorboard callback seems to introduce more overhead compared to before. Disabling it should make the performance for synthetic data go beyond 9K+ images/sec.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-03-22T07:44:51Z",
        "closed_at": "2019-03-26T19:59:00Z",
        "merged_at": "2019-03-26T19:59:00Z",
        "body": "https://mypy.readthedocs.io/en/latest/cheat_sheet.html\r\n\r\n[flake8](http://flake8.pycqa.org) testing of https://github.com/tensorflow/models on Python 3.7.1\r\n\r\n$ __flake8 . --count --select=E9,F63,F72,F82 --show-source --statistics__\r\n```\r\n./official/recommendation/data_pipeline.py:346:41: F821 undefined name 'string'\r\n               epoch_dir=None           # type: string\r\n                                        ^\r\n```",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 27,
        "deletions": 18,
        "changed_files": 2,
        "created_at": "2019-03-21T15:22:38Z",
        "closed_at": "2019-03-22T16:41:29Z",
        "merged_at": "2019-03-22T16:41:29Z",
        "body": "Fixes https://github.com/tensorflow/models/issues/6393",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-03-20T18:48:02Z",
        "closed_at": "2020-04-25T03:16:58Z",
        "merged_at": "2020-04-25T03:16:57Z",
        "body": "It might seem redundant, but I followed this whole tutorial not knowing what <path-to-tensorflow> meant, and tried to install into the actual \"tensorflow\" package inside of my python installation.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 239,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2019-03-20T12:05:14Z",
        "closed_at": "2020-04-26T00:42:04Z",
        "merged_at": null,
        "body": "- Recommended command on installation guide is not working.\r\n- Tested with Python 3.6 and protoc installed.",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-03-20T03:14:28Z",
        "closed_at": "2020-04-24T06:59:24Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 336,
        "deletions": 111,
        "changed_files": 9,
        "created_at": "2019-03-20T01:53:42Z",
        "closed_at": "2019-03-21T16:55:01Z",
        "merged_at": "2019-03-21T16:55:01Z",
        "body": "233991726  by Sergio Guadarrama:\r\n\r\n    Internal change\r\n\r\n231925959  by Sergio Guadarrama:\r\n\r\n    Internal change\r\n\r\n231253502  by Sergio Guadarrama:\r\n\r\n    Internal change\r\n\r\n229973546  by Sergio Guadarrama:\r\n\r\n    Internal change\r\n\r\n229870842  by Sergio Guadarrama:\r\n\r\n    Internal change\r\n\r\nPiperOrigin-RevId: 233991726",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 24,
        "deletions": 8,
        "changed_files": 3,
        "created_at": "2019-03-19T22:30:28Z",
        "closed_at": "2019-03-19T23:33:42Z",
        "merged_at": "2019-03-19T23:33:42Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 63,
        "deletions": 7,
        "changed_files": 4,
        "created_at": "2019-03-19T01:36:09Z",
        "closed_at": "2019-03-20T00:42:15Z",
        "merged_at": "2019-03-20T00:42:15Z",
        "body": "Use GPU private threads to schedule and launch kernels, and limit the number of tf.data preprocessing threads to reduce contention.\r\n\r\nThis should bring the performance of real data tests close to synthetic ones.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 16,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-03-18T20:08:05Z",
        "closed_at": "2020-04-24T15:21:29Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2019-03-18T07:55:14Z",
        "closed_at": "2020-02-04T09:03:34Z",
        "merged_at": null,
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-03-16T22:28:52Z",
        "closed_at": "2019-04-08T17:47:34Z",
        "merged_at": "2019-04-08T17:47:34Z",
        "body": "Updated README to specify python2.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2019-03-14T23:29:18Z",
        "closed_at": "2019-03-19T20:51:14Z",
        "merged_at": "2019-03-19T20:51:14Z",
        "body": "Add the option to run Keras resnet model on multiple workers.\r\nFix the logic that computes the number of workers to include chief if it is present.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 854,
        "deletions": 0,
        "changed_files": 6,
        "created_at": "2019-03-14T22:25:07Z",
        "closed_at": "2020-04-24T05:17:47Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-03-14T01:08:58Z",
        "closed_at": "2019-03-26T03:41:15Z",
        "merged_at": "2019-03-26T03:41:15Z",
        "body": "In models/official/mnist/dataset.py: the use of ```tf.to_int32``` raises deprecated warning.\r\n\r\nI've changed ```tf.to_int32(label)``` to ```tf.cast(label, tf.int32)```",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 16,
        "deletions": 2,
        "changed_files": 3,
        "created_at": "2019-03-13T06:09:46Z",
        "closed_at": "2019-03-13T21:12:29Z",
        "merged_at": "2019-03-13T21:12:29Z",
        "body": "The failure is mostly caused by the flag values passed in. \r\nThe Keras implementation is sensitive about the batch_size, which needs to be dividable by (NUM_EVAL_NEGATIVES+1). In the test, the NUM_EVAL_NEGATIVES is set to 2, while in an ordinary run, it is 999. ",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2019-03-12T23:10:21Z",
        "closed_at": "2019-04-03T00:55:01Z",
        "merged_at": "2019-04-03T00:55:01Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 31,
        "deletions": 9,
        "changed_files": 2,
        "created_at": "2019-03-12T18:00:18Z",
        "closed_at": "2019-03-19T22:09:02Z",
        "merged_at": "2019-03-19T22:09:02Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 76,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2019-03-12T06:25:49Z",
        "closed_at": "2022-04-06T05:04:24Z",
        "merged_at": null,
        "body": "@rikel i add a original MAB thompson sampling, helpful for compare with Contextual Bandit algorighm effective.\r\n\r\nplease merge this pull request",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2019-03-12T06:19:02Z",
        "closed_at": "2019-03-29T16:55:45Z",
        "merged_at": "2019-03-29T16:55:45Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 23,
        "deletions": 9,
        "changed_files": 3,
        "created_at": "2019-03-09T00:31:50Z",
        "closed_at": "2019-03-18T23:44:34Z",
        "merged_at": "2019-03-18T23:44:34Z",
        "body": "\u2026ability to store epochs in a user specified location.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-03-08T21:26:23Z",
        "closed_at": "2019-03-26T03:32:14Z",
        "merged_at": "2019-03-26T03:32:14Z",
        "body": "Added missing 's' character in \"install\". Added link to pyglet documentation.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 89,
        "deletions": 9,
        "changed_files": 2,
        "created_at": "2019-03-08T19:27:08Z",
        "closed_at": "2019-03-11T17:16:00Z",
        "merged_at": "2019-03-11T17:16:00Z",
        "body": "Adding LARS to ResNet",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-03-08T05:44:28Z",
        "closed_at": "2020-04-24T07:07:35Z",
        "merged_at": null,
        "body": "Currently, the dropout seems to be ignored in regular RNN given that it's not actually used in the `DropoutWrapper`:\r\n\r\n```python\r\nif params.dropout > 0.0:\r\n      cells_fw = [tf.contrib.rnn.DropoutWrapper(cell) for cell in cells_fw]\r\n      cells_bw = [tf.contrib.rnn.DropoutWrapper(cell) for cell in cells_bw]\r\n```\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3667,
        "deletions": 136,
        "changed_files": 47,
        "created_at": "2019-03-07T06:39:38Z",
        "closed_at": "2019-03-07T18:36:04Z",
        "merged_at": "2019-03-07T18:36:04Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 285,
        "deletions": 66,
        "changed_files": 6,
        "created_at": "2019-03-07T05:28:15Z",
        "closed_at": "2019-03-28T21:38:45Z",
        "merged_at": "2019-03-28T21:38:45Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 26,
        "deletions": 6,
        "changed_files": 3,
        "created_at": "2019-03-07T02:56:27Z",
        "closed_at": "2019-03-07T16:50:37Z",
        "merged_at": "2019-03-07T16:50:37Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 59,
        "deletions": 60,
        "changed_files": 1,
        "created_at": "2019-03-07T02:24:15Z",
        "closed_at": "2019-04-10T15:03:43Z",
        "merged_at": "2019-04-10T15:03:43Z",
        "body": "",
        "comments": 10
    },
    {
        "merged": true,
        "additions": 8381,
        "deletions": 2431,
        "changed_files": 94,
        "created_at": "2019-03-07T00:01:09Z",
        "closed_at": "2019-03-07T20:19:47Z",
        "merged_at": "2019-03-07T20:19:47Z",
        "body": "236813471  by lzc:\r\n\r\n    Internal change.\r\n\r\n--\r\n236507310  by lzc:\r\n\r\n    Fix preprocess.random_resize_method config type issue. The target height and width will be passed as \"size\" to tf.image.resize_images which only accepts integer.\r\n\r\n--\r\n236409989  by Zhichao Lu:\r\n\r\n    Config export_to_tpu from function parameter instead of HParams for TPU inference.\r\n\r\n--\r\n236403186  by Zhichao Lu:\r\n\r\n    Make graph file names optional arguments.\r\n\r\n--\r\n236237072  by Zhichao Lu:\r\n\r\n    Minor bugfix for keyword args.\r\n\r\n--\r\n236209602  by Zhichao Lu:\r\n\r\n    Add support for PartitionedVariable to get_variables_available_in_checkpoint.\r\n\r\n--\r\n235828658  by Zhichao Lu:\r\n\r\n    Automatically stop evaluation jobs when training is finished.\r\n\r\n--\r\n235817964  by Zhichao Lu:\r\n\r\n    Add an optional process_metrics_fn callback to eval_util, it gets called\r\n    with evaluation results once each evaluation is complete.\r\n\r\n--\r\n235788721  by lzc:\r\n\r\n    Fix yml file tf runtime version.\r\n\r\n--\r\n235262897  by Zhichao Lu:\r\n\r\n    Add keypoint support to the random_pad_image preprocessor method.\r\n\r\n--\r\n235257380  by Zhichao Lu:\r\n\r\n    Support InputDataFields.groundtruth_confidences in retain_groundtruth(), retain_groundtruth_with_positive_classes(), filter_groundtruth_with_crowd_boxes(), filter_groundtruth_with_nan_box_coordinates(), filter_unrecognized_classes().\r\n\r\n--\r\n235109188  by Zhichao Lu:\r\n\r\n    Fix bug in pad_input_data_to_static_shapes for num_additional_channels > 0; make color-specific data augmentation only touch RGB channels.\r\n\r\n--\r\n235045010  by Zhichao Lu:\r\n\r\n    Don't slice class_predictions_with_background when add_background_class is false.\r\n\r\n--\r\n235026189  by lzc:\r\n\r\n    Fix import in g3doc.\r\n\r\n--\r\n234863426  by Zhichao Lu:\r\n\r\n    Added fixes in exporter to allow writing a checkpoint to a specified temporary directory.\r\n\r\n--\r\n234671886  by lzc:\r\n\r\n    Internal Change.\r\n\r\n--\r\n234630803  by rathodv:\r\n\r\n    Internal Change.\r\n\r\n--\r\n233985896  by Zhichao Lu:\r\n\r\n    Add Neumann optimizer to object detection.\r\n\r\n--\r\n233560911  by Zhichao Lu:\r\n\r\n    Add NAS-FPN object detection with Resnet and Mobilenet v2.\r\n\r\n--\r\n233513536  by Zhichao Lu:\r\n\r\n    Export TPU compatible object detection model\r\n\r\n--\r\n233495772  by lzc:\r\n\r\n    Internal change.\r\n\r\n--\r\n233453557  by Zhichao Lu:\r\n\r\n    Create Keras-based SSD+MobilenetV1 for object detection.\r\n\r\n--\r\n233220074  by lzc:\r\n\r\n    Update release notes date.\r\n\r\n--\r\n233165761  by Zhichao Lu:\r\n\r\n    Support depth_multiplier and min_depth in _SSDResnetV1FpnFeatureExtractor.\r\n\r\n--\r\n233160046  by lzc:\r\n\r\n    Internal change.\r\n\r\n--\r\n232926599  by Zhichao Lu:\r\n\r\n    [tf.data] Switching tf.data functions to use `defun`, providing an escape hatch to continue using the legacy `Defun`.\r\n\r\n    There are subtle differences between the implementation of `defun` and `Defun` (such as resources handling or control flow) and it is possible that input pipelines that use control flow or resources in their functions might be affected by this change. To migrate majority of existing pipelines to the recommended way of creating functions in TF 2.0 world, while allowing (a small number of) existing pipelines to continue relying on the deprecated behavior, this CL provides an escape hatch.\r\n\r\n    If your input pipeline is affected by this CL, it should apply the escape hatch by replacing `foo.map(...)` with `foo.map_with_legacy_function(...)`.\r\n\r\n--\r\n232891621  by Zhichao Lu:\r\n\r\n    Modify faster_rcnn meta architecture to normalize raw detections.\r\n\r\n--\r\n232875817  by Zhichao Lu:\r\n\r\n    Make calibration a post-processing step.\r\n\r\n    Specifically:\r\n    - Move the calibration config from pipeline.proto --> post_processing.proto\r\n    - Edit post_processing_builder.py to return a calibration function. If no calibration config is provided, it None.\r\n    - Edit SSD and FasterRCNN meta architectures to optionally call the calibration function on detection scores after score conversion and before NMS.\r\n\r\n--\r\n232704481  by Zhichao Lu:\r\n\r\n    Edit calibration builder to build a function that will be used within a detection model's `postprocess` method, after score conversion and before non-maxima suppression.\r\n\r\n    Specific Edits:\r\n    - The returned function now accepts class_predictions_with_background as its argument instead of detection_scores and detection_classes.\r\n    - Class-specific calibration was temporarily removed, as it requires more significant refactoring. Will be added later.\r\n\r\n--\r\n232615379  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n--\r\n232483345  by ronnyvotel:\r\n\r\n    Making the use of bfloat16 restricted to TPUs.\r\n\r\n--\r\n232399572  by Zhichao Lu:\r\n\r\n    Edit calibration builder and proto to support class-agnostic calibration.\r\n\r\n    Specifically:\r\n    - Edit calibration protos to include path to relevant label map if required for class-specific calibration. Previously, label maps were inferred from other parts of the pipeline proto; this allows all information required by the builder stay within the calibration proto and remove extraneous information from being passed with class-agnostic calibration.\r\n    - Add class-agnostic protos to the calibration config.\r\n\r\n    Note that the proto supports sigmoid and linear interpolation parameters, but the builder currently only supports linear interpolation.\r\n\r\n--\r\n231613048  by Zhichao Lu:\r\n\r\n    Add calibration builder for applying calibration transformations from output of object detection models.\r\n\r\n    Specifically:\r\n    - Add calibration proto to support sigmoid and isotonic regression (stepwise function) calibration.\r\n    - Add a builder to support calibration from isotonic regression outputs.\r\n\r\n--\r\n231519786  by lzc:\r\n\r\n    model_builder test refactor.\r\n    - removed proto text boilerplate in each test case and let them call a create_default_proto function instead.\r\n    - consolidated all separate ssd model creation tests into one.\r\n    - consolidated all separate faster rcnn model creation tests into one.\r\n    - used parameterized test for testing mask rcnn models and use_matmul_crop_and_resize\r\n    - added all failures test.\r\n\r\n--\r\n231448169  by Zhichao Lu:\r\n\r\n    Return static shape as a constant tensor.\r\n\r\n--\r\n231423126  by lzc:\r\n\r\n    Add a release note for OID v4 models.\r\n\r\n--\r\n231401941  by Zhichao Lu:\r\n\r\n    Adding correct labelmap for the models trained on Open Images V4 (*oid_v4\r\n    config suffix).\r\n\r\n--\r\n231320357  by Zhichao Lu:\r\n\r\n    Add scope to Nearest Neighbor Resize op so that it stays in the same name scope as the original resize ops.\r\n\r\n--\r\n231257699  by Zhichao Lu:\r\n\r\n    Switch to using preserve_aspect_ratio in tf.image.resize_images rather than using a custom implementation.\r\n\r\n--\r\n231247368  by rathodv:\r\n\r\n    Internal change.\r\n\r\n--\r\n231004874  by lzc:\r\n\r\n    Update documentations to use tf 1.12 for object detection API.\r\n\r\n--\r\n230999911  by rathodv:\r\n\r\n    Use tf.batch_gather instead of ops.batch_gather\r\n\r\n--\r\n230999720  by huizhongc:\r\n\r\n    Fix weight equalization test in ops_test.\r\n\r\n--\r\n230984728  by rathodv:\r\n\r\n    Internal update.\r\n\r\n--\r\n230929019  by lzc:\r\n\r\n    Add an option to replace preprocess operation with placeholder for ssd feature extractor.\r\n\r\n--\r\n230845266  by lzc:\r\n\r\n    Require tensorflow version 1.12 for object detection API and rename keras_applications to keras_models\r\n\r\n--\r\n230392064  by lzc:\r\n\r\n    Add RetinaNet 101 checkpoint trained on OID v4 to detection model zoo.\r\n\r\n--\r\n230014128  by derekjchow:\r\n\r\n    This file was re-located below the tensorflow/lite/g3doc/convert\r\n\r\n--\r\n229941449  by lzc:\r\n\r\n    Update SSD mobilenet v2 quantized model download path.\r\n\r\n--\r\n229843662  by lzc:\r\n\r\n    Add an option to use native resize tf op in fpn top-down feature map generation.\r\n\r\n--\r\n229636034  by rathodv:\r\n\r\n    Add deprecation notice to a few old parameters in train.proto\r\n\r\n--\r\n228959078  by derekjchow:\r\n\r\n    Remove duplicate elif case in _check_and_convert_legacy_input_config_key\r\n\r\n--\r\n228749719  by rathodv:\r\n\r\n    Minor refactoring to make exporter's `build_detection_graph` method public.\r\n\r\n--\r\n228573828  by rathodv:\r\n\r\n    Mofity model.postprocess to return raw detections and raw scores.\r\n\r\n    Modify, post-process methods in core/model.py and the meta architectures to export raw detection (without any non-max suppression) and raw multiclass score logits for those detections.\r\n\r\n--\r\n228420670  by Zhichao Lu:\r\n\r\n    Add shims for custom architectures for object detection models.\r\n\r\n--\r\n228241692  by Zhichao Lu:\r\n\r\n    Fix the comment on \"losses_mask\" in \"Loss\" class.\r\n\r\n--\r\n228223810  by Zhichao Lu:\r\n\r\n    Support other_heads' predictions in WeightSharedConvolutionalBoxPredictor. Also remove a few unused parameters and fix a couple of comments in convolutional_box_predictor.py.\r\n\r\n--\r\n228200588  by Zhichao Lu:\r\n\r\n    Add Expected Calibration Error and an evaluator that calculates the metric for object detections.\r\n\r\n--\r\n228167740  by lzc:\r\n\r\n    Add option to use bounded activations in FPN top-down feature map generation.\r\n\r\n--\r\n227767700  by rathodv:\r\n\r\n    Internal.\r\n\r\n--\r\n226295236  by Zhichao Lu:\r\n\r\n    Add Open Image V4 Resnet101-FPN training config to third_party\r\n\r\n--\r\n226254842  by Zhichao Lu:\r\n\r\n    Fix typo in documentation.\r\n\r\n--\r\n225833971  by Zhichao Lu:\r\n\r\n    Option to have no resizer in object detection model.\r\n\r\n--\r\n225824890  by lzc:\r\n\r\n    Fixes p3 compatibility for model_lib.py\r\n\r\n--\r\n225760897  by menglong:\r\n\r\n    normalizer should be at least 1.\r\n\r\n--\r\n225559842  by menglong:\r\n\r\n    Add extra logic filtering unrecognized classes.\r\n\r\n--\r\n225379421  by lzc:\r\n\r\n    Add faster_rcnn_inception_resnet_v2_atrous_oid_v4 config to third_party\r\n\r\n--\r\n225368337  by Zhichao Lu:\r\n\r\n    Add extra logic filtering unrecognized classes.\r\n\r\n--\r\n225341095  by Zhichao Lu:\r\n\r\n    Adding Open Images V4 models to OD API model zoo and corresponding configs to the\r\n    configs.\r\n\r\n--\r\n225218450  by menglong:\r\n\r\n    Add extra logic filtering unrecognized classes.\r\n\r\n--\r\n225057591  by Zhichao Lu:\r\n\r\n    Internal change.\r\n\r\n--\r\n224895417  by rathodv:\r\n\r\n    Internal change.\r\n\r\n--\r\n224209282  by Zhichao Lu:\r\n\r\n    Add two data augmentations to object detection: (1) Self-concat (2) Absolute pads.\r\n\r\n--\r\n224073762  by Zhichao Lu:\r\n\r\n    Do not create tf.constant until _generate() is actually called in the object detector.\r\n\r\n--\r\n\r\nPiperOrigin-RevId: 236813471",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 73,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-03-06T23:53:45Z",
        "closed_at": "2019-03-07T03:12:53Z",
        "merged_at": "2019-03-07T03:12:53Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 22,
        "deletions": 10,
        "changed_files": 2,
        "created_at": "2019-03-06T02:13:54Z",
        "closed_at": "2019-03-06T20:59:55Z",
        "merged_at": "2019-03-06T20:59:55Z",
        "body": "Add mixed precision support to the Keras Resnet model.\r\n\r\nThis uses the experimental tf.keras mixed precision API. The API will eventually allow users to use mixed precision with a single line of code, but currently it requires several changes to model code.\r\n\r\nI tested mixed precision converges with the command line:\r\n\r\n```\r\npython keras_imagenet_main.py --clean --num_gpus=8 --data_dir=/raid/imagenet-2012-tfrecord --batch_size=1024 --train_epochs=90 --model_dir ~/fp16_keras_mod --dtype=fp16 --enable_eager=true --datasets_num_private_threads=14\r\n```\r\n\r\nThe final validation accuracy is 76.35%. I ran tensorflow at commit tensorflow/tensorflow@23ec33ae1418d56c3ce0294720782b636595a2b3.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 9337,
        "deletions": 0,
        "changed_files": 189,
        "created_at": "2019-03-05T16:08:58Z",
        "closed_at": "2019-03-09T03:04:44Z",
        "merged_at": null,
        "body": "",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 15956,
        "deletions": 3697,
        "changed_files": 214,
        "created_at": "2019-03-05T14:42:23Z",
        "closed_at": "2019-05-30T00:02:02Z",
        "merged_at": null,
        "body": "Hi community,\r\nthis is my first PR, so please bear with me if the changes are too naive. Thanks.",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 28,
        "deletions": 28,
        "changed_files": 1,
        "created_at": "2019-03-04T19:50:33Z",
        "closed_at": "2023-04-08T01:48:34Z",
        "merged_at": null,
        "body": "Google Colab will only display image results if the `%matplotlib inline` _precedes_ `from matplotlib import pyplot as plt`. This pr moves the ENV code cell above the IMPORTS cell.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 40,
        "deletions": 48,
        "changed_files": 3,
        "created_at": "2019-03-04T16:06:31Z",
        "closed_at": "2020-04-24T05:22:46Z",
        "merged_at": null,
        "body": "Migrated `dataset.py`, `mnist_eager.py` and `mnist_eager_test.py` to TF 2.0\r\n\r\nI am not sure about `defun` tests in `mnist_eager_test.py`, have skipped them for now. Can someone tell me about how to go about them?",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 76,
        "deletions": 25,
        "changed_files": 6,
        "created_at": "2019-03-02T19:28:57Z",
        "closed_at": "2019-03-02T21:33:20Z",
        "merged_at": "2019-03-02T21:33:20Z",
        "body": "This PR extends the end-to-end tests used by Estimator to the Keras paths as well. They don't test for correctness, but they're good for catching silly syntax errors and the like. There is currently an issue with NCF Keras and synthetic data, so I added the tests but also disabled them.\r\n\r\nI have confirmed that the additional tests to cifar and imagenet would have caught the outdated scope issue. (As well as fixed that.) We definitely hit these sort of issues with annoying frequency when doing lots of changes on the Estimator side as well, so hopefully this will make our lives a bit easier.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 100,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-03-01T22:15:55Z",
        "closed_at": "2019-03-28T17:14:53Z",
        "merged_at": "2019-03-28T17:14:53Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 61,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2019-03-01T01:42:58Z",
        "closed_at": "2020-04-24T06:58:48Z",
        "merged_at": null,
        "body": "This commit adds an option to order the input sentences on token-count instead of wordcount to translate.py. Order of input sentences sorted on wordcount is quite different than sentences sorted on token-count. This is the reason possibly the padding overhead in wordcount is higher than token-count. We found that default sorting on wordcount results in slower inference throughput. Hence, the commit. We ensured that the ordering has no effect on BLEU score.\r\n\r\nTo run with this option, pass --sort_by_tokens=True from the command line to translate.py\r\n\r\nWe also add options to pass inter_op and intra_op from command line.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 83,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2019-02-28T18:58:36Z",
        "closed_at": "2019-03-01T19:07:23Z",
        "merged_at": "2019-03-01T19:07:23Z",
        "body": "Add Keras XLA benchmarks and monkey-patched the `assert_broadcastable` op to avoid OOM. The monkey patch should be reverted once the OOM issue is fixed.\r\n\r\nTested with [PerfZero](https://github.com/tensorflow/benchmarks/tree/master/perfzero) on Google Cloud.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 13,
        "deletions": 17,
        "changed_files": 1,
        "created_at": "2019-02-28T09:12:21Z",
        "closed_at": "2019-02-28T23:28:50Z",
        "merged_at": "2019-02-28T23:28:50Z",
        "body": "Also removed the bfc allocator one. We'll add GPU thread pool, inter op, intra op pool later.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2019-02-28T02:53:01Z",
        "closed_at": "2019-02-28T23:29:27Z",
        "merged_at": "2019-02-28T23:29:27Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2019-02-28T00:32:45Z",
        "closed_at": "2019-02-28T15:46:33Z",
        "merged_at": "2019-02-28T15:46:33Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-02-27T12:51:20Z",
        "closed_at": "2020-03-25T12:24:30Z",
        "merged_at": null,
        "body": "weighed -> weighted\r\nweigth -> weight",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 5800,
        "deletions": 0,
        "changed_files": 29,
        "created_at": "2019-02-26T22:19:22Z",
        "closed_at": "2019-02-27T22:53:52Z",
        "merged_at": "2019-02-27T22:53:52Z",
        "body": "Open-source [FEELVOS](https://arxiv.org/pdf/1902.09513.pdf), the Fast End-to-End Embedding Learning for Video Object Segmentation.\r\nFEELVOS was developed by Paul Voigtlaender during his 2018 summer internship at Google.\r\nThe work has been accepted to CVPR 2019.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 0,
        "changed_files": 0,
        "created_at": "2019-02-26T21:40:53Z",
        "closed_at": "2019-03-05T22:25:06Z",
        "merged_at": null,
        "body": "235262897  by Zhichao Lu:\r\n\r\n    Add keypoint support to the random_pad_image preprocessor method.\r\n\r\n--\r\n235257380  by Zhichao Lu:\r\n\r\n    Support InputDataFields.groundtruth_confidences in retain_groundtruth(), retain_groundtruth_with_positive_classes(), filter_groundtruth_with_crowd_boxes(), filter_groundtruth_with_nan_box_coordinates(), filter_unrecognized_classes().\r\n\r\n--\r\n235109188  by Zhichao Lu:\r\n\r\n    Fix bug in pad_input_data_to_static_shapes for num_additional_channels > 0; make color-specific data augmentation only touch RGB channels.\r\n\r\n--\r\n235045010  by Zhichao Lu:\r\n\r\n    Don't slice class_predictions_with_background when add_background_class is false.\r\n\r\n--\r\n235026189  by lzc:\r\n\r\n    Fix import in g3doc.\r\n\r\n--\r\n234863426  by Zhichao Lu:\r\n\r\n    Added fixes in exporter to allow writing a checkpoint to a specified temporary directory.\r\n\r\n--\r\n234671886  by lzc:\r\n\r\n    Internal Change.\r\n\r\n--\r\n234630803  by rathodv:\r\n\r\n    Internal Change.\r\n\r\n--\r\n233985896  by Zhichao Lu:\r\n\r\n    Add Neumann optimizer to object detection.\r\n\r\n--\r\n233560911  by Zhichao Lu:\r\n\r\n    Add NAS-FPN object detection with Resnet and Mobilenet v2.\r\n\r\n--\r\n233513536  by Zhichao Lu:\r\n\r\n    Export TPU compatible object detection model\r\n\r\n--\r\n233495772  by lzc:\r\n\r\n    Internal change.\r\n\r\n--\r\n233453557  by Zhichao Lu:\r\n\r\n    Create Keras-based SSD+MobilenetV1 for object detection.\r\n\r\n--\r\n233220074  by lzc:\r\n\r\n    Update release notes date.\r\n\r\n--\r\n233165761  by Zhichao Lu:\r\n\r\n    Support depth_multiplier and min_depth in _SSDResnetV1FpnFeatureExtractor.\r\n\r\n--\r\n233160046  by lzc:\r\n\r\n    Internal change.\r\n\r\n--\r\n232926599  by Zhichao Lu:\r\n\r\n    [tf.data] Switching tf.data functions to use `defun`, providing an escape hatch to continue using the legacy `Defun`.\r\n\r\n    There are subtle differences between the implementation of `defun` and `Defun` (such as resources handling or control flow) and it is possible that input pipelines that use control flow or resources in their functions might be affected by this change. To migrate majority of existing pipelines to the recommended way of creating functions in TF 2.0 world, while allowing (a small number of) existing pipelines to continue relying on the deprecated behavior, this CL provides an escape hatch.\r\n\r\n    If your input pipeline is affected by this CL, it should apply the escape hatch by replacing `foo.map(...)` with `foo.map_with_legacy_function(...)`.\r\n\r\n--\r\n232891621  by Zhichao Lu:\r\n\r\n    Modify faster_rcnn meta architecture to normalize raw detections.\r\n\r\n--\r\n232875817  by Zhichao Lu:\r\n\r\n    Make calibration a post-processing step.\r\n\r\n    Specifically:\r\n    - Move the calibration config from pipeline.proto --> post_processing.proto\r\n    - Edit post_processing_builder.py to return a calibration function. If no calibration config is provided, it None.\r\n    - Edit SSD and FasterRCNN meta architectures to optionally call the calibration function on detection scores after score conversion and before NMS.\r\n\r\n--\r\n232704481  by Zhichao Lu:\r\n\r\n    Edit calibration builder to build a function that will be used within a detection model's `postprocess` method, after score conversion and before non-maxima suppression.\r\n\r\n    Specific Edits:\r\n    - The returned function now accepts class_predictions_with_background as its argument instead of detection_scores and detection_classes.\r\n    - Class-specific calibration was temporarily removed, as it requires more significant refactoring. Will be added later.\r\n\r\n--\r\n232615379  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n--\r\n232483345  by ronnyvotel:\r\n\r\n    Making the use of bfloat16 restricted to TPUs.\r\n\r\n--\r\n232399572  by Zhichao Lu:\r\n\r\n    Edit calibration builder and proto to support class-agnostic calibration.\r\n\r\n    Specifically:\r\n    - Edit calibration protos to include path to relevant label map if required for class-specific calibration. Previously, label maps were inferred from other parts of the pipeline proto; this allows all information required by the builder stay within the calibration proto and remove extraneous information from being passed with class-agnostic calibration.\r\n    - Add class-agnostic protos to the calibration config.\r\n\r\n    Note that the proto supports sigmoid and linear interpolation parameters, but the builder currently only supports linear interpolation.\r\n\r\n--\r\n231613048  by Zhichao Lu:\r\n\r\n    Add calibration builder for applying calibration transformations from output of object detection models.\r\n\r\n    Specifically:\r\n    - Add calibration proto to support sigmoid and isotonic regression (stepwise function) calibration.\r\n    - Add a builder to support calibration from isotonic regression outputs.\r\n\r\n--\r\n231519786  by lzc:\r\n\r\n    model_builder test refactor.\r\n    - removed proto text boilerplate in each test case and let them call a create_default_proto function instead.\r\n    - consolidated all separate ssd model creation tests into one.\r\n    - consolidated all separate faster rcnn model creation tests into one.\r\n    - used parameterized test for testing mask rcnn models and use_matmul_crop_and_resize\r\n    - added all failures test.\r\n\r\n--\r\n231448169  by Zhichao Lu:\r\n\r\n    Return static shape as a constant tensor.\r\n\r\n--\r\n231423126  by lzc:\r\n\r\n    Add a release note for OID v4 models.\r\n\r\n--\r\n231401941  by Zhichao Lu:\r\n\r\n    Adding correct labelmap for the models trained on Open Images V4 (*oid_v4\r\n    config suffix).\r\n\r\n--\r\n231320357  by Zhichao Lu:\r\n\r\n    Add scope to Nearest Neighbor Resize op so that it stays in the same name scope as the original resize ops.\r\n\r\n--\r\n231257699  by Zhichao Lu:\r\n\r\n    Switch to using preserve_aspect_ratio in tf.image.resize_images rather than using a custom implementation.\r\n\r\n--\r\n231247368  by rathodv:\r\n\r\n    Internal change.\r\n\r\n--\r\n231004874  by lzc:\r\n\r\n    Update documentations to use tf 1.12 for object detection API.\r\n\r\n--\r\n230999911  by rathodv:\r\n\r\n    Use tf.batch_gather instead of ops.batch_gather\r\n\r\n--\r\n230999720  by huizhongc:\r\n\r\n    Fix weight equalization test in ops_test.\r\n\r\n--\r\n230984728  by rathodv:\r\n\r\n    Internal update.\r\n\r\n--\r\n230929019  by lzc:\r\n\r\n    Add an option to replace preprocess operation with placeholder for ssd feature extractor.\r\n\r\n--\r\n230845266  by lzc:\r\n\r\n    Require tensorflow version 1.12 for object detection API and rename keras_applications to keras_models\r\n\r\n--\r\n230392064  by lzc:\r\n\r\n    Add RetinaNet 101 checkpoint trained on OID v4 to detection model zoo.\r\n\r\n--\r\n230014128  by derekjchow:\r\n\r\n    This file was re-located below the tensorflow/lite/g3doc/convert\r\n\r\n--\r\n229941449  by lzc:\r\n\r\n    Update SSD mobilenet v2 quantized model download path.\r\n\r\n--\r\n229843662  by lzc:\r\n\r\n    Add an option to use native resize tf op in fpn top-down feature map generation.\r\n\r\n--\r\n229636034  by rathodv:\r\n\r\n    Add deprecation notice to a few old parameters in train.proto\r\n\r\n--\r\n228959078  by derekjchow:\r\n\r\n    Remove duplicate elif case in _check_and_convert_legacy_input_config_key\r\n\r\n--\r\n228749719  by rathodv:\r\n\r\n    Minor refactoring to make exporter's `build_detection_graph` method public.\r\n\r\n--\r\n228573828  by rathodv:\r\n\r\n    Mofity model.postprocess to return raw detections and raw scores.\r\n\r\n    Modify, post-process methods in core/model.py and the meta architectures to export raw detection (without any non-max suppression) and raw multiclass score logits for those detections.\r\n\r\n--\r\n228420670  by Zhichao Lu:\r\n\r\n    Add shims for custom architectures for object detection models.\r\n\r\n--\r\n228241692  by Zhichao Lu:\r\n\r\n    Fix the comment on \"losses_mask\" in \"Loss\" class.\r\n\r\n--\r\n228223810  by Zhichao Lu:\r\n\r\n    Support other_heads' predictions in WeightSharedConvolutionalBoxPredictor. Also remove a few unused parameters and fix a couple of comments in convolutional_box_predictor.py.\r\n\r\n--\r\n228200588  by Zhichao Lu:\r\n\r\n    Add Expected Calibration Error and an evaluator that calculates the metric for object detections.\r\n\r\n--\r\n228167740  by lzc:\r\n\r\n    Add option to use bounded activations in FPN top-down feature map generation.\r\n\r\n--\r\n227767700  by rathodv:\r\n\r\n    Internal.\r\n\r\n--\r\n226295236  by Zhichao Lu:\r\n\r\n    Add Open Image V4 Resnet101-FPN training config to third_party\r\n\r\n--\r\n226254842  by Zhichao Lu:\r\n\r\n    Fix typo in documentation.\r\n\r\n--\r\n225833971  by Zhichao Lu:\r\n\r\n    Option to have no resizer in object detection model.\r\n\r\n--\r\n225824890  by lzc:\r\n\r\n    Fixes p3 compatibility for model_lib.py\r\n\r\n--\r\n225760897  by menglong:\r\n\r\n    normalizer should be at least 1.\r\n\r\n--\r\n225559842  by menglong:\r\n\r\n    Add extra logic filtering unrecognized classes.\r\n\r\n--\r\n225379421  by lzc:\r\n\r\n    Add faster_rcnn_inception_resnet_v2_atrous_oid_v4 config to third_party\r\n\r\n--\r\n225368337  by Zhichao Lu:\r\n\r\n    Add extra logic filtering unrecognized classes.\r\n\r\n--\r\n225341095  by Zhichao Lu:\r\n\r\n    Adding Open Images V4 models to OD API model zoo and corresponding configs to the\r\n    configs.\r\n\r\n--\r\n225218450  by menglong:\r\n\r\n    Add extra logic filtering unrecognized classes.\r\n\r\n--\r\n225057591  by Zhichao Lu:\r\n\r\n    Internal change.\r\n\r\n--\r\n224895417  by rathodv:\r\n\r\n    Internal change.\r\n\r\n--\r\n224209282  by Zhichao Lu:\r\n\r\n    Add two data augmentations to object detection: (1) Self-concat (2) Absolute pads.\r\n\r\n--\r\n224073762  by Zhichao Lu:\r\n\r\n    Do not create tf.constant until _generate() is actually called in the object detector.\r\n\r\n--\r\n\r\nPiperOrigin-RevId: 235262897",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 613,
        "deletions": 911,
        "changed_files": 5,
        "created_at": "2019-02-25T19:50:00Z",
        "closed_at": "2020-04-24T05:13:54Z",
        "merged_at": null,
        "body": "Hi Jon, Sherry\r\nI updated the cifar10.py's input pipeline to use the new DataSet API. Also the cifar10_train.py is updated to do both train and eval (after every epoch) instead of doing them in two different py files.\r\nPlease take a look",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2019-02-25T08:02:44Z",
        "closed_at": "2019-02-25T16:03:25Z",
        "merged_at": "2019-02-25T16:03:25Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2019-02-22T23:19:36Z",
        "closed_at": "2019-03-06T22:55:44Z",
        "merged_at": "2019-03-06T22:55:44Z",
        "body": "replace the usage of python's built in sort with numpy's argsort, which is faster. Also use the given axes to get the most_likely_words instead of calling enumerate and list (it's slower and more memory consuming)",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-02-21T01:08:05Z",
        "closed_at": "2019-02-21T16:33:13Z",
        "merged_at": "2019-02-21T16:33:13Z",
        "body": "This PR contains two entries to the gitignore file for the data files that one downloads when following [word-embedding tutorial](https://github.com/tensorflow/models/blob/master/tutorials/embedding/README.md):\r\n\r\n- `tutorials/embedding/text8`\r\n- `tutorials/embedding/questions-words.txt`",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 42,
        "deletions": 4,
        "changed_files": 3,
        "created_at": "2019-02-21T00:38:58Z",
        "closed_at": "2019-02-21T16:34:19Z",
        "merged_at": "2019-02-21T16:34:19Z",
        "body": "Add `--enable_xla` flag to ResNet models for ImageNet and Cifar. Note that this feature is still being developed and currently still requires manually patching a diff to enable it.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-02-20T19:55:01Z",
        "closed_at": "2019-02-21T18:56:01Z",
        "merged_at": "2019-02-21T18:56:01Z",
        "body": "This import from google3.third_party doesn't work.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 472,
        "deletions": 0,
        "changed_files": 6,
        "created_at": "2019-02-20T15:42:46Z",
        "closed_at": "2020-04-24T05:19:55Z",
        "merged_at": null,
        "body": "(WIP) This PR adds codes for training Keras App Models in TF2.0 and benchmarking them.\r\n\r\nNot finished yet. Let's firstly discuss code structure and design principles. I tried to follow the principles below, but they're just my opinions and we should definitely discuss.\r\n\r\n1. Try to use 2.0 codes and avoid \"compat.v1\".\r\n2. Try to not introduce cross-directory dependency in the training code. I think it would be easier for external users adopting those examples, as they don't need to understand hierarchical code structures or non-core utils.\r\n3. Try to adopt best practice for simple training -- dataset, keras and dist_strat.\r\n4. Try to use APIs only in tf.data, tf.keras and tf.distribute.\r\n\r\nAs a result, the code looks less \"engineered\". I'm not very sure if the principles are correct. Opening the Draft PR for discussing before I go too far.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 2215,
        "deletions": 727,
        "changed_files": 34,
        "created_at": "2019-02-20T03:28:10Z",
        "closed_at": "2019-02-24T02:51:40Z",
        "merged_at": "2019-02-24T02:51:40Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-02-19T03:37:43Z",
        "closed_at": "2019-02-21T06:25:25Z",
        "merged_at": null,
        "body": "Rename detection_inference.py from deetection_inference",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-02-17T23:25:48Z",
        "closed_at": "2020-04-24T07:07:12Z",
        "merged_at": null,
        "body": "In the loop for initializing writers, Flags.output_shards is being used even though output_shards is passed as a parameter to the function \"convert_data()\".",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 8,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-02-17T15:40:04Z",
        "closed_at": "2019-02-21T06:17:54Z",
        "merged_at": null,
        "body": "  - added `setup.py` step to g3doc/installation.md\r\n  - credit to @DanMossa for the fix",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 45,
        "deletions": 24,
        "changed_files": 3,
        "created_at": "2019-02-17T04:13:21Z",
        "closed_at": "2019-02-22T01:35:51Z",
        "merged_at": "2019-02-22T01:35:51Z",
        "body": "Currently the benchmark class harcodes the path to the dataset, e.g. /data/imagenet for imagenet benchmark. This may not always work since sometimes the dataset may not be under directory `/data`.\r\n\r\nThis patch adds optional parameter to the constructor of these benchmark classes so that user can specify a directory other than `/data` for dataset.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 12,
        "changed_files": 2,
        "created_at": "2019-02-17T02:14:02Z",
        "closed_at": "2019-02-19T06:31:46Z",
        "merged_at": "2019-02-19T06:31:46Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 123,
        "deletions": 51,
        "changed_files": 3,
        "created_at": "2019-02-15T01:34:39Z",
        "closed_at": "2019-02-21T21:59:55Z",
        "merged_at": "2019-02-21T21:59:55Z",
        "body": "This change adds support for running on multiple workers using `CollectiveAllReduceStrategy`.  It adds 2 flags to `resnet_run_loop.py`: `worker_hosts` and `task_index`.  These flags provide information to each worker about peers in the multi-worker setup.\r\n\r\nAfter this change, when the official resnet model runs with `tf.contrib.distribute.CollectiveAllReduceStrategy,` it uses `tf.estimator.train_and_evaluate` rather than separate `train` and `evaluate` calls.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-02-14T22:55:21Z",
        "closed_at": "2019-02-15T00:43:49Z",
        "merged_at": "2019-02-15T00:43:49Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2019-02-14T19:56:59Z",
        "closed_at": "2019-02-14T21:52:59Z",
        "merged_at": "2019-02-14T21:52:59Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 17,
        "changed_files": 1,
        "created_at": "2019-02-14T18:15:28Z",
        "closed_at": "2019-02-14T19:49:07Z",
        "merged_at": "2019-02-14T19:49:07Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-02-14T04:34:15Z",
        "closed_at": "2019-02-21T06:15:37Z",
        "merged_at": "2019-02-21T06:15:37Z",
        "body": "This file was inadvertantly renamed in #6071.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-02-14T00:57:03Z",
        "closed_at": "2019-02-14T04:27:56Z",
        "merged_at": "2019-02-14T04:27:56Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-02-14T00:09:39Z",
        "closed_at": "2019-02-14T01:33:44Z",
        "merged_at": "2019-02-14T01:33:44Z",
        "body": "One device from contrib to core.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2019-02-13T19:06:54Z",
        "closed_at": "2019-02-14T01:11:50Z",
        "merged_at": "2019-02-14T01:11:50Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 38,
        "deletions": 9,
        "changed_files": 3,
        "created_at": "2019-02-13T04:57:06Z",
        "closed_at": "2019-02-14T01:34:31Z",
        "merged_at": "2019-02-14T01:34:31Z",
        "body": "Keep in mind this will be \"dead code\" at some point soon.  I did not want to rework it to track the time like we do for the keras hook.  I just wanted an approximation of average examples_per_second minus a small warmup.  I am not too worried about a perfect test, but if I want to make it better I can share the log_steps from keras with this in the future.  \r\n\r\nAdding this will also allow me to add short estimator tests.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 2,
        "changed_files": 3,
        "created_at": "2019-02-12T05:41:01Z",
        "closed_at": "2019-02-13T23:45:20Z",
        "merged_at": "2019-02-13T23:45:20Z",
        "body": "As discussed.  Open to changes.  Things look different when done vs. verbally discussing.  This really is not a big deal as the the tests for eager all set eager=True.  What this does is ensure a user that uses the code will not end up running a weird code path with tf.enable.eager=False.  And in a month or so I will remove this If all together.  Once tf 2.0 performance matches tf 1.0 eager and we feel good about it we can kind of shutdown tf 1.0 testing of keras or make branch until tf 1.0 is done.\r\n\r\nI have no idea how this works internally, e.g. how do know you are running TF 2.0?  ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-02-12T01:38:54Z",
        "closed_at": "2019-02-12T05:30:14Z",
        "merged_at": "2019-02-12T05:30:14Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 102,
        "deletions": 56,
        "changed_files": 11,
        "created_at": "2019-02-12T01:27:35Z",
        "closed_at": "2019-02-13T07:16:57Z",
        "merged_at": "2019-02-13T07:16:57Z",
        "body": "",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 28,
        "deletions": 18,
        "changed_files": 1,
        "created_at": "2019-02-11T18:45:23Z",
        "closed_at": "2019-02-12T02:15:40Z",
        "merged_at": "2019-02-12T02:15:40Z",
        "body": "Fixes issues that contrib is used to remove the monkey patch.  If running no_dist_strat this is not needed and prevents V2 tests from running.  We knew the \"patch\" would have issues and is a temporary thing anyway.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2019-02-09T21:52:18Z",
        "closed_at": "2019-02-12T02:05:24Z",
        "merged_at": "2019-02-12T02:05:24Z",
        "body": "- Modest speedup for CIFAR-10\r\n- Slightly greater speedup expected for ImageNet ResNet50.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 6,
        "changed_files": 2,
        "created_at": "2019-02-09T21:51:51Z",
        "closed_at": "2019-02-11T08:56:11Z",
        "merged_at": "2019-02-11T08:56:11Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 29,
        "deletions": 23,
        "changed_files": 6,
        "created_at": "2019-02-09T03:37:28Z",
        "closed_at": "2019-02-11T20:29:56Z",
        "merged_at": "2019-02-11T20:29:56Z",
        "body": "Use tf.data.options which will work with TF 2.0.  This is the last hurdle to get some basic TF 2.0 tests running.  OneDeviceStrategy will then unlock other options.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 78,
        "deletions": 1,
        "changed_files": 4,
        "created_at": "2019-02-08T22:37:53Z",
        "closed_at": "2019-02-09T01:03:44Z",
        "merged_at": "2019-02-09T01:03:44Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 266,
        "deletions": 251,
        "changed_files": 34,
        "created_at": "2019-02-07T22:11:00Z",
        "closed_at": "2019-02-08T17:20:58Z",
        "merged_at": "2019-02-08T17:20:58Z",
        "body": "\u2026#6162)\"\r\n\r\nThis reverts commit 57e075203f8fba8d85e6b74f17f63d0a07da233a.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 41,
        "deletions": 8,
        "changed_files": 7,
        "created_at": "2019-02-05T20:19:41Z",
        "closed_at": "2020-03-11T22:36:16Z",
        "merged_at": null,
        "body": "...and added a cached_real_data option to that flag. ",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 14,
        "deletions": 5,
        "changed_files": 3,
        "created_at": "2019-02-05T19:29:40Z",
        "closed_at": "2019-03-21T20:29:49Z",
        "merged_at": null,
        "body": "",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 22,
        "deletions": 9,
        "changed_files": 3,
        "created_at": "2019-02-05T17:19:00Z",
        "closed_at": "2020-03-12T08:59:33Z",
        "merged_at": null,
        "body": "These fixes have been tested with Pascal VOC evaluation and MS COCO evaluation.\r\n\r\nFixes #3252 and #5369 among others.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 266,
        "deletions": 251,
        "changed_files": 34,
        "created_at": "2019-02-04T21:57:30Z",
        "closed_at": "2019-02-05T15:54:05Z",
        "merged_at": "2019-02-05T15:54:05Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-02-04T08:44:44Z",
        "closed_at": "2020-04-24T07:25:03Z",
        "merged_at": null,
        "body": "The `inference.py` expects arg as `kitti_video`",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 453,
        "deletions": 312,
        "changed_files": 43,
        "created_at": "2019-02-04T01:31:45Z",
        "closed_at": "2019-02-12T01:20:00Z",
        "merged_at": null,
        "body": "",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 19,
        "deletions": 7,
        "changed_files": 2,
        "created_at": "2019-02-03T04:09:04Z",
        "closed_at": "2019-02-12T15:53:11Z",
        "merged_at": "2019-02-12T15:53:11Z",
        "body": "- Failure only occurs when all 1_gpu tests are run\r\ntogether with the error:\r\ntensorflow.python.framework.errors_impl.NotFoundError:\r\nResource localhost/logdir:/tmp/cifar10_model/\r\nN10tensorflow22SummaryWriterInterfaceE does not exist.\r\n[Op:WriteScalarSummary] name: epoch_loss/\r\n\r\nAnother fix might be to generate a different model_dir\r\nin the core code, but that has other draw backs such as\r\nrestarting from the checkpoint.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 130,
        "deletions": 8,
        "changed_files": 8,
        "created_at": "2019-02-01T21:50:08Z",
        "closed_at": "2019-10-09T21:44:52Z",
        "merged_at": "2019-10-09T21:44:52Z",
        "body": "CombinedNMS op was recently added to TensorFlow.\r\nhttps://github.com/tensorflow/tensorflow/pull/23567\r\n\r\nThis PR adds CombinedNMS to the object detection API in TensorFlow.\r\n\r\nThe main difference between this new op and the old ones is that it does all of NMS in one op.\r\nIt's much more efficient, and it's also easier to swap out with a more efficient version of it from TF custom backends such as TensorRT and XLA.",
        "comments": 11
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-02-01T16:42:13Z",
        "closed_at": "2019-02-01T18:06:33Z",
        "merged_at": "2019-02-01T18:06:33Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 143,
        "deletions": 48,
        "changed_files": 1,
        "created_at": "2019-01-31T22:55:37Z",
        "closed_at": "2019-02-01T02:36:43Z",
        "merged_at": "2019-02-01T02:36:43Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-01-31T19:51:38Z",
        "closed_at": "2019-02-01T16:45:02Z",
        "merged_at": "2019-02-01T16:45:02Z",
        "body": "Now if you run the README as-is it will work.  I made the default data_dir go deeper into the directory structure.  If a user does their own --data_dir there will still be a mismatch but this will improve the situation for anyone just running the command which I believe is the most normal.\r\n\r\nThe final fix would be to have download_and_extract move the data up a folder.  \r\n\r\nThis problem was created to fix tests in borg where the cifar-10 dataset is not nested under `cifar-10-batches-bin`.  Maybe that was a mistake, I don't think so but... shrug...open to opinion.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 18,
        "changed_files": 4,
        "created_at": "2019-01-31T06:22:52Z",
        "closed_at": "2019-02-01T00:04:23Z",
        "merged_at": "2019-02-01T00:04:23Z",
        "body": "Switch from using tf.contrib.distribute.MirroredStrategy to tf.distribute.MirroredStrategy.\r\n\r\ntf.distribute.MirroredStrategy when used with keras takes input with global batch size so change that as well.\r\nOneDeviceStrategy etc will be changed once they are exposed in core TF. \r\n\r\nPerformance for Resnet50 is seen to drop with this change due to the input change. Working on tuning the input pipeline to get close to the original performance. ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2019-01-31T04:57:49Z",
        "closed_at": "2019-02-01T18:39:05Z",
        "merged_at": "2019-02-01T18:39:05Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-01-31T01:28:45Z",
        "closed_at": "2019-02-02T14:46:27Z",
        "merged_at": "2019-02-02T14:46:27Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 217,
        "deletions": 217,
        "changed_files": 35,
        "created_at": "2019-01-31T00:37:16Z",
        "closed_at": "2019-02-04T20:20:43Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2019-01-28T22:33:48Z",
        "closed_at": "2019-01-30T00:10:48Z",
        "merged_at": "2019-01-30T00:10:48Z",
        "body": "1. Explicitly allow for script execution from any directory.  \r\n2. Make envars visible in python script.\r\n\r\nThese issues were encountered while launching on TPU.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 207,
        "deletions": 125,
        "changed_files": 4,
        "created_at": "2019-01-28T09:53:35Z",
        "closed_at": "2019-02-01T23:07:40Z",
        "merged_at": "2019-02-01T23:07:40Z",
        "body": "This patch is needed for benchmark classes defined in EstimatorCifar10BenchmarkTests to be executed by PerfZero benchmark harness after we merge https://github.com/tensorflow/benchmarks/pull/292.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 268,
        "deletions": 87,
        "changed_files": 2,
        "created_at": "2019-01-27T16:07:32Z",
        "closed_at": "2019-01-31T19:14:48Z",
        "merged_at": "2019-01-31T19:14:48Z",
        "body": "- created base benchmark module\r\n- renamed accuracy test class to contain the word Accuracy\r\nwhich will result in a need to update all the jobs\r\nand a loss of history but is worth it.\r\n- short tests are mostly copied from shining with oss refactor",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-01-26T11:05:55Z",
        "closed_at": "2022-04-06T05:04:43Z",
        "merged_at": null,
        "body": "Logging reports that extra conv layers are added but that lies on a condition afterwards creating a wrong impression to anyone reading the logging",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-01-25T23:36:33Z",
        "closed_at": "2019-01-26T22:01:44Z",
        "merged_at": "2019-01-26T22:01:44Z",
        "body": "1. Clarify instructions to avoid friction. https://github.com/tensorflow/tensorflow/issues/24136\r\n2. If trying to run in Colab experienced issue entering Python path. https://medium.com/@cwcgchello/how-to-set-pythonpath-in-colab-bf8c239c7c29",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 0,
        "changed_files": 18,
        "created_at": "2019-01-25T17:47:55Z",
        "closed_at": "2020-04-25T04:04:37Z",
        "merged_at": "2020-04-25T04:04:37Z",
        "body": "Remove byte-compiled files from the repo.\r\n\r\nBy the way: `__pycache__/` is already added to `.gitignore`, so those `*.pyc` files must have been force added by mistake.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-01-25T05:30:19Z",
        "closed_at": "2020-09-19T00:11:36Z",
        "merged_at": "2020-09-19T00:11:36Z",
        "body": "Currently, a variable named base_name is not defined.\r\nSo, occur error while extract from downloaded model file.\r\n\r\nSigned-off-by: MyungSung Kwak <yesmung@gmail.com>",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 594,
        "deletions": 239,
        "changed_files": 11,
        "created_at": "2019-01-24T00:51:03Z",
        "closed_at": "2019-03-01T23:00:00Z",
        "merged_at": "2019-03-01T23:00:00Z",
        "body": "Made a keras implementation of the NCF model. Extract some common code used by both Keras and Estimator into the ncf_common.py file. \r\n\r\nThe command I used to run the keras code:\r\n```\r\npython ncf_keras_main.py \\\r\n--model_dir \"/tmp/model_dir/ncf/\" \\\r\n--data_dir \"/data/movielens_data\" \\\r\n--dataset \"ml-20m\" \\\r\n--hooks \"\" \\\r\n--num_gpus 1 \\\r\n--clean \\\r\n--train_epochs 14 \\\r\n--batch_size 160000 \\\r\n--learning_rate 0.00382059 \\\r\n--beta1 0.783529 \\\r\n--beta2 0.909003 \\\r\n--epsilon 1.45439e-07 \\\r\n--layers 256,256,128,64 \\\r\n--num_factors 64 \\\r\n--hr_threshold 0.635 \\\r\n--ml_perf\r\n```\r\n\r\nTodo:\r\n1. TPU support. (Not necessarily in this PR or by me)\r\n2. Distribution strategy support. \r\n\r\nUpdate: the model does not converge with DS, and I have not been able to find out why. \r\nThis PR is going to focus on non-DS versino. ",
        "comments": 9
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2019-01-23T18:35:45Z",
        "closed_at": "2020-04-24T05:25:19Z",
        "merged_at": null,
        "body": "In reading the documentation, I found a reference to the [original name](https://arxiv.org/abs/1711.06798v1) of the paper and a typo regarding rank of a Tensor.\r\n\r\nThese are minor changes, but will prevent any confusion of future readers",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2019-01-22T22:38:49Z",
        "closed_at": "2019-04-19T14:15:20Z",
        "merged_at": null,
        "body": "Quoting the README in `models/research/slim`: **ResNet V2 models use Inception pre-processing and input image size of 299 (use `--preprocessing_name inception --eval_image_size 299` when using `eval_image_classifier.py`).**\r\n\r\nThe file `preprocessing_factory.py` should then link `resnet_v2_*` models to `inception_preprocessing` and not `vgg_preprocessing`.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 0,
        "changed_files": 0,
        "created_at": "2019-01-21T11:11:22Z",
        "closed_at": "2019-10-28T21:10:38Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1282,
        "deletions": 0,
        "changed_files": 17,
        "created_at": "2019-01-21T09:17:13Z",
        "closed_at": "2019-01-22T02:59:43Z",
        "merged_at": null,
        "body": "A model on SSD for object detection using Pytorch",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 34,
        "deletions": 0,
        "changed_files": 5,
        "created_at": "2019-01-21T01:18:14Z",
        "closed_at": "2019-02-14T01:36:10Z",
        "merged_at": null,
        "body": "* Adding `--validation_freq` and `--validarion_freq_list` flags, which take an integer and a list of comma separated integers, to specify at which epochs to invoke validation during training.\r\n* Reduce the validation frequency of eager benchmarks tests (for both imagenet and cifar10). This is a temporary fix due to b/122886254.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-01-21T00:36:23Z",
        "closed_at": "2019-02-11T04:06:29Z",
        "merged_at": "2019-02-11T04:06:29Z",
        "body": "As discussed here: https://github.com/tensorflow/tensorflow/issues/11312, this change allows this script to work in Python 3.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-01-17T07:53:09Z",
        "closed_at": "2019-01-19T00:24:49Z",
        "merged_at": "2019-01-19T00:24:49Z",
        "body": "This file was re-located below the tensorflow/lite/g3doc/convert\r\n\r\nSigned-off-by: MyungSung Kwak <yesmung@gmail.com>",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1492,
        "deletions": 20,
        "changed_files": 10,
        "created_at": "2019-01-17T03:28:42Z",
        "closed_at": "2019-01-17T07:06:21Z",
        "merged_at": "2019-01-17T07:06:21Z",
        "body": "228203246  by Sergio Guadarrama:\r\n\r\n    Add a write text graphdef option.\r\n\r\n--\r\n226110161  by Sergio Guadarrama:\r\n\r\n    Add license to i3d/s3dg and tests.\r\n\r\n--\r\n226074013  by Sergio Guadarrama:\r\n\r\n    Network definitions for I3D and S3D-G.\r\n\r\n--\r\n224394404  by Sergio Guadarrama:\r\n\r\n    Add video model option for exported inference graphs.\r\n\r\n--\r\n224220779  by Sergio Guadarrama:\r\n\r\n    Internal change\r\n\r\n223589268  by Sergio Guadarrama:\r\n\r\n    Internal change\r\n\r\nPiperOrigin-RevId: 228203246",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-01-16T23:44:48Z",
        "closed_at": "2019-01-17T14:56:42Z",
        "merged_at": "2019-01-17T14:56:42Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 344,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2019-01-16T18:55:42Z",
        "closed_at": "2020-04-24T06:58:07Z",
        "merged_at": null,
        "body": "#### Fix for issue no. #5976: Hassle free own data input to Transformer\r\n\r\nCreated a script to pre-process own data to train the transformer model on. Updated the README with the instructions on how to use it. ",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 24,
        "deletions": 17,
        "changed_files": 3,
        "created_at": "2019-01-16T18:38:57Z",
        "closed_at": "2019-01-16T23:27:24Z",
        "merged_at": "2019-01-16T23:27:24Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 505,
        "deletions": 218,
        "changed_files": 11,
        "created_at": "2019-01-15T05:00:24Z",
        "closed_at": "2020-04-24T04:57:06Z",
        "merged_at": null,
        "body": "Hello.\r\nWhen I run data util, it shows that\r\nCommand 'git clone https://github.com/brendenlake/omniglot.git' returned non-zero exit status 1.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-01-15T02:58:40Z",
        "closed_at": "2019-01-15T18:24:55Z",
        "merged_at": "2019-01-15T18:24:54Z",
        "body": "It currently fails with\r\nTypeError: not all arguments converted during string formatting",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-01-14T22:18:34Z",
        "closed_at": "2020-04-24T04:48:19Z",
        "merged_at": null,
        "body": "This will help to know more about Tensorflow.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 5412,
        "changed_files": 31,
        "created_at": "2019-01-14T21:06:04Z",
        "closed_at": "2019-01-15T02:16:03Z",
        "merged_at": "2019-01-15T02:16:03Z",
        "body": "**This should only be merged after the corresponding code has been successfully pushed to tensorflow/privacy. **",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 48,
        "deletions": 8,
        "changed_files": 2,
        "created_at": "2019-01-12T22:10:10Z",
        "closed_at": "2019-01-15T02:49:36Z",
        "merged_at": "2019-01-15T02:49:36Z",
        "body": "- Add Eager for Imagenet.\r\n- Add 2 GPU tests instead of 4 for ResNet56.\r\n- Add pass fail for Keras tests based on accuracy.\r\n\r\nNext PRs will likely create a base class to hold pass/fail logic and add tracking of average examples per second.  ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2019-01-12T07:32:36Z",
        "closed_at": "2019-01-14T18:36:27Z",
        "merged_at": "2019-01-14T18:36:27Z",
        "body": "Changes in Tensorflow contrib:\r\nhttps://github.com/tensorflow/tensorflow/commit/304faf0444260912b6996d39227417c09561c37e\r\n\r\nCauses tensortt.py to fail. \r\n\r\nExample:\r\n```\r\npython research/tensorrt/tensorrt.py \\\r\n--savedmodel_dir=$WORKDIR/resnet_v2_fp32_savedmodel_NCHW/1538687196/ \\\r\n--image_file=$WORKDIR/image.jpg \\\r\n--native --fp32 --fp16 --int8 \\\r\n--output_dir=$WORKDIR\r\n```\r\nError:\r\n```\r\nAttributeError: 'module' object has no attribute 'get_signature_def_by_key'\r\n```\r\n\r\nSolution:\r\n\r\nReplace `tf.contrib.saved_model.get_signature_def_by_key` with `meta_graph_def.signature_def`",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 16,
        "deletions": 11,
        "changed_files": 1,
        "created_at": "2019-01-12T01:42:39Z",
        "closed_at": "2019-01-12T20:57:39Z",
        "merged_at": "2019-01-12T20:57:39Z",
        "body": "I think this does what we need and I added returning the average although in most tests we would want to skip the first timestamp as a warmup. \r\n\r\nTake your time looking this over and thinking about if it works for you.  I think this works and it is as numerically correct as we can get.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2019-01-11T21:36:47Z",
        "closed_at": "2019-01-11T23:16:41Z",
        "merged_at": "2019-01-11T23:16:41Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2019-01-11T05:22:53Z",
        "closed_at": "2019-01-11T16:59:00Z",
        "merged_at": "2019-01-11T16:59:00Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 93,
        "deletions": 15,
        "changed_files": 2,
        "created_at": "2019-01-10T22:43:28Z",
        "closed_at": "2019-01-11T00:51:00Z",
        "merged_at": "2019-01-11T00:51:00Z",
        "body": "- using batch-size 64 because nightly binaries might be before your fix?\r\n- Will look at issues related to the unit tests that you commented on in the other thread before I finish this one.  ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 84,
        "deletions": 16,
        "changed_files": 4,
        "created_at": "2019-01-10T21:30:48Z",
        "closed_at": "2019-01-11T04:14:47Z",
        "merged_at": "2019-01-11T04:14:47Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 106,
        "deletions": 2,
        "changed_files": 3,
        "created_at": "2019-01-10T17:49:16Z",
        "closed_at": "2019-01-11T00:07:23Z",
        "merged_at": "2019-01-11T00:07:23Z",
        "body": "Adds end-to-end accuracy tests for cifar-10 estimator model.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 19,
        "deletions": 18,
        "changed_files": 3,
        "created_at": "2019-01-09T19:02:21Z",
        "closed_at": "2019-01-10T00:18:11Z",
        "merged_at": "2019-01-10T00:18:11Z",
        "body": "According to official ResNet model, we should not use bias in Conv2D layers. This also helps remove BiasAdd ops in all layers, which end up with a 8% throughput gain. Convergence tests show that the model still converges well.\r\n\r\n```\r\n... ...\r\nEpoch 60/90 - val_loss: 1.9972 - val_sparse_categorical_accuracy: 0.6598\r\nEpoch 61/90 - val_loss: 1.6311 - val_sparse_categorical_accuracy: 0.7411\r\nEpoch 62/90 - val_loss: 1.6008 - val_sparse_categorical_accuracy: 0.7464\r\nEpoch 63/90 - val_loss: 1.5808 - val_sparse_categorical_accuracy: 0.7496\r\nEpoch 64/90 - val_loss: 1.5623 - val_sparse_categorical_accuracy: 0.7503\r\nEpoch 65/90 - val_loss: 1.5507 - val_sparse_categorical_accuracy: 0.7504\r\nEpoch 66/90 - val_loss: 1.5401 - val_sparse_categorical_accuracy: 0.7528\r\nEpoch 67/90 - val_loss: 1.5228 - val_sparse_categorical_accuracy: 0.7538\r\nEpoch 68/90 - val_loss: 1.5150 - val_sparse_categorical_accuracy: 0.7543\r\nEpoch 69/90 - val_loss: 1.5072 - val_sparse_categorical_accuracy: 0.7548\r\nEpoch 70/90 - val_loss: 1.4974 - val_sparse_categorical_accuracy: 0.7549\r\nEpoch 71/90 - val_loss: 1.4883 - val_sparse_categorical_accuracy: 0.7549\r\nEpoch 72/90 - val_loss: 1.4793 - val_sparse_categorical_accuracy: 0.7556\r\nEpoch 73/90 - val_loss: 1.4707 - val_sparse_categorical_accuracy: 0.7559\r\nEpoch 74/90 - val_loss: 1.4638 - val_sparse_categorical_accuracy: 0.7569\r\nEpoch 75/90 - val_loss: 1.4606 - val_sparse_categorical_accuracy: 0.7567\r\nEpoch 76/90 - val_loss: 1.4469 - val_sparse_categorical_accuracy: 0.7563\r\nEpoch 77/90 - val_loss: 1.4419 - val_sparse_categorical_accuracy: 0.7564\r\nEpoch 78/90 - val_loss: 1.4358 - val_sparse_categorical_accuracy: 0.7580\r\nEpoch 79/90 - val_loss: 1.4297 - val_sparse_categorical_accuracy: 0.7567\r\nEpoch 80/90 - val_loss: 1.4250 - val_sparse_categorical_accuracy: 0.7573\r\nEpoch 81/90 - val_loss: 1.4017 - val_sparse_categorical_accuracy: 0.7618\r\nEpoch 82/90 - val_loss: 1.3985 - val_sparse_categorical_accuracy: 0.7632\r\nEpoch 83/90 - val_loss: 1.3963 - val_sparse_categorical_accuracy: 0.7636\r\nEpoch 84/90 - val_loss: 1.3950 - val_sparse_categorical_accuracy: 0.7632\r\nEpoch 85/90 - val_loss: 1.3930 - val_sparse_categorical_accuracy: 0.7644\r\nEpoch 86/90 - val_loss: 1.3927 - val_sparse_categorical_accuracy: 0.7630\r\nEpoch 87/90 - val_loss: 1.3912 - val_sparse_categorical_accuracy: 0.7647\r\nEpoch 88/90 - val_loss: 1.3895 - val_sparse_categorical_accuracy: 0.7650\r\nEpoch 89/90 - val_loss: 1.3892 - val_sparse_categorical_accuracy: 0.7644\r\nEpoch 90/90 - val_loss: 1.3882 - val_sparse_categorical_accuracy: 0.7658\r\n```",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-01-09T11:30:42Z",
        "closed_at": "2019-01-11T17:37:48Z",
        "merged_at": null,
        "body": "INITIAL_DIR variable is unuseful if the synsets file is not specified using a parameter because it is in the same directory as the running script, anyway probably the synsets parameter is always specified with its path and the INITIAL_DIR variable causes the script to point to a wrong non existent path.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-01-09T11:18:39Z",
        "closed_at": "2019-01-11T17:38:17Z",
        "merged_at": "2019-01-11T17:38:17Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-01-09T11:16:15Z",
        "closed_at": "2019-01-11T17:38:12Z",
        "merged_at": "2019-01-11T17:38:12Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 24,
        "deletions": 11,
        "changed_files": 4,
        "created_at": "2019-01-08T18:40:50Z",
        "closed_at": "2019-01-09T18:14:16Z",
        "merged_at": "2019-01-09T18:14:16Z",
        "body": "1. When `data_format` is `channels_first`, transpose the input tensors to `NCHW` for better performance on GPU;\r\n2. Compile only the training graph when `skip_eval` flag is `True`. This allows better memory efficiency so that a larger (per-GPU) batch size can be used for training.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-01-08T09:26:08Z",
        "closed_at": "2019-02-10T05:53:22Z",
        "merged_at": "2019-02-10T05:53:22Z",
        "body": "As https://github.com/tensorflow/models/issues/5059#issuecomment-451654039 suggested, num_examples is deprecated, however, when setting run_once flag in new evaluation script, it would raise parameter not found error. Therefore, this PR has fix it.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 95,
        "deletions": 15,
        "changed_files": 3,
        "created_at": "2019-01-08T08:55:12Z",
        "closed_at": "2019-05-22T18:55:25Z",
        "merged_at": null,
        "body": "Create a unit test for Keras application models in TF 2.0. (Named models_v2_test.py)\r\n\r\nMinor: move the shared model definition in models.py.\r\n\r\nTested in tf-nightly-2.0-preview. \r\n$ python official/keras_application_models/models_v2_test.py",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2019-01-08T01:05:10Z",
        "closed_at": "2019-01-08T17:51:26Z",
        "merged_at": null,
        "body": "I'm seeing mysterious SIGABRT's and this is a scratch space for running presubmits to debug them.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-01-07T07:55:24Z",
        "closed_at": "2020-04-25T23:36:02Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2019-01-07T05:38:33Z",
        "closed_at": "2019-01-07T07:15:10Z",
        "merged_at": "2019-01-07T07:15:10Z",
        "body": "This change is to add repeat() to datasets to avoid exhausting data in training and validation.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 2879,
        "changed_files": 16,
        "created_at": "2019-01-04T10:54:25Z",
        "closed_at": "2019-01-04T17:47:48Z",
        "merged_at": "2019-01-04T17:47:48Z",
        "body": "A lot of the code that used to be in models/research/differential_privacy was improved and migrated to a new repository at tensorflow/privacy. This PR removes the old code to avoid any confusions.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-01-04T05:06:09Z",
        "closed_at": "2019-01-04T06:32:50Z",
        "merged_at": "2019-01-04T06:32:50Z",
        "body": "Fixes the variable name for the tf proto example function.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-01-04T00:13:00Z",
        "closed_at": "2019-01-07T19:17:33Z",
        "merged_at": "2019-01-07T19:17:33Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 35,
        "deletions": 12,
        "changed_files": 3,
        "created_at": "2019-01-03T21:46:21Z",
        "closed_at": "2019-01-04T00:02:39Z",
        "merged_at": "2019-01-04T00:02:39Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2019-01-03T18:45:36Z",
        "closed_at": "2020-04-24T06:34:09Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2019-01-02T04:01:03Z",
        "closed_at": "2019-01-07T21:07:53Z",
        "merged_at": "2019-01-07T21:07:53Z",
        "body": "Fix a Python3 incompatibility error in model_lib.py.\r\n\r\nThanks to @gfkeith https://github.com/tensorflow/models/issues/4780#issuecomment-405441448 and @MaeThird https://github.com/tensorflow/models/issues/4996#issuecomment-411970644.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-12-28T13:26:29Z",
        "closed_at": "2019-02-20T11:44:49Z",
        "merged_at": null,
        "body": "It may be 'crop', not 'cropt'.\r\n--by a OCD patient:)",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-12-27T23:26:38Z",
        "closed_at": "2018-12-28T01:22:42Z",
        "merged_at": "2018-12-28T01:22:42Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-12-25T07:32:46Z",
        "closed_at": "2020-04-24T15:30:30Z",
        "merged_at": null,
        "body": "it would raise this ValueEroor when n = max_size \r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py\", line 757, in argpartition\r\n    return _wrapfunc(a, 'argpartition', kth, axis=axis, kind=kind, order=order)\r\n  File \"/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py\", line 51, in _wrapfunc\r\n    return getattr(obj, method)(*args, **kwds)\r\nValueError: kth(=10) out of bounds (10)\r\n```",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-12-24T03:47:17Z",
        "closed_at": "2021-12-16T00:23:43Z",
        "merged_at": null,
        "body": "absl.flags validation happens at tf.app.run(). See https://github.com/abseil/abseil-py/blob/master/absl/flags/_validators.py#L329\r\n\r\nThe flags validator was not working in the previous code, and the error message would be \"TypeError: Expected binary or unicode string, got None\" when required flags were not correctly provided in arguments, which is not very helpful for debugging.\r\nAfter the modification, the error message will be like \"absl.flags._exceptions.IllegalFlagValueError: flag --pipeline_config_path=None: Flag --pipeline_config_path must be specified\".",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-12-21T20:16:11Z",
        "closed_at": "2021-07-15T18:50:11Z",
        "merged_at": null,
        "body": "Added a link to the using_your_own_dataset instructions.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 44,
        "deletions": 36,
        "changed_files": 5,
        "created_at": "2018-12-21T11:26:07Z",
        "closed_at": "2019-09-13T07:29:31Z",
        "merged_at": null,
        "body": "Python 3 treats legacy __print__ statements as syntax errors but __print()__ function works as expected in both Python 2 and Python 3.\r\n* __xrange()__ --> __six.moves.xrange()__  # https://six.readthedocs.io\r\n* __raw_input()__ --> __six.moves.input()__\r\n* import logging\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 15,
        "deletions": 6,
        "changed_files": 2,
        "created_at": "2018-12-18T22:15:31Z",
        "closed_at": "2022-03-28T03:46:39Z",
        "merged_at": null,
        "body": "fixed unicode category_name for compatibility with python 3.x\r\nfixed bug where `groundtruth_dict[standard_fields.InputDataFields.groundtruth_group_of]` of NoneType would throw an error in the if statement",
        "comments": 8
    },
    {
        "merged": false,
        "additions": 10,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2018-12-18T19:39:59Z",
        "closed_at": "2020-04-25T23:56:12Z",
        "merged_at": null,
        "body": "When I read these instructions, I thought that the models/research directory was something that was located in my tensorflow directory that pip created. I did not realize that this repository had to be cloned. It seems that other people were confused by this as well: https://github.com/tensorflow/models/issues/2253\r\n\r\nI have updated the instructions to try to indicate that the models directory is the root of this repository, and not part of pip's TensorFlow installation.",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 11,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-12-18T19:35:42Z",
        "closed_at": "2018-12-19T02:23:21Z",
        "merged_at": null,
        "body": "I did not realize that the tensorflow/models repository had to be cloned and setup. It looks like other people also did not realize this: https://github.com/tensorflow/models/issues/2031#issuecomment-317999079\r\n\r\nThe readme files in models/ and models/research do not mention anything about this either. Therefore, I updated this repository to mention that these steps must be done.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1332,
        "deletions": 32,
        "changed_files": 12,
        "created_at": "2018-12-18T18:26:37Z",
        "closed_at": "2018-12-27T19:56:05Z",
        "merged_at": "2018-12-27T19:56:05Z",
        "body": "Extract common code from keras_cifar_main.py and keras_imagenet_main.py into keras_common.py. ",
        "comments": 11
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-12-18T02:29:33Z",
        "closed_at": "2019-01-04T04:15:52Z",
        "merged_at": "2019-01-04T04:15:52Z",
        "body": "",
        "comments": 8
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-12-18T00:44:58Z",
        "closed_at": "2020-04-24T06:35:39Z",
        "merged_at": null,
        "body": "Corrected typo in metavar=\"<IN>\"",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 96568,
        "deletions": 875021,
        "changed_files": 1614,
        "created_at": "2018-12-17T13:06:21Z",
        "closed_at": "2018-12-17T22:05:08Z",
        "merged_at": null,
        "body": "I have downloaded GD-Xray Casting dataset, the tota number of the dataset is 2727 that is the same as the paper. But I have found that just 842 images are of bounding box value, it is different from what the paper has mentioned. Do I loss some critical information?\r\nI am looking forward to your answer, Thanks!",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 55,
        "deletions": 256,
        "changed_files": 4,
        "created_at": "2018-12-13T15:05:01Z",
        "closed_at": "2019-04-22T18:47:05Z",
        "merged_at": "2019-04-22T18:47:05Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2018-12-12T07:51:23Z",
        "closed_at": "2018-12-12T17:52:29Z",
        "merged_at": "2018-12-12T17:52:28Z",
        "body": "In order to re-use the existing input pipeline with Keras, we need a slight modification of the parsed label. Allowing for a custom parse record method allows to plug that in. \r\n\r\nSee example usage in this branch:\r\nhttps://github.com/tensorflow/models/blob/cifar_keras/official/resnet/keras/keras_cifar_main.py#L238",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 4,
        "changed_files": 3,
        "created_at": "2018-12-11T10:29:42Z",
        "closed_at": "2019-07-30T18:14:10Z",
        "merged_at": "2019-07-30T18:14:10Z",
        "body": "Now, version comparison is performed in the following way.\r\n\r\n```python\r\n\"1.4\" <= tf_version\r\n```\r\n\r\nThis is problematic. For example, when `tf_version` is `1.10.1`, we would expect the above statement to return `True`. However, it will return `False` since it is using string comparison.\r\n\r\n```python\r\n>>> import tensorflow as tf\r\n>>> tf_version = tf.__version__\r\n>>> print(tf_version)\r\n1.10.1\r\n>>> \"1.4\" <= tf_version\r\nFalse\r\n```\r\n\r\nTo fix this bug, we need to use some version comparison packages for Python. And in `object_detection_tutorial.ipynb`, `distutils.version.StrictVersion` is used. So it is also used here to be consistent.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 34,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2018-12-11T07:45:56Z",
        "closed_at": "2018-12-19T23:47:51Z",
        "merged_at": "2018-12-19T23:47:51Z",
        "body": "Add CIFAR-10 for keras application models.\r\n\r\n- Add CIFAR-10 dataset to dataset.py;\r\n- Add custom keras model adapted with CIFAR-10 input_shape and num_classes;\r\n- Enable the test on CIFAR-10 when FLAGS.use_synthetic_dat is False.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 306,
        "deletions": 10,
        "changed_files": 3,
        "created_at": "2018-12-10T04:57:44Z",
        "closed_at": "2018-12-11T19:39:38Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 7760,
        "deletions": 171,
        "changed_files": 51,
        "created_at": "2018-12-05T14:14:10Z",
        "closed_at": "2018-12-06T20:17:50Z",
        "merged_at": "2018-12-06T20:17:50Z",
        "body": "Releasing the training and eval code for our recent HRL papers.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2018-12-03T00:47:05Z",
        "closed_at": "2018-12-20T00:47:59Z",
        "merged_at": "2018-12-20T00:47:59Z",
        "body": "1. `tf.contrib.data.batch_and_drop_remainder()` has been deprecated for a while now.\r\n2. `Dataset.make_one_shot_iterator()` is no longer necessary in input functions, and avoiding it lead to better performance on TPUs. (It will also be removed in TF 2.0.)",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-12-02T15:58:41Z",
        "closed_at": "2020-04-24T15:20:14Z",
        "merged_at": null,
        "body": "When I trained ResNet in FP16, it gave an error since some gradients' values are None and cannot be divided by the loss_scale. ",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 2732,
        "deletions": 1220,
        "changed_files": 66,
        "created_at": "2018-11-30T18:52:55Z",
        "closed_at": "2018-12-14T01:20:02Z",
        "merged_at": "2018-12-14T01:20:02Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-11-28T21:04:04Z",
        "closed_at": "2018-12-20T00:48:21Z",
        "merged_at": "2018-12-20T00:48:21Z",
        "body": "For tf2 this will only be available in `compat.v1`.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-11-28T19:17:22Z",
        "closed_at": "2020-04-24T04:56:18Z",
        "merged_at": null,
        "body": "Just adding `.vscode` to .gitignore.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-11-28T12:46:46Z",
        "closed_at": "2020-04-24T07:06:49Z",
        "merged_at": null,
        "body": "In line:33 and line:35, if `'\\n'` is replaced by '<eof>', the the `<eof>` will be concatenated with the word before it and after it.\r\n**for example:**\r\n>I would like\\n\r\n>Do you?\r\n\r\nAfter processed in this initial code, it would become `like<eof>Do`\r\nAnd this token makes no sense.\r\n\r\nSo I modify it to ' <eof> ' with two space before and after it.\r\nThen after being splited, the example mentioned above would be \r\n> I would like \\<eof\\> Do you",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-11-27T18:22:32Z",
        "closed_at": "2019-09-13T07:29:17Z",
        "merged_at": null,
        "body": "__unicode()__ was removed in Python 3 because all __str__ are Unicode.  This PR proposes using [__six.text_type__](https://six.readthedocs.io/#six.text_type) instead.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-11-27T16:34:58Z",
        "closed_at": "2019-09-13T07:29:00Z",
        "merged_at": null,
        "body": "@calberti @markomernick Can we please get your review on this simple change that is compatible with both Python 2 and Python 3.  This is a syntax error.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 10,
        "deletions": 9,
        "changed_files": 1,
        "created_at": "2018-11-27T16:29:56Z",
        "closed_at": "2019-09-13T07:28:46Z",
        "merged_at": null,
        "body": "@lukemetz",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1558,
        "deletions": 2276,
        "changed_files": 16,
        "created_at": "2018-11-20T01:53:16Z",
        "closed_at": "2019-01-08T22:38:10Z",
        "merged_at": "2019-01-08T22:38:10Z",
        "body": "Note: this PR still needs a fair bit of polish before it is ready to merge.\r\n\r\nMajor changes:\r\n1) Bring data generation back into the main process. (Though on a side thread.) `data_async_generation.py` has been removed, and `data_pipeline.py` is its spiritual successor.\r\n2) Materialize all negative examples at the start, and replace the per batch set exclusion Monte Carlo with random lookups. This approach does not scale as it requires a (num_users x num_items) matrix. I have a plan for larger datasets but it will not be in this PR.\r\n3) The last partial batch is now padded and masked instead of resampled.\r\n4) The pandas work at the start is now cached and invalidated on a daily basis. This is just a quality of life improvement, as it means that two minutes of waiting at the start goes away.\r\n5) I've updated the parameters in run.sh to use a larger batch size. 2k just isn't enough to keep an accelerator busy.\r\n\r\nPerformance:\r\n8-30 second startup cost to materialize the full (user x item matrix). (depending on machine)\r\n4-5 seconds to generate an epoch.\r\n\r\nUnfortunately a lot of these operations haven't threaded nearly as well as I expected that they should, so on large machines most of the cores are unused. Naive multiprocessing doesn't help, because you spend more time serializing and deserializing than you gain from the extra workers. The solution is likely going to be using `multiprocessing.sharedctypes.RawArray` and `np.frombuffer` to get around the multiprocessing pickling, but I haven't gotten a chance to do it yet. Not altogether terrible, but definitely lots of room for finesse.\r\n\r\nBreakages:\r\n1) Model runner. I'm considering removing it altogether.\r\n2) TPUs. I'm now using Dataset.from_generator, which I can't ship to a TPU. My plan is to write local files and us `StreamingFilesDataset`; putting TFRecords in GCS is probably not optimal going forward.\r\n3) Multi-GPU doesn't work with XLA for unknown reasons. (I haven't tested if this is also broken on TPUs)\r\n\r\nMy plan is to just live with the sub-optimal pipeline performance for this round, and focus on getting a baseline in. That should hopefully unblock Shining for his Keras work.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 3864,
        "deletions": 0,
        "changed_files": 15,
        "created_at": "2018-11-19T20:03:01Z",
        "closed_at": "2018-11-19T21:07:13Z",
        "merged_at": "2018-11-19T21:07:13Z",
        "body": "This is open source code for our AAAI paper: \r\nhttps://arxiv.org/abs/1811.06152\r\nPlease merge it.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-11-19T16:12:19Z",
        "closed_at": "2018-11-19T19:17:06Z",
        "merged_at": "2018-11-19T19:17:06Z",
        "body": "Casting predictions to float32 allows to schedule slice and resize operations on GPU, which reduces much memory copying between device and host.\r\n\r\nIn our case (xception65, 3328x3328 input size and GeForce RTX 2080Ti.) it decreased inference time by 32%.\r\n\r\nBelow screens from profiling.\r\nBefore:\r\n![before](https://user-images.githubusercontent.com/4547501/48719585-2b093d80-ec1e-11e8-92cc-ca94d8c9a3b4.png)\r\nAfter:\r\n![after](https://user-images.githubusercontent.com/4547501/48719584-2b093d80-ec1e-11e8-81dd-66cf26342d4a.png)\r\n\r\n\r\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2018-11-19T13:49:44Z",
        "closed_at": "2018-11-27T23:21:21Z",
        "merged_at": "2018-11-27T23:21:21Z",
        "body": "Line 219 runtime version updated to 1.9, current version of 1.8 will trigger 'TypeError: non_max_suppression() got an unexpected keyword argument 'score_threshold'' on the Google Cloud since 1.8 and older does not support this keyword argument.",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-11-19T05:39:02Z",
        "closed_at": "2018-11-21T00:58:42Z",
        "merged_at": "2018-11-21T00:58:42Z",
        "body": "We've deprecated the \"tower\" terminology in DistributionStrategy, so the \"cross_tower_ops\" argument is now \"cross_device_ops\", matching the current name of \"AllReduceCrossDeviceOps\".",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2018-11-19T05:24:45Z",
        "closed_at": "2018-11-21T00:59:15Z",
        "merged_at": "2018-11-21T00:59:15Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-11-17T14:26:05Z",
        "closed_at": "2020-04-26T00:01:28Z",
        "merged_at": "2020-04-26T00:01:28Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-11-17T14:04:42Z",
        "closed_at": "2018-11-17T18:51:43Z",
        "merged_at": "2018-11-17T18:51:43Z",
        "body": "Only fixed a broken link.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-11-14T19:28:29Z",
        "closed_at": "2018-12-20T00:38:48Z",
        "merged_at": "2018-12-20T00:38:48Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-11-14T06:12:49Z",
        "closed_at": "2018-11-14T21:50:43Z",
        "merged_at": "2018-11-14T21:50:43Z",
        "body": "`num_replicas` is being replaced by `num_replicas_in_sync` and something that returns the number of steps running concurrently.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2018-11-13T20:57:25Z",
        "closed_at": "2020-04-26T00:03:19Z",
        "merged_at": null,
        "body": "Fix the setup steps in `mobilenet_example.ipynb`.\r\n\r\n1. The existing Jupyter notebook interchangeably uses `base_name` and `checkpoint_name`, but `base_name` is never defined.\r\n\r\nThis leads to the vanilla setup to fail with `NameError`:\r\n<img width=\"922\" alt=\"screenshot 2018-11-13 13 07 12\" src=\"https://user-images.githubusercontent.com/1895508/48443272-63ec7280-e745-11e8-83d2-8b0833c46f71.png\">\r\n\r\nThis PR replaces all `base_name` references to `checkpoint_name`.\r\n\r\n2. Fix an incorrect `slim` path.\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2018-11-13T09:07:01Z",
        "closed_at": "2018-11-21T09:09:07Z",
        "merged_at": null,
        "body": "Cloud MLE Execution using TF 1.8 runtime results in this error, hence this PR upgrades the runtime into 1.9. I can successfully run the training using TF 1.9 runtime :)\r\n```\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/core/post_processing.py\", line 170, in multiclass_non_max_suppression\r\n    score_threshold=score_thresh)\r\nTypeError: non_max_suppression() got an unexpected keyword argument 'score_threshold'\r\n```\r\n\r\nExpand the details below for full error stack trace from Stackdriver:\r\n<details>\r\n```\r\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/model_main.py\", line 109, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 126, in run\r\n    _sys.exit(main(argv))\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/model_main.py\", line 105, in main\r\n    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 439, in train_and_evaluate\r\n    executor.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 546, in run\r\n    getattr(self, task_to_run)()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 556, in run_worker\r\n    return self._start_distributed_training()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 739, in _start_distributed_training\r\n    saving_listeners=saving_listeners)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 363, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 843, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 856, in _train_model_default\r\n    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 831, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/model_lib.py\", line 269, in model_fn\r\n    features[fields.InputDataFields.true_image_shape])\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/meta_architectures/faster_rcnn_meta_arch.py\", line 688, in predict\r\n    self._anchors.get(), image_shape, true_image_shapes))\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/meta_architectures/faster_rcnn_meta_arch.py\", line 775, in _predict_second_stage\r\n    anchors, image_shape_2d, true_image_shapes)\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/meta_architectures/faster_rcnn_meta_arch.py\", line 1285, in _postprocess_rpn\r\n    clip_window=clip_window)\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/core/post_processing.py\", line 478, in batch_multiclass_non_max_suppression\r\n    parallel_iterations=parallel_iterations)\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/utils/shape_utils.py\", line 228, in static_or_dynamic_map_fn\r\n    return tf.map_fn(fn, elems, dtype, parallel_iterations, back_prop)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/functional_ops.py\", line 423, in map_fn\r\n    swap_memory=swap_memory)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 3224, in while_loop\r\n    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2956, in BuildLoop\r\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2893, in _BuildLoop\r\n    body_result = body(*packed_vars_for_body)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/functional_ops.py\", line 413, in compute\r\n    packed_fn_values = fn(packed_values)\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/core/post_processing.py\", line 452, in _single_image_nms_fn\r\n    additional_fields=per_image_additional_fields)\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/core/post_processing.py\", line 170, in multiclass_non_max_suppression\r\n    score_threshold=score_thresh)\r\nTypeError: non_max_suppression() got an unexpected keyword argument 'score_threshold'\r\n\"   \r\n  pathname:  \"/var/sitecustomize/sitecustomize.py\"   \r\n```\r\n</details>",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-11-12T23:42:09Z",
        "closed_at": "2020-05-01T05:34:00Z",
        "merged_at": null,
        "body": "When loading weights for channel-scaled versions of mobilenet, such as `mobilenet_v2_0.75_224`, I get an error:\r\n\r\n`Assign requires shapes of both tensors to match. lhs shape= [1,1,240,960] rhs shape= [1,1,240,1280]`.\r\n\r\nThis seems to stem from the fact that the layer just prior to avgpool is supposed to always have no less than 1280 channels -- yet it is incorrectly scaled down to 960 instead when the mutiplier is .75.\r\n\r\nThis PR fixes the issue that mobilenets appear to work as expected.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-11-12T21:18:59Z",
        "closed_at": "2019-05-22T18:57:48Z",
        "merged_at": null,
        "body": "If these flags are not passed, a default value of 0 will be used.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-11-11T00:42:34Z",
        "closed_at": "2018-11-12T17:25:51Z",
        "merged_at": "2018-11-12T17:25:51Z",
        "body": "`lite` is no longer under `contrib`. \r\n\r\nAdditionally, `--config=opt` fails, see: https://github.com/tensorflow/serving/issues/517",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-11-10T19:55:46Z",
        "closed_at": "2020-04-26T00:09:56Z",
        "merged_at": null,
        "body": "Second last step to confirm correct installation for windows was missing.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 863,
        "deletions": 56,
        "changed_files": 9,
        "created_at": "2018-11-09T20:58:49Z",
        "closed_at": "2019-01-18T05:16:51Z",
        "merged_at": null,
        "body": "- Add a ResNet 1.5 Keras model\r\n- Run native Keras APIs with the ResNet 1.5 model\r\n\r\n@tfboyd : Do add to this any changes that may seem relevant to this PR.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2018-11-08T15:42:05Z",
        "closed_at": "2018-11-20T11:00:05Z",
        "merged_at": "2018-11-20T11:00:05Z",
        "body": "Scipy struggles with some WAV formats (e.g. when there is additional metadata present: https://stackoverflow.com/a/18958665/1194335). Reading the same files using the Pysoundfile works.",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 364,
        "deletions": 11,
        "changed_files": 14,
        "created_at": "2018-11-08T14:31:37Z",
        "closed_at": "2020-04-24T05:44:57Z",
        "merged_at": null,
        "body": "pull isiosia",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2018-11-07T16:30:17Z",
        "closed_at": "2018-11-08T14:51:32Z",
        "merged_at": null,
        "body": "Scipy struggles with some WAV formats (e.g. when there is additional metadata present: https://stackoverflow.com/a/18958665/1194335). Reading the same files using the Pysoundfile works.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-11-07T08:57:56Z",
        "closed_at": "2021-12-29T15:01:16Z",
        "merged_at": null,
        "body": "Bug in config_util.py `within get_configs_from_multiple_files()`",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 289,
        "deletions": 160,
        "changed_files": 4,
        "created_at": "2018-11-06T23:55:02Z",
        "closed_at": "2018-12-20T00:25:09Z",
        "merged_at": null,
        "body": "There are two commits in this PR.  The first commit is exactly @robieta 's threading commit https://github.com/tensorflow/models/commit/08c05a22be341d98068b07b9e368bd9b148abd32.\r\n\r\nThe second commit is just iterator change.  Feel free to selectively merge just that commit as you see fit.\r\n\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-11-06T09:21:41Z",
        "closed_at": "2020-04-24T07:02:04Z",
        "merged_at": null,
        "body": "Each batch contains sequences of length in [buckets_min, buckets_max), so that the longest instance in a batch will have length buckets_max - 1. Without this fix, instances with length == batch_size will result in buckets of zero elements, causing the dataset iterator to crash.\r\n\r\nAs a bonus this adds an extra instance per batch.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-11-05T05:08:41Z",
        "closed_at": "2018-11-05T18:57:41Z",
        "merged_at": "2018-11-05T18:57:41Z",
        "body": "Fixed grammar errors and typos.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-11-02T19:41:02Z",
        "closed_at": "2018-12-20T00:26:43Z",
        "merged_at": "2018-12-20T00:26:43Z",
        "body": "input_url doesn't get correct URL in Windows environment. The os.path.join() function add \"\\\\\" to the path, and it got incorrect URL for the data file. ",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 64,
        "deletions": 45,
        "changed_files": 1,
        "created_at": "2018-11-02T16:25:47Z",
        "closed_at": "2018-12-21T00:22:32Z",
        "merged_at": null,
        "body": "Updated the documentation to accurately reflect [which evaluation protocols](https://github.com/tensorflow/models/blob/master/research/object_detection/eval_util.py#L38) can be used in the current API.\r\n\r\nWithout these doc updates, users will be thrown `ValueError: Metric not found` when using a metric from the [list of eval protocols](https://github.com/tensorflow/models/blob/master/research/object_detection/legacy/evaluator.py#L33) that are now in the legacy directory.\r\n\r\nRelated issue:\r\nhttps://github.com/tensorflow/models/issues/4907",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-11-02T08:29:24Z",
        "closed_at": "2018-11-02T15:49:02Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2018-11-02T08:21:23Z",
        "closed_at": "2018-11-02T15:49:18Z",
        "merged_at": null,
        "body": "The `_create_modified_mobilenet_config()`[1] function would change the\r\n`mobilenet_v2.V2_DEF` and cause `num_outputs` inconsistency(256 vs 1280) in `layer_19` in ssd_mobilenet_v2_feature_extractor.py[2]\r\n\r\n\r\n\r\n```python\r\nroot@pc:/workspace/projects/models/research# export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim\r\nroot@pc:/workspace/projects/models/research# python\r\nPython 3.5.2 (default, Nov 23 2017, 16:37:01) \r\n[GCC 5.4.0 20160609] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import copy\r\n>>> import tensorflow as tf\r\n>>> from nets.mobilenet import mobilenet\r\n>>> from nets.mobilenet import mobilenet_v2\r\n>>> slim = tf.contrib.slim\r\n>>> \r\n>>> def _create_modified_mobilenet_config():\r\n...   conv_defs = copy.copy(mobilenet_v2.V2_DEF)\r\n...   conv_defs['spec'][-1] = mobilenet.op(\r\n...       slim.conv2d, stride=1, kernel_size=[1, 1], num_outputs=256)\r\n...   return conv_defs\r\n... \r\n>>> # before\r\n...                    \r\n>>> mobilenet_v2.V2_DEF['spec'][-1].params['num_outputs']\r\n1280\r\n>>> # after\r\n...\r\n>>> _CONV_DEFS = _create_modified_mobilenet_config()\r\n>>> mobilenet_v2.V2_DEF['spec'][-1].params['num_outputs']\r\n256\r\n```\r\n\r\nRef:\r\n\r\n- [1] https://github.com/tensorflow/models/blob/master/research/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor.py#L41\r\n- [2] https://github.com/tensorflow/models/blob/master/research/object_detection/models/ssd_mobilenet_v2_feature_extractor.py#L108\r\n- [3] https://github.com/tensorflow/models/blob/master/research/object_detection/builders/model_builder.py#L49\r\n- [4] https://arxiv.org/abs/1801.04381",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2018-11-01T21:03:03Z",
        "closed_at": "2018-11-02T00:02:05Z",
        "merged_at": "2018-11-02T00:02:05Z",
        "body": "The progress bar indicator, while mildly useful in interactive mode, is extremely troublesome when logs are caught.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-11-01T08:25:35Z",
        "closed_at": "2018-11-01T13:51:05Z",
        "merged_at": "2018-11-01T13:51:05Z",
        "body": "the number of batches per epoch also depends on the number of gpus. it should be `num_batches_per_epoch = (cifar10.NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN / FLAGS.batch_size / FLAGS.num_gpus)`",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 154,
        "deletions": 36,
        "changed_files": 5,
        "created_at": "2018-11-01T01:45:22Z",
        "closed_at": "2018-11-01T21:50:10Z",
        "merged_at": "2018-11-01T21:50:09Z",
        "body": "## Benchmark results\r\nI ran the following command on a Volta DGX1, with tf-nightly-gpu==1.13.0.dev20181027, Cuda 9.0, cuDNN 7.3.0, with a single V100 by setting CUDA_VISIBLE_DEVICES=0. I ran with and without while loops, 3 times each, with #5652 also patched in. I measured the average per-epoch time, skipping the first two epochs as warmups.\r\n\r\n```\r\npython ncf_main.py --model_dir=/home/reedwm/ncf_model_dir_gpu_1 --data_dir=/home/reedwm/ncf_data_dir_gpu_1 --dataset ml-20m --hooks= --num_gpus -1 --clean --train_epochs 14 --batch_size 65536 --eval_batch_size 65536 --layers 256,256,128,64 --num_factors 64 --hr_threshold 0.99 --learning_rate=0.00281936 --beta1=0.0490852 --beta2=0.965095 --epsilon=1.23757e-08 --ml_perf --use_xla_for_gpu --nouse_estimator --use_while_loop=$USE_WHILE_LOOP --output_ml_perf_compliance_logging\r\n```\r\n\r\nWithout while loops, the average per-epoch time was 22.05 seconds. With while loops, the average per-epoch time was 21.22 seconds, a 3.9% improvement.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 35,
        "deletions": 15,
        "changed_files": 5,
        "created_at": "2018-11-01T01:08:11Z",
        "closed_at": "2018-11-03T00:12:00Z",
        "merged_at": "2018-11-03T00:12:00Z",
        "body": "I've noticed sometimes the async process's pool processes do not die when ncf_main.py ends and kills the async process. This commit fixes the issue.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-10-31T17:21:40Z",
        "closed_at": "2019-03-08T01:01:55Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 23,
        "deletions": 13,
        "changed_files": 1,
        "created_at": "2018-10-30T16:20:29Z",
        "closed_at": "2018-10-30T17:55:19Z",
        "merged_at": "2018-10-30T17:55:19Z",
        "body": "Keras throws\r\n```\r\nValueError: Output tensors to a Model must be the output of a TensorFlow `Layer` (thus holding past layer metadata). Found: Tensor(\"rating/BiasAdd:0\", shape=(12288, 1), dtype=float32)\r\n```\r\n\r\nwhen trying to run on the TPU since embedding lookups are tensors rather than Keras layers. This PR simply wraps the tensor operations in Lambda layers. There may be a more Keras-y way to do it, but this way at least works.\r\n\r\n@tayo This doesn't seem to have a performance impact, but can you confirm that this is fine from your side?",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 79,
        "deletions": 44,
        "changed_files": 2,
        "created_at": "2018-10-30T01:16:45Z",
        "closed_at": "2018-10-30T02:43:53Z",
        "merged_at": "2018-10-30T02:43:53Z",
        "body": "Integrates the TPU-TC Estimator implementation with the main version.\r\n\r\nPrevious PR #5631 somehow corrupted its history.  Started this new PR to achieve a clean merge.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 447,
        "deletions": 135,
        "changed_files": 5,
        "created_at": "2018-10-29T09:12:38Z",
        "closed_at": "2018-10-30T01:02:33Z",
        "merged_at": null,
        "body": "This PR attempts to integrate the TPU-TC Estimator implementation with the main version.\r\n\r\nChanges that should be discussed in particular:\r\n- The eval_pred_fn creation occurs in every loop iteration.  Can this be pulled out of the loop?\r\n- The calculation of num_train_steps was previously called 'approx_train_steps' and was slightly diffferent.  One version wraps the equation in a ceil() and the other does not.  Correctness should be confirmed.",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-10-29T03:54:12Z",
        "closed_at": "2018-12-20T00:50:02Z",
        "merged_at": "2018-12-20T00:50:02Z",
        "body": "Update to the new name for an argument to the __init__() method of MirroredStrategy.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-10-27T14:52:11Z",
        "closed_at": "2020-04-24T06:41:47Z",
        "merged_at": null,
        "body": "Fix typo likeihood -> likelihood",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 373,
        "deletions": 95,
        "changed_files": 5,
        "created_at": "2018-10-27T01:28:20Z",
        "closed_at": "2018-10-29T22:43:21Z",
        "merged_at": "2018-10-29T22:43:21Z",
        "body": "To test convergence, I ran the following 48 times.\r\n```\r\npython ncf_main.py --model_dir=$HOME/ncf_model_dir_gpu_0 --data_dir=$HOME/ncf_data_dir_gpu_0 --dataset ml-20m --hooks= --num_gpus -1 --clean --train_epochs 14 --batch_size 65536 --eval_batch_size 65536 --layers 256,256,128,64 --num_factors 64 --hr_threshold 0.99 --ml_perf --learning_rate=0.00281936 --beta1=0.0490852 --beta2=0.965095 --epsilon=1.23757e-08 --use_xla_for_gpu --nouse_estimator\r\n```\r\n\r\nI hit a hit-rate of 63.5 44/48 times.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 59,
        "deletions": 32,
        "changed_files": 2,
        "created_at": "2018-10-26T21:05:07Z",
        "closed_at": "2020-03-27T22:23:28Z",
        "merged_at": null,
        "body": "\u2026enient consumption by multiple hosts etc.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 50,
        "deletions": 4,
        "changed_files": 5,
        "created_at": "2018-10-25T23:34:14Z",
        "closed_at": "2018-10-26T20:17:11Z",
        "merged_at": "2018-10-26T20:17:11Z",
        "body": "--ml_perf now just changes the model to make it MLPerf compliant. The compliance logging is now only done when flag --output_ml_perf_compliance_logging is specified.\r\n\r\nAlso add a test for --ml_perf.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 11727,
        "deletions": 979,
        "changed_files": 83,
        "created_at": "2018-10-25T22:02:38Z",
        "closed_at": "2018-11-02T15:48:35Z",
        "merged_at": "2018-11-02T15:48:34Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-10-25T03:40:35Z",
        "closed_at": "2019-02-23T20:00:26Z",
        "merged_at": "2019-02-23T20:00:26Z",
        "body": "",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 4047,
        "deletions": 1,
        "changed_files": 30,
        "created_at": "2018-10-24T23:47:26Z",
        "closed_at": "2018-11-26T19:09:28Z",
        "merged_at": "2018-11-26T19:09:28Z",
        "body": "We are open sourcing mobile video object detection framework that implements the following paper: \r\nMobile Video Object Detection with Temporally-Aware Feature Maps, Liu, Mason and Zhu, Menglong ,CVPR 2018.\r\n\r\nThis codebase allows you to train video detection models that can be easily deployed on mobile devices with Tensorflow Lite to perform video object detection in realtime.\r\n\r\nIf you find the code to be useful, please cite:\r\n\r\n@article{liu2018mobile,\r\n  title={Mobile Video Object Detection with Temporally-Aware Feature Maps},\r\n  author={Liu, Mason and Zhu, Menglong},\r\n  journal={CVPR},\r\n  year={2018}\r\n}\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-10-24T19:00:56Z",
        "closed_at": "2018-10-24T21:41:10Z",
        "merged_at": "2018-10-24T21:41:10Z",
        "body": "To match new terminology in DistributionStrategy.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-10-24T18:59:23Z",
        "closed_at": "2018-10-25T20:13:41Z",
        "merged_at": "2018-10-25T20:13:41Z",
        "body": "Update to reflect new name of (contrib) AllReduceCrossTowerOps since we are moving away from the \"tower\" terminology.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-10-24T02:33:38Z",
        "closed_at": "2018-11-20T01:43:25Z",
        "merged_at": "2018-11-20T01:43:25Z",
        "body": "to save people's time when reproducing the experiment using Python 3",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-10-23T20:01:46Z",
        "closed_at": "2020-04-26T00:51:54Z",
        "merged_at": null,
        "body": "Added `image_num_channels` for non-RGB input images \r\n* 1 channel: MNIST, grayscale images\r\n* 4 channel inputs: RGB-D images\r\n* other custom inputs",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 142,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-10-23T03:17:50Z",
        "closed_at": "2018-11-20T01:42:46Z",
        "merged_at": "2018-11-20T01:42:46Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 421,
        "deletions": 55,
        "changed_files": 7,
        "created_at": "2018-10-20T20:58:32Z",
        "closed_at": "2018-10-24T18:51:44Z",
        "merged_at": "2018-10-24T18:51:44Z",
        "body": "This PR adds a util for mlperf logging (conditional logging and shielded import), and adds logging calls to NCF.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 26,
        "deletions": 10,
        "changed_files": 4,
        "created_at": "2018-10-19T16:56:41Z",
        "closed_at": "2018-10-20T00:22:54Z",
        "merged_at": "2018-10-20T00:22:53Z",
        "body": "I verified convergence, by running the following command 100 times with 1.13.0.dev20181017 and converging to 0.635 92% of the time.\r\n```\r\npython ncf_main.py --model_dir=$HOME/ncf_model_dir_gpu_0 --data_dir=$HOME/ncf_data_dir_gpu_0 --dataset ml-20m --hooks= --num_gpus -1 --clean --train_epochs 14 --batch_size 65536 --eval_batch_size 65536 --layers 256,256,128,64 --num_factors 64 --hr_threshold 0.99 --ml_perf --learning_rate=0.00281936 --beta1=0.0490852 --beta2=0.965095 --epsilon=1.23757e-08 --use_xla_for_gpu\r\n```\r\n\r\nI obtained the following training performance results on a Z840 with a Titan V, with TensorFlow 1.13.0.dev20181018, Cuda 9.0 with cuDNN 7.2.1 and the `ptxas` binary from Cuda 9.2 patched in, as recommended by XLA. I ran the following command, both with and without `--use_xla_for_gpu`, five times each and took the averages.\r\n\r\n```\r\npython ncf_main.py --model_dir=$HOME/ncf_model_dir_1 --data_dir=$HOME/ncf_data_dir_1 --dataset ml-20m --num_gpus -1 --clean --train_epochs 1 --batch_size 65536 --layers 256,256,128,64 --num_factors 64 --use_synthetic_data --ml_perf --hooks=examplespersecondhook\r\n```\r\n\r\nWithout `--use_xla_for_gpu`, the training performance was 5038888 examples/sec and with `--use_xla_for_gpu`, the training performance was 6132903 examples/sec, a 21.7% improvement.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2018-10-19T14:55:22Z",
        "closed_at": "2020-04-24T05:49:52Z",
        "merged_at": "2020-04-24T05:49:52Z",
        "body": "Original code attempts to apply `str.decode('utf-8')`, which throws an error in python 3.x. This now uses a try/except block to catch the error and allow backwards compatibility.\r\n\r\nIt also fixes a deprecation error on a dependency.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2018-10-18T09:25:56Z",
        "closed_at": "2020-04-26T02:44:29Z",
        "merged_at": null,
        "body": "lead a bug \"TYPEERROR: CAN'T PICKLE DICTVALUES OBJECTS\"",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 59,
        "deletions": 33,
        "changed_files": 1,
        "created_at": "2018-10-17T22:50:24Z",
        "closed_at": "2018-10-18T00:37:17Z",
        "merged_at": "2018-10-18T00:37:17Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-10-16T21:05:25Z",
        "closed_at": "2020-04-24T06:27:43Z",
        "merged_at": null,
        "body": "",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 40,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-10-16T09:07:26Z",
        "closed_at": "2020-04-24T05:59:52Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 328,
        "deletions": 355,
        "changed_files": 6,
        "created_at": "2018-10-15T16:46:06Z",
        "closed_at": "2018-10-18T20:39:27Z",
        "merged_at": "2018-10-18T20:39:27Z",
        "body": "This PR does two things:\r\n\r\n1) It replaces the \"spillover\" mechanism with a more conventional padding which is ignored by the cross entropy. @shizhiw In the last batch the padded keys all lookup at index zero. Is this hot key going to be an issue? (If so I can spread out the keys; it's just easier to read if all the paddings have the same value.)\r\n\r\n2) It consolidates a lot of the eval generation and merges the training and eval generation. This removes some duplicate code. However, it also makes the performance properties much better:\r\n * Training and eval now use the same base data shards, saving a ~2GB .npz intermediate file\r\n * The eval set is now computed after the first training epoch, so training can begin sooner.\r\n * The clock start can be moved to right before the subprocess starts, because the random sampling for eval no longer happens as part of the main thread data preprocessing.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-10-14T10:32:15Z",
        "closed_at": "2020-04-24T07:06:23Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-10-14T10:31:09Z",
        "closed_at": "2018-10-14T19:16:07Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-10-14T08:30:25Z",
        "closed_at": "2020-04-24T06:52:30Z",
        "merged_at": null,
        "body": "#5525\r\nUpdated predict.py to make seperate calls to `read_light_curve()` and `process_light_curve()` to eliminate **AttributeError: 'module' object has no attribute 'read_and_process_light_curve'**\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 34,
        "deletions": 18,
        "changed_files": 3,
        "created_at": "2018-10-13T23:40:44Z",
        "closed_at": "2018-10-14T07:01:15Z",
        "merged_at": "2018-10-14T07:01:15Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 136,
        "deletions": 35,
        "changed_files": 5,
        "created_at": "2018-10-13T15:03:09Z",
        "closed_at": "2018-10-18T18:54:07Z",
        "merged_at": "2018-10-18T18:54:07Z",
        "body": "Adds the smallest number of perf args to allow a test of \"stock\" vs. manual tuned (preset) for the latest hardware.  This will allow me to move my perf testing from my fork to here which benefits everyone.\r\n\r\nThere are a few ways to do this so I am totally cool taking our time on this PR to get it right.\r\n\r\nFor ResNet V1 on GCE 8xV100s\r\n- Stock (no perf flags): ~5100 images/sec\r\n- Manual flags:  ~5400 images/sec\r\n- benchmark code (non-xla), 5,700 images/sec\r\n\r\n```bash\r\npython -m official.resnet.imagenet_main --all_reduce_alg nccl --batch_size 2048 --data_dir /data/imagenet --dtype fp16 --epochs_between_evals 4 --hooks ExamplesPerSecondHook LoggingTensorHook --intra_op_parallelism_threads 1 --model_dir /workspace/tmp/81_eval_4_tuned_full_2 --num_gpus 8 --datasets_num_parallel_batches 2 --resnet_size 50 --resnet_version 1 --tf_gpu_thread_mode gpu_private --train_epochs=81\r\n```",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 14,
        "deletions": 7,
        "changed_files": 2,
        "created_at": "2018-10-13T05:58:41Z",
        "closed_at": "2018-10-14T07:05:22Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2018-10-13T00:32:05Z",
        "closed_at": "2018-10-13T03:58:00Z",
        "merged_at": "2018-10-13T03:58:00Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 171,
        "deletions": 304,
        "changed_files": 2,
        "created_at": "2018-10-13T00:26:07Z",
        "closed_at": "2020-03-11T22:35:01Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2018-10-11T06:31:02Z",
        "closed_at": "2018-10-11T15:35:58Z",
        "merged_at": "2018-10-11T15:35:58Z",
        "body": "fixed bug and introduced python3 compatability.\r\ndescribtion: The automated marco did not account for the output of the tensorflow model enumerated the dictionary keys in the order of the scores. \r\n\r\nAdditionally removed the conversion to % ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 113,
        "deletions": 18,
        "changed_files": 3,
        "created_at": "2018-10-10T16:45:29Z",
        "closed_at": "2018-10-10T18:40:25Z",
        "merged_at": "2018-10-10T18:40:25Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 99,
        "deletions": 49,
        "changed_files": 5,
        "created_at": "2018-10-09T22:51:23Z",
        "closed_at": "2018-10-11T23:03:27Z",
        "merged_at": "2018-10-11T23:03:27Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2018-10-08T17:45:46Z",
        "closed_at": "2018-10-08T19:52:44Z",
        "merged_at": "2018-10-08T19:52:44Z",
        "body": "I made a mistake in testing and AUTOTUNE was not being turned on, so other than reducing code my other PR was a no op.  When I actually turn on AUTOTUNE it creates problems, which is not unexpected as the feature is new and will be figured out by the owner. \r\n\r\nThe reduced code by removing `take` is still good.  This rolls back AUTOTUNE. \r\n\r\nSorry about that.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-10-08T14:02:27Z",
        "closed_at": "2020-04-25T04:44:04Z",
        "merged_at": null,
        "body": "Fixed python3 compatibility issue #4780",
        "comments": 8
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-10-07T15:16:52Z",
        "closed_at": "2022-12-29T22:20:26Z",
        "merged_at": null,
        "body": "When using the run_once flag ` estimator.evaluate(input_fn, num_eval_steps=None, checkpoint_path=tf.train.latest_checkpoint(FLAGS.checkpoint_dir))` is called, but [tf.estimator.Estimator.evaluate()](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#evaluate) has no num_eval_steps kwarg. This leads to \"TypeError: evaluate() got an unexpected keyword argument 'num_eval_steps'\". Fixed by removing the argument.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 20,
        "changed_files": 1,
        "created_at": "2018-10-05T15:23:42Z",
        "closed_at": "2018-10-05T18:42:59Z",
        "merged_at": "2018-10-05T18:42:59Z",
        "body": "Set map_batch to use AUTOTUNE, tests on a GCE 8xV100 on GCE yielded.  Note this change needs 1.12 (cut not built yet) or nightly as of ~OCT-02:\r\n\r\n- 5,100-5,190 images/sec.  Painful full disclosure.  My fork had dropped in performance with num_parallel_batches=1 to 4,600 from ~5K, it does not seem that the main branch (here) has that issue for some reason.  This change improved my fork from 4,600 to 5,200 and for the **\"official\" had change** but less code.  We need to merge in my perf args and stop using the fork for perf testing.  Still very nice to clean up the code so embarrassing and perplexing but still a win as well as a reminder as to why long-term forks are bad news.\r\n- In my tuned version AUTOTUNE is equal or better than hand tuning num_parallel_batches. 5,400+\r\n\r\nOther changes:\r\n\r\n- Remove dataset.take that was not doing anything.\r\n- Tweaked some comments to be shorter and match style guide.\r\n\r\nRan end-to-end test of 90 Epochs with expected accuracy achieved.\r\n\r\n- top_1: 76.25%\r\n- top_5: 93.077% \r\n\r\n{'name': 'accuracy', 'timestamp': '2018-10-05T12:30:24.004028Z', 'value': 0.7625200152397156, 'extras': [], 'unit': None, 'global_step': 56286}\r\n\r\nI1005 12:30:24.004206 139731230779136 tf_logging.py:115] Benchmark metric: {'name': 'accuracy_top_5', 'timestamp': '2018-10-05T12:30:24.004190Z', 'value': 0.9307799935340881, 'extras': [], 'unit': None, 'global_step': 56286}\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 35,
        "deletions": 13,
        "changed_files": 1,
        "created_at": "2018-10-04T21:43:56Z",
        "closed_at": "2018-10-04T23:12:08Z",
        "merged_at": "2018-10-04T23:12:08Z",
        "body": "The ResNet pretrained models have drifted away from HEAD in the last few months. This PR updates the README to point to shiny new models with better accuracy (Thanks Toby!) and SavedModels which follow best practices and accommodate a wider range of use cases.\r\n\r\nCC @netfs @tfboyd ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 18,
        "deletions": 11,
        "changed_files": 5,
        "created_at": "2018-10-04T19:53:27Z",
        "closed_at": "2018-10-04T23:11:34Z",
        "merged_at": "2018-10-04T23:11:34Z",
        "body": "Stripping default attributes is recommended practice for wider SavedModel portability between TensorFlow versions. (https://www.tensorflow.org/guide/saved_model#manually_build_a_savedmodel) This PR update official models to follow the convention of setting `strip_default_attrs=True` when exporting SavedModels.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-10-04T16:01:28Z",
        "closed_at": "2018-10-05T00:00:37Z",
        "merged_at": "2018-10-05T00:00:37Z",
        "body": "None was going into an int() call in the default case.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 19,
        "deletions": 10,
        "changed_files": 3,
        "created_at": "2018-10-04T10:09:47Z",
        "closed_at": "2022-05-16T04:39:28Z",
        "merged_at": null,
        "body": "There are missing variables between [.ckpt file](https://github.com/tensorflow/models/tree/master/research/slim)  you give and resnet. Therefore, error occurred when restoring variables with setting ignore_missing_vars=False. Warning occurred when restoring variables with setting ignore_missing_vars=True.\r\n\r\n# Resnet with ignore_missing_vars=False\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.slim.nets as nets\r\nimport tensorflow.contrib.slim as slim\r\nimport os\r\n\r\n# use single GPU\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\r\n\r\n# define placeholder \r\nxp = tf.placeholder(tf.float32, shape = (None, None, None, 3))\r\n\r\nnets.resnet_v1.resnet_v1_101(xp, num_classes = 1000, is_training = True)\r\n\r\nwith tf.Session() as sess:\r\n    # initial weight\r\n    init = tf.global_variables_initializer()\r\n    sess.run(init)\r\n    # load weight\r\n    variables_to_restore = slim.get_variables_to_restore()\r\n    init_assign_op, init_feed_dict = slim.assign_from_checkpoint('./models/resnet_v1_101.ckpt', \r\n                                                                 variables_to_restore, \r\n                                                                 ignore_missing_vars=False)\r\n    sess.run(init_assign_op, feed_dict=init_feed_dict)\r\n```\r\n# Error\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 23, in <module>\r\n    ignore_missing_vars=False)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 671, in assign_from_checkpoint\r\n    raise ValueError(log_str)\r\nValueError: Checkpoint is missing variable [resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/biases]\r\n\r\n# Resnet with ignore_missing_vars=True\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.slim.nets as nets\r\nimport tensorflow.contrib.slim as slim\r\nimport os\r\n\r\n# use single GPU\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\r\n\r\n# define placeholder \r\nxp = tf.placeholder(tf.float32, shape = (None, None, None, 3))\r\n\r\nnets.resnet_v1.resnet_v1_101(xp, num_classes = 1000, is_training = True)\r\n\r\nwith tf.Session() as sess:\r\n    # initial weight\r\n    init = tf.global_variables_initializer()\r\n    sess.run(init)\r\n    # load weight\r\n    variables_to_restore = slim.get_variables_to_restore()\r\n    init_assign_op, init_feed_dict = slim.assign_from_checkpoint('./models/resnet_v1_101.ckpt', \r\n                                                                 variables_to_restore, \r\n                                                                 ignore_missing_vars=True)\r\n    sess.run(init_assign_op, feed_dict=init_feed_dict)\r\n```\r\n# Warning\r\n\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/biases]\r\n\r\n# Resnet with ignore_missing_vars=False\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.slim.nets as nets\r\nimport tensorflow.contrib.slim as slim\r\nimport os\r\n\r\n# use single GPU\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\r\n\r\n# define placeholder \r\nxp = tf.placeholder(tf.float32, shape = (None, None, None, 3))\r\n\r\nnets.resnet_v2.resnet_v2_101(xp, num_classes = 1001, is_training = True)\r\n\r\nwith tf.Session() as sess:\r\n    # initial weight\r\n    init = tf.global_variables_initializer()\r\n    sess.run(init)\r\n    # load weight\r\n    variables_to_restore = slim.get_variables_to_restore()\r\n    init_assign_op, init_feed_dict = slim.assign_from_checkpoint('./models/resnet_v2_101.ckpt', \r\n                                                                 variables_to_restore, \r\n                                                                 ignore_missing_vars=False)\r\n    sess.run(init_assign_op, feed_dict=init_feed_dict)\r\n```\r\n# Error\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 22, in <module>\r\n    ignore_missing_vars=False)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 671, in assign_from_checkpoint\r\n    raise ValueError(log_str)\r\nValueError: Checkpoint is missing variable [resnet_v2_101/block3/unit_20/bottleneck_v2/conv2/biases]\r\n\r\n# Resnet with ignore_missing_vars=True\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.slim.nets as nets\r\nimport tensorflow.contrib.slim as slim\r\nimport os\r\n\r\n# use single GPU\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\r\n\r\n# define placeholder \r\nxp = tf.placeholder(tf.float32, shape = (None, None, None, 3))\r\n\r\nnets.resnet_v2.resnet_v2_101(xp, num_classes = 1001, is_training = True)\r\n\r\nwith tf.Session() as sess:\r\n    # initial weight\r\n    init = tf.global_variables_initializer()\r\n    sess.run(init)\r\n    # load weight\r\n    variables_to_restore = slim.get_variables_to_restore()\r\n    init_assign_op, init_feed_dict = slim.assign_from_checkpoint('./models/resnet_v2_101.ckpt', \r\n                                                                 variables_to_restore, \r\n                                                                 ignore_missing_vars=True)\r\n    sess.run(init_assign_op, feed_dict=init_feed_dict)\r\n\r\n```\r\n# Warning\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_20/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_7/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_19/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block1/unit_1/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block1/unit_3/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block2/unit_2/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_1/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_15/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_10/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_13/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_12/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block4/unit_3/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block4/unit_3/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block2/unit_4/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_17/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block1/unit_2/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_9/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_21/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block2/unit_1/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_21/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_4/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block2/unit_3/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_6/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_22/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_15/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_8/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_8/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_14/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_4/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block4/unit_1/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_5/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block4/unit_2/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_9/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block4/unit_2/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block1/unit_1/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_17/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_22/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_2/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_20/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_6/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_19/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_14/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_1/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block2/unit_4/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block1/unit_2/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block2/unit_2/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_2/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block2/unit_3/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_11/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block4/unit_1/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_12/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_3/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block1/unit_3/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_11/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_3/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_23/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_18/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_13/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_5/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_16/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_16/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_18/bottleneck_v2/conv2/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_23/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_7/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block3/unit_10/bottleneck_v2/conv1/biases]\r\nWARNING:tensorflow:Checkpoint is missing variable [resnet_v2_101/block2/unit_1/bottleneck_v2/conv1/biases]\r\n\r\n\r\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-10-04T06:52:55Z",
        "closed_at": "2020-04-26T00:14:33Z",
        "merged_at": null,
        "body": "keep_checkpoint_every_n_hour (uint32 -> float)\r\nInterpreted as a float in the API (saver.py).\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.11/tensorflow/python/training/saver.py#L699\r\n\r\nLets us save checkpoints more often than every hour",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 123659,
        "deletions": 10274,
        "changed_files": 920,
        "created_at": "2018-10-03T19:08:36Z",
        "closed_at": "2020-04-21T02:29:13Z",
        "merged_at": null,
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 771,
        "deletions": 162,
        "changed_files": 12,
        "created_at": "2018-10-03T04:57:23Z",
        "closed_at": "2018-10-05T03:23:21Z",
        "merged_at": "2018-10-05T03:23:20Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-10-02T20:44:49Z",
        "closed_at": "2018-10-03T18:15:51Z",
        "merged_at": "2018-10-03T18:15:51Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 363,
        "deletions": 238,
        "changed_files": 9,
        "created_at": "2018-10-01T03:50:14Z",
        "closed_at": "2018-10-03T02:04:34Z",
        "merged_at": "2018-10-03T02:04:34Z",
        "body": "As the name suggests, the main purpose of this PR is to remove the .predict() call and subsequent numpy vectorized hit rate calculation, and replace it with tensorflow code inside and evaluate call.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 22,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-09-30T21:26:49Z",
        "closed_at": "2018-10-03T23:58:56Z",
        "merged_at": "2018-10-03T23:58:56Z",
        "body": "update installation instrument for mac users",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-09-30T15:42:36Z",
        "closed_at": "2020-04-24T15:44:29Z",
        "merged_at": "2020-04-24T15:44:28Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 12,
        "changed_files": 5,
        "created_at": "2018-09-29T21:11:05Z",
        "closed_at": "2018-10-05T00:27:21Z",
        "merged_at": "2018-10-05T00:27:21Z",
        "body": "Updates links, plus a small python3 compatability fix.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1837,
        "deletions": 80,
        "changed_files": 27,
        "created_at": "2018-09-29T08:09:44Z",
        "closed_at": "2018-10-02T08:31:35Z",
        "merged_at": "2018-10-02T08:31:35Z",
        "body": "PiperOrigin-RevId: 215004158\r\n\r\nUpdates include:\r\n- add stargan and stargan estimator example\r\n- improve cyclegan data provider to generate a dataset\r\n- some cosmetic changes to other examples",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 509,
        "deletions": 118,
        "changed_files": 7,
        "created_at": "2018-09-29T01:43:30Z",
        "closed_at": "2020-04-24T06:39:10Z",
        "merged_at": "2020-04-24T06:39:10Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 43,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2018-09-28T00:17:11Z",
        "closed_at": "2018-10-01T16:35:10Z",
        "merged_at": "2018-10-01T16:35:10Z",
        "body": "Add `--image_bytes_as_serving_input` flag to export SavedModel with\r\nserving signature that accepts JPEG image bytes instead of a fixed size\r\n[HxWxC] image tensor.\r\n\r\nPassing JPEG image bytes is easier for inference/serving use cases.\r\nThe model internally resizes/crops the image to required [HxWxC]\r\nshaped tensor before passing it on for actual model inference.\r\n\r\nThis change aligns with Cloud TPU/ResNet-50 model that offers a\r\nsimilar interface (jpeg bytes) for inferencing here:\r\nhttps://github.com/tensorflow/tpu/tree/master/models/official/resnet\r\n\r\nNOTE: This flag is set to `True` by default.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-09-26T18:19:31Z",
        "closed_at": "2020-04-24T05:33:11Z",
        "merged_at": null,
        "body": "other README.md docs in tensorflow have the git clone requirement declared.\r\n\r\nthe way the documentation is set up to point PYTHON PATH to the models module path sounds like the models module was already on my machine , esp since the github repo has it as part of tensorflow master repo",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 31,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-09-25T18:31:12Z",
        "closed_at": "2018-10-01T19:43:22Z",
        "merged_at": "2018-10-01T19:43:22Z",
        "body": "As per many users request over stack_overflow and github, I am enabling prediction in mnist_tpu.\r\nRight now we don't have input data for prediction. So using top 10 entries of test data as input.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 186,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-09-24T21:20:04Z",
        "closed_at": "2018-09-25T17:50:10Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-09-23T14:01:13Z",
        "closed_at": "2018-10-01T17:36:17Z",
        "merged_at": "2018-10-01T17:36:17Z",
        "body": "save people the trouble of training a model and trying to convert only to realize they should have used SSD model",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-09-22T01:37:04Z",
        "closed_at": "2022-03-28T03:47:11Z",
        "merged_at": null,
        "body": "See https://stackoverflow.com/questions/46082397/insert-newline-n-using-sed\n\n<!-- Reviewable:start -->\n---\nThis change is\u2002[<img src=\"https://reviewable.io/review_button.svg\" height=\"34\" align=\"absmiddle\" alt=\"Reviewable\"/>](https://reviewable.io/reviews/tensorflow/models/5355)\n<!-- Reviewable:end -->\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 100,
        "deletions": 29,
        "changed_files": 10,
        "created_at": "2018-09-21T22:59:23Z",
        "closed_at": "2018-09-25T22:22:56Z",
        "merged_at": "2018-09-25T22:22:56Z",
        "body": "213899768  by Sergio Guadarrama:\r\n\r\n    Fixes #3819.\r\n\r\n--\r\n213493831  by Sergio Guadarrama:\r\n\r\n    Internal change\r\n\r\n212057654  by Sergio Guadarrama:\r\n\r\n    Internal change\r\n\r\n210747685  by Sergio Guadarrama:\r\n\r\n    For FPN, when use_depthwise is set to true, use slightly modified mobilenet v1 config.\r\n\r\n--\r\n210128931  by Sergio Guadarrama:\r\n\r\n    Allow user-defined current_step in NASNet.\r\n\r\n--\r\n209092664  by Sergio Guadarrama:\r\n\r\n    Add quantized fine-tuning / training / eval and export to slim image classifier binaries.\r\n\r\n--\r\n207651347  by Sergio Guadarrama:\r\n\r\n    Update mobilenet v1 docs to include revised tflite models.\r\n\r\n--\r\n207165245  by Sergio Guadarrama:\r\n\r\n    Internal change\r\n\r\n207095064  by Sergio Guadarrama:\r\n\r\n    Internal change\r\n\r\nPiperOrigin-RevId: 213899768",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2243,
        "deletions": 0,
        "changed_files": 35,
        "created_at": "2018-09-21T22:16:18Z",
        "closed_at": "2018-09-24T21:17:59Z",
        "merged_at": "2018-09-24T21:17:59Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1252,
        "deletions": 763,
        "changed_files": 30,
        "created_at": "2018-09-21T21:21:26Z",
        "closed_at": "2018-09-21T22:33:32Z",
        "merged_at": null,
        "body": "213899768  by Sergio Guadarrama:\r\n\r\n    Fixes #3819.\r\n\r\n--\r\n213493831  by Sergio Guadarrama:\r\n\r\n    Internal change\r\n\r\n212057654  by Sergio Guadarrama:\r\n\r\n    Internal change\r\n\r\n210747685  by Sergio Guadarrama:\r\n\r\n    For FPN, when use_depthwise is set to true, use slightly modified mobilenet v1 config.\r\n\r\n--\r\n210128931  by Sergio Guadarrama:\r\n\r\n    Allow user-defined current_step in NASNet.\r\n\r\n--\r\n209092664  by Sergio Guadarrama:\r\n\r\n    Add quantized fine-tuning / training / eval and export to slim image classifier binaries.\r\n\r\n--\r\n207651347  by Sergio Guadarrama:\r\n\r\n    Update mobilenet v1 docs to include revised tflite models.\r\n\r\n--\r\n207165245  by Sergio Guadarrama:\r\n\r\n    Internal change\r\n\r\n207095064  by Sergio Guadarrama:\r\n\r\n    Internal change\r\n\r\nPiperOrigin-RevId: 213899768",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-09-21T14:28:13Z",
        "closed_at": "2018-10-01T17:37:56Z",
        "merged_at": "2018-10-01T17:37:56Z",
        "body": "As per https://github.com/tensorflow/models/blob/master/research/object_detection/samples/cloud/cloud.yml#L5\n\n<!-- Reviewable:start -->\n---\nThis change is\u2002[<img src=\"https://reviewable.io/review_button.svg\" height=\"34\" align=\"absmiddle\" alt=\"Reviewable\"/>](https://reviewable.io/reviews/tensorflow/models/5350)\n<!-- Reviewable:end -->\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-09-21T14:15:00Z",
        "closed_at": "2021-12-16T19:23:55Z",
        "merged_at": null,
        "body": " * I might be misunderstanding (e.g. if the docs are compiled), but the [anchor on github](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/using_your_own_dataset.md#conversion-script-outline) is currently broken\r\n * Tutorials modify `PYTHONPATH` to resolve module imports directly out of `models/research`; the rest of the world doesn't have a `google3` namespace ;)\r\n\r\n<!-- Reviewable:start -->\r\n---\r\nThis change is\u2002[<img src=\"https://reviewable.io/review_button.svg\" height=\"34\" align=\"absmiddle\" alt=\"Reviewable\"/>](https://reviewable.io/reviews/tensorflow/models/5349)\r\n<!-- Reviewable:end -->\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-09-20T08:45:56Z",
        "closed_at": "2020-04-24T06:16:39Z",
        "merged_at": null,
        "body": "If you do not add 'rb', python will think you're opening a text file, and the program would fail with an UnicodeDecodeError",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 2125,
        "deletions": 1,
        "changed_files": 11,
        "created_at": "2018-09-19T20:25:57Z",
        "closed_at": "2018-09-19T22:15:35Z",
        "merged_at": "2018-09-19T22:15:35Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 153,
        "deletions": 33,
        "changed_files": 6,
        "created_at": "2018-09-19T17:14:48Z",
        "closed_at": "2018-09-20T01:07:17Z",
        "merged_at": "2018-09-20T01:07:17Z",
        "body": "* Cleanup run script. Fix hr threshold and add ml_perf flag\r\n* Make exit behavior more stable\r\n* Add seed to reduce variation. There is still unaccounted for variation, but this at least removes some of it.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 8,
        "changed_files": 3,
        "created_at": "2018-09-18T13:14:31Z",
        "closed_at": "2018-09-19T03:06:51Z",
        "merged_at": "2018-09-19T03:06:51Z",
        "body": "Parameter `final_size` is not really configurable, it has only one correct value depending on other parameters  and input image size, setting it to incorrect value will cause shape mismatch error.\r\n\r\nSo I think it's better to remove it and just let the code deduce its value. Actually by using `tf.squeeze(tensor, axes)` we don't need  'final_size' at all.\r\n\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-09-17T23:21:05Z",
        "closed_at": "2020-04-24T05:34:35Z",
        "merged_at": null,
        "body": "",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 1092,
        "deletions": 0,
        "changed_files": 12,
        "created_at": "2018-09-14T03:29:34Z",
        "closed_at": "2020-04-24T05:35:25Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-09-13T02:39:26Z",
        "closed_at": "2018-09-20T20:02:00Z",
        "merged_at": "2018-09-20T20:02:00Z",
        "body": "This PR passes session config in run_params object to device_lib.list_local_devices() call. Otherwise this call instantiates a session and may ignore any gpu configuration that user might have.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 11,
        "deletions": 504,
        "changed_files": 5,
        "created_at": "2018-09-12T02:00:04Z",
        "closed_at": "2018-12-20T00:29:38Z",
        "merged_at": null,
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 21943,
        "deletions": 1897,
        "changed_files": 100,
        "created_at": "2018-09-11T23:50:50Z",
        "closed_at": "2018-09-21T17:41:08Z",
        "merged_at": "2018-09-21T17:41:07Z",
        "body": "212389173  by Zhichao Lu:\r\n\r\n    1. Replace tf.boolean_mask with tf.where\r\n\r\n--\r\n212282646  by Zhichao Lu:\r\n\r\n    1. Fix a typo in model_builder.py and add a test to cover it.\r\n\r\n--\r\n212142989  by Zhichao Lu:\r\n\r\n    Only resize masks in meta architecture if it has not already been resized in the input pipeline.\r\n\r\n--\r\n212136935  by Zhichao Lu:\r\n\r\n    Choose matmul or native crop_and_resize in the model builder instead of faster r-cnn meta architecture.\r\n\r\n--\r\n211907984  by Zhichao Lu:\r\n\r\n    Make eval input reader repeated field and update config util to handle this field.\r\n\r\n--\r\n211858098  by Zhichao Lu:\r\n\r\n    Change the implementation of merge_boxes_with_multiple_labels.\r\n\r\n--\r\n211843915  by Zhichao Lu:\r\n\r\n    Add Mobilenet v2 + FPN support.\r\n\r\n--\r\n211655076  by Zhichao Lu:\r\n\r\n    Bug fix for generic keys in config overrides\r\n\r\n    In generic configuration overrides, we had a duplicate entry for train_input_config and we were missing the eval_input_config and eval_config.\r\n\r\n    This change also introduces testing for all config overrides.\r\n\r\n--\r\n211157501  by Zhichao Lu:\r\n\r\n    Make the locally-modified conv defs a copy.\r\n\r\n    So that it doesn't modify MobileNet conv defs globally for other code that\r\n    transitively imports this package.\r\n\r\n--\r\n211112813  by Zhichao Lu:\r\n\r\n    Refactoring visualization tools for Estimator's eval_metric_ops. This will make it easier for future models to take advantage of a single interface and mechanics.\r\n\r\n--\r\n211109571  by Zhichao Lu:\r\n\r\n    A test decorator.\r\n\r\n--\r\n210747685  by Zhichao Lu:\r\n\r\n    For FPN, when use_depthwise is set to true, use slightly modified mobilenet v1 config.\r\n\r\n--\r\n210723882  by Zhichao Lu:\r\n\r\n    Integrating the losses mask into the meta architectures. When providing groundtruth, one can optionally specify annotation information (i.e. which images are labeled vs. unlabeled). For any image that is unlabeled, there is no loss accumulation.\r\n\r\n--\r\n210673675  by Zhichao Lu:\r\n\r\n    Internal change.\r\n\r\n--\r\n210546590  by Zhichao Lu:\r\n\r\n    Internal change.\r\n\r\n--\r\n210529752  by Zhichao Lu:\r\n\r\n    Support batched inputs with ops.matmul_crop_and_resize.\r\n\r\n    With this change the new inputs are images of shape [batch, heigh, width, depth] and boxes of shape [batch, num_boxes, 4]. The output tensor is of the shape [batch, num_boxes, crop_height, crop_width, depth].\r\n\r\n--\r\n210485912  by Zhichao Lu:\r\n\r\n    Fix TensorFlow version check in object_detection_tutorial.ipynb\r\n\r\n--\r\n210484076  by Zhichao Lu:\r\n\r\n    Reduce TPU memory required for single image matmul_crop_and_resize.\r\n\r\n    Using tf.einsum eliminates intermediate tensors, tiling and expansion. for an image of size [40, 40, 1024] and boxes of shape [300, 4] HBM memory usage goes down from 3.52G to 1.67G.\r\n\r\n--\r\n210468361  by Zhichao Lu:\r\n\r\n    Remove PositiveAnchorLossCDF/NegativeAnchorLossCDF to resolve \"Main thread is not in main loop error\" issue in local training.\r\n\r\n--\r\n210100253  by Zhichao Lu:\r\n\r\n    Pooling pyramid feature maps: add option to replace max pool with convolution layers.\r\n\r\n--\r\n209995842  by Zhichao Lu:\r\n\r\n    Fix a bug which prevents variable sharing in Faster RCNN.\r\n\r\n--\r\n209965526  by Zhichao Lu:\r\n\r\n    Add support for enabling export_to_tpu through the estimator.\r\n\r\n--\r\n209946440  by Zhichao Lu:\r\n\r\n    Replace deprecated tf.train.Supervisor with tf.train.MonitoredSession. MonitoredSession also takes away the hassle of starting queue runners.\r\n\r\n--\r\n209888003  by Zhichao Lu:\r\n\r\n    Implement function to handle data where source_id is not set.\r\n\r\n    If the field source_id is found to be the empty string for any image during runtime, it will be replaced with a random string. This avoids hash-collisions on dataset where many examples do not have source_id set. Those hash-collisions have unintended site effects and may lead to bugs in the detection pipeline.\r\n\r\n--\r\n209842134  by Zhichao Lu:\r\n\r\n    Converting loss mask into multiplier, rather than using it as a boolean mask (which changes tensor shape). This is necessary, since other utilities (e.g. hard example miner) require a loss matrix with the same dimensions as the original prediction tensor.\r\n\r\n--\r\n209768066  by Zhichao Lu:\r\n\r\n    Adding ability to remove loss computation from specific images in a batch, via an optional boolean mask.\r\n\r\n--\r\n209722556  by Zhichao Lu:\r\n\r\n    Remove dead code.\r\n\r\n    (_USE_C_API was flipped to True by default in TensorFlow 1.8)\r\n\r\n--\r\n209701861  by Zhichao Lu:\r\n\r\n    This CL cleans-up some tf.Example creation snippets, by reusing the convenient tf.train.Feature building functions in dataset_util.\r\n\r\n--\r\n209697893  by Zhichao Lu:\r\n\r\n    Do not overwrite num_epoch for eval input. This leads to errors in some cases.\r\n\r\n--\r\n209694652  by Zhichao Lu:\r\n\r\n    Sample boxes by jittering around the currently given boxes.\r\n\r\n--\r\n209550300  by Zhichao Lu:\r\n\r\n    `create_category_index_from_labelmap()` function now accepts `use_display_name` parameter.\r\n    Also added create_categories_from_labelmap function for convenience\r\n\r\n--\r\n209490273  by Zhichao Lu:\r\n\r\n    Check result_dict type before accessing image_id via key.\r\n\r\n--\r\n209442529  by Zhichao Lu:\r\n\r\n    Introducing the capability to sample examples for evaluation. This makes it easy to specify one full epoch of evaluation, or a subset (e.g. sample 1 of every N examples).\r\n\r\n--\r\n208941150  by Zhichao Lu:\r\n\r\n    Adding the capability of exporting the results in json format.\r\n\r\n--\r\n208888798  by Zhichao Lu:\r\n\r\n    Fixes wrong dictionary key for num_det_boxes_per_image.\r\n\r\n--\r\n208873549  by Zhichao Lu:\r\n\r\n    Reduce the number of HLO ops created by matmul_crop_and_resize.\r\n\r\n    Do not unroll along the channels dimension. Instead, transpose the input image dimensions, apply tf.matmul and transpose back.\r\n\r\n    The number of HLO instructions for 1024 channels reduce from 12368 to 110.\r\n\r\n--\r\n208844315  by Zhichao Lu:\r\n\r\n    Add an option to use tf.non_maximal_supression_padded in SSD post-process\r\n\r\n--\r\n208731380  by Zhichao Lu:\r\n\r\n    Add field in box_predictor config to enable mask prediction and update builders accordingly.\r\n\r\n--\r\n208699405  by Zhichao Lu:\r\n\r\n    This CL creates a keras-based multi-resolution feature map extractor.\r\n\r\n--\r\n208557208  by Zhichao Lu:\r\n\r\n    Add TPU tests for Faster R-CNN Meta arch.\r\n\r\n    * Tests that two_stage_predict and total_loss tests run successfully on TPU.\r\n    * Small mods to multiclass_non_max_suppression to preserve static shapes.\r\n\r\n--\r\n208499278  by Zhichao Lu:\r\n\r\n    This CL makes sure the Keras convolutional box predictor & head layers apply activation layers *after* normalization (as opposed to before).\r\n\r\n--\r\n208391694  by Zhichao Lu:\r\n\r\n    Updating visualization tool to produce multiple evaluation images.\r\n\r\n--\r\n208275961  by Zhichao Lu:\r\n\r\n    This CL adds a Keras version of the Convolutional Box Predictor, as well as more general infrastructure for making Keras Prediction heads & Keras box predictors.\r\n\r\n--\r\n208275585  by Zhichao Lu:\r\n\r\n    This CL enables the Keras layer hyperparameter object to build a dedicated activation layer, and to disable activation by default in the op layer construction kwargs.\r\n\r\n    This is necessary because in most cases the normalization layer must be applied before the activation layer. So, in Keras models we must set the convolution activation in a dedicated layer after normalization is applied, rather than setting it in the convolution layer construction args.\r\n\r\n--\r\n208263792  by Zhichao Lu:\r\n\r\n    Add a new SSD mask meta arch that can predict masks for SSD models.\r\n    Changes including:\r\n     - overwrite loss function to add mask loss computation.\r\n     - update ssd_meta_arch to handle masks if predicted in predict and postprocessing.\r\n\r\n--\r\n208000218  by Zhichao Lu:\r\n\r\n    Make FasterRCNN choose static shape operations only in training mode.\r\n\r\n--\r\n207997797  by Zhichao Lu:\r\n\r\n    Add static boolean_mask op to box_list_ops.py and use that in faster_rcnn_meta_arch.py to support use_static_shapes option.\r\n\r\n--\r\n207993460  by Zhichao Lu:\r\n\r\n    Include FGVC detection models in model zoo.\r\n\r\n--\r\n207971213  by Zhichao Lu:\r\n\r\n    remove the restriction to run tf.nn.top_k op on CPU\r\n\r\n--\r\n207961187  by Zhichao Lu:\r\n\r\n    Build the first stage NMS function in the model builder and pass it to FasterRCNN meta arch.\r\n\r\n--\r\n207960608  by Zhichao Lu:\r\n\r\n    Internal Change.\r\n\r\n--\r\n207927015  by Zhichao Lu:\r\n\r\n    Have an option to use the TPU compatible NMS op cl/206673787, in the batch_multiclass_non_max_suppression function. On setting pad_to_max_output_size to true, the output nmsed boxes are padded to be of length max_size_per_class.\r\n\r\n    This can be used in first stage Region Proposal Network in FasterRCNN model by setting the first_stage_nms_pad_to_max_proposals field to true in config proto.\r\n\r\n--\r\n207809668  by Zhichao Lu:\r\n\r\n    Add option to use depthwise separable conv instead of conv2d in FPN and WeightSharedBoxPredictor. More specifically, there are two related configs:\r\n    - SsdFeatureExtractor.use_depthwise\r\n    - WeightSharedConvolutionalBoxPredictor.use_depthwise\r\n\r\n--\r\n207808651  by Zhichao Lu:\r\n\r\n    Fix the static balanced positive negative sampler's TPU tests\r\n\r\n--\r\n207798658  by Zhichao Lu:\r\n\r\n    Fixes a post-refactoring bug where the pre-prediction convolution layers in the convolutional box predictor are ignored.\r\n\r\n--\r\n207796470  by Zhichao Lu:\r\n\r\n    Make slim endpoints visible in FasterRCNNMetaArch.\r\n\r\n--\r\n207787053  by Zhichao Lu:\r\n\r\n    Refactor ssd_meta_arch so that the target assigner instance is passed into the SSDMetaArch constructor rather than constructed inside.\r\n\r\n--\r\n\r\nPiperOrigin-RevId: 212389173",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 19,
        "deletions": 29,
        "changed_files": 1,
        "created_at": "2018-09-11T13:12:50Z",
        "closed_at": "2018-09-11T14:48:15Z",
        "merged_at": "2018-09-11T14:48:15Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2018-09-11T02:19:03Z",
        "closed_at": "2018-09-11T06:15:09Z",
        "merged_at": null,
        "body": "By doing this, we can also use python3 to run object_detection scripts without running error.\r\n\r\nSigned-off-by: Pei Zhang <changpei1982@gmail.com>",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2018-09-10T01:10:54Z",
        "closed_at": "2018-09-11T19:54:26Z",
        "merged_at": "2018-09-11T19:54:26Z",
        "body": "Fix issue where occasionally, \"ValueError: No JSON object could be decoded\" would be thrown.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-09-09T19:40:23Z",
        "closed_at": "2018-09-19T08:22:34Z",
        "merged_at": "2018-09-19T08:22:34Z",
        "body": "In object detection, load_image_into_numpy_array(image) raises ValueError when the given image is png format.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-09-08T15:07:06Z",
        "closed_at": "2018-09-11T17:52:10Z",
        "merged_at": "2018-09-11T17:52:10Z",
        "body": "General guidelines for Google Python Style Guide links to a deprecated style guide from google",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 19727,
        "deletions": 922,
        "changed_files": 46,
        "created_at": "2018-09-07T16:37:06Z",
        "closed_at": "2018-09-10T21:32:53Z",
        "merged_at": "2018-09-10T21:32:53Z",
        "body": "Updating the fivo codebase, moving files around and adding some new models, functionality, and tests.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 7642,
        "deletions": 0,
        "changed_files": 26,
        "created_at": "2018-09-07T16:21:32Z",
        "closed_at": "2018-09-11T18:03:19Z",
        "merged_at": "2018-09-11T18:03:19Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 7639,
        "deletions": 0,
        "changed_files": 26,
        "created_at": "2018-09-07T05:44:37Z",
        "closed_at": "2018-09-07T15:23:53Z",
        "merged_at": null,
        "body": "",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 19,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2018-09-07T02:49:36Z",
        "closed_at": "2018-11-28T08:12:24Z",
        "merged_at": null,
        "body": "don't use os.path.join for http url, add flag to not delete downloaded input file, so that it can be reused if needed.\r\n\r\nURL format doesn't depend on OS, shouldn't use os.path.join, otherwise will generate wrong format on windows, such as\r\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/00280\\HIGGS.csv.gz, and cause 404 error.",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 110,
        "deletions": 69,
        "changed_files": 5,
        "created_at": "2018-09-06T04:05:16Z",
        "closed_at": "2018-12-20T00:29:31Z",
        "merged_at": null,
        "body": "Combined the codes for cifar10 and cifar100 training and download datasets into a single file. ",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 0,
        "changed_files": 0,
        "created_at": "2018-09-05T22:12:11Z",
        "closed_at": "2018-09-06T03:56:37Z",
        "merged_at": null,
        "body": "Added the Cifar100 dataset builder and training for ResNet model in official/resnet.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 27,
        "deletions": 15,
        "changed_files": 4,
        "created_at": "2018-09-05T21:29:46Z",
        "closed_at": "2018-09-05T23:54:52Z",
        "merged_at": "2018-09-05T23:54:52Z",
        "body": "Moves the tf.cast for tf.float16 to the input pipeline which is run on cpu and pipelined.  This seemed to have a consistent ~50 images/sec boost on 8xV100 FP16 with real imagenet data, which is a small 1% gain and logical.\r\n\r\nFYI,  ```tf.image.per_image_standardization(image)``` Returns tf.float32 even if passed a tf.float16 tensor thus the cast to tf.float16 must be done after preprocessing.  ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 7,
        "changed_files": 2,
        "created_at": "2018-09-05T21:04:24Z",
        "closed_at": "2018-09-05T23:34:00Z",
        "merged_at": "2018-09-05T23:34:00Z",
        "body": "The error \"Generation subprocess did not start correctly\" would occur if the async process started up after the main process checked for the subproc_alive file.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-09-05T09:59:36Z",
        "closed_at": "2018-09-07T02:49:49Z",
        "merged_at": null,
        "body": "Url format doesn't depend on OS, shouldn't use os.path.join, otherwise will generate wrong format on windows, such as \r\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/00280\\HIGGS.csv.gz, and cause 404 error.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-09-05T07:07:17Z",
        "closed_at": "2021-07-15T18:50:27Z",
        "merged_at": null,
        "body": "As the number of classes (which is generally less than 200) should perfectly fit in `int32`, there is no need to use an `int64` data type for prediction labels. \r\n\r\nAlso, this change should fix this [issue](https://github.com/tensorflow/models/issues/4278) while using the model in **tflite** or `toco`.\r\n\r\nDidn't use `uint8` instead of `int32`, because **argmax** expects only `int32` or `int64` datatype.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2018-09-04T23:34:16Z",
        "closed_at": "2018-09-28T21:35:42Z",
        "merged_at": "2018-09-28T21:35:41Z",
        "body": "I updated the lr schedule to match the original ResNet paper.  The example is using 50K training images rather than the 45K used by the paper so the number of steps is different but the epochs is a close match.  I also changed the code to use use ResNet56 as the default from ResNet32 because it gets  93% and on a GTX-1080 the time to train is almost identical.  The paper trained for ~182 epochs, I found ~164 epochs was enough for the test but recognize 182 would be more official and did some runs of that length and the results end up similar.  If top_1 is not 93% at 164 it will not be better at 182.  I also did not find a need to lower the learning rate, which was not in the original paper, again as was occurring in the previous defaults.  \r\n\r\nThis also **reduces the training time by 40-50%** by fixing lr and default num_epochs to train.\r\n\r\nI ran FP16 and FP32 tests that I think we could also include them in the README.\r\n\r\nmax (mean +/- std) over 5 runs single V100 bs=128\r\n   * FP32: .9344 (.9312 +/- .002)\r\n   * FP16 (mixed-precision): .9344 (.9312 +/- .002)\r\n\r\nCommands:\r\n**FP32**\r\n```bash\r\npython -m official.resnet.cifar10_main --data_dir=/data/cifar10 --hooks ExamplesPerSecondHook --num_gpus=1 --batch_size=128 --resnet_size=56 --model_dir=/tmp/resnet-56_fp32 --dtype=fp32 --train_epochs=164\r\n```\r\n**FP16 (mixed-precision)**\r\n```bash\r\npython -m official.resnet.cifar10_main --data_dir=/data/cifar10 --hooks ExamplesPerSecondHook --num_gpus=1 --batch_size=128 --resnet_size=56 --model_dir=/tmp/resnet-56_fp16 --dtype=fp16 --train_epochs=164\r\n```\r\n\r\nThere is not a huge performance improvement for FP16 due to the very small size of the data and minimal compute required per step.\r\n\r\n\r\n\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-09-04T18:49:23Z",
        "closed_at": "2022-05-16T04:39:09Z",
        "merged_at": null,
        "body": "At the moment, when the model dir is set to an S3 prefix, metrics logging is flaky (the eval dir checkpoints show up late or never). We can fix this issue by flushing the `summary_writer` after each evaluation.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 31,
        "deletions": 12,
        "changed_files": 5,
        "created_at": "2018-09-03T13:25:46Z",
        "closed_at": "2018-09-06T06:57:37Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 0,
        "changed_files": 0,
        "created_at": "2018-09-03T08:36:37Z",
        "closed_at": "2019-02-26T11:22:29Z",
        "merged_at": null,
        "body": "Continuous eval needs to read the model to be evaluated from\r\ncheckpoint_dir instead of model_dir (where evaluation output is written)\r\n\r\nFixes #5208",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-09-03T04:53:03Z",
        "closed_at": "2021-09-16T01:01:50Z",
        "merged_at": null,
        "body": "Moved object_detection vis_utils import in model_lib.py above eval_utils as matplotlib import has to be set to Agg to allow for headless. (current import order meant that matplotlib was not set correctly for headless).",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-09-02T15:54:38Z",
        "closed_at": "2018-09-20T18:10:31Z",
        "merged_at": "2018-09-20T18:10:31Z",
        "body": "Great job with the models! Here, I've fixed a typo! :)",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 44,
        "deletions": 23,
        "changed_files": 5,
        "created_at": "2018-09-02T15:42:55Z",
        "closed_at": "2018-09-04T23:56:34Z",
        "merged_at": "2018-09-04T23:56:34Z",
        "body": "All numbers are form a DGX-1 with V100s\r\n\r\ntl;dr; I improved synthetic data performance from ~4,800 images/sec to 5,500 images/sec  14.6% speedup on ResNetV1 FP16 maybe more with smaller models.\r\n\r\nThe current Synthetic data has a couple problems.  1) the dtype is set to float32 and is then cast on the GPU (which is something that needs changed for real data a well but is less problematic and I will do a PR for next) no matter what 2) it does not seem to have prefetch.  Both of these combine for a situation where real data is faster than synthetic data:  Real data ~5,200 images/sec ResNet V1 and ~4,800 images/sec synthetic data.  \r\n\r\nDuring my testing I found:\r\n\r\n- Change current code to tf.float16 and leave the tf.cast gets 5,273 images/sec\r\n- Change current code to tf.float16 and remove tf.cast gest 5,329 images/sec.  I have doubts the unneeded cast has any cost in this scenario and could have been noise.  \r\n- Change the input_fn to my solution based on tf_cnn_benchmarks  5,534 images/sec\r\n\r\nThis solution still has the host to device copy, which I believe can only be removed with a custom dataset and I have some doubt it is worth it in the near-term.  \r\n\r\nFor followup work is to move the tf.cast to fp16 for real data as part of the input pipeline and then removing the tf.cast in resnet_run_loop had a small but seemingly consistent improvement.  It also seems more valid and keeps work off the GPU.  \r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 4,
        "changed_files": 3,
        "created_at": "2018-09-01T20:22:50Z",
        "closed_at": "2018-09-04T23:56:56Z",
        "merged_at": "2018-09-04T23:56:56Z",
        "body": "Changes the default ResNet to use to v1 from v2 and lowers the epochs from 100 to 90.  \r\n\r\nFYI: I feel less great about the README update and it could use more tweaks to tell the story completely and concisely.  The topic is confusing and I do not want to gloss over it.\r\n\r\nResNet50v1 (which is really v1.5 in this example) trains to 76.2+% top_1  and 93%+ top_5 at 81 epochs most times if not always and \"always\" at 90 epochs.  90 epochs is also the general standard without using different sized images and learning rate tweaks.  I short, it is a nice test.\r\n\r\nThe purpose of this is also to have the internal CI tests change from v2 to v1 with 90 epochs, which is more useful than running V2 for 100 epochs.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-08-29T15:59:37Z",
        "closed_at": "2018-09-06T07:00:01Z",
        "merged_at": null,
        "body": "\u2026te()\r\n\r\nunicode() doesn't exist in python 3, and when executed, a NameError exception is thrown.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-08-28T17:05:57Z",
        "closed_at": "2018-08-28T18:15:08Z",
        "merged_at": "2018-08-28T18:15:08Z",
        "body": "Adding a note on fairness to the wide and deep model README.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 60,
        "deletions": 19,
        "changed_files": 2,
        "created_at": "2018-08-24T21:46:43Z",
        "closed_at": "2018-08-29T16:36:59Z",
        "merged_at": "2018-08-29T16:36:59Z",
        "body": "Hi All,\r\n\r\nIn this PR, the distribution strategy is added to the benchmark of keras application model. Could you help to review it? Thanks!\r\n\r\nI will also submit the CL to run the benchmark on Kokoro, so we can get some numbers soon.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 29,
        "deletions": 10,
        "changed_files": 1,
        "created_at": "2018-08-24T19:11:14Z",
        "closed_at": "2018-08-27T22:12:09Z",
        "merged_at": "2018-08-27T22:12:09Z",
        "body": "This PR slightly changes the ResNet control flow to address two issues:\r\n\r\n1) It is not currently straightforward to simply perform evaluation, which makes it difficult to assess and validate checkpoints.\r\n\r\n2) Training does not behave intuitively when `--epochs_between_evals` does not evenly divide `--train_epochs`.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 628,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-08-24T18:35:21Z",
        "closed_at": "2018-08-27T20:41:50Z",
        "merged_at": null,
        "body": "Formula in code for L2 weight regularization: https://github.com/keras-team/keras/blob/23bdd4d417f0fda90465e3ab612c682e1d207ee3/keras/regularizers.py#L42",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 18,
        "changed_files": 1,
        "created_at": "2018-08-24T09:37:42Z",
        "closed_at": "2018-08-28T23:08:07Z",
        "merged_at": "2018-08-28T23:08:07Z",
        "body": "I tried to run distributed tensorflow with mnist but it did not work. So I fixed such problem with MirroredStrategy API.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-08-24T09:09:03Z",
        "closed_at": "2018-08-27T19:09:10Z",
        "merged_at": "2018-08-27T19:09:10Z",
        "body": "The Object_detection_tutorial is compatible with TensorFlow 1.10 but the check says that version 1.4 is newer than version 1.10. This change uses the StrictVersion check from [PEP-0386 ](https://www.python.org/dev/peps/pep-0386/) to ensure good version checks in the future.\r\n\r\nSolves #5069, #3033\r\n\r\nI have also changed `tensorflow` to `TensorFlow` in the error message. ",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 30,
        "deletions": 19,
        "changed_files": 2,
        "created_at": "2018-08-23T22:30:18Z",
        "closed_at": "2018-09-04T23:57:36Z",
        "merged_at": null,
        "body": "I can can see where this flag might not fit into base.  \r\n\r\nI only half care about this as a feature but I did it and found it useful.  If there is an easy way to make this work and fit with your philogphy that is great.  If not, moving on.\r\n\r\nSide Note:\r\nI really think it should eval either all the checkpoints in the dir or really better and more concise let you specify a specific checkpoint rather than the model directory.  I didn't try it so I am look like a fool but I suspect it works like tf_cnn_bench does and it uses some util class to find which checkpoint to load, what we did is if the path contains what looks like a checkpoint file then don't guess just us it.  ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 16,
        "deletions": 9,
        "changed_files": 2,
        "created_at": "2018-08-23T22:16:54Z",
        "closed_at": "2018-08-25T00:43:38Z",
        "merged_at": "2018-08-25T00:43:38Z",
        "body": "Add top 5 accuracy to resnet eval",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 25,
        "deletions": 29,
        "changed_files": 4,
        "created_at": "2018-08-23T21:59:32Z",
        "closed_at": "2018-08-27T22:10:52Z",
        "merged_at": "2018-08-27T22:10:52Z",
        "body": "Using this LR improve accuracy significantly for larger batch sizes and has no harm to small batch sizes, and gets a higher accuracy with less epochs than the pre-trained models presented.  Testing was focused on ResNetV1.5 which the official code lists as version=1.\r\n\r\nA higher base lr (.128) is preferred and will be in another PR.  Results below from this change.\r\n\r\nGPUs | dtype | batch_size | system | top_1 (90 epochs) | top_5 (90 epochs) | top_1 (85 epochs) | top_1 (81 epochs) | command | initial_lr\r\n-- | -- | -- | -- | -- | -- | -- | -- | -- | --\r\n8xV100 | fp16 | 2048 | gce | 0.7614 | \u00a0 | 0.7612 | N/A | python -m  official.resnet.imagenet_main --data_dir=/data/imagenet --resnet_version=1 --intra_op_parallelism_threads=1 --num_gpus=8 --tf_gpu_thread_mode=gpu_shared  --model_dir=/workspace/model_ckpt/test_0_128_2 --dtype=fp16 --batch_size=2048 --epochs_between_evals=5 --train_epochs=90 | 0.1\r\n8xV100 | fp16 | 2048 | gce | 0.76396 | \u00a0 | 0.7633 | N/A | python -m  official.resnet.imagenet_main --data_dir=/data/imagenet --resnet_version=1 --intra_op_parallelism_threads=1 --num_gpus=8 --tf_gpu_thread_mode=gpu_shared  --model_dir=/workspace/model_ckpt/test_0_128_2 --dtype=fp16 --batch_size=2048 --epochs_between_evals=5 --train_epochs=90 | 0.128\r\n8xV100 | fp32 | 1024 | gce | 0.7636 | \u00a0 | 0.7633 | 0.7625 | python -m  official.resnet.imagenet_main --data_dir=/data/imagenet --resnet_version=1 --intra_op_parallelism_threads=1 --num_gpus=8 --model_dir=/workspace/model_ckpt/test3 --dtype=fp32 --batch_size=1024 | 0.1\r\n\r\n",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-08-23T09:10:42Z",
        "closed_at": "2018-08-23T18:44:10Z",
        "merged_at": "2018-08-23T18:44:10Z",
        "body": "The bash script to submit training job for pets detection has runtime-version of 1.8. This will trigger `TypeError: non_max_suppression() got an unexpected keyword argument 'score_threshold'` on the Google Cloud since 1.8 and older does not support this keyword argument. Therefore, update this runtime version to 1.9, which is the most recent runtime version that is published on June 27, 2018. \r\n\r\nSee \r\nhttps://github.com/tensorflow/models/issues/5056\r\nhttps://cloud.google.com/ml-engine/docs/tensorflow/runtime-version-list",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-08-22T21:14:42Z",
        "closed_at": "2018-09-19T18:51:22Z",
        "merged_at": null,
        "body": "Hello good people of tensorflow models, \r\n\r\nChange:\r\nAdding missing method call `plt.show()` in the 'basic classification' example. \r\n\r\nReason: \r\nIt can be confusing for those who are running the examples without a Jupyter notebook.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-08-22T11:12:26Z",
        "closed_at": "2020-04-25T02:49:09Z",
        "merged_at": "2020-04-25T02:49:09Z",
        "body": "The URL of the script for downloading and converting ImageNet data to TFRecord format has changed. I update the URL.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 385,
        "deletions": 37,
        "changed_files": 6,
        "created_at": "2018-08-22T00:48:12Z",
        "closed_at": "2018-08-22T21:34:08Z",
        "merged_at": "2018-08-22T21:34:08Z",
        "body": "Thank you to @robieta for helping me find these issues, and for providng an algorithm for the `get_hit_rate_and_ndcg_mlperf` function.\r\n\r\nThis change causes every forked process to set a new seed, so that forked processes do not generate the same set of random numbers. This improves evaluation hit rates.\r\n\r\nAdditionally, it adds a flag, --ml_perf, that makes further changes so that the evaluation hit rate can match the MLPerf reference implementation.\r\n\r\nI ran 4 times with --ml_perf and 4 times without. Without --ml_perf, the highest hit rates achieved by each run were 0.6278, 0.6287, 0.6289, and 0.6241. With --ml_perf, the highest hit rates were 0.6353, 0.6356, 0.6367, and 0.6353.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 92,
        "deletions": 6330,
        "changed_files": 9,
        "created_at": "2018-08-21T20:54:39Z",
        "closed_at": "2018-08-27T17:49:16Z",
        "merged_at": "2018-08-27T17:49:16Z",
        "body": "These have all moved to https://github.com/tensorflow/docs/tree/master/site/en",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 12,
        "deletions": 5,
        "changed_files": 13,
        "created_at": "2018-08-21T15:44:58Z",
        "closed_at": "2020-04-17T06:44:50Z",
        "merged_at": null,
        "body": "Unicode decode error--   Issue  #5016",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-08-21T14:44:25Z",
        "closed_at": "2020-04-25T02:47:38Z",
        "merged_at": null,
        "body": "putting `import StrinIO` in try-except block with `except ImportError` ensures that the code runs in python2 and python3\r\n\r\nAuthor: Pinaki Nath Chowdhury <pinakinathc@gmail.com>",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-08-21T12:23:23Z",
        "closed_at": "2018-08-21T18:46:25Z",
        "merged_at": "2018-08-21T18:46:24Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-08-21T11:54:24Z",
        "closed_at": "2018-08-21T18:57:05Z",
        "merged_at": "2018-08-21T18:57:05Z",
        "body": "This one line change makes the notebook compatible with Python 2.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-08-21T11:47:57Z",
        "closed_at": "2018-08-29T15:59:07Z",
        "merged_at": null,
        "body": "### Before\r\n\r\n![before](https://user-images.githubusercontent.com/6289998/44399665-c0e3ec80-a58b-11e8-88c2-28a2ef391792.png)\r\n\r\n### After\r\n\r\n![image](https://user-images.githubusercontent.com/6289998/44399656-baee0b80-a58b-11e8-8017-778379980fa8.png)\r\n\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-08-21T09:40:26Z",
        "closed_at": "2018-10-26T14:08:43Z",
        "merged_at": null,
        "body": "As discussed in https://github.com/tensorflow/models/issues/5054, I'm opening a initial PR. I've only edited the readme file, but further changes will be necessary.\r\n\r\nThe problem I'm addressing is that the link of Inception V2 in the readme file refers [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167). The implemented [network architecture](https://github.com/tensorflow/models/blob/master/research/slim/nets/inception_v2.py) has the same output sizes as in the paper (p. 11), so I think that the reference to the paper is correct. It is named BN-Inception.\r\n\r\nInception V2 (with V3) was introduced in [Rethinking the Inception Architecture for Computer Vision](https://arxiv.org/abs/1512.00567) and it has a different network architecture compared to the implemented one (see p. 6).\r\n\r\nTherefore I think that the name of the network architecture in the repository should be changed from Inception V2 to BN-Inception.",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-08-21T06:37:42Z",
        "closed_at": "2022-03-28T03:46:52Z",
        "merged_at": null,
        "body": " We should set  fine_tune_batch_norm to false while the  train_batch_size is 4  to avoid the OOM of  the limited resource at hand.The details can be found in the file of train.py:\r\n>  Set to True if one wants to fine-tune the batch norm parameters in DeepLabv3.\r\n    Set to False and use small batch size to save GPU memory.\r\n    flags.DEFINE_boolean('fine_tune_batch_norm', False,\r\n                     'Fine tune the batch norm parameters or not.')\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 23,
        "deletions": 8,
        "changed_files": 3,
        "created_at": "2018-08-20T22:00:54Z",
        "closed_at": "2021-06-05T21:03:57Z",
        "merged_at": null,
        "body": "This pull request adds support for specifying class weights as below,\r\n\r\n```\r\n_CUSTOM_SEG_INFORMATION = DatasetDescriptor(\r\n    splits_to_sizes={\r\n        'train': 8643,\r\n        'trainval': 10803,\r\n        'val': 2160,\r\n    },\r\n    num_classes=5,\r\n    ignore_label=255,\r\n    label_weights=[1.0, 5.0, 30.0, 10.0, 5.0],\r\n)\r\n```\r\n\r\nPlease have a look and let me know if any change required.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-08-20T17:05:09Z",
        "closed_at": "2018-08-20T20:36:05Z",
        "merged_at": "2018-08-20T20:36:05Z",
        "body": "There is a unicode character that makes flags a bit nicer, but breaks `--helpfull` if python can't find utf-8. This PR just removes that character.\r\n\r\ncc @tfboyd ",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 10,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2018-08-20T16:32:13Z",
        "closed_at": "2022-11-23T23:48:09Z",
        "merged_at": null,
        "body": "I think eval_interval_secs is originally designed to be passed as one of EvalSpec parameter - throttle_secs, which defines the frequency of saving checkpoint and evaluation.\r\nBecause setting eval_interval_secs is not working, there is no other way to change the frequency of evaluation.\r\nTherefore, I simply parse eval_interval_secs from eval config and pass it to EvalSpec as a parameters to complete this functionality.",
        "comments": 10
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2018-08-18T15:02:06Z",
        "closed_at": "2018-08-19T04:41:45Z",
        "merged_at": "2018-08-19T04:41:45Z",
        "body": "Updated the arg for plt.grid to avoid the matlab deprecation warning message. Thought it would help beginners (like myself :) ) when working through the keras tutorials/samples.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-08-17T17:21:11Z",
        "closed_at": "2020-04-17T06:45:25Z",
        "merged_at": null,
        "body": "Add a note pointing to pointer-generator network.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-08-17T01:33:34Z",
        "closed_at": "2019-03-18T23:18:20Z",
        "merged_at": null,
        "body": "This is a hotfix for an issue with sed on osX brought to attention by [#5033](https://github.com/tensorflow/models/issues/5033). Although it isn't very readable have semi-colon imports the files are packaged into a gzip for use in internals on cloud ml engine.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 9,
        "changed_files": 2,
        "created_at": "2018-08-16T17:16:53Z",
        "closed_at": "2018-08-16T20:56:28Z",
        "merged_at": "2018-08-16T20:56:28Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 15,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-08-16T11:03:54Z",
        "closed_at": "2022-05-16T04:38:54Z",
        "merged_at": null,
        "body": "I think there is a bug in NasNet normal and reduction cell: used_hiddenstates does not match the authors article. The current code introduces additional skip connections from prev prev cell to concat for normal cell and from second block to concat for reduction cell that are not present in the paper. This claim is easily verified by observing the graph of the provided checkpoint in tensorboard.\r\n\r\nThere are 3 possibilities:\r\n- The schemas in the paper are wrong and should be fixed. Minor changes in the text should describe the motivations for these additional connections.\r\n- The code is not correct and the present request can be used to fix it.\r\n- I am missing something and it would be helpful if someone could clarify for me.\r\n\r\nIn case the code is wrong, provided checkpoints should be fixed.",
        "comments": 8
    },
    {
        "merged": false,
        "additions": 11,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-08-16T01:23:30Z",
        "closed_at": "2018-09-24T21:39:21Z",
        "merged_at": null,
        "body": "This allows one to use DeepLab on a custom dataset whose details are supplied via the environment.  The motivating use case is when the dataset(s) is (are) built by a tool rather than being a one-off with a well-known name.",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 155,
        "deletions": 188,
        "changed_files": 1,
        "created_at": "2018-08-15T20:27:01Z",
        "closed_at": "2018-08-16T21:37:10Z",
        "merged_at": "2018-08-16T21:37:10Z",
        "body": "While going through the basic classification tutorial I found myself wanting to see the prediction arrays. How confident was the prediction? When it was right, was it quite confident? When it made a mistake, was it confident or were two options a contender? To help me see that, I added a few charts to the tutorial. \r\n\r\nFor a single image, I made charts like this to accompany the images. \r\n\r\n![mj6ndbxm901](https://user-images.githubusercontent.com/7397271/44171108-40565500-a08e-11e8-8035-56510520fa5d.png)\r\n\r\nIt some cases, there are other labels which the model deems somewhat likely, which we can see in the grey bars. \r\n\r\n![ij6c8ngbxtr](https://user-images.githubusercontent.com/7397271/44171120-4815f980-a08e-11e8-953d-25389f59c925.png)\r\n\r\nWhen the prediction is wrong, it looks like this:\r\n\r\n![fhap6vj630u](https://user-images.githubusercontent.com/7397271/44171137-4f3d0780-a08e-11e8-8a58-c7eab18baff2.png)\r\n\r\nI can also show these charts for the first X images. \r\n\r\n![usow2ifxkxa](https://user-images.githubusercontent.com/7397271/44171151-56fcac00-a08e-11e8-8a8c-7fb9098e2cc3.png)\r\n\r\nColab to run [here](https://colab.sandbox.google.com/drive/1mNr12BN2BreC7i0sSKcYpVD26AOjdUXT#scrollTo=hQlnbqaw2Qu_).\r\n\r\nNote - there were a few places where it was changing per-cell colab settings related to autoexec. I just left these in the pr for now, but feel welcome to remove. \r\n\r\nThe main commit is ab347ae. The others were a merge from a branch to main on my repo, and accidentally saving a copy in the wrong place (and undoing it). Let me know if I should try to remove these before merging? ",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2018-08-15T14:16:21Z",
        "closed_at": "2018-08-16T23:39:07Z",
        "merged_at": "2018-08-16T23:39:07Z",
        "body": "In order for the order of the files to be deterministic, in `tf.data.Dataset.list_files(..., shuffle)`, shuffle needs to be True, otherwise different iterator inits will yield different file orders, and, as such, different dataset orders",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-08-15T10:01:17Z",
        "closed_at": "2021-12-16T00:23:22Z",
        "merged_at": null,
        "body": "Some user still prefers to run concurrently legacy/train.py and legacy/eval.py instead of /model_main.py. What happens is that both files cannot be executed at the same time because the first one saturates the GPU memory. With just these 3 loc it is possible to avoid this problem.\r\nAt this [link](https://gist.github.com/giacomobartoli/694986a2d9a0d89bd9a92d58a3c1743f) you can find a gist of this reported error.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-08-15T00:30:28Z",
        "closed_at": "2018-08-15T21:57:58Z",
        "merged_at": "2018-08-15T21:57:58Z",
        "body": "Added a pointer to a Colab that illustrates how to use the public AudioSet models to generate embeddings for user-specified sounds.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-08-14T20:47:59Z",
        "closed_at": "2018-08-14T22:17:38Z",
        "merged_at": "2018-08-14T22:17:38Z",
        "body": "Tensorflow raises an error when tf_inspect.getfullargspec is called on a functools.partial in Python 2.X. This issue would be hit during the eval stage of the Transformer TPU model. This change replaces the call to functools.partial with a lambda to work around the issue.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-08-14T19:06:04Z",
        "closed_at": "2020-04-25T02:25:40Z",
        "merged_at": null,
        "body": "In this PR , we added following parameters to improve the training and evaluation\r\nout-of-box experiences on CPU and make it easier for users to control the parallelism \r\non CPU for slim models: \r\n 1. inter_op_parallelism_threads\r\n 2. intra_op_parallelism_threads\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2018-08-14T04:53:12Z",
        "closed_at": "2018-08-17T06:24:38Z",
        "merged_at": "2018-08-17T06:24:38Z",
        "body": "change flag name to checkpoint_dir according to the variable name\r\nused by the checkpoint_utils within tensorflow python framework.\r\n\r\nThe important point is that when run the run_eval script, an error\r\noccurs due to the different flag name.\r\n\r\nSigned-off-by: MyungSung Kwak <yesmung@gmail.com>",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-08-13T11:55:01Z",
        "closed_at": "2020-04-24T07:19:02Z",
        "merged_at": null,
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-08-13T07:44:25Z",
        "closed_at": "2018-08-13T14:30:36Z",
        "merged_at": "2018-08-13T14:30:36Z",
        "body": "There is a typing error.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-08-13T02:39:30Z",
        "closed_at": "2020-04-24T07:26:34Z",
        "merged_at": "2020-04-24T07:26:34Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-08-11T07:40:52Z",
        "closed_at": "2019-02-14T10:20:04Z",
        "merged_at": null,
        "body": "An inference graph file should be opened as a binary file. Please fix a bug reported here. https://github.com/tensorflow/models/issues/2892 , https://github.com/tensorflow/models/issues/3772 and https://github.com/tensorflow/models/issues/3903 .",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2018-08-11T00:03:59Z",
        "closed_at": "2020-04-24T05:57:06Z",
        "merged_at": null,
        "body": "Fixes #3382 and #2709",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 1199,
        "deletions": 1792,
        "changed_files": 4,
        "created_at": "2018-08-10T19:39:00Z",
        "closed_at": "2018-08-13T19:40:21Z",
        "merged_at": "2018-08-13T19:40:21Z",
        "body": "Clear output, move buttons to the top, shrink images, keep image aspect ratio, add plots during optimization.\r\n\r\nStaging:\r\n\r\nhttps://colab.research.google.com/github/MarkDaoust/models/blob/nst_fixes/research/nst_blogpost/4_Neural_Style_Transfer_with_Eager_Execution.ipynb\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2018-08-10T16:53:25Z",
        "closed_at": "2018-08-30T16:18:10Z",
        "merged_at": "2018-08-30T16:18:10Z",
        "body": "- fixed entropy sign \r\n- changed entropy implementation for numeric stability",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2018-08-10T12:43:13Z",
        "closed_at": "2020-04-24T05:55:23Z",
        "merged_at": null,
        "body": "Thank you for open sourcing your great work! However, the code have some problems.\r\nIt depends on a binary file that does not work on different architectures (ex. MacOS).\r\nI also found problem in creating TFRecords, and  I fixed them.\r\n\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-08-10T00:29:03Z",
        "closed_at": "2020-04-24T19:12:04Z",
        "merged_at": "2020-04-24T19:12:04Z",
        "body": "Added `axis=1` for reconstruction error calculation. This will avoid taking the sum of cost so that the training objective will no longer be batch-size dependent.\r\n\r\nFixes #2243",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 63,
        "deletions": 6,
        "changed_files": 6,
        "created_at": "2018-08-09T21:47:13Z",
        "closed_at": "2018-08-14T19:53:19Z",
        "merged_at": "2018-08-14T19:53:19Z",
        "body": "This is an extension of [this PR](https://github.com/tensorflow/models/pull/5036). I opened a new pull request b/c my previous commits were done without a configured gitconfig",
        "comments": 12
    },
    {
        "merged": true,
        "additions": 32,
        "deletions": 4,
        "changed_files": 4,
        "created_at": "2018-08-09T19:38:04Z",
        "closed_at": "2018-08-15T22:46:29Z",
        "merged_at": "2018-08-15T22:46:29Z",
        "body": "--inter_op_parallelism_threads and --intra_op_parallelism_threads are two optional flags to experiment with.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 45,
        "deletions": 7,
        "changed_files": 3,
        "created_at": "2018-08-08T23:59:55Z",
        "closed_at": "2018-08-09T21:48:22Z",
        "merged_at": null,
        "body": "warm start a resent with all but the dense layer and only update the final layer weights when fine tuning",
        "comments": 10
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-08-08T21:39:20Z",
        "closed_at": "2018-10-03T06:48:09Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 3102,
        "deletions": 1390,
        "changed_files": 59,
        "created_at": "2018-08-07T21:34:59Z",
        "closed_at": "2018-08-08T02:00:27Z",
        "merged_at": "2018-08-08T02:00:27Z",
        "body": " - Uses the new non_max_suppression op in tf 1.9 with extra score_threshold argument in post processing, so that data flow will not jump between CPU and GPU back and forth.\r\n - Fixes the tensor slicing [issue](https://github.com/tensorflow/tensorflow/issues/21320) when max_number_of_boxes is less than number of groundtruth boxes.",
        "comments": 11
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-08-07T20:57:28Z",
        "closed_at": "2018-10-03T15:22:34Z",
        "merged_at": null,
        "body": "Added fine_tune_checkpoint_type for fine-tuning from a checkpoint. \r\nhttps://github.com/tensorflow/models/issues/4940",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-08-07T11:17:55Z",
        "closed_at": "2018-08-07T16:59:00Z",
        "merged_at": "2018-08-07T16:59:00Z",
        "body": "Fixed the constant extension length which assumes extensions are always of length 3 but fails for other lengths. eg. for file types **tiff**.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-08-06T14:51:04Z",
        "closed_at": "2018-08-06T17:52:22Z",
        "merged_at": null,
        "body": "Fix invalid attribute name while updating eval steps.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-08-03T22:27:02Z",
        "closed_at": "2018-08-04T02:00:45Z",
        "merged_at": "2018-08-04T02:00:45Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 38,
        "deletions": 93,
        "changed_files": 1,
        "created_at": "2018-08-03T20:09:53Z",
        "closed_at": "2018-08-13T20:49:43Z",
        "merged_at": "2018-08-13T20:49:43Z",
        "body": "Add some plots to final cells.\r\n\r\nStaging: https://colab.research.google.com/github/MarkDaoust/models/blob/add-regression-plots/samples/core/tutorials/keras/basic_regression.ipynb",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-08-02T15:07:12Z",
        "closed_at": "2018-08-03T20:42:57Z",
        "merged_at": "2018-08-03T20:42:57Z",
        "body": "`iteritems()` was removed from python3. `items()` does the same functionality so changing it will work in both python2 and python3. The only difference as far as I know is `iteritems()` returns a generator where `items` returns a list. But for this this code it will not make any difference where we are just changing the key of the dict to a string.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-08-02T06:30:28Z",
        "closed_at": "2020-04-25T02:20:54Z",
        "merged_at": "2020-04-25T02:20:54Z",
        "body": "- Update directory path with Tensorflow directoy folder: tensorflow/models/research/\r\n- Add option to refresh source ~/.bashrc",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-08-02T01:45:58Z",
        "closed_at": "2018-08-02T19:52:19Z",
        "merged_at": "2018-08-02T19:52:19Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-08-01T19:05:50Z",
        "closed_at": "2020-04-24T07:04:15Z",
        "merged_at": null,
        "body": "Change vocab_size from 33708 to 33945 in models/official/transformer/model/model_params.py\r\nThe original vocab_size causes InvalidArgumentError when training Transformer using CPU.",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-08-01T17:06:23Z",
        "closed_at": "2020-04-25T02:18:47Z",
        "merged_at": null,
        "body": "Fixed the path for fsns dataset (DEFAULT_DATASET_DIR) on windows . \r\n\r\nThe previous code would create an error : \r\n\r\n\"C:\\Users\\DELL\\Anaconda3\\envs\\python35DL\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 519, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.NotFoundError: NewRandomAccessFile failed to Create/Open .. The system cannot find the path specified .\r\n\r\nAbove changes have fixed this error. \r\n\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 555,
        "deletions": 0,
        "changed_files": 5,
        "created_at": "2018-08-01T12:18:27Z",
        "closed_at": "2020-04-24T06:56:49Z",
        "merged_at": null,
        "body": "Fixed #3001\r\nthe broken sample code [here](https://github.com/tensorflow/models/blob/master/research/syntaxnet/g3doc/universal.md) is now valid and runnable.",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 5062,
        "deletions": 2175,
        "changed_files": 80,
        "created_at": "2018-08-01T00:28:09Z",
        "closed_at": "2018-08-01T18:13:44Z",
        "merged_at": "2018-08-01T18:13:44Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-07-31T21:52:54Z",
        "closed_at": "2018-07-31T23:34:08Z",
        "merged_at": "2018-07-31T23:34:08Z",
        "body": "Previously the NCF test waited 5 seconds for the generation subprocess to open and signal that it is alive. However this turned out not to be enough in some cases.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-07-31T19:23:09Z",
        "closed_at": "2020-04-24T06:46:16Z",
        "merged_at": "2020-04-24T06:46:16Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-07-31T03:25:51Z",
        "closed_at": "2019-02-23T19:56:25Z",
        "merged_at": null,
        "body": "to solve ssd_resnet_50_v1_fpn training problems: not available in checkpoint #4940 \r\nupdate var_name",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-07-31T00:30:55Z",
        "closed_at": "2018-07-31T16:47:38Z",
        "merged_at": "2018-07-31T16:47:38Z",
        "body": "Sorry for the extra pr, just needed to add a readme ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-07-30T16:58:28Z",
        "closed_at": "2018-08-01T00:07:45Z",
        "merged_at": "2018-08-01T00:07:45Z",
        "body": "Fix broken json.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2018-07-30T15:06:33Z",
        "closed_at": "2018-07-30T16:53:34Z",
        "merged_at": "2018-07-30T16:53:34Z",
        "body": "Removed the conditional over distributed strategies when computing metrics.\r\nMetrics are now computed even when distributed strategies are used.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1767,
        "deletions": 944,
        "changed_files": 18,
        "created_at": "2018-07-30T01:27:07Z",
        "closed_at": "2018-07-30T21:33:16Z",
        "merged_at": "2018-07-30T21:33:16Z",
        "body": "This PR moves data file generation into a side process, replaces lots of serial code with vectorized equivalents, and updates the MLPerf run scripts.\r\n\r\n(https://github.com/tensorflow/models/issues/4865) Improved shuffling helps accuracy significantly.\r\n(https://github.com/tensorflow/models/issues/4787) I observed a max memory use of 10.5 GB while testing this branch, so this should address the OOM errors occurring in master.\r\n\r\n__CC__\r\n@petermattson \r\n@reedwm \r\n@tayo\r\n@codyaustun\r\n@christ1ne",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 3903,
        "deletions": 2051,
        "changed_files": 65,
        "created_at": "2018-07-29T22:18:15Z",
        "closed_at": "2018-08-01T00:13:30Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2018-07-29T17:45:27Z",
        "closed_at": "2018-07-30T13:52:48Z",
        "merged_at": "2018-07-30T13:52:48Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2018-07-29T08:48:42Z",
        "closed_at": "2018-07-30T19:49:44Z",
        "merged_at": null,
        "body": "",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2018-07-29T07:43:06Z",
        "closed_at": "2018-07-30T15:08:32Z",
        "merged_at": null,
        "body": "The order in which metrics were computed for distributed strategies was incorrect and had to interchanged.\r\n\r\nError with regards to data_format was also fixed. This was mentioned in a separate pull request.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 19,
        "deletions": 20,
        "changed_files": 1,
        "created_at": "2018-07-28T12:42:47Z",
        "closed_at": "2018-07-30T14:02:48Z",
        "merged_at": "2018-07-30T14:02:48Z",
        "body": "Bugs fixed:\r\n * replaced the fizzbuzz call whose signature no longer matched\r\n * remove the Flatter layer which seems to be buggy\r\n\r\nNote: is there a way to include external colabs into tests?",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 11,
        "deletions": 22,
        "changed_files": 1,
        "created_at": "2018-07-27T06:04:38Z",
        "closed_at": "2020-04-24T05:53:56Z",
        "merged_at": null,
        "body": "This PR allows exported models to be fed with batches of images for inference, e.g.\r\n`    feed_dict = { \"ImageTensor:0\": [ image0, image1, image2, ... ] }`\r\nInference times for batches of size 1 are unaffected.\r\n\r\nSorry for the mess of commits -- I had to sync this to upstream/master since I had accidentally used dheera/master for another pull request in-progress and created another branch for this particular PR which is separate. This pull request contains only the code necessary for the batch inference. The only file changed should be export_model.py (see the Files changed section)",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1284,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2018-07-26T22:25:16Z",
        "closed_at": "2018-08-02T18:59:12Z",
        "merged_at": "2018-08-02T18:59:12Z",
        "body": "Corresponding blog post can be found [here](https://docs.google.com/document/d/1y-ohUAMi2FjwgufFD0hudPt8A60TnHdysj4VcQrOxEA/edit#) ",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-07-26T03:53:34Z",
        "closed_at": "2018-09-06T06:46:47Z",
        "merged_at": null,
        "body": "run_inference_for_single_image",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-07-26T02:40:57Z",
        "closed_at": "2020-04-24T07:29:49Z",
        "merged_at": "2020-04-24T07:29:49Z",
        "body": "Plus minor formatting proposals",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 601,
        "deletions": 2,
        "changed_files": 7,
        "created_at": "2018-07-25T18:51:04Z",
        "closed_at": "2020-03-28T03:05:37Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-07-25T17:39:51Z",
        "closed_at": "2018-07-26T01:51:38Z",
        "merged_at": "2018-07-26T01:51:38Z",
        "body": "fix batch_size in transformer_main.py which causes ResourceExhaustedError: OOM during training Transformer models using models/official/transformer",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 257,
        "deletions": 19,
        "changed_files": 12,
        "created_at": "2018-07-25T16:49:11Z",
        "closed_at": "2018-07-26T19:30:17Z",
        "merged_at": "2018-07-26T19:30:17Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-07-25T10:20:24Z",
        "closed_at": "2018-07-25T13:41:42Z",
        "merged_at": null,
        "body": "The previous bibtex link resulted in a not found error.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 8388,
        "deletions": 180,
        "changed_files": 449,
        "created_at": "2018-07-25T01:01:41Z",
        "closed_at": "2019-01-18T05:40:29Z",
        "merged_at": null,
        "body": "**DO NOT MERGE**\r\n\r\nFollowing this issue https://github.com/tensorflow/models/issues/4887, I did a small test and everything seems to be ok to make the `object_detection` pip installable.\r\n\r\nProtobuf files compilation works during pip installation (with or without the `-e` option): https://github.com/hadim/models/blob/535affae95d5da46b8819989cb6e1123d169d245/research/object_detection/setup.py#L18\r\n\r\nThe PR is pretty big because I add to move the Python files into a subdirectory called `object_detection/`.\r\n\r\nI have also added an entry point for [`model_builder_test`](https://github.com/hadim/models/blob/535affae95d5da46b8819989cb6e1123d169d245/research/object_detection/setup.py#L62). Of course many more can be added if needed.\r\n\r\nNote also the addition of an [`environment.yml`](https://github.com/hadim/models/blob/535affae95d5da46b8819989cb6e1123d169d245/research/object_detection/environment.yml) file making the installation of deps much easier. People don't have to worry anymore about installing protobuf since it's available on Anaconda.\r\n\r\n**Important:** at the moment this PR breaks the `object_detection` API code and `model_builder_test` returns an error when it is run. This is because the `slim` package provided by tensorflow seems to be older than the one provided by this repo. I don't have for the moment a good solution for this. I can suggest two options:\r\n\r\n1. Update the Tensorflow slim API to match the one provided on this repo.\r\n2. Make the `slim` package provided by this repo \"official\" and release it on PyPi. Then it's just a matter of adding `slim` as a pip dependency.\r\n\r\n**This PR is mainly for demonstration purpose.**",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 11,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-07-24T23:41:10Z",
        "closed_at": "2021-12-16T00:22:58Z",
        "merged_at": null,
        "body": "Setting inter-op and intra-op thread settings will help improving the performance of CPU if Tensorflow is built with MKL support.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2260,
        "deletions": 0,
        "changed_files": 5,
        "created_at": "2018-07-24T20:59:17Z",
        "closed_at": "2018-07-31T23:39:51Z",
        "merged_at": "2018-07-31T23:39:51Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1688,
        "deletions": 0,
        "changed_files": 9,
        "created_at": "2018-07-24T19:24:03Z",
        "closed_at": "2018-07-26T23:13:33Z",
        "merged_at": "2018-07-26T23:13:32Z",
        "body": "KeypoingNet code related to our 3D keypoint discovery paper. More details are available at https://keypointnet.github.io.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-07-24T19:08:44Z",
        "closed_at": "2018-07-24T20:41:08Z",
        "merged_at": "2018-07-24T20:41:08Z",
        "body": "The following error doesn't occur with the above change in code.\r\n\r\nError: Argument must be a dense tensor: range(0, 3) - got shape [3], but wanted []\r\n\r\nThe range function on the vairable 'num_boundaries' should be a list! Please merge this request!",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1685,
        "deletions": 0,
        "changed_files": 9,
        "created_at": "2018-07-24T16:27:40Z",
        "closed_at": "2018-07-24T19:02:19Z",
        "merged_at": null,
        "body": "The code for our 3D keypoint discovery paper -- keypointnet (https://keypointnet.github.io)",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-07-24T11:54:05Z",
        "closed_at": "2018-07-30T07:22:44Z",
        "merged_at": null,
        "body": "Fixed an error where data of type 'channels_last' was not being correctly transformed to 'channels_first'.\r\n\r\n1. The if statement was incorrectly checking for the string 'channels_first' instead of checking for 'channels_last'.\r\n2. After transposing the data the variable self.data_format has to be updated to 'channels_first' to reflect the changes made.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 100,
        "deletions": 36,
        "changed_files": 7,
        "created_at": "2018-07-24T06:35:58Z",
        "closed_at": "2018-07-25T03:10:54Z",
        "merged_at": "2018-07-25T03:10:54Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 3716,
        "deletions": 0,
        "changed_files": 37,
        "created_at": "2018-07-24T06:20:42Z",
        "closed_at": "2020-04-24T05:10:29Z",
        "merged_at": null,
        "body": "-",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-07-24T02:56:29Z",
        "closed_at": "2018-09-06T07:07:55Z",
        "merged_at": null,
        "body": "When iou_threshold = 1.0, code will also do NMS but actually do nothing, as num_hard_examples == num_boxes. But this operation is very slow in CPU, and have a side effect on the train speed. So if iou_threshold = 1.0, we can simply skip the NMS operation.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4290,
        "deletions": 0,
        "changed_files": 40,
        "created_at": "2018-07-23T20:31:59Z",
        "closed_at": "2018-07-23T22:19:52Z",
        "merged_at": "2018-07-23T22:19:52Z",
        "body": "The code corresponds to the following paper:\r\n\r\nDeep Bayesian Bandits Showdown: An Empirical Comparison of Bayesian Deep Networks for Thompson Sampling (https://arxiv.org/abs/1802.09127), published in ICLR 2018.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2018-07-23T19:48:34Z",
        "closed_at": "2018-07-31T21:26:19Z",
        "merged_at": "2018-07-31T21:26:19Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2018-07-21T22:26:40Z",
        "closed_at": "2020-04-24T05:38:38Z",
        "merged_at": null,
        "body": "",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 192,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-07-21T12:51:06Z",
        "closed_at": "2019-02-23T19:38:17Z",
        "merged_at": null,
        "body": "Add a sample of  config, which has passed the test.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-07-21T00:18:38Z",
        "closed_at": "2018-07-23T22:28:20Z",
        "merged_at": "2018-07-23T22:28:20Z",
        "body": "float32 should be fine for mnist loss and accuracy metrics and float64\r\nis not available on TPUs.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 370,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-07-20T23:11:13Z",
        "closed_at": "2018-07-24T21:31:18Z",
        "merged_at": "2018-07-24T21:31:18Z",
        "body": "Created PR for a3c for cartpole blog post. ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2018-07-20T14:59:00Z",
        "closed_at": "2018-07-21T02:35:01Z",
        "merged_at": "2018-07-21T02:35:01Z",
        "body": "Correcting the comments to match the code.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-07-20T05:16:48Z",
        "closed_at": "2018-07-21T03:49:43Z",
        "merged_at": "2018-07-21T03:49:43Z",
        "body": "test data -> training data",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-07-20T00:54:55Z",
        "closed_at": "2020-04-25T23:26:58Z",
        "merged_at": null,
        "body": "",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 89836,
        "changed_files": 370,
        "created_at": "2018-07-19T16:31:29Z",
        "closed_at": "2018-08-10T17:38:11Z",
        "merged_at": "2018-08-10T17:38:11Z",
        "body": "cc @tombstone \r\n\r\nApologies for the clutter, and any confusion we may have caused.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 314,
        "deletions": 66,
        "changed_files": 1,
        "created_at": "2018-07-19T16:27:17Z",
        "closed_at": "2018-07-19T20:35:09Z",
        "merged_at": "2018-07-19T20:35:09Z",
        "body": "+ Use meaningful function names\r\n\r\nColab link to this PR:\r\n\r\nhttps://colab.research.google.com/github/markdaoust/models/blob/autograph/samples/core/guide/autograph.ipynb",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2018-07-19T01:49:53Z",
        "closed_at": "2018-07-19T17:00:15Z",
        "merged_at": "2018-07-19T17:00:15Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 45,
        "deletions": 18,
        "changed_files": 2,
        "created_at": "2018-07-18T21:50:18Z",
        "closed_at": "2018-07-20T16:47:28Z",
        "merged_at": "2018-07-20T16:47:28Z",
        "body": "Hi All,\r\n\r\nCould you help to review this PR? This PR is created to refine the keras model benchmark by:\r\n1) Use models_helper for synthetic dataset generation\r\n2) Add eager mode for keras model. \r\n\r\nSome notes about eager mode: to run with eager mode, the optimizer should be TF native; Also, currently eager mode and keras multi_gpu_model are not compatible. With eager mode enabled, only one GPU is used even multiple GPUs are provided.\r\n\r\nThanks,\r\nYanhui\r\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-07-18T20:08:04Z",
        "closed_at": "2018-07-19T18:28:19Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-07-18T18:44:13Z",
        "closed_at": "2018-07-20T19:35:29Z",
        "merged_at": "2018-07-20T19:35:29Z",
        "body": "Tiny bug: sometimes, when resuming an experiment, the experiment would resume right at a logging step, and would attempt to log even though there has not yet been any data stored, leading to a divide-by-zero.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-07-18T16:34:01Z",
        "closed_at": "2018-07-18T20:14:40Z",
        "merged_at": "2018-07-18T20:14:40Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-07-18T15:04:44Z",
        "closed_at": "2018-07-18T16:39:59Z",
        "merged_at": "2018-07-18T16:39:59Z",
        "body": "this won't even work in 1.10, so it will be a while before it should show up in guide/",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-07-18T13:45:16Z",
        "closed_at": "2020-04-25T01:14:44Z",
        "merged_at": null,
        "body": "The usage of the variable 'base_name' raise a NameError since it was never defined.\r\nThe value which 'base_name' is expected to have is contained in 'checkpoint_name' \r\nThe solution was to change the variable name 'base_name' to 'checkpoint_name'",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-07-18T09:58:43Z",
        "closed_at": "2021-01-26T05:10:54Z",
        "merged_at": null,
        "body": "Use same scope name as in https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md trained model weight file.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 163,
        "deletions": 252,
        "changed_files": 6,
        "created_at": "2018-07-18T06:16:30Z",
        "closed_at": "2018-07-20T23:10:46Z",
        "merged_at": "2018-07-20T23:10:46Z",
        "body": "- This is an update for the sentiment analysis model's pure Keras version.\r\n-- Converting it from the version using Tensorflow's estimator, as it has a issue that affects the accuracy of the model negatively.\r\n- The implementation is with the reference to paddle version.\r\n-- Adjustment of the hyperparameters was done to achieve the accuracy of ~90%",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 2034,
        "deletions": 548,
        "changed_files": 18,
        "created_at": "2018-07-17T20:51:36Z",
        "closed_at": "2018-07-27T18:06:13Z",
        "merged_at": null,
        "body": "Firstly, the branch name is misleading; this has nothing to do with file buffered datasets. This branch has gone a very different direction than I expected.\r\n\r\nSecondly, while I know that this is a very large PR, a lot of those lines are either documentation or machine generated files.\r\n\r\nSummary of changes:\r\n1) The TFRecords based data pipeline has been replaced by a tf.contrib.rpc.rpc() based one.\r\nhttps://github.com/tensorflow/models/tree/feat/file_buffered_datasets/official/recommendation/data_server\r\nThis is the bulk of the PR\r\n\r\n2) Vectorized and parallelized both preprocessing and evaluation steps. Wherever possible I moved operations out of Python and into NumPy.\r\n\r\n3) Replaced the Keras model-to-estimator with a normal Estimator (which still uses the Keras layers).\r\n\r\n4) Updated the MLPerf run script.\r\n\r\nI still have to do a bit more delinting and adjustments to the unit tests; however I decided to open the PR now since you should be able to assess it in the mean time.",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 106,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-07-17T11:04:01Z",
        "closed_at": "2021-06-05T21:03:44Z",
        "merged_at": null,
        "body": "add slim/scripts/finetune_inception_v4_on_flowers.sh",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2018-07-17T03:29:42Z",
        "closed_at": "2021-01-26T05:10:17Z",
        "merged_at": null,
        "body": "correct the description of padding or clipping tensor method.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 36,
        "deletions": 32,
        "changed_files": 1,
        "created_at": "2018-07-16T22:01:23Z",
        "closed_at": "2018-08-07T02:52:04Z",
        "merged_at": "2018-08-07T02:52:04Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 985,
        "deletions": 33,
        "changed_files": 9,
        "created_at": "2018-07-16T20:47:58Z",
        "closed_at": "2018-08-10T05:30:37Z",
        "merged_at": null,
        "body": "PiperOrigin-RevId: 204795031\r\n\r\n+@joel-shor ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 72,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-07-16T18:47:19Z",
        "closed_at": "2018-07-16T21:07:31Z",
        "merged_at": "2018-07-16T21:07:31Z",
        "body": "processes all crystal growth images in directory and  sub directories and prints results to console, and a comma seperated file. Removes dependencies of google SDK(only dependent on tensorflow and python 2.7)\r\n\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 229,
        "deletions": 233,
        "changed_files": 1,
        "created_at": "2018-07-16T18:28:08Z",
        "closed_at": "2018-07-17T17:04:52Z",
        "merged_at": "2018-07-17T17:04:52Z",
        "body": "Staging:\r\n\r\nhttps://colab.research.google.com/github/markdaoust/models/blob/add-notebook/samples/core/tutorials/estimators/linear.ipynb",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-07-16T18:25:01Z",
        "closed_at": "2018-07-18T22:17:58Z",
        "merged_at": "2018-07-18T22:17:58Z",
        "body": "* Bug in label discovered at OSCON with @random-forests.\r\n* I'm not exactly sure how to test, but the change seems straightforward enough to submit.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 270,
        "deletions": 40,
        "changed_files": 5,
        "created_at": "2018-07-16T14:33:41Z",
        "closed_at": "2020-03-09T00:59:16Z",
        "merged_at": null,
        "body": "update to newest version ,especially for object detection",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2018-07-15T07:31:06Z",
        "closed_at": "2021-01-26T05:10:07Z",
        "merged_at": null,
        "body": "",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 495,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-07-14T21:58:41Z",
        "closed_at": "2019-12-03T07:09:32Z",
        "merged_at": null,
        "body": "Bringing in keras-estimator notebook from kashif/tf-keras-tutorial (see: https://github.com/kashif/tf-keras-tutorial/issues/1) ---Thanks, Dr. Kashif Rasul!\r\n\r\nNeeds a technical and editorial review before adding to tensorflow.org\r\n\r\nStage: https://colab.research.google.com/github/lamberta/models/blob/keras-estimator-tutorial/samples/core/tutorials/estimators/keras_estimator.ipynb\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-07-13T16:06:32Z",
        "closed_at": "2018-07-13T19:14:59Z",
        "merged_at": "2018-07-13T19:14:59Z",
        "body": "This is trying to address the long pause in https://github.com/tensorflow/models/pull/4749.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2018-07-13T14:24:14Z",
        "closed_at": "2018-07-25T23:11:05Z",
        "merged_at": "2018-07-25T23:11:05Z",
        "body": "I've added an explanation how to use the protoc compiler manually, in case the distribution version is not working.\r\nI think it'll make it a lot more accessible to people who aren't familiar with protobuf, since the release page might be a little confusing with all those different versions available.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 196,
        "deletions": 65,
        "changed_files": 6,
        "created_at": "2018-07-13T06:03:28Z",
        "closed_at": "2018-07-13T17:04:27Z",
        "merged_at": "2018-07-13T17:04:27Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 1158876,
        "changed_files": 1982,
        "created_at": "2018-07-12T08:05:10Z",
        "closed_at": "2018-07-16T16:13:45Z",
        "merged_at": null,
        "body": "Pulling available TursorFlow Java samples",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-07-12T02:04:00Z",
        "closed_at": "2018-07-12T05:04:18Z",
        "merged_at": "2018-07-12T05:04:18Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 68,
        "deletions": 5,
        "changed_files": 3,
        "created_at": "2018-07-11T23:21:28Z",
        "closed_at": "2018-07-12T00:28:33Z",
        "merged_at": "2018-07-12T00:28:33Z",
        "body": "Hi All,\r\n\r\nIn this PR, we add a script to run the benchmark of deep speech model, and also add instructions in README file. Let me know if you have any comments. Thank you!\r\n\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1404,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-07-11T22:46:14Z",
        "closed_at": "2018-07-13T21:52:38Z",
        "merged_at": "2018-07-13T21:52:38Z",
        "body": "Colab staging link: \r\n\r\nhttps://colab.sandbox.google.com/github/lamberta/models/blob/mark-estimator-wide-2/samples/core/tutorials/estimators/linear.ipynb\r\n\r\nfixes: tensorflow/tensorflow#18929",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2018-07-11T06:51:56Z",
        "closed_at": "2018-07-11T17:56:17Z",
        "merged_at": "2018-07-11T17:56:17Z",
        "body": "Leverage [__six.ensure_text()__](https://github.com/benjaminp/six/blob/master/six.py#L890) to deliver Unicode text in both Python 2 and Python 3.\r\n\r\nFollow Python porting best practice [use feature detection instead of version detection](https://docs.python.org/3/howto/pyporting.html#use-feature-detection-instead-of-version-detection) in ___unicode_to_native()__.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1871,
        "deletions": 0,
        "changed_files": 11,
        "created_at": "2018-07-10T18:30:06Z",
        "closed_at": "2018-07-11T18:39:08Z",
        "merged_at": "2018-07-11T18:39:08Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 943,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-07-10T16:34:14Z",
        "closed_at": "2018-07-13T21:22:53Z",
        "merged_at": "2018-07-13T21:22:53Z",
        "body": "Pull [AutoGraph Workshop](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/autograph/examples/notebooks/workshop.ipynb) notebook into tensorflow.org/guide\r\n\r\nStaging link:\r\n\r\nhttps://colab.research.google.com/github/markdaoust/models/blob/autopgraph-guide/samples/core/guide/autograph_control_flow.ipynb",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 548,
        "deletions": 496,
        "changed_files": 8,
        "created_at": "2018-07-10T07:02:00Z",
        "closed_at": "2018-07-11T00:13:37Z",
        "merged_at": "2018-07-11T00:13:37Z",
        "body": "Hi,\r\n\r\nThis PR contains the final version of DeepSpeech 2 model implemented with tensorflow high level API. Changes included in this PR:\r\n1) Add a README file and requirements.txt (yanhui & haoliang).\r\n2) Code refactoring across the whole pipeline to improve code readability (yanhui).\r\n3) Use tensorflow high level API to replace the previous Keras implementation (yanhui & haoliang)\r\n\r\nThe main reason we switched to TF API is that Kera's BatchNormalization layer could not be handled correctly by tf.keras.model_to_estimator. The issue we found is:\r\n      a) The model_to_estimator function fails to add update_ops as a control dependency of the train_op. \r\n      b) Even if we write our own model_fn and add update_ops manually, with the current tf-nightly build, update_ops associated with Kera's BatchNormalization layer is not added to the tf.GraphKeys.UPDATE_OPs. So it's impossible for us to find a graceful solution to make Kera's BN layer work seamlessly with estimator.\r\n\r\nFor model evaluation, we obtain the best result from a 5-layer RNN with 800 hidden units. The network is trained on train-clean-100 and train-clean-360 dataset. At the 16000 steps, we reach WER of 0.21 (compared with mlperf pytorch 0.23).\r\n\r\nThanks a lot for reviewing this PR!",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 17,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2018-07-09T18:37:08Z",
        "closed_at": "2019-01-18T05:14:35Z",
        "merged_at": null,
        "body": "Hi Kathy,\r\n\r\nThere is a github issue about adding Python path in the official/README file: https://github.com/tensorflow/models/issues/4656\r\n\r\nSo I update the texts a little bit to make it clear. Feel free to re-word it. Thanks!",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2018-07-09T14:28:59Z",
        "closed_at": "2018-07-10T16:08:49Z",
        "merged_at": "2018-07-10T16:08:48Z",
        "body": "The name of the files to run specified in the README.md file were not updated.\r\nThe names need to be updated as well in:\r\nhttps://www.tensorflow.org/tutorials/wide_and_deep\r\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2018-07-09T12:35:04Z",
        "closed_at": "2019-12-03T07:09:32Z",
        "merged_at": null,
        "body": "According to [official source code](https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet), inception's preprocessing is used during training time. So same method should be used for evaluation.\r\n\r\nNote: this modification will decrease prediction accuracy, but increase fairness.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-07-07T00:58:16Z",
        "closed_at": "2019-12-03T07:09:32Z",
        "merged_at": null,
        "body": "Changed line 74 from \"There many Tensorflow APIs\"->\"There are many Tensorflow APIs\"",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1244,
        "deletions": 1154,
        "changed_files": 7,
        "created_at": "2018-07-06T22:45:29Z",
        "closed_at": "2018-07-09T16:46:49Z",
        "merged_at": "2018-07-09T16:46:49Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-07-04T13:45:40Z",
        "closed_at": "2019-12-03T07:09:31Z",
        "merged_at": null,
        "body": "This fixes a problem when running evaluation with run_once. Examples get evaluated and logging shows the result, but the summary_writer doesn't write to disk.\r\nForce the summary_writer to write the changes to file.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-07-03T13:52:53Z",
        "closed_at": "2018-07-03T16:17:34Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 89836,
        "deletions": 0,
        "changed_files": 370,
        "created_at": "2018-07-02T22:42:28Z",
        "closed_at": "2018-07-02T23:54:17Z",
        "merged_at": "2018-07-02T23:54:17Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 132,
        "deletions": 28,
        "changed_files": 7,
        "created_at": "2018-07-02T22:42:23Z",
        "closed_at": "2018-07-03T17:39:14Z",
        "merged_at": "2018-07-03T17:39:14Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 591,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2018-07-02T18:01:34Z",
        "closed_at": "2018-07-03T05:03:14Z",
        "merged_at": null,
        "body": "This PR presents an initial implementation of an alternative to TFRecords as a format for feeding highly structured numeric data during training.\r\n\r\nThe context for this PR comes from performance tuning of NCF Recommendation (`official/recommendation`). NCF is arguably a worst case scenario for TFRecords:\r\n1) New data must be generated each epoch, so the serialization is a per-epoch cost rather than a one-time upfront cost.\r\n2) The amount of information per example is very small, consisting of one int32, one uint16, and one int8. So TFRecords is forced to spend 24 bytes to store 7 bytes of information.\r\n\r\nI'm saving the refactor of NCF for a separate PR since it contains other optimizations and I don't want to clutter the discussion.\r\n\r\nThe basic approach is to write an array's binary buffer to a file, ingest the bytes using FixedLengthRecordDataset, and then use .map() and tf.decode_raw() to get the bytes into tensors. I experimented with using .from_generator() and a python generator that fed bytes and it was somewhat faster, but not much and involved doing dangerous things like hanging onto a memoryview() of a numpy array, so I abandoned that approach.\r\n\r\nThis is all implemented using the public API as I did not feel confident writing a new class in the c++ side, and time is somewhat important for the MLPerf deadline. However even as a strawman it performs quite well. I have included a script `official/utils/data/performance_comparison.py` that I don't intend to merge into master, but is useful for demonstration.\r\n\r\n@mrry I'm curious what you think of this practice of looting the bytes from array buffers.",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 591,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2018-07-02T16:58:57Z",
        "closed_at": "2018-07-02T17:59:48Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-07-01T10:04:03Z",
        "closed_at": "2018-07-01T11:36:41Z",
        "merged_at": null,
        "body": "I found a unnecessary set \"resnet_v2.default_image_size = 224\" at line 249 , because it has been set at line 224 .",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1873,
        "deletions": 750,
        "changed_files": 71,
        "created_at": "2018-07-01T08:58:05Z",
        "closed_at": "2018-07-02T12:11:50Z",
        "merged_at": "2018-07-02T12:11:50Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 173,
        "deletions": 99,
        "changed_files": 1,
        "created_at": "2018-06-29T05:09:27Z",
        "closed_at": "2018-06-29T20:54:27Z",
        "merged_at": "2018-06-29T20:54:27Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 411,
        "deletions": 136,
        "changed_files": 4,
        "created_at": "2018-06-29T00:37:47Z",
        "closed_at": "2018-07-09T17:08:44Z",
        "merged_at": "2018-07-09T17:08:44Z",
        "body": "Hi All, \r\n\r\nWe add the model evaluation part (Haoliang works on it), and also apply multiprocessing to dataset in this PR. Let us know if you have any comments. Thank you!",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2804,
        "deletions": 0,
        "changed_files": 166,
        "created_at": "2018-06-27T06:06:38Z",
        "closed_at": "2018-06-27T17:00:29Z",
        "merged_at": "2018-06-27T17:00:29Z",
        "body": "STEVE is the hybrid model-based/model-free reinforcement learning algorithm from our paper \"Sample-Efficient Reinforcement Learning with Stochastic Ensemble Value Expansion\".",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 21,
        "deletions": 21,
        "changed_files": 7,
        "created_at": "2018-06-27T00:32:55Z",
        "closed_at": "2018-06-27T03:58:33Z",
        "merged_at": "2018-06-27T03:58:33Z",
        "body": "No visual changes, just makes it easier to grab on the website.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2018-06-26T21:55:57Z",
        "closed_at": "2018-06-26T22:56:54Z",
        "merged_at": "2018-06-26T22:56:54Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 850,
        "deletions": 0,
        "changed_files": 7,
        "created_at": "2018-06-26T03:27:07Z",
        "closed_at": "2018-06-28T18:21:41Z",
        "merged_at": "2018-06-28T18:21:41Z",
        "body": "Hi All,\r\n\r\nCould you help to review this PR of deep speech model? The PR includes:\r\n1. deep speech model with keras implemenation\r\n2. the training run-loop\r\n\r\n@A30041839 will add the dataset.py for input_fn soon, and we are still working on the eval part. Will submit a new PR later. I am testing the train loop with multi-gpus on GCP instance, and will also add the test results soon.\r\n\r\nThanks a lot!",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 33,
        "deletions": 33,
        "changed_files": 14,
        "created_at": "2018-06-26T00:31:21Z",
        "closed_at": "2018-06-27T20:57:33Z",
        "merged_at": "2018-06-27T20:57:33Z",
        "body": "Follow-up to cl/201766994\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 3,
        "changed_files": 4,
        "created_at": "2018-06-25T23:01:51Z",
        "closed_at": "2018-06-27T16:28:13Z",
        "merged_at": "2018-06-27T16:28:12Z",
        "body": "Fixes #3564",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 149,
        "deletions": 77,
        "changed_files": 4,
        "created_at": "2018-06-25T14:12:55Z",
        "closed_at": "2018-06-25T16:24:32Z",
        "merged_at": null,
        "body": "",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 900,
        "deletions": 93,
        "changed_files": 27,
        "created_at": "2018-06-25T11:47:09Z",
        "closed_at": "2019-12-03T07:09:31Z",
        "merged_at": null,
        "body": "I added a few new features for supporting Quantization on object_detection and also fixed some small bugs in this project.\r\n1. add .gitignore for ignoring proto generated files\r\n2. suppress double logging info\r\n3. use growth gpu memory allocating strategy when evaluating and training on one gpu.\r\n4. solved several py2/py3 compatibility problems by six moudule\r\n5. fix the bug that learning_rate may sometimes not be added to summary and tensorboard\r\n6. add new options when restore variables from a checkpoint\r\n(Which may important for quantize. tf.contrib.quantize.create_training_graph slows down the speed of training. So you may train the model without graph rewriter. After the first-time's convergence of model, the rewriter will be activated and then keep on training to refine the accuracy. However, the variable restoration from previous checkpoint will restore the variable generated by optimizer which slows down the second-time's convergence because of low learning rate.)\r\n7. support for exporting tflite compatible subgraph\r\n8. add a few documents and config samples for quantize\r\n\r\nTests passed:\r\nfaster_rcnn_meta_arch_test.py\r\nrfcn_meta_arch_test.py\r\nssd_meta_arch_test.py\r\nmodel_lib_test.py\r\ntrainer_test.py\r\neval_util_test\r\nexporter_test.py",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-06-22T22:24:07Z",
        "closed_at": "2019-12-03T07:09:31Z",
        "merged_at": null,
        "body": "Remove outdated tf.contrib.data references and replace with appropriate tf.data API's so tutorial will run in current versions of TF.  ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 15,
        "changed_files": 1,
        "created_at": "2018-06-22T20:55:33Z",
        "closed_at": "2018-06-22T22:48:57Z",
        "merged_at": "2018-06-22T22:48:57Z",
        "body": "Replaced all string activations to their tf versions",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2018-06-22T19:33:57Z",
        "closed_at": "2018-06-23T16:09:36Z",
        "merged_at": "2018-06-23T16:09:36Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 14,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-06-21T22:01:00Z",
        "closed_at": "2019-12-03T07:09:30Z",
        "merged_at": null,
        "body": "Having this feature will allow users to run both training and testing on a single GPU.\r\nUsers will have the ability to partition a fraction of their GPU for training and also run evaluation loop at the same time in order to monitor the accuracy/recall.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2018-06-21T20:06:52Z",
        "closed_at": "2019-12-03T07:09:30Z",
        "merged_at": null,
        "body": "Changing `.pbtxt` to `.config` to align with samples provided in `research\\object_detection\\samples\\configs\\`\r\n\r\nConsistency will help avoid confusion when supplying pipeline file to train and eval scripts.\r\n\r\nFiles:\r\n`research/object_detection/eval.py`\r\n`research/object_detection/train.py`\r\n\r\n___\r\nNote:\r\n`export_inference_graph.py` uses the consistent extensions proposed.\r\n```\r\nExample Usage:\r\n--------------\r\npython export_inference_graph \\\r\n    --input_type image_tensor \\\r\n    --pipeline_config_path path/to/ssd_inception_v2.config \\\r\n    --trained_checkpoint_prefix path/to/model.ckpt \\\r\n    --output_directory path/to/exported_model_directory\r\n```\r\n\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-06-20T15:59:56Z",
        "closed_at": "2019-12-03T07:09:30Z",
        "merged_at": null,
        "body": "Under \"Manual Installation\" section, the code blocks for the bazel portion were missing ",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 162,
        "deletions": 57,
        "changed_files": 1,
        "created_at": "2018-06-20T01:01:14Z",
        "closed_at": "2018-06-20T04:40:03Z",
        "merged_at": "2018-06-20T04:40:03Z",
        "body": "Patch @yashk2810 's PR https://github.com/tensorflow/models/pull/4580 because of issues.\r\n\r\nStage: https://colab.sandbox.google.com/github/lamberta/models/blob/fix-remove-preprocess-fn/samples/core/get_started/basic_classification.ipynb\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 30,
        "deletions": 14,
        "changed_files": 4,
        "created_at": "2018-06-19T23:42:09Z",
        "closed_at": "2019-12-03T07:09:29Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-06-19T21:13:51Z",
        "closed_at": "2019-12-03T07:09:29Z",
        "merged_at": null,
        "body": "This symbol notes that post-processing input size to the model must be of size\r\n299 per the linked arxiv paper.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-06-19T19:08:24Z",
        "closed_at": "2018-06-19T22:42:46Z",
        "merged_at": "2018-06-19T22:42:46Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-06-19T17:44:47Z",
        "closed_at": "2019-12-03T07:09:29Z",
        "merged_at": null,
        "body": "reference to base_name appears to be incorrect. changing base_name to checkpoint_name resolves unpacking error and broken notebook example",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 20,
        "changed_files": 1,
        "created_at": "2018-06-19T15:03:25Z",
        "closed_at": "2018-06-19T23:04:55Z",
        "merged_at": null,
        "body": "Removed the preprocess function which just performed division. @MarkDaoust ",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-06-19T08:48:56Z",
        "closed_at": "2018-06-19T14:09:53Z",
        "merged_at": "2018-06-19T14:09:53Z",
        "body": "the default max_step is set to 100000 which makes epoch 2560.\r\nIt confuses users whether 256 epoch or 2560 epoch.\r\n256 epoch is presented as previous comments and example results.\r\nAlso cifar-10 and this kind of network written here doesn't need too many epoch.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 8,
        "deletions": 8,
        "changed_files": 5,
        "created_at": "2018-06-19T00:49:53Z",
        "closed_at": "2018-06-20T05:16:46Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-06-18T08:57:22Z",
        "closed_at": "2019-04-17T21:22:04Z",
        "merged_at": "2019-04-17T21:22:04Z",
        "body": "Dictionary's .iteritem() raises an error in Python3.\r\nReplaced it with iteritem from six library.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-06-15T21:13:07Z",
        "closed_at": "2018-06-18T20:56:06Z",
        "merged_at": "2018-06-18T20:56:06Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 272,
        "deletions": 106,
        "changed_files": 4,
        "created_at": "2018-06-15T19:26:41Z",
        "closed_at": "2018-06-19T04:13:47Z",
        "merged_at": "2018-06-19T04:13:47Z",
        "body": "Fixes #3754",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 66,
        "deletions": 16,
        "changed_files": 7,
        "created_at": "2018-06-15T16:19:19Z",
        "closed_at": "2018-06-19T22:48:53Z",
        "merged_at": "2018-06-19T22:48:53Z",
        "body": "1. Splits train_image_classifier into library and binary rule, to sim\u2026plify reuse.\r\n\r\n2. Flag that allows to prevent imagenet.py  from downloading label_to_names from github and/or dumping into training directory (which might be read-only)\r\n3. Adds some comments about how decay steps are computed, since it computed differently when there are clones vs sync replicas.\r\n4. Updates mobilenet.md to describe the training process using train_image_classifer\r\n5. Add citation for TF-Slim model library.\r\n\r\nPiperOrigin-RevId: 191955231\r\n\r\nPiperOrigin-RevId: 193254125\r\n\r\nPiperOrigin-RevId: 193371562\r\n\r\nPiperOrigin-RevId: 194085628\r\n\r\nPiperOrigin-RevId: 194857067\r\n\r\nPiperOrigin-RevId: 196125653\r\n\r\nPiperOrigin-RevId: 196589070\r\n\r\nPiperOrigin-RevId: 199522873\r\n\r\nPiperOrigin-RevId: 200351305",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-06-15T02:08:16Z",
        "closed_at": "2019-12-04T06:35:45Z",
        "merged_at": "2019-12-04T06:35:45Z",
        "body": "Fix variable name issue in MobileNet example notebook.\r\nMake sure all `base_name` variables are renamed to `checkpoint_name`.",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 223,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-06-15T00:05:24Z",
        "closed_at": "2018-06-19T22:00:10Z",
        "merged_at": "2018-06-19T22:00:10Z",
        "body": "Staged: https://colab.sandbox.google.com/github/lamberta/models/blob/get-started-index/samples/core/get_started/_index.ipynb",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 761,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-06-14T21:22:36Z",
        "closed_at": "2018-06-18T22:45:50Z",
        "merged_at": "2018-06-18T22:45:50Z",
        "body": "Staging:\r\n\r\nhttps://colab.sandbox.google.com/github/MarkDaoust/models/blob/overfit-and-underfit/samples/core/get_started/overfit_and_underfit.ipynb",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 84,
        "deletions": 3,
        "changed_files": 4,
        "created_at": "2018-06-14T19:58:39Z",
        "closed_at": "2019-12-03T07:09:28Z",
        "merged_at": null,
        "body": "Allows input data to be augmented using power law (gain, gamma) and hue adjustments.\r\nFlags added with defaults set to not performing any adjustments.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 248,
        "deletions": 193,
        "changed_files": 14,
        "created_at": "2018-06-14T08:17:23Z",
        "closed_at": "2018-06-15T05:24:53Z",
        "merged_at": "2018-06-15T05:24:53Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 635,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-06-13T20:17:23Z",
        "closed_at": "2018-06-18T22:46:38Z",
        "merged_at": "2018-06-18T22:46:38Z",
        "body": "Staging:\r\n\r\nhttps://colab.sandbox.google.com/github/markdaoust/models/blob/basic-regression/samples/core/get_started/basic_regression.ipynb",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 810,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-06-13T19:38:32Z",
        "closed_at": "2018-06-18T23:03:43Z",
        "merged_at": "2018-06-18T23:03:43Z",
        "body": "Staging:\r\n\r\nhttps://colab.sandbox.google.com/github/markdaoust/models/blob/basic-text-classification/samples/core/get_started/basic_text_classification.ipynb",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1043,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-06-13T19:08:14Z",
        "closed_at": "2018-06-18T23:04:29Z",
        "merged_at": "2018-06-18T23:04:29Z",
        "body": "The broken image will be fixed when we publish the site.\r\n\r\npreview link:\r\n\r\nhttps://colab.sandbox.google.com/github/markdaoust/models/blob/basic-classification/samples/core/get_started/basic_classification.ipynb",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-06-13T10:18:57Z",
        "closed_at": "2018-06-13T20:39:04Z",
        "merged_at": "2018-06-13T20:39:04Z",
        "body": "Fix the bug that evaluator don't reload the min-max values of fake_quantize op which automatically added by tf.contrib.create_eval_graph() from latest checkpoint.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-06-12T23:22:17Z",
        "closed_at": "2019-09-02T22:51:32Z",
        "merged_at": null,
        "body": "added python setup step",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-06-12T17:49:50Z",
        "closed_at": "2018-06-13T06:31:44Z",
        "merged_at": "2018-06-13T06:31:44Z",
        "body": "Very minor documentation edit, but for those that are not overly familiar with `.bashrc` configuration I figured it's worth being explicit on what to do with the installation docs",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-06-12T15:40:42Z",
        "closed_at": "2019-12-03T07:09:28Z",
        "merged_at": null,
        "body": "Fixed invalid variable name for checkpoint filename prefix",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 2095,
        "deletions": 1028,
        "changed_files": 32,
        "created_at": "2018-06-11T20:57:57Z",
        "closed_at": "2018-06-20T21:58:04Z",
        "merged_at": "2018-06-20T21:58:04Z",
        "body": "In order to prep wide-deep to run on more substantial hardware, this PR adds the Kaggle movie dataset as an option, and refactors the wide-deep code to allow for multiple datasets.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 17,
        "deletions": 17,
        "changed_files": 1,
        "created_at": "2018-06-11T09:33:04Z",
        "closed_at": "2018-06-11T11:36:31Z",
        "merged_at": null,
        "body": "Fixed evaluation during training\r\n\r\nex) train_epochs:250, epochs_between_evals=10\r\n\r\nbefore : total cycle:25, 1evalutaion / 1cycle\r\nafter : total cycle:250, 1evalution / 25cycle",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2018-06-09T21:09:59Z",
        "closed_at": "2018-06-13T19:16:13Z",
        "merged_at": "2018-06-13T19:16:12Z",
        "body": "Stage: https://colab.sandbox.google.com/github/tensorflow/models/blob/92b560d4d8da2ce4bee4863c6423ed5d349d3e3a/samples/core/get_started/eager.ipynb\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 391,
        "deletions": 0,
        "changed_files": 8,
        "created_at": "2018-06-08T23:52:10Z",
        "closed_at": "2018-06-22T20:22:43Z",
        "merged_at": "2018-06-22T20:22:43Z",
        "body": "- This is an implementation of the Sentiment Analysis model.\r\n- The implementation is with the reference to paddle version.",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-06-08T23:28:23Z",
        "closed_at": "2018-06-11T21:43:53Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 207,
        "deletions": 91,
        "changed_files": 7,
        "created_at": "2018-06-08T22:45:59Z",
        "closed_at": "2018-06-12T18:33:58Z",
        "merged_at": "2018-06-12T18:33:58Z",
        "body": "Having a tf.gfile.Exists in a flag validator is causing BUILD target to fail. I wanted to add a note that says to avoid doing this, and decided to add the rest of the model checklist.\r\n\r\nIf anyone has suggestions, please comment here or feel free to commit changes into this PR.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-06-07T22:29:37Z",
        "closed_at": "2018-06-11T15:47:48Z",
        "merged_at": "2018-06-11T15:47:48Z",
        "body": "Thanks @nealwu for letting me know.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 7,
        "changed_files": 2,
        "created_at": "2018-06-07T16:58:47Z",
        "closed_at": "2018-06-07T18:33:41Z",
        "merged_at": "2018-06-07T18:33:41Z",
        "body": "unittest is blocking the BUILD file from being added to the Transformer model. ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 727,
        "deletions": 1,
        "changed_files": 6,
        "created_at": "2018-06-07T16:01:03Z",
        "closed_at": "2018-06-07T17:41:24Z",
        "merged_at": "2018-06-07T17:41:24Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-06-07T07:30:12Z",
        "closed_at": "2019-12-03T07:09:27Z",
        "merged_at": null,
        "body": "Wrapped range() with a list, for python3 compatability.\r\n\r\nSee: https://github.com/tensorflow/models/issues/4455",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 406,
        "deletions": 0,
        "changed_files": 5,
        "created_at": "2018-06-07T00:38:43Z",
        "closed_at": "2018-07-13T23:08:40Z",
        "merged_at": "2018-07-13T23:08:40Z",
        "body": "Hi All,\r\n\r\nCould you help to review this PR of keras application model benchmark? It includes:\r\n- benchmark_main.py: the main function to run benchmark pipeline\r\n- model_callbacks: customized callbacks for benchmark.\r\n- README \r\n\r\nNote that, the current benchmark runs with synthetic dataset to test the pipeline. Will test it with ImageNet dataset in next PR. Thanks!",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 13,
        "deletions": 26,
        "changed_files": 2,
        "created_at": "2018-06-06T21:33:00Z",
        "closed_at": "2018-06-18T18:02:09Z",
        "merged_at": "2018-06-18T18:02:09Z",
        "body": "@karmel Apologies, I didn't address your initial cleanup requests.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 9,
        "changed_files": 1,
        "created_at": "2018-06-06T17:41:45Z",
        "closed_at": "2018-06-06T21:08:40Z",
        "merged_at": "2018-06-06T21:08:40Z",
        "body": "Open and preserve the file handler of the metric log file during\r\ninit, which reduce the overhead of open/close the file for each\r\nlog_metric call.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 37,
        "deletions": 8,
        "changed_files": 3,
        "created_at": "2018-06-06T17:00:44Z",
        "closed_at": "2018-06-06T20:16:15Z",
        "merged_at": "2018-06-06T20:16:15Z",
        "body": "This trims the ResNet pipeline to guarantee that the number of batches during training is divisible by the number of devices. (It is not necessary during eval because eval currently only uses one device, even in MirrorStrategy) Once all_reduce is cancel-able this can be reverted. ",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-06-06T06:30:54Z",
        "closed_at": "2019-12-03T07:09:27Z",
        "merged_at": null,
        "body": "there should use absolute path\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 208,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-06-06T05:08:04Z",
        "closed_at": "2018-06-08T18:08:37Z",
        "merged_at": "2018-06-08T18:08:37Z",
        "body": "Download & preprocess for LibriSpeech data. What this change does:\r\n1) Download dataset and unzip the tar files.\r\n2) Convert flac audio to wav.\r\n3) Generate a .csv file for each dataset. Three columns in the csv: \"wav_filename\", \"wav_filesize\", \"transcript\", separated by tab.",
        "comments": 8
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-06-06T02:46:57Z",
        "closed_at": "2018-09-05T02:20:10Z",
        "merged_at": null,
        "body": "The pets data set provides PNG masks. The default mask type should be set to `PNG_MASKS` according to the input reader source code https://github.com/tensorflow/models/blob/master/research/object_detection/protos/input_reader.proto#L22. Currently, the setting is null, which means the default is `NUMERICAL_MASKS` according to https://github.com/tensorflow/models/blob/master/research/object_detection/protos/input_reader.proto#L20, which causes errors.\r\n\r\nThis issue hindered fresh users to train pets data set for instance segmentation. A friendly config file could save a lot of people's time.",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-06-06T02:13:58Z",
        "closed_at": "2019-12-03T07:09:27Z",
        "merged_at": null,
        "body": "The doc string should be consistent with the parameter names.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 198,
        "deletions": 19,
        "changed_files": 5,
        "created_at": "2018-06-06T00:07:17Z",
        "closed_at": "2018-06-06T19:38:19Z",
        "merged_at": "2018-06-06T19:38:19Z",
        "body": "This PR adds tests, and a few tweaks. Tests have revealed that we can skip a matmul after embedding, reducing the run time by 0.2%!",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 369,
        "deletions": 161,
        "changed_files": 15,
        "created_at": "2018-06-05T21:35:59Z",
        "closed_at": "2018-06-12T16:54:13Z",
        "merged_at": "2018-06-12T16:54:13Z",
        "body": "Hi all, I added DistributionStrategy to the Transformer model. Currently, the model isn't running very well with MirroredStrategy and I'm not sure why. @robieta @guptapriya As people familiar with DistributionStrategy, please help!\r\n\r\nCurrent stats:\r\n\r\nGPUs | Global steps/sec | batch size (per device)\r\n---|---|---\r\n1 GPU | 1.11 | 4096\r\n4 GPU | 0.34 | 3072\r\n\r\nI decreased the batch size because of OOM errors.",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-06-05T08:48:55Z",
        "closed_at": "2019-12-03T07:09:26Z",
        "merged_at": null,
        "body": "The indices of kernel_size were wrong when computing the kernel_size_effective.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 13783,
        "deletions": 0,
        "changed_files": 38,
        "created_at": "2018-06-05T00:58:09Z",
        "closed_at": "2018-06-05T23:06:10Z",
        "merged_at": "2018-06-05T23:06:10Z",
        "body": "Add open-source implementation of vid2depth model.\r\n\r\nProject website: https://sites.google.com/view/vid2depth\r\n\r\nArXiv: https://arxiv.org/pdf/1802.05522.pdf",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-06-04T18:27:28Z",
        "closed_at": "2018-06-04T20:19:52Z",
        "merged_at": "2018-06-04T20:19:52Z",
        "body": "This will help us differentiate between dataset.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-06-03T19:34:03Z",
        "closed_at": "2018-06-04T16:43:06Z",
        "merged_at": null,
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-06-01T22:10:50Z",
        "closed_at": "2018-06-04T20:31:09Z",
        "merged_at": "2018-06-04T20:31:09Z",
        "body": "We haven't had pretrained checkpoints since the recent topology changes. This adds them back.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 124,
        "deletions": 12,
        "changed_files": 9,
        "created_at": "2018-06-01T19:19:49Z",
        "closed_at": "2018-06-01T21:56:57Z",
        "merged_at": "2018-06-01T21:56:57Z",
        "body": "The ID can be used to differentiate between different runs (eg resnet convergence vs performance).",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-05-31T17:57:02Z",
        "closed_at": "2018-06-04T19:09:01Z",
        "merged_at": "2018-06-04T19:09:01Z",
        "body": "Code was written for python2",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-05-30T22:22:02Z",
        "closed_at": "2018-06-18T22:53:14Z",
        "merged_at": null,
        "body": "\"algorithms\" was mis-spelled as \"algorthims\"",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-05-30T22:15:11Z",
        "closed_at": "2018-06-29T20:55:13Z",
        "merged_at": "2018-06-29T20:55:13Z",
        "body": "\"algorithms\" was mis-spelled as \"algorthims\"",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 16,
        "changed_files": 3,
        "created_at": "2018-05-30T15:01:58Z",
        "closed_at": "2018-05-30T17:21:23Z",
        "merged_at": "2018-05-30T17:21:23Z",
        "body": "Hi,\r\nThe README was unclear about how to get the data from MNIST and the use of Bazel.\r\nI've tried to make it more simple, or fixed a pb of zip() linked to the python version which caused a NoVariable Exception in TF.\r\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 6,
        "changed_files": 2,
        "created_at": "2018-05-30T10:43:47Z",
        "closed_at": "2019-12-03T07:09:26Z",
        "merged_at": null,
        "body": "Explicitly cast range function to list or tuple when the result is not used as an iterator. This makes the code Python 3 compatible.\r\n\r\nThis fixes an issue that I had running the Pet detector example with Python 3 and tensorflow 1.8. I tested the Pet detector example with tensorflow 1.8 and Python 3.6 locally and Python 3.5 on GC. This PR fixes the issues that I had.\r\n\r\nSimilar issue as #3465. Also related to the fixes suggested in #3705 and #3752.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 205,
        "deletions": 39,
        "changed_files": 14,
        "created_at": "2018-05-29T23:34:57Z",
        "closed_at": "2018-06-01T20:47:56Z",
        "merged_at": "2018-06-01T20:47:56Z",
        "body": "The status is recorded into a separate bigquery table, due to the limit of streaming uploading of run that block the record from being updated. The new status table is only inserted/updated via standard SQL query.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 68,
        "deletions": 15,
        "changed_files": 3,
        "created_at": "2018-05-29T23:03:34Z",
        "closed_at": "2018-05-30T21:41:01Z",
        "merged_at": "2018-05-30T21:41:01Z",
        "body": "By modifying output signature def.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-05-29T13:03:53Z",
        "closed_at": "2019-12-03T07:09:26Z",
        "merged_at": null,
        "body": "Finish the uncompleted code comments of function `_configure_learning_rate`.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2018-05-29T11:55:41Z",
        "closed_at": "2018-07-08T04:53:29Z",
        "merged_at": null,
        "body": "Beacause some operation, like 'divide', will convert the 'int' variable to 'float' variable, so there will some wrongs to send the 'float' variable to parameters which can only be 'int' as below:\r\nTypeError: Expected int32 passed to parameter 'y' of op 'GreaterEqual', got 125.0 of type 'float' instead.\r\nSo I use a Type Cast like \"int()\" and \"tf.cast()\" to solve this issue.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-05-29T08:43:37Z",
        "closed_at": "2019-12-03T07:09:25Z",
        "merged_at": null,
        "body": "In '*_test.py', no function set the GPU device, default is 0. So if the GPU 0 is used by others and the memory is full, there will an exception like\r\n'''failed to allocate 6.04G (6487007744 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY'''\r\nso there is a necessity to set the GPU device(and it's optional).",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2018-05-28T11:24:15Z",
        "closed_at": "2018-05-29T16:34:46Z",
        "merged_at": "2018-05-29T16:34:46Z",
        "body": "This PR catches errors during the directory creating, which previously resulted in executing the whole script again.\r\nNow, if the script was previously interrupted the script will continue if the needed directories already exist.\r\n\r\nFurthermore, the `ILSVRC2012_bbox_train_v2.tar.gz` is now only downloaded once, in the case where no `BASE_URL_CHANGE` was neccessary.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-05-26T06:20:16Z",
        "closed_at": "2018-05-26T12:08:00Z",
        "merged_at": "2018-05-26T12:08:00Z",
        "body": "fixing typo",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-05-26T03:13:54Z",
        "closed_at": "2018-05-26T05:32:48Z",
        "merged_at": null,
        "body": "tensorboard logdir should be in train directory",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 148,
        "deletions": 116,
        "changed_files": 4,
        "created_at": "2018-05-25T23:39:52Z",
        "closed_at": "2018-05-29T22:21:09Z",
        "merged_at": "2018-05-29T22:21:09Z",
        "body": "Hi All,\r\n\r\nI update the boosted_trees code to make it more garden-style:\r\n1. Add official flags in data_download.py, and fix a minor bug\r\n2. Add benchmark logger in train_higgs.py\r\n3. Update single quote with double quotes",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 60,
        "deletions": 3,
        "changed_files": 4,
        "created_at": "2018-05-25T23:33:35Z",
        "closed_at": "2018-05-30T22:32:07Z",
        "merged_at": null,
        "body": "Not to be merged.\r\n\r\nThis is an example of how if hooks could access the train op, they could be written in a way that ensures deterministic, correct behavior.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 90,
        "deletions": 6,
        "changed_files": 5,
        "created_at": "2018-05-24T20:16:14Z",
        "closed_at": "2019-12-03T07:09:25Z",
        "merged_at": null,
        "body": "In this PR, We added following parameters to improve the training and evaluation out-of-box experiences on CPU and make it easier for users to control the parallelism on CPU for object detection API.\r\n1) inter_op and intra_op to control the parallelism.\r\n2) performance tuning parameters specific to MKL (kmp_block_time and kmp_affinity) if MKL is enabled.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 129,
        "deletions": 90,
        "changed_files": 6,
        "created_at": "2018-05-24T17:21:57Z",
        "closed_at": "2018-05-25T16:41:25Z",
        "merged_at": "2018-05-25T16:41:25Z",
        "body": "Examples per second is not being logged anywhere except stdout right now; this PR fixes that. This does not, however, fix the issues with test flakiness on GPUs. @yhliang2018 is looking into that separately.\r\n\r\nTested with Resnet, and logging seems to work as intended:\r\n```\r\ncat /tmp/benchmark/metric.log \r\n{\"name\": \"average_examples_per_sec\", \"timestamp\": \"2018-05-24T16:57:45.987002Z\", \"value\": 223.58538671516752, \"extras\": [], \"unit\": null, \"global_step\": 106}\r\n{\"name\": \"current_examples_per_sec\", \"timestamp\": \"2018-05-24T16:57:45.987382Z\", \"value\": 223.58538671516752, \"extras\": [], \"unit\": null, \"global_step\": 106}\r\n```",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-05-24T12:40:15Z",
        "closed_at": "2018-05-24T16:41:37Z",
        "merged_at": "2018-05-24T16:41:37Z",
        "body": "Fix a bug in the resnet pipeline reported in https://github.com/tensorflow/models/issues/4354.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-05-24T10:51:05Z",
        "closed_at": "2019-12-03T07:09:25Z",
        "merged_at": null,
        "body": "When number of objects are more than uint8's range, the earlier code crates problems. This is a fix.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-05-23T20:21:00Z",
        "closed_at": "2018-08-10T17:33:13Z",
        "merged_at": null,
        "body": "`SyntheticDataset` allows to easily build a performant synthetic input pipeline. Use that in resnet examples.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-05-23T18:11:23Z",
        "closed_at": "2018-05-24T13:26:41Z",
        "merged_at": "2018-05-24T13:26:41Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 524,
        "deletions": 183,
        "changed_files": 9,
        "created_at": "2018-05-22T23:46:35Z",
        "closed_at": "2018-05-25T00:35:16Z",
        "merged_at": "2018-05-25T00:35:16Z",
        "body": "Hi All,\r\n\r\nI have add official flags and benchmark logs for the recommendation model. A simple unit test for dataset.py is also added based on previous comments. As dataset.py needs to read csv files, I add a folder \"unittest_data\" for the csv files.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 189,
        "deletions": 0,
        "changed_files": 4,
        "created_at": "2018-05-22T22:22:31Z",
        "closed_at": "2019-12-03T07:09:24Z",
        "merged_at": null,
        "body": "I find the example scripts very useful for demonstrating end-to-end flows. Are you interested in contributions like this for quantizing models and converting to quantized TF-Lite models via TOCO?",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 16,
        "deletions": 14,
        "changed_files": 4,
        "created_at": "2018-05-22T20:48:18Z",
        "closed_at": "2018-05-23T15:43:35Z",
        "merged_at": "2018-05-23T15:43:35Z",
        "body": "Added the following changes to improve input pipeline.\r\n\r\n1. Remove usage of one_hot labels (~2% improvement)\r\n2. Add drop_remainder to batching. This helps in input shape being determined ahead of time which helps improve performance. (~2% improvement)\r\n3. Use parallel_interleave for imagenet dataset reading. (~3% improvement)\r\n\r\nThe improvements were observed when testing with 8 V100 GPUs on DGX-1 using mirrored strategy (fp16, resnet v2). Also saw improvements in GCE V100. No improvement observed on K80s but that is expected since they are not bottlenecked on input. ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 4,
        "changed_files": 3,
        "created_at": "2018-05-22T04:02:19Z",
        "closed_at": "2018-05-22T23:49:10Z",
        "merged_at": "2018-05-22T23:49:10Z",
        "body": "Hi, when running the training script I've encountered.\r\n1. `StringIO` import error.\r\n2. `float' to 'int' conversion error.\r\n3. concatenating bytes to str.\r\n\r\nI tried a fix and successfully trained the model.\r\n\r\nThanks. ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3441,
        "deletions": 0,
        "changed_files": 29,
        "created_at": "2018-05-22T00:40:50Z",
        "closed_at": "2018-05-22T20:22:29Z",
        "merged_at": "2018-05-22T20:22:29Z",
        "body": "Added the MorphNet library (described in this paper https://arxiv.org/abs/1711.06798)",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 29,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-05-21T22:38:34Z",
        "closed_at": "2019-01-18T05:08:27Z",
        "merged_at": null,
        "body": "To setup continuous builds of container images that will includes all the models in this repo via [google cloud container builder](https://cloud.google.com/container-builder/), this PR introduces a container builder configuration file that explicitly specified the images that will be built for every commit to this branch and more importantly the need for a larger size VM to run these builds in the background.\r\n\r\nTo submit builds manually to container builder run the following command:\r\n```shell\r\n$ cd official \r\n$ gcloud container builds submit --config cloudbuild.yaml . --project <your-gcp-project> --substitutions=COMMIT_SHA=$(git rev-parse HEAD)\r\n```\r\n\r\nBuilds will be automated via container builder and you can list the images available periodically as follows:\r\n```shell\r\n$ gcloud container images list-tags gcr.io/tensorflow/models\r\n$ gcloud container images list-tags gcr.io/tensorflow/models-gpu\r\n```",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1465,
        "deletions": 110,
        "changed_files": 20,
        "created_at": "2018-05-19T01:06:07Z",
        "closed_at": "2018-05-19T03:07:50Z",
        "merged_at": "2018-05-19T03:07:50Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 24,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-05-18T19:56:05Z",
        "closed_at": "2018-05-18T21:17:46Z",
        "merged_at": "2018-05-18T21:17:46Z",
        "body": "This is based on the discussion with Toby and existing tf_cnn_benchmark.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-05-17T16:34:08Z",
        "closed_at": "2018-05-17T18:23:35Z",
        "merged_at": "2018-05-17T18:23:35Z",
        "body": "Fixes https://github.com/tensorflow/tensorflow/issues/19348",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 727,
        "deletions": 180,
        "changed_files": 17,
        "created_at": "2018-05-17T16:25:29Z",
        "closed_at": "2018-06-04T17:47:43Z",
        "merged_at": "2018-06-04T17:47:43Z",
        "body": "This is very much a first attempt. Performance is not good (~15% TPU utilization), but it's a start.\r\nEDIT: Utilization is now at 40%. Still not great, but better.\r\n\r\n1) Static batching:\r\nTransformer tries to group sequences of shorter lengths and run with larger batches when it does so. So one batch may have shape [30, 68], while the next might have shape [20, 100]. This is completely anathema to XLA's shape requirements. In order to run on TPUs sequences must be padded to the max allowable length which ensures static shape. (Thanks a lot @k-w-w for explaining and implementing this.)\r\n\r\n2) Feed forward padding:\r\nSimilarly the final dense layers of transformer can save  work by ignoring the padded elements. However, this confuses XLA because of the presence of tf.where, and so must be disable for TPU use.\r\n\r\n3) params dict instead of params object:\r\nTransformer stores parameters in an object which results in very clean code, but TPUEstimator demands params be passed as a dict because it does checking and strategic value insertion. params are still initially stored in an object for readability and inheritance, and then simply converted to a dict before being passed to the estimator. As a result there are lots of changes in this PR that simply change `params.foo` to `params[\"foo\"]`.\r\n\r\n4) Schedule manager:\r\nThe control flow logic in Transformer was already non-trivial as it supports both a step basis and an epoch basis, and TPUs further complicate things because even when epochs are specified the estimator still has to use steps under the hood. (As well as other such complications) I elected to pull all of this logic into a controller class rather than have it interspersed throughout the run loop.\r\n\r\n5) Host call:\r\nSummary ops are complicated with TPUs. I more or less copied the host call (and lovely docstring) from the cloud TPU implementation of ResNet.\r\n\r\n6) Hooks and eval metrics:\r\nHooks are completely disabled with TPUs for now. Hopefully they can be brought back soon. 3 of the eval metrics are disabled for TPUs because they use tf.py_func which is not supported by XLA. They may or may not ever support TPUs.\r\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-05-17T14:59:08Z",
        "closed_at": "2019-12-03T07:08:33Z",
        "merged_at": null,
        "body": "related : https://github.com/tensorflow/models/pull/3741  \r\nbuild_ade20k_data.py has a same problem.\r\nThe FastGFile(.., 'b') does not work for Python 3",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 167,
        "deletions": 52,
        "changed_files": 3,
        "created_at": "2018-05-16T18:10:38Z",
        "closed_at": "2018-06-05T22:15:13Z",
        "merged_at": "2018-06-05T22:15:13Z",
        "body": "Also added instructions for using the SavedModel to the README",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 683,
        "deletions": 134,
        "changed_files": 4,
        "created_at": "2018-05-16T03:51:06Z",
        "closed_at": "2019-12-03T07:08:33Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 83,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2018-05-16T01:17:31Z",
        "closed_at": "2019-12-03T07:08:33Z",
        "merged_at": null,
        "body": "\u2026test accuracy with 2K global batch size, 32 per CPU rank); add number of intra and inter threads to get better training performance on CPU",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 31,
        "deletions": 12,
        "changed_files": 2,
        "created_at": "2018-05-16T00:53:02Z",
        "closed_at": "2018-09-25T00:35:14Z",
        "merged_at": null,
        "body": "The groundtruth visualization now includes instance masks and boundaries if available, also groundtruth class labels are now shown. \r\nFurthermore, the default line thickness of 4 leads to unrecognizable visualizations for smaller image sizes, therefore an option in the eval_config was added to be able to change this value. ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2018-05-15T18:18:00Z",
        "closed_at": "2018-05-15T21:55:06Z",
        "merged_at": "2018-05-15T21:55:06Z",
        "body": "Thanks for finding this @robieta ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 451,
        "deletions": 69,
        "changed_files": 1,
        "created_at": "2018-05-14T18:32:35Z",
        "closed_at": "2018-05-31T18:53:32Z",
        "merged_at": "2018-05-31T18:53:32Z",
        "body": "Set private_outputs = true\r\n\r\nAdd more code examples, demonstrating things running after being defined.",
        "comments": 10
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 9,
        "changed_files": 2,
        "created_at": "2018-05-14T18:22:57Z",
        "closed_at": "2018-05-17T15:45:57Z",
        "merged_at": "2018-05-17T15:45:57Z",
        "body": "The official v1 model contains BN and Relu between input layer and pooling. See http://ethereon.github.io/netscope/#/gist/db945b393d40bfa26006. \r\n\r\nFor v2, I am also convinced that it should have those 2 layers, based on Appendix: Implementation Details in https://arxiv.org/pdf/1603.05027.pdf. Here is the quote:\r\n\r\n\"When using the pre-activation Residual Units (Fig. 4(d)(e) and Fig. 5), we\r\npay special attention to the first and the last Residual Units of the entire network.\r\nFor the first Residual Unit (that follows a stand-alone convolutional layer,\r\nconv1), **we adopt the first activation right after conv1 and before splitting into\r\ntwo paths**; for the last Residual Unit (followed by average pooling and a fullyconnected\r\nclassifier), we adopt an extra activation right after its element-wise\r\naddition. These two special cases are the natural outcome when we obtain the\r\npre-activation network via the modification procedure as shown in Fig. 5.\"",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-05-13T22:57:49Z",
        "closed_at": "2019-12-03T07:08:32Z",
        "merged_at": null,
        "body": "#4251 container-vm images no longer work - see https://cloud.google.com/container-optimized-os/docs/resources/faq\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 15,
        "deletions": 14,
        "changed_files": 6,
        "created_at": "2018-05-11T23:54:43Z",
        "closed_at": "2018-08-10T17:32:27Z",
        "merged_at": null,
        "body": "Added the following changes to improve input pipeline:\r\n1. Remove usage of one_hot labels  (~2% improvement)\r\n2. Add drop_remainder to batching. This helps in input shape being determined ahead of time which helps improve performance. (~2% improvement)\r\n3. Use parallel_interleave for imagenet dataset reading. (~3% improvement)\r\n\r\nThe improvements were observed when testing with 8 V100 GPUs on DGX-1 using mirrored strategy (fp16, resnet v2). The differences may not be noticeable in other cases where input pipeline is not the bottleneck.\r\n\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2018-05-11T20:31:19Z",
        "closed_at": "2018-05-11T21:48:20Z",
        "merged_at": "2018-05-11T21:48:20Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1088,
        "deletions": 299,
        "changed_files": 42,
        "created_at": "2018-05-11T00:53:08Z",
        "closed_at": "2018-05-11T20:20:54Z",
        "merged_at": "2018-05-11T20:20:54Z",
        "body": "196161788  by Zhichao Lu:\r\n\r\n    Add eval_on_train_steps parameter.\r\n\r\n    Since the number of samples in train dataset is usually different to the number of samples in the eval dataset.\r\n\r\n--\r\n196151742  by Zhichao Lu:\r\n\r\n    Add an optional random sampling process for SSD meta arch and update mean stddev coder to use default std dev when corresponding tensor is not added to boxlist field.\r\n\r\n--\r\n196148940  by Zhichao Lu:\r\n\r\n    Release ssdlite mobilenet v2 coco trained model.\r\n\r\n--\r\n196058528  by Zhichao Lu:\r\n\r\n    Apply FPN feature map generation before we add additional layers on top of resnet feature extractor.\r\n\r\n--\r\n195818367  by Zhichao Lu:\r\n\r\n    Add support for exporting detection keypoints.\r\n\r\n--\r\n195745420  by Zhichao Lu:\r\n\r\n    Introduce include_metrics_per_category option to Object Detection eval_config.\r\n\r\n--\r\n195734733  by Zhichao Lu:\r\n\r\n    Rename SSDLite config to be more explicit.\r\n\r\n--\r\n195717383  by Zhichao Lu:\r\n\r\n    Add quantized training to object_detection.\r\n\r\n--\r\n195683542  by Zhichao Lu:\r\n\r\n    Fix documentation for the interaction of fine_tune_checkpoint_type and load_all_detection_checkpoint_vars interaction.\r\n\r\n--\r\n195668233  by Zhichao Lu:\r\n\r\n    Using batch size from params dictionary if present.\r\n\r\n--\r\n195570173  by Zhichao Lu:\r\n\r\n    A few fixes to get new estimator API eval to match legacy detection eval binary by (1) plumbing `is_crowd` annotations through to COCO evaluator, (2) setting the `sloppy` flag in tf.contrib.data.parallel_interleave based on whether shuffling is enabled, and (3) saving the original image instead of the resized original image, which allows for small/medium/large mAP metrics to be properly computed.\r\n\r\n--\r\n195316756  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n--\r\n\r\nPiperOrigin-RevId: 196161788",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-05-10T17:45:52Z",
        "closed_at": "2018-05-10T18:57:03Z",
        "merged_at": "2018-05-10T18:57:03Z",
        "body": "The final BN and ReLU layer is only need for v2 model since it was\r\ndoing preactivation in each block.",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-05-10T03:29:29Z",
        "closed_at": "2019-12-03T07:08:32Z",
        "merged_at": null,
        "body": "According to code here:\r\nhttps://github.com/tensorflow/models/blob/master/research/object_detection/meta_architectures/ssd_meta_arch.py#L780\r\n\r\nThe interface that DetectionModels should implement to load a checkpoint into the Tensorflow graph should be `restore_map` rather than `restore`.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 40,
        "deletions": 25,
        "changed_files": 2,
        "created_at": "2018-05-09T21:52:39Z",
        "closed_at": "2018-05-10T00:18:03Z",
        "merged_at": "2018-05-10T00:18:03Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-05-09T11:04:52Z",
        "closed_at": "2019-12-03T07:08:32Z",
        "merged_at": null,
        "body": "when i incised big picture to small picture , i forgot to change xml \u201csize parameters\u201d. As follow:\r\n![image](https://user-images.githubusercontent.com/10041362/39810764-dc1d1ac8-53b8-11e8-93eb-2156332e3981.png)\r\nxml size: width=4963  height=3509 ,image size: width=1024  height=1024\r\n\r\nbut it can generate tfreord,as follow:\r\n![image](https://user-images.githubusercontent.com/10041362/39810808-0d780402-53b9-11e8-902c-92a5980d329b.png)\r\n\r\nit worked!\r\n\r\nI used the tfreord to train my model and  it did't report error , but  using tensorboard to find out that some loss was abnormal. As follow:\r\n![image](https://user-images.githubusercontent.com/10041362/39810985-cc813cce-53b9-11e8-93c0-e8e610c0943e.png)\r\n\r\nAfter a few hours, i found error that xml size is wrong and using  software \u201clabelImg\u201d cannot find error. As follow:\r\n \r\n![image](https://user-images.githubusercontent.com/10041362/39811171-6b900d4a-53ba-11e8-8284-dbfc39eaee83.png)\r\n\r\nBut tensorflow/models did't check out it. \r\n\r\nAfter i changed code , it can check out.As follow:\r\n![image](https://user-images.githubusercontent.com/10041362/39811477-68a3a0dc-53bb-11e8-8259-68280a9e65a4.png)\r\n\r\nWishing that it can help other people to avoid this error. ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-05-09T09:23:21Z",
        "closed_at": "2018-05-09T15:36:23Z",
        "merged_at": "2018-05-09T15:36:23Z",
        "body": "Update mnist_eager.py to use GPU if available and not specified otherwise. At the moment it uses the CPU even if a GPU is available, since \"if flags_obj.no_gpu or tf.test.is_gpu_available():\" in \"def run_mnist_eager(flags_obj):\" evaluates to True if a GPU is available.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 10,
        "changed_files": 3,
        "created_at": "2018-05-09T04:03:15Z",
        "closed_at": "2018-05-15T16:03:57Z",
        "merged_at": "2018-05-15T16:03:57Z",
        "body": "Make some code parts more pythonic.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 450,
        "deletions": 116,
        "changed_files": 10,
        "created_at": "2018-05-09T00:10:22Z",
        "closed_at": "2018-05-11T20:11:22Z",
        "merged_at": "2018-05-11T20:11:22Z",
        "body": "1. All three type of benchmark loggers are behind the control flag:\r\nbenchmark_logger_type.\r\n\r\n2. The benchmark_uploader is spilt into lib and main module.\r\n\r\n3. Added test cases with mock for bigquery related classes.\r\n\r\n4. The git mv does not seems to preserve the file history, even I try to just move the file to new location in the first commit.",
        "comments": 8
    },
    {
        "merged": false,
        "additions": 501,
        "deletions": 156,
        "changed_files": 12,
        "created_at": "2018-05-08T22:09:43Z",
        "closed_at": "2018-05-09T00:11:49Z",
        "merged_at": null,
        "body": "1. All three type of benchmark loggers are behind the control flag:\r\nbenchmark_logger_type.\r\n\r\n2. The benchmark_uploader is spilt into lib and main module.\r\n\r\n3. Added test cases with mock for bigquery related classes.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 16,
        "deletions": 37,
        "changed_files": 1,
        "created_at": "2018-05-08T21:15:41Z",
        "closed_at": "2019-12-03T07:08:31Z",
        "merged_at": null,
        "body": "Corrected Matplotlib warning during imports.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 27,
        "deletions": 2,
        "changed_files": 4,
        "created_at": "2018-05-08T17:58:07Z",
        "closed_at": "2018-05-08T20:11:49Z",
        "merged_at": "2018-05-08T20:11:49Z",
        "body": "This PR adds a flag validator to prevent this particular numerically unstable configuration.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-05-08T14:18:15Z",
        "closed_at": "2018-05-15T04:00:43Z",
        "merged_at": "2018-05-15T04:00:43Z",
        "body": "In current implementation in `models/research/object_detection/utils/dataset_util.py` at `line 137` `records_dataset.shuffle(config.shuffle_buffer_size)` is not assigned to variable, and it should be `\r\nrecords_dataset = records_dataset.shuffle(config.shuffle_buffer_size)`",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 874,
        "deletions": 501,
        "changed_files": 10,
        "created_at": "2018-05-07T21:50:49Z",
        "closed_at": "2018-05-08T18:10:37Z",
        "merged_at": "2018-05-08T18:10:37Z",
        "body": "* Several new plots for the slide deck in plots_for_slides.py.\r\n* Updates to text/commens.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-05-07T15:42:52Z",
        "closed_at": "2019-12-03T07:08:31Z",
        "merged_at": null,
        "body": "Fix document typo about default lossType of hardExampleMiner\r\nI send out this PR because I would like to double confirm the default lossType is \"BOTH\" instead of just classification loss.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-05-05T20:05:45Z",
        "closed_at": "2018-05-07T12:55:16Z",
        "merged_at": "2018-05-07T12:55:16Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 2529,
        "deletions": 129,
        "changed_files": 40,
        "created_at": "2018-05-05T13:49:33Z",
        "closed_at": "2018-06-05T07:54:46Z",
        "merged_at": "2018-06-05T07:54:45Z",
        "body": "Fixes #3209. Fixes #3428\r\n\r\nTested:\r\npython generate_cifar10_tfrecords.py --data-dir=\"/tmp/cifar10_tfrecords/python\"\r\npython3 generate_cifar10_tfrecords.py --data-dir=\"/tmp/cifar10_tfrecords/python3\"",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-05-05T11:32:11Z",
        "closed_at": "2018-05-09T00:55:35Z",
        "merged_at": null,
        "body": "I try to use generate_cifar10_tfrecords.py to generate tfrcord,but it report UnicodeEncodeError. I change \"data_dict = pickle.load(f)\" to \"data_dict = pickle.load(f,encoding='latin1')\", then it works. Latin-1 works for any input as it maps the byte values 0-255 to the first 256 Unicode codepoints directly",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2018-05-04T22:44:31Z",
        "closed_at": "2018-05-07T13:22:51Z",
        "merged_at": "2018-05-07T13:22:51Z",
        "body": "Stage: https://colab.sandbox.google.com/github/lamberta/models/blob/b73af7d26ed8b20a7b5d4aeac0258dfa461a65ba/samples/core/get_started/eager.ipynb",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1110,
        "deletions": 0,
        "changed_files": 7,
        "created_at": "2018-05-04T20:08:15Z",
        "closed_at": "2018-05-22T05:31:34Z",
        "merged_at": "2018-05-22T05:31:34Z",
        "body": "Add recommendation model to the garden. Will update readme and add unit tests.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 111,
        "deletions": 98,
        "changed_files": 7,
        "created_at": "2018-05-03T23:36:04Z",
        "closed_at": "2018-05-04T01:39:14Z",
        "merged_at": "2018-05-04T01:39:13Z",
        "body": "Inside Google's testing infrastructure the namespace `version` is already taken, and this is breaking testing.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 408,
        "deletions": 280,
        "changed_files": 7,
        "created_at": "2018-05-03T22:12:35Z",
        "closed_at": "2018-05-11T18:02:04Z",
        "merged_at": "2018-05-11T18:02:04Z",
        "body": "",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-05-03T12:41:50Z",
        "closed_at": "2018-05-03T16:14:43Z",
        "merged_at": null,
        "body": "See issue #4047 for more details on the problems encountered and fix.",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 1114,
        "deletions": 10,
        "changed_files": 8,
        "created_at": "2018-05-03T05:28:14Z",
        "closed_at": "2018-05-03T20:30:49Z",
        "merged_at": null,
        "body": "195147413  by Zhichao Lu:\r\n\r\n    SSDLite config for mobilenet v2.\r\n\r\n--\r\n194883585  by Zhichao Lu:\r\n\r\n    Simplify TPU compatible nearest neighbor upsampling using reshape and broadcasting.\r\n\r\n--\r\n194851009  by Zhichao Lu:\r\n\r\n    Include ava v2.1 detection models in model zoo.\r\n\r\n--\r\n194510347  by Zhichao Lu:\r\n\r\n    Contains implementation of Visual Relations Detection evaluation metric\r\n    (evaluation metric itself).\r\n\r\n--\r\n194292198  by Zhichao Lu:\r\n\r\n    Add option to evaluate any checkpoint (without requiring write access to that directory and overwriting any existing logs there).\r\n\r\n--\r\n194122420  by Zhichao Lu:\r\n\r\n    num_gt_boxes_per_image and num_det_boxes_per_image value incorrect.\r\n    Should be not the expand dim.\r\n\r\n--\r\n193974479  by Zhichao Lu:\r\n\r\n    Fixing a bug in the coco evaluator.\r\n\r\n--\r\n193959861  by Zhichao Lu:\r\n\r\n    Read the default batch size from config file.\r\n\r\n--\r\n193737238  by Zhichao Lu:\r\n\r\n    Fix data augmentation functions.\r\n\r\n--\r\n193576336  by Zhichao Lu:\r\n\r\n    Add support for training keypoints.\r\n\r\n--\r\n193409179  by Zhichao Lu:\r\n\r\n    Update protobuf requirements to 3+ in installation docs.\r\n\r\n--\r\n193382651  by Zhichao Lu:\r\n\r\n    Updating coco evaluation metrics to allow for a batch of image info, rather than a single image.\r\n\r\n--\r\n193244778  by Zhichao Lu:\r\n\r\n    Remove deprecated batch_norm_trainable field from ssd mobilenet v2 config\r\n\r\n--\r\n193228972  by Zhichao Lu:\r\n\r\n    Make sure the final layers are also resized proportional to conv_depth_ratio.\r\n\r\n--\r\n193204364  by Zhichao Lu:\r\n\r\n    Do not add batch norm parameters to final conv2d ops that predict boxes encodings and class scores in weight shared conv box predictor.\r\n\r\n    This allows us to set proper bias and force initial predictions to be background when using focal loss.\r\n\r\n--\r\n193137342  by Zhichao Lu:\r\n\r\n    Add a util function to visualize value histogram as a tf.summary.image.\r\n\r\n--\r\n193119411  by Zhichao Lu:\r\n\r\n    Adding support for reading in logits as groundtruth labels and applying an optional temperature (scaling) before softmax in support of distillation.\r\n\r\n--\r\n193087707  by Zhichao Lu:\r\n\r\n    Post-process now works again in train mode.\r\n\r\n--\r\n193067658  by Zhichao Lu:\r\n\r\n    fix flakiness in testSSDRandomCropWithMultiClassScores due to randomness.\r\n\r\n--\r\n192922089  by Zhichao Lu:\r\n\r\n    Add option to set dropout for classification net in weight shared box predictor.\r\n\r\n--\r\n192850747  by Zhichao Lu:\r\n\r\n    Remove inaccurate caveat from proto file.\r\n\r\n--\r\n192837477  by Zhichao Lu:\r\n\r\n    Extend to accept different ratios of conv channels.\r\n\r\n--\r\n192813444  by Zhichao Lu:\r\n\r\n    Adding option for one_box_for_all_classes to the box_predictor\r\n\r\n--\r\n192624207  by Zhichao Lu:\r\n\r\n    Update to trainer to allow for reading multiclass scores\r\n\r\n--\r\n192583425  by Zhichao Lu:\r\n\r\n    Contains implementation of Visual Relations Detection evaluation metric (per\r\n    image evaluation).\r\n\r\n--\r\n192529600  by Zhichao Lu:\r\n\r\n    Modify the ssd meta arch to allow the option of not adding an implicit background class.\r\n\r\n--\r\n192512429  by Zhichao Lu:\r\n\r\n    Refactor model_tpu_main.py files and move continuous eval loop into model_lib.py\r\n\r\n--\r\n192494267  by Zhichao Lu:\r\n\r\n    Update create_pascal_tf_record.py and create_pet_tf_record.py\r\n\r\n--\r\n192485456  by Zhichao Lu:\r\n\r\n    Enforcing that all eval metric ops have valid python strings.\r\n\r\n--\r\n192472546  by Zhichao Lu:\r\n\r\n    Set regularize_depthwise to true in mobilenet_v1_argscope.\r\n\r\n--\r\n192421843  by Zhichao Lu:\r\n\r\n    Refactoring of Mask-RCNN to put all mask prediction code in third stage.\r\n\r\n--\r\n192320460  by Zhichao Lu:\r\n\r\n    Returning eval_on_train_input_fn from create_estimator_and_inputs(), rather than using train_input_fn in EVAL mode (which will still have data augmentation).\r\n\r\n--\r\n192226678  by Zhichao Lu:\r\n\r\n    Access TPUEstimator and CrossShardOptimizer from tf namesspace.\r\n\r\n--\r\n192195514  by Zhichao Lu:\r\n\r\n    Fix test that was flaky due to randomness\r\n\r\n--\r\n192166224  by Zhichao Lu:\r\n\r\n    Minor fixes to match git repo.\r\n\r\n--\r\n192147130  by Zhichao Lu:\r\n\r\n    use shape utils for assertion in feature extractor.\r\n\r\n--\r\n192132440  by Zhichao Lu:\r\n\r\n    Class agnostic masks for mask_rcnn\r\n\r\n--\r\n192006190  by Zhichao Lu:\r\n\r\n    Add learning rate summary in EVAL mode in model.py\r\n\r\n--\r\n192004845  by Zhichao Lu:\r\n\r\n    Migrating away from Experiment class, as it is now deprecated. Also, refactoring into a separate model library and binaries.\r\n\r\n--\r\n191957195  by Zhichao Lu:\r\n\r\n    Add classification_loss and localiztion_loss metrics for TPU jobs.\r\n\r\n--\r\n191932855  by Zhichao Lu:\r\n\r\n    Add an option to skip the last striding in mobilenet. The modified network has nominal output stride 16 instead of 32.\r\n\r\n--\r\n191787921  by Zhichao Lu:\r\n\r\n    Add option to override base feature extractor hyperparams in SSD models. This would allow us to use the same set of hyperparams for the complete feature extractor (base + new layers) if desired.\r\n\r\n--\r\n191743097  by Zhichao Lu:\r\n\r\n    Adding an attribute to SSD model to indicate which fields in prediction dictionary have a batch dimension. This will be useful for future video models.\r\n\r\n--\r\n191668425  by Zhichao Lu:\r\n\r\n    Internal change.\r\n\r\n--\r\n191649512  by Zhichao Lu:\r\n\r\n    Introduce two parameters in ssd.proto - freeze_batchnorm, inplace_batchnorm_update - and set up slim arg_scopes in ssd_meta_arch.py such that applies it to all batchnorm ops in the predict() method.\r\n\r\n    This centralizes the control of freezing and doing inplace batchnorm updates.\r\n\r\n--\r\n191620303  by Zhichao Lu:\r\n\r\n    Modifications to the preprocessor to support multiclass scores\r\n\r\n--\r\n\r\nPiperOrigin-RevId: 195147413",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 9237,
        "deletions": 2951,
        "changed_files": 145,
        "created_at": "2018-05-02T21:38:49Z",
        "closed_at": "2018-05-11T19:13:26Z",
        "merged_at": "2018-05-11T19:13:26Z",
        "body": "Releases the DRAGNN runtime, along with a large batch of other updates.  Notably, upgrades the TF submodule to r1.8.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 77,
        "deletions": 16,
        "changed_files": 6,
        "created_at": "2018-05-02T21:24:54Z",
        "closed_at": "2018-05-03T21:19:51Z",
        "merged_at": "2018-05-03T21:19:51Z",
        "body": "Probably will hit a merge conflict with Taylor's flag change.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 0,
        "changed_files": 0,
        "created_at": "2018-05-02T20:33:24Z",
        "closed_at": "2018-05-02T21:43:03Z",
        "merged_at": null,
        "body": "Please disregard. Apologies for the PR spam.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2018-05-02T19:46:35Z",
        "closed_at": "2018-09-25T22:15:56Z",
        "merged_at": null,
        "body": "The text indicating that pycoco installation is causing some confusion (https://github.com/tensorflow/models/issues/3829), so this PR simply removes it.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 10638,
        "deletions": 0,
        "changed_files": 24,
        "created_at": "2018-05-02T17:54:26Z",
        "closed_at": "2018-05-02T21:31:24Z",
        "merged_at": "2018-05-02T21:31:24Z",
        "body": "Just a direct copy from the working repo - no changes have been made.\r\nedit: Made one edit to update the licensing message. No more edits in this PR! ",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-05-02T15:20:20Z",
        "closed_at": "2018-05-11T22:46:07Z",
        "merged_at": "2018-05-11T22:46:07Z",
        "body": "The instructions for exporting object detection models state that the `--output_directory` argument is the path to where the frozen inference graph is saved, when actually the argument specifies the directory where the model is exported, which exports more than just a frozen graph.\r\n\r\nThis corrects the argument and description to match the actual implementation.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-05-02T00:11:42Z",
        "closed_at": "2018-05-02T03:51:13Z",
        "merged_at": "2018-05-02T03:51:13Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 15,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-05-01T23:20:42Z",
        "closed_at": "2018-05-02T21:55:44Z",
        "merged_at": null,
        "body": "If this seems good I'll apply it to all of the notebooks. \r\nI'll use the same pattern for the \"source on github\" blocks in the api-docs.\r\n\r\nUsing a table is the only way to get something that's at all reasonable on all 4 platforms:\r\n\r\n* [Github](https://drive.google.com/open?id=1ni6osln5_eGhtkfaGe9Fzta4ZNlkB_mO)\r\n* [Colab](https://drive.google.com/open?id=1LqCuSc-svCiumwlpkXgQRGtwuR9tWDIm)\r\n* [Jupyter](https://drive.google.com/open?id=1tw_FND8QiGDKav8q0BsYEw29ADMHV8vb)\r\n* [TensorFlow.org](https://drive.google.com/file/d/1dRkaRxaHkN_6Vc9SNpgtxU16d2_y66YQ)",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 14,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2018-05-01T18:34:57Z",
        "closed_at": "2019-12-03T07:08:30Z",
        "merged_at": null,
        "body": "Resolving issue #4036 ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2018-05-01T04:51:35Z",
        "closed_at": "2018-05-01T17:02:48Z",
        "merged_at": "2018-05-01T17:02:47Z",
        "body": "@MarkDaoust : Is there some tests I should be running as well? And once this is in, does https://www.tensorflow.org/get_started/eager need to be regenerated?",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 116,
        "deletions": 0,
        "changed_files": 5,
        "created_at": "2018-05-01T00:27:22Z",
        "closed_at": "2018-05-01T02:27:31Z",
        "merged_at": "2018-05-01T02:27:31Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 201,
        "deletions": 260,
        "changed_files": 10,
        "created_at": "2018-04-30T21:29:11Z",
        "closed_at": "2018-05-03T19:09:27Z",
        "merged_at": "2018-05-03T19:09:27Z",
        "body": "This PR reverts 823da3187f25593275f437ec86624b42c8395fbc plus a couple of minor merge conflicts.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-04-30T18:09:17Z",
        "closed_at": "2018-04-30T22:40:57Z",
        "merged_at": "2018-04-30T22:40:57Z",
        "body": "This adds new import paths to mnist_tpu.py so individuals can check out the git repository and run `python mnist_tpu.py` without finagling with python import search paths.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 121,
        "deletions": 149,
        "changed_files": 2,
        "created_at": "2018-04-29T09:08:58Z",
        "closed_at": "2018-04-30T05:07:07Z",
        "merged_at": "2018-04-30T05:07:07Z",
        "body": "Thanks to Yaoming Zhu for pointing out the bug.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-04-28T17:02:43Z",
        "closed_at": "2018-04-30T17:30:17Z",
        "merged_at": "2018-04-30T17:30:17Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 16,
        "deletions": 14,
        "changed_files": 1,
        "created_at": "2018-04-28T06:28:02Z",
        "closed_at": "2019-12-03T07:08:30Z",
        "merged_at": null,
        "body": "I have a legacy boxes-only dataset without masks and here are the fixes to let script process it as before.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2018-04-27T11:22:01Z",
        "closed_at": "2018-04-30T17:37:38Z",
        "merged_at": "2018-04-30T17:37:38Z",
        "body": "Refer to commit \"use reduce_mean instead of Average Pooling\"(d5663b3c04631b742623c64d2da497904d32bf05), \"second_pool_size\" and \"second_pool_stride\" no longer needed in resnet_model",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 214808,
        "deletions": 0,
        "changed_files": 69,
        "created_at": "2018-04-27T04:02:27Z",
        "closed_at": "2018-05-02T03:42:25Z",
        "merged_at": null,
        "body": "This work is used to reproduce MTCNN, a Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks using TensorFlow framework.\r\n\r\n1) See <ROOT>/data/WIDER_Face/README.md for downloading WIDER Face dataset.\r\n2) See <ROOT>//data/LFW_Landmark/README.md for downloading LFW facial landmark dataset.\r\n\r\n3) Generate a basic dataset i.e. PNet dataset.\r\npython generate_simple_dataset.py \\\r\n\t--annotation_image_dir=./data/WIDER_Face/WIDER_train/images \\ \r\n\t--annotation_file_name=./data/WIDER_Face/WIDER_train/wider_face_train.txt \\\r\n\t--landmark_image_dir=./data/LFW_Landmark \\\r\n\t--landmark_file_name=./data/LFW_Landmark/trainImageList.txt \\\r\n\t--target_root_dir=./data/datasets/mtcnn \\\r\n\t--minimum_face=12\r\n\r\n4) Train PNet.\r\npython train_model.py \\\r\n\t--network_name=PNet \\ \r\n\t--train_root_dir=./data/models/mtcnn/train \\\r\n\t--dataset_root_dir=./data/datasets/mtcnn \\\r\n\t--base_learning_rate=0.01 \\\r\n\t--max_number_of_epoch=30\r\n\r\n5) Generate a hard dataset i.e. RNet dataset.\r\npython generate_hard_dataset.py \\\r\n\t--network_name=RNet \\ \r\n\t--train_root_dir=./data/models/mtcnn/train \\\r\n\t--annotation_image_dir=./data/WIDER_Face/WIDER_train/images \\ \r\n\t--annotation_file_name=./data/WIDER_Face/WIDER_train/wider_face_train.txt \\\r\n\t--landmark_image_dir=./data/LFW_Landmark \\\r\n\t--landmark_file_name=./data/LFW_Landmark/trainImageList.txt \\\r\n\t--target_root_dir=./data/datasets/mtcnn \\\r\n\t--minimum_face=24\r\n\r\n6) Train RNet.\r\npython train_model.py \\\r\n\t--network_name=RNet \\ \r\n\t--train_root_dir=./data/models/mtcnn/train \\\r\n\t--dataset_root_dir=./data/datasets/mtcnn \\\r\n\t--base_learning_rate=0.01 \\\r\n\t--max_number_of_epoch=22\r\n\r\n7) Generate a hard dataset i.e. ONet dataset.\r\npython generate_hard_dataset.py \\\r\n\t--network_name=ONet \\ \r\n\t--train_root_dir=./data/models/mtcnn/train \\\r\n\t--annotation_image_dir=./data/WIDER_Face/WIDER_train/images \\ \r\n\t--annotation_file_name=./data/WIDER_Face/WIDER_train/wider_face_train.txt \\\r\n\t--landmark_image_dir=./data/LFW_Landmark \\\r\n\t--landmark_file_name=./data/LFW_Landmark/trainImageList.txt \\\r\n\t--target_root_dir=./data/datasets/mtcnn \\\r\n\t--minimum_face=24\r\n\r\n8) Train ONet.\r\npython train_model.py \\\r\n\t--network_name=ONet \\ \r\n\t--train_root_dir=./data/models/mtcnn/train \\\r\n\t--dataset_root_dir=./data/datasets/mtcnn \\\r\n\t--base_learning_rate=0.01 \\\r\n\t--max_number_of_epoch=22\r\n\r\n9) Webcamera demo.\r\npython webcamera_demo.py \r\nOR\r\npython webcamera_demo.py \\\r\n\t --test_mode\r\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1429,
        "deletions": 322,
        "changed_files": 40,
        "created_at": "2018-04-26T23:50:53Z",
        "closed_at": "2018-05-01T23:41:16Z",
        "merged_at": "2018-05-01T23:41:16Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 891,
        "deletions": 636,
        "changed_files": 22,
        "created_at": "2018-04-26T20:45:58Z",
        "closed_at": "2018-05-03T00:25:07Z",
        "merged_at": "2018-05-03T00:25:07Z",
        "body": "This is a mock up of what arg parsing would look like with absl.flags instead of argparse. Run demo.py to see `-help` and `-helpfull`. Sadly there is no `-h`.\r\n\r\nEDIT: `-h` is possible.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2018-04-25T23:07:32Z",
        "closed_at": "2018-04-26T14:38:42Z",
        "merged_at": "2018-04-26T14:38:42Z",
        "body": "Fixes #3844 . cc @samikama",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 534,
        "deletions": 134,
        "changed_files": 8,
        "created_at": "2018-04-25T22:35:13Z",
        "closed_at": "2018-04-27T00:07:51Z",
        "merged_at": "2018-04-27T00:07:51Z",
        "body": "+ plot_partition.py (budget allocation with smooth sensitivity).\r\n+ utility_queries_answered.py (Figure 1, left).\r\n+ several changes to the scripts required for the ICLR poster.\r\n+ Fixing the owners list of the differential_privacy directory.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-04-25T15:58:15Z",
        "closed_at": "2018-04-25T17:15:09Z",
        "merged_at": "2018-04-25T17:15:09Z",
        "body": "This is trying to fix #4059 ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 45,
        "deletions": 80,
        "changed_files": 5,
        "created_at": "2018-04-25T14:25:39Z",
        "closed_at": "2018-04-25T23:30:01Z",
        "merged_at": "2018-04-25T23:30:01Z",
        "body": "1. Solved by adding cast with tf.cast(predictions, tf.float64) at the point of\nproblem case.\n2. Completed make_dataset() of automobile_data.py for the transforming of\nDataFrame to Dataset, the standard one we know of official site.\n3. Added from_dataset() in automobile_data.py for re-use by others sites in\ncookbook/regression.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-04-25T07:11:41Z",
        "closed_at": "2019-12-03T07:08:30Z",
        "merged_at": null,
        "body": "fix the miss suffix 'py' of /build_imagenet_data.py",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 534,
        "deletions": 134,
        "changed_files": 8,
        "created_at": "2018-04-25T00:49:13Z",
        "closed_at": "2018-04-25T22:36:03Z",
        "merged_at": null,
        "body": "+ plot_partition.py (budget allocation with smooth sensitivity).\r\n+ utility_queries_answered.py (Figure 1, left).\r\n+ several changes to the scripts required for the ICLR poster.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 168,
        "deletions": 64,
        "changed_files": 6,
        "created_at": "2018-04-24T23:29:29Z",
        "closed_at": "2018-04-26T22:08:20Z",
        "merged_at": null,
        "body": "I think it is finally time to have a dedicated argparsing class. The primary motivation is to provide a good way to do secondary parsing on flags without individual models overriding .parse_args(). And as long as I'm at it may as well implement the desperately needed --helpful flag.\r\n\r\nSecondary parsing should live in the base parser, and individual models generally shouldn't need to worry about it. Currently the only secondary parsing is the dtype rewriting, but there will be more with DistributionStrategies and TPUs. By accessing the dict that underlies flags, it is possible to make secondary parsing methods bow out gracefully if not needed (i.e. if a flag is not present) rather than forcing individual models to choose which secondary parsing to use. (see .parse_dtype_info() as an example)\r\n\r\n--helpful is implemented by parent parsers keeping track of a self.verbose_flags list; these flags will show up in --helpful but not --help. Again, this is entirely voluntary. If a parser doesn't implement this convention none of it's flags will be suppressed. If you have strong feelings about a flag being verbose/not verbose, feel free to suggest changes.",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 568,
        "deletions": 1,
        "changed_files": 8,
        "created_at": "2018-04-24T17:47:26Z",
        "closed_at": "2018-05-18T21:03:52Z",
        "merged_at": "2018-05-18T21:03:52Z",
        "body": "Hello @karmel and @yhliang2018 \r\n\r\nWe are adding a boosted_trees model for the higgs dataset.\r\nPlease review.\r\n\r\nThanks!\r\n\r\nFYI @ispirmustafa ",
        "comments": 8
    },
    {
        "merged": false,
        "additions": 28,
        "deletions": 10,
        "changed_files": 1,
        "created_at": "2018-04-22T03:25:19Z",
        "closed_at": "2018-09-06T06:50:55Z",
        "merged_at": null,
        "body": "https://github.com/tensorflow/models/commit/7a9934df2afdf95be9405b4e9f1f2480d748dc40 has change the matplotlib imports, it cause\r\nobject_det4ection_tutorial.ipynb to unable to run.\r\nThis commit fixes the problem (#3786) .",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 271,
        "deletions": 160,
        "changed_files": 6,
        "created_at": "2018-04-22T00:28:27Z",
        "closed_at": "2018-05-04T16:30:41Z",
        "merged_at": "2018-05-04T16:30:41Z",
        "body": "Add more flags to allow run each individual step only. Arguments/flags are not finalized. Feel free to add comments/suggestions, thanks.\r\nWill update readme with more detailed commands.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 67,
        "deletions": 26,
        "changed_files": 5,
        "created_at": "2018-04-20T21:41:49Z",
        "closed_at": "2018-04-26T23:50:03Z",
        "merged_at": "2018-04-26T23:50:03Z",
        "body": "Looks like wide deep is the only official model that doesn't currently export savedmodel. Here are the changes to export it.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 171,
        "deletions": 44,
        "changed_files": 3,
        "created_at": "2018-04-20T08:51:28Z",
        "closed_at": "2019-11-02T03:04:08Z",
        "merged_at": null,
        "body": "This is a small additional feature which will be helpful  for people with **single GPU (gtx-1060, gtx-1080 etc)** or **limited GPU memory.**\r\n\r\nIf above is the case, when both the Training and evaluation scripts are started together (official recommended way), training might hang or might cause Resource Exhaust Error! (Especially with Faster RCNN architecture). In most cases the user experiences training freeze because, The evaluation script will take over the hardware, creating a training bottleneck.There are two ways to go about this problem.\r\n\r\n1. Run training in GPU and run evaluation in CPU. (even this solution does not guarantee that your training will work without freezing if you have RAM less than 16GB or you use a heavy model).\r\n\r\n2. Run only training script for specific iterations and then run the evaluation script, to check if the model has converged. I know this is a round about way but, I couldn't think of any better solution .Before this commit, evaluation script runs evaluation only on the latest checkpoint thus, you won't be able to evaluate other checkpoints. This commit also addresses this problem by optionally making it to run on all the checkpoints\r\n\r\nBoth of the above cases can be set using boolean via terminal while calling eval.py script",
        "comments": 16
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-04-20T06:38:02Z",
        "closed_at": "2018-05-17T17:57:31Z",
        "merged_at": "2018-05-17T17:57:31Z",
        "body": "Fixes #4013 ",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-04-19T22:21:39Z",
        "closed_at": "2019-12-03T07:08:30Z",
        "merged_at": null,
        "body": "The image family `gci-stable` in `google-containers` project has long been deprecated.\r\n```\r\n$ gcloud compute images list --project google-containers --no-standard-images\r\nNAME                    PROJECT            FAMILY        DEPRECATED  STATUS\r\ncontainer-vm-v20170214  google-containers  container-vm              READY\r\n```\r\nThe preferred way to use COS images is via `cos-stable` image family in `cos-cloud` project.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 160,
        "deletions": 66,
        "changed_files": 6,
        "created_at": "2018-04-19T17:57:00Z",
        "closed_at": "2018-04-19T21:39:27Z",
        "merged_at": "2018-04-19T21:39:27Z",
        "body": "1. Create global instance of benchmark logger, which default log to\r\ntf.logging.info\r\n2. Allow user to config the logging location.\r\n3. Fix nits in code and comment.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-04-19T10:49:35Z",
        "closed_at": "2019-12-03T07:08:29Z",
        "merged_at": null,
        "body": "modify depth_multiplier param in slim.separable_conv2d in mobilenet_v1_base function, change depth_multiplier=1 to depth_multiplier",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2646,
        "deletions": 244,
        "changed_files": 20,
        "created_at": "2018-04-19T00:38:21Z",
        "closed_at": "2018-04-20T23:12:13Z",
        "merged_at": "2018-04-20T23:12:13Z",
        "body": "I add unit tests for some of the core py files. It's a large code base again, sorry.....",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-04-18T22:22:34Z",
        "closed_at": "2018-04-20T01:25:45Z",
        "merged_at": "2018-04-20T01:25:45Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 20,
        "changed_files": 1,
        "created_at": "2018-04-18T16:57:33Z",
        "closed_at": "2018-04-23T16:31:59Z",
        "merged_at": "2018-04-23T16:31:59Z",
        "body": "Incorporate some changes to the MNIST TPU example that makes interacting with the cluster more intuitive.\r\n\r\n@saeta @frankchn Do we need to wait for a tf-nightly build with your other cluster resolver changes to merge this?",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-04-18T09:00:05Z",
        "closed_at": "2018-08-19T15:58:42Z",
        "merged_at": "2018-08-19T15:58:42Z",
        "body": null,
        "comments": 1
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 12,
        "changed_files": 1,
        "created_at": "2018-04-18T01:11:04Z",
        "closed_at": "2018-04-18T02:28:38Z",
        "merged_at": "2018-04-18T02:28:38Z",
        "body": "CC @samikama",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-04-17T20:30:00Z",
        "closed_at": "2018-04-17T21:32:20Z",
        "merged_at": "2018-04-17T21:32:20Z",
        "body": "Five seems like a nice round number? Is two really sufficient?",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-04-17T19:13:17Z",
        "closed_at": "2018-04-19T00:36:47Z",
        "merged_at": "2018-04-19T00:36:47Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-04-17T09:58:25Z",
        "closed_at": "2018-04-17T16:28:15Z",
        "merged_at": "2018-04-17T16:28:15Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-04-15T09:21:53Z",
        "closed_at": "2019-12-03T07:08:29Z",
        "merged_at": null,
        "body": "posterior post_zs should start from 0\r\n\r\nExample\r\n```\r\n>>> a = [1,5,23,45]\r\n>>> a[1:]\r\n[5, 23, 45]\r\n>>> a[0:]\r\n[1, 5, 23, 45]\r\n```",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-04-15T09:06:58Z",
        "closed_at": "2019-12-03T07:08:29Z",
        "merged_at": null,
        "body": "Adding self to datasets and factors_dim",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-04-13T23:00:08Z",
        "closed_at": "2018-04-16T17:59:06Z",
        "merged_at": "2018-04-16T17:59:06Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2808,
        "deletions": 1218,
        "changed_files": 61,
        "created_at": "2018-04-13T17:01:40Z",
        "closed_at": "2018-04-17T00:05:02Z",
        "merged_at": "2018-04-17T00:05:02Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-04-13T10:18:39Z",
        "closed_at": "2019-12-03T07:08:28Z",
        "merged_at": null,
        "body": "\u2026elism\r\n\r\nSigned-off-by: shaohua <shaohua.zhang@intel.com>",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-04-13T10:03:46Z",
        "closed_at": "2019-12-03T07:08:28Z",
        "merged_at": null,
        "body": "Signed-off-by: shaohua <shaohua.zhang@intel.com>",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2018-04-13T01:18:41Z",
        "closed_at": "2018-04-16T22:42:41Z",
        "merged_at": null,
        "body": "Quick bug fix for #3959. It's probably best not to have graph-dependent logging in the model.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-04-12T21:17:53Z",
        "closed_at": "2018-04-12T22:23:20Z",
        "merged_at": null,
        "body": "The recent change to make MNIST use Sequential is not compatible with TensorFlow 1.7. This is an issue because 1.7 is the latest publicly available cloud TPU version. The fix is a very minor additional shape specification.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-04-12T01:17:42Z",
        "closed_at": "2018-04-12T02:47:29Z",
        "merged_at": "2018-04-12T02:47:29Z",
        "body": "This commit changes a tiny typo in the Eager Execution notebook.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 70,
        "deletions": 1,
        "changed_files": 6,
        "created_at": "2018-04-11T22:29:31Z",
        "closed_at": "2019-12-03T07:08:28Z",
        "merged_at": null,
        "body": "This adds flags to set the random seed for python and tensorflow. This is intended to make timing benchmarks (more) repeatable. ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3721,
        "deletions": 0,
        "changed_files": 19,
        "created_at": "2018-04-11T21:41:16Z",
        "closed_at": "2018-04-18T22:50:26Z",
        "merged_at": "2018-04-18T22:50:26Z",
        "body": "The original MiniGo can be roughly divided into three main parts: DualNet model, MCTS, and Go-related domain knowledge. This PR is mainly about the DualNet model part, and asks for reviews on the following four files:\r\nminigo.py: The main entry to run minigo.\r\ndualnet_model.py: The model definition.\r\ndual_net.py: The run loop of DualNet.\r\nmodel_utils: Utils for DualNet model, including model parameters and other misc.\r\n\r\nFor other py files, feel free to add any comments if you have. I am still working on them, mainly about code clean up and Python2 compatibility. ",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-04-11T11:43:16Z",
        "closed_at": "2019-12-03T07:08:27Z",
        "merged_at": null,
        "body": "Running the [Recurrent Neural Networks for Drawing Classification](https://www.tensorflow.org/tutorials/recurrent_quickdraw) tutorial with the suggested command:\r\n```bash\r\npython train_model.py \\\r\n    --training_data=rnn_tutorial_data/training.tfrecord-?????-of-????? \\\r\n    --eval_data=rnn_tutorial_data/eval.tfrecord-?????-of-????? \\\r\n    --classes_file=rnn_tutorial_data/training.tfrecord.classes\r\n```\r\n\r\ncurrently produces a ValueError crash without explicitly specifying the `--model_dir`\r\n\r\ne.g.\r\n```\r\nTraceback (most recent call last):\r\n  File \"train_model.py\", line 388, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/Volumes/GP_2T/tensorflow_tutorials/tf_src/venv/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 126, in run\r\n    _sys.exit(main(argv))\r\n  File \"train_model.py\", line 297, in main\r\n    save_summary_steps=100))\r\n  File \"/Volumes/GP_2T/tensorflow_tutorials/tf_src/venv/lib/python2.7/site-packages/tensorflow/python/estimator/run_config.py\", line 450, in __init__\r\n    compat_internal.path_to_str(model_dir))\r\n  File \"/Volumes/GP_2T/tensorflow_tutorials/tf_src/venv/lib/python2.7/site-packages/tensorflow/python/estimator/run_config.py\", line 754, in _get_model_dir\r\n    raise ValueError('model_dir should be non-empty.')\r\nValueError: model_dir should be non-empty.\r\n```\r\n\r\nOne option is to update the tutorial to mention the model directory **must** be specified, otherwise a quick fix is to default to the current directory\r\n\r\nP.S. I agree with @angersson 's [comment](https://github.com/tensorflow/models/issues/3478#issuecomment-368979610) which is why I've started a [stackoverflow thread](https://stackoverflow.com/questions/49774035/how-to-classify-a-quickdraw-doodle-using-tensorflows-sketch-rnn-tutorial) voicing my confusion over the tutorial",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-04-11T10:11:32Z",
        "closed_at": "2018-04-11T19:40:57Z",
        "merged_at": null,
        "body": "from documentation (https://docs.python.org/3.1/whatsnew/3.0.html#builtins)\r\nRemoved. dict.has_key() \u2013 use the in operator instead.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-04-11T04:55:28Z",
        "closed_at": "2019-12-03T07:08:27Z",
        "merged_at": null,
        "body": "Fixes issue #1916",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2018-04-11T04:51:50Z",
        "closed_at": "2018-04-11T18:22:57Z",
        "merged_at": "2018-04-11T18:22:57Z",
        "body": "While the original code works fine in practice, it technically\r\nallows gradient application and moving average update to happen\r\nin any order. This causes the behavior to deviate from pure\r\nmathematical specifications.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2018-04-10T23:23:18Z",
        "closed_at": "2018-04-11T19:37:13Z",
        "merged_at": "2018-04-11T19:37:13Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 52,
        "deletions": 58,
        "changed_files": 4,
        "created_at": "2018-04-10T19:10:04Z",
        "closed_at": "2018-04-11T23:25:11Z",
        "merged_at": "2018-04-11T23:25:11Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-04-10T18:11:43Z",
        "closed_at": "2018-04-10T19:33:42Z",
        "merged_at": "2018-04-10T19:33:42Z",
        "body": "The current code does not work in py2 since the input string could\r\ncontain unicode string, and default encoding in ASCII in py2. Change\r\nthe method to only do encode() which convert string to byte array\r\nwhen running python3.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 0,
        "changed_files": 0,
        "created_at": "2018-04-10T03:57:39Z",
        "closed_at": "2018-04-10T18:07:00Z",
        "merged_at": null,
        "body": "The current does not work in py2 since the input string could contain\r\nunicode string, and default encoding in ASCII in py2. Change the\r\nmethod to only do encode() which convert string to byte array when\r\nrunning python3.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-04-10T03:12:48Z",
        "closed_at": "2019-12-03T07:08:27Z",
        "merged_at": null,
        "body": "Performing `grid = tf.expand_dims(grid, 0)` right before `grid = tf.reshape(grid, [-1])` seems redundant.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 23,
        "deletions": 23,
        "changed_files": 43,
        "created_at": "2018-04-10T00:45:05Z",
        "closed_at": "2018-04-10T23:44:46Z",
        "merged_at": "2018-04-10T23:44:46Z",
        "body": "Reference tests are failing on TAP because they use open(). Due to some quirks with gfile (in py2 it defaults to bytes and in py3 it defaults to string, but it is illegal to pass \"rt\" or \"rb\") it is necessary to only interact with files as bytes. This leads to some awkward encode/decode calls with json, but those calls keep the code identical between py2 and py3.",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2018-04-09T07:41:49Z",
        "closed_at": "2018-04-10T08:56:49Z",
        "merged_at": null,
        "body": "I have the need to keep more than just 5 checkpoints during training. So, I've added tf.train.Saver's max_to_keep as a configurable parameter in the training pipeline file.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-04-09T05:44:36Z",
        "closed_at": "2018-04-09T19:01:02Z",
        "merged_at": "2018-04-09T19:01:02Z",
        "body": "duplicate eval metric: change the fourth metric from ## Weighted PASCAL VOC detection metric to ##  Weighted PASCAL VOC instance segmentation metric .",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-04-08T14:31:20Z",
        "closed_at": "2018-04-08T17:52:51Z",
        "merged_at": "2018-04-08T17:52:51Z",
        "body": "ignore_lable -> ignore_label from eval.py",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 0,
        "changed_files": 0,
        "created_at": "2018-04-08T02:40:52Z",
        "closed_at": "2018-04-09T17:11:10Z",
        "merged_at": null,
        "body": "This PR is trying to fix https://github.com/tensorflow/models/issues/3885\r\n\r\nThe current does not work in py2 since the input string could contain\r\nunicode string, and default encoding in ASCII in py2. Change the\r\nmethod to only do encode() which convert string to byte array when\r\nrunning python3.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-04-07T01:18:46Z",
        "closed_at": "2018-06-25T16:37:27Z",
        "merged_at": null,
        "body": "made a few changes to make things clear.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-04-06T03:59:31Z",
        "closed_at": "2018-04-06T17:26:33Z",
        "merged_at": "2018-04-06T17:26:33Z",
        "body": "For b/77657597. Btw, I don't have a TPU instance to validate this change, I think the tf.gfile should do the trick with internal env.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-04-06T02:57:54Z",
        "closed_at": "2019-11-24T23:44:52Z",
        "merged_at": null,
        "body": "Had variables for `master`, `worker` in the pyobject being `json.dumps`'d instead of strings.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 195,
        "deletions": 257,
        "changed_files": 10,
        "created_at": "2018-04-05T17:19:02Z",
        "closed_at": "2018-04-12T21:22:16Z",
        "merged_at": "2018-04-12T21:22:16Z",
        "body": "This PR pulls the work of the distribution strategies team back into official/resnet. Specifically it removes replicate model function and tower optimizer, incorporates some changes to the dataset pipeline, and uses various distribution strategies in the estimators.\r\n\r\n@guptapriya Would you be so kind as to check that this is a faithful port of your code?\r\n\r\nSo far I have only performed one run: ResNet_50_v2 on ImageNet. It converged to 76% in 2 days. I will be performing a full battery of runs in the coming days.\r\n\r\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 12,
        "deletions": 10,
        "changed_files": 2,
        "created_at": "2018-04-05T12:20:44Z",
        "closed_at": "2018-06-25T10:35:08Z",
        "merged_at": null,
        "body": "Pylint will catch more Syntax Errors if it is run on Python 3 rather than on Python 2.\r\n\r\n$ __python2 -m pylint --disable=all --enable=E0001 research/learning_unsupervised_learning__\r\n```\r\nNo config file found, using default configuration\r\n\r\n------------------------------------\r\nYour code has been rated at 10.00/10\r\n```\r\n$ __python3 -m pylint --disable=all --enable=E0001 research/learning_unsupervised_learning__\r\n```\r\nNo config file found, using default configuration\r\n\r\n************* Module learning_unsupervised_learning.variable_replace\r\nE: 94, 0: Missing parentheses in call to 'print'. Did you mean print(\"Didn't use all replacements\")? (<string>, line 94) (syntax-error)\r\n************* Module learning_unsupervised_learning.meta_objective.sklearn\r\nE:116, 0: invalid syntax (<string>, line 116) (syntax-error)\r\n```\r\n\r\nCodeowners: @lukemetz @nirum",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 7,
        "deletions": 1,
        "changed_files": 7,
        "created_at": "2018-04-05T10:57:33Z",
        "closed_at": "2018-06-25T10:35:33Z",
        "merged_at": null,
        "body": "A repeat of PRs #3702 #3520 #3206\r\n\r\nCould __python3 -m flake8 . --select=F821__ be added to the testing to automatically spot these?",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2018-04-04T23:57:54Z",
        "closed_at": "2018-04-06T18:36:57Z",
        "merged_at": "2018-04-06T18:36:57Z",
        "body": "* \"Machine Learning\" --> Machine learning.\r\n* \"steepest the ascent\" --> \"steepest ascent\"\r\n* \"standard gradient descent\" --> \"stochastic gradient descent\"\r\n* Delete equivalence between step and learning rate (the two are different concepts).",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 103,
        "deletions": 7,
        "changed_files": 4,
        "created_at": "2018-04-04T20:58:51Z",
        "closed_at": "2018-04-05T03:12:03Z",
        "merged_at": null,
        "body": "This writes the end time of training as well as elapsed time to benchmark_run.log. If used as in the resnet loop, this will be equivalent to time-to-converge in cases where we run from start to convergence.\r\n\r\nNote that this does not handle run starting and stopping; this is intentional for now.\r\nNote also that the user bears the burden of calling the log_run_end method; this is also intentional, as we want to maintain flexibility in the face of different model architectures and rule sets.\r\n\r\n@yhliang2018 - For new models added, we would want to add the logging logic as in Resnet.\r\n@qlzh727 - This will require an update to the BigQuery Table, which, once approved, I can do.\r\n\r\nSample output (emphasis added):\r\n\r\n{**\"end_date\": \"2018-04-04T20:49:41.972510Z\"**, \"run_date\": \"2018-04-04T20:15:49.432197Z\", \"machine_config\": {\"cpu_info\": {\"cpu_info\": \"Intel(R) Xeon(R) CPU @ 2.30GHz\", \"mhz_per_cpu\": 2300.0, \"num_cores\": 32}, \"gpu_info\": {\"count\": 4, \"model\": \"Tesla P100-PCIE-16GB\"}, \"memory_total\": 126739050496, \"memory_available\": 121141805056}, \"tensorflow_version\": {\"git_hash\": \"v1.7.0-rc1-1091-gc7a04561fb\", \"version\": \"1.8.0-dev20180402\"}, **\"elapsed_time\": \"0:33:52.540313\"**, **\"elapsed_seconds\": 2032.540313**, \"tensorflow_environment_variables\": [{\"name\": \"TF_ENABLE_WINOGRAD_NONFUSED\", \"value\": \"1\"}], \"model_name\": \"resnet\"}\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-04-04T11:28:19Z",
        "closed_at": "2018-04-04T16:23:17Z",
        "merged_at": "2018-04-04T16:23:17Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 171,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-04-04T05:55:58Z",
        "closed_at": "2018-09-06T06:49:45Z",
        "merged_at": null,
        "body": "ADD inference.py for simple inference",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 167,
        "deletions": 4,
        "changed_files": 9,
        "created_at": "2018-04-03T22:26:05Z",
        "closed_at": "2018-04-10T15:35:46Z",
        "merged_at": "2018-04-10T15:35:46Z",
        "body": "We want to be able to stop training at a specified accuracy or other model-specific metric. Helper function added here, along with run loop logic for existing models.\r\n\r\n@qlzh727 -- when running time-to-converge tests, we will likely want to run with the flag --stop_threshold=<relevant number for the given model>\r\n\r\n@yhliang2018 -- when adding new models, they should include stopping logic in the run loop.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 15,
        "changed_files": 14,
        "created_at": "2018-04-03T17:28:25Z",
        "closed_at": "2018-04-03T21:35:46Z",
        "merged_at": "2018-04-03T21:35:46Z",
        "body": "The name `logging` conflicts with the Python builtin, and this causes problems if a module happens to be at the same level as our logging directory. Renaming here.\r\n\r\n@yhliang2018 and @qlzh727 -- you have worked the most with these files; please search your brains for unusual occurrences of the import or other scripts/places you rely on this path that are not captured here.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-04-03T13:03:14Z",
        "closed_at": "2018-04-04T03:27:23Z",
        "merged_at": "2018-04-04T03:27:23Z",
        "body": "This addresses a runtime error describing below (for the attention_ocr) model. Please have a look if it is acceptable. @alexgorban \r\n\r\nFollowing the README.txt file, after running \"python -m unittest discover -p  '*_test.py'\", I would get the following error message. It seems this comes from the defining of the flag momentum in common_flags.py\r\nIllegalFlagValueError: flag --momentum=0.9: flag value must be a string, found \"<type 'float'>\"\r\n\r\nNote that I tested on the following environment (Ubuntu 16.04.3 LTS, Python 2.7.12, Tensorflow version 1.5.0)\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 357,
        "deletions": 18,
        "changed_files": 9,
        "created_at": "2018-04-03T12:06:49Z",
        "closed_at": "2018-04-09T17:37:53Z",
        "merged_at": "2018-04-09T17:37:53Z",
        "body": "This PR provide scripts/documents for downloading/converting the ADE20K dataset and training deeplabv3 on it. One particular thing to note about is the `exclude_list` variable in `utils/train_utils.py`. I think it is OK to do this, but it might hurt performance of other models.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 21,
        "deletions": 13,
        "changed_files": 7,
        "created_at": "2018-04-03T08:32:41Z",
        "closed_at": "2018-04-04T06:08:58Z",
        "merged_at": "2018-04-04T06:08:58Z",
        "body": "Hope DeepLab model will soon support py3. I tried to modify a few files to run it on py3, currently tested data_preperation/train/eval for Cityscapes & Pascal.\r\n\r\n> For Cityscapes, change `ciyscapesscripts/helpers/annotation.py`: near line 238 into `print(type(obj).__name__)` (just add the parentheses).  \r\n> Someone has opened [a PR about that change](https://github.com/mcordts/cityscapesScripts/pull/47) for [cityscapesScripts](https://github.com/mcordts/cityscapesScripts), hope they accept it soon.\r\n\r\nAny discussions will help.\r\n\r\nA further step of #3741 ",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 30,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2018-04-03T07:27:01Z",
        "closed_at": "2018-04-04T16:44:57Z",
        "merged_at": "2018-04-04T16:44:57Z",
        "body": "It's nice to be able to see these things in TensorBoard to see if your model is doing well over the course of training.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-04-03T04:37:31Z",
        "closed_at": "2019-12-03T07:08:27Z",
        "merged_at": null,
        "body": "Hi, I rewrote some parts of the description to make it more clear and concise. Hope this helps.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1021,
        "deletions": 240,
        "changed_files": 40,
        "created_at": "2018-04-03T02:03:31Z",
        "closed_at": "2018-04-03T18:37:13Z",
        "merged_at": "2018-04-03T18:37:13Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-04-03T00:55:48Z",
        "closed_at": "2018-04-03T02:12:51Z",
        "merged_at": "2018-04-03T02:12:51Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-04-02T21:02:59Z",
        "closed_at": "2018-04-26T14:38:42Z",
        "merged_at": null,
        "body": "__long__ (used on line 603) was removed in Python 3 in favor of __int__.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-04-02T19:45:43Z",
        "closed_at": "2018-04-03T23:14:14Z",
        "merged_at": "2018-04-03T23:14:14Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2018-04-02T16:41:48Z",
        "closed_at": "2018-04-02T22:52:47Z",
        "merged_at": "2018-04-02T22:52:47Z",
        "body": "See https://github.com/tensorflow/models/pull/3808#discussion_r178217596 .",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2623,
        "deletions": 0,
        "changed_files": 21,
        "created_at": "2018-03-31T22:54:12Z",
        "closed_at": "2018-04-03T16:06:06Z",
        "merged_at": "2018-04-03T16:06:06Z",
        "body": "This is code for our paper: \"Learning of Unsupervised Update Rules\".\r\nCurrently there is a placeholder link in the README that will be updated when the paper is live.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 55,
        "deletions": 22,
        "changed_files": 1,
        "created_at": "2018-03-31T17:17:55Z",
        "closed_at": "2019-12-03T07:08:26Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 877,
        "deletions": 3,
        "changed_files": 10,
        "created_at": "2018-03-30T20:12:42Z",
        "closed_at": "2018-04-04T17:28:18Z",
        "merged_at": "2018-04-04T17:28:18Z",
        "body": "Note this is just syncing with our internal repo.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-03-29T23:33:26Z",
        "closed_at": "2018-04-02T21:44:00Z",
        "merged_at": "2018-04-02T21:44:00Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-03-29T21:40:15Z",
        "closed_at": "2018-03-29T23:13:35Z",
        "merged_at": "2018-03-29T23:13:35Z",
        "body": "The original code passes a dimension object to tf.reshape(), which is not recognized with error. This pull request casts the dimension object to int to fix this problem. The stack trace of the original code is attached below:\r\n\r\n\r\n  File \"/home/models/tutorials/image/cifar10/cifar10.py\", line 243, in inference\r\n    reshape = tf.reshape(pool2, [images.get_shape()[0], -1])\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 2619, in reshape\r\n    name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 493, in apply_op\r\n    raise err\r\nTypeError: Failed to convert object of type <type 'list'> to Tensor. Contents: [Dimension(128), -1]. Consider casting elements to a supported type.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 767,
        "deletions": 0,
        "changed_files": 4,
        "created_at": "2018-03-29T20:46:57Z",
        "closed_at": "2018-03-30T01:05:01Z",
        "merged_at": "2018-03-30T01:05:01Z",
        "body": "This script is a work in progress, but we want to have some examples available for the Summit of usin g TensorRT with the official models.\r\n\r\n@tfboyd - Take a look and make sure it meets your needs.\r\n\r\n@k-w-w - Can you read over for readability and general clarity? Deadline is tight, but we can always do follow-up changes in another PR.\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1162,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-03-29T18:04:59Z",
        "closed_at": "2018-03-29T21:22:25Z",
        "merged_at": "2018-03-29T21:22:25Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 11,
        "deletions": 17,
        "changed_files": 1,
        "created_at": "2018-03-29T15:31:12Z",
        "closed_at": "2019-12-03T07:08:26Z",
        "merged_at": null,
        "body": "It took me some time to figure out environment variable of\r\nTF_CONFIG is used for distributed training instead of Flags variables.\r\nThis PR removes these unused flags, so that it would not make someone confused again.",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 12,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2018-03-29T07:43:24Z",
        "closed_at": "2018-08-10T18:09:14Z",
        "merged_at": null,
        "body": "* checkpoint_save_interval_secs is used to change how often the checkpoints are serialized (default 600 seconds)\r\n\r\n* save_summaries_secs is used to change how often summaries are saved (default 120 seconds)\r\n\r\n* max_checkpoints_to_keep is used to change how many checkpoints are kept (default 5 checkpoints)",
        "comments": 8
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 0,
        "changed_files": 0,
        "created_at": "2018-03-29T03:06:37Z",
        "closed_at": "2018-04-26T17:17:42Z",
        "merged_at": null,
        "body": "update_from_origin_20180329",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 49,
        "deletions": 5,
        "changed_files": 3,
        "created_at": "2018-03-28T20:01:04Z",
        "closed_at": "2018-03-29T20:15:46Z",
        "merged_at": "2018-03-29T20:15:46Z",
        "body": "There is already static test data for wide-deep, so I simply used that rather than adding synthetic data.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 76,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-03-28T19:35:12Z",
        "closed_at": "2018-04-02T22:54:23Z",
        "merged_at": "2018-04-02T22:54:23Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 237,
        "deletions": 32,
        "changed_files": 9,
        "created_at": "2018-03-27T19:11:44Z",
        "closed_at": "2018-03-28T20:03:52Z",
        "merged_at": "2018-03-28T20:03:52Z",
        "body": "Also update the benchmark logger and bigquery schema for the\r\nerrors found during the integration test.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 345,
        "deletions": 0,
        "changed_files": 4,
        "created_at": "2018-03-27T15:18:27Z",
        "closed_at": "2018-04-26T19:32:38Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-03-27T08:41:51Z",
        "closed_at": "2018-04-06T08:04:13Z",
        "merged_at": null,
        "body": "from_detection_checkpoint check needs to be true to using pre-trained models.\r\n(otherwise no variables found error thrown while training)",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-03-27T08:34:15Z",
        "closed_at": "2018-03-30T18:04:46Z",
        "merged_at": "2018-03-30T18:04:46Z",
        "body": "when setting `--also_save_raw_predictions=True`, a file-not-found error is report because we are saving into the `--vis_logdir` using the fullpath of that image.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2018-03-27T00:17:58Z",
        "closed_at": "2018-03-27T17:11:44Z",
        "merged_at": "2018-03-27T17:11:44Z",
        "body": "Now that we have dependencies beyond what TensorFlow already pulls in, we may as well put a bit of formalism to help people out.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 188,
        "deletions": 15,
        "changed_files": 8,
        "created_at": "2018-03-26T21:16:55Z",
        "closed_at": "2018-03-28T21:28:41Z",
        "merged_at": "2018-03-28T21:28:41Z",
        "body": "This adds the ability to export a Saved Model to ResNet. Note that this will be followed up with more functionality for TensorRT shortly.\r\n\r\nIdeally, we want to update the WideDeep and all other new models to do the same-- then we can push the ExportParser into BaseParser.\r\n\r\n@isaprykin - a question for you: right now, I [pass batch_size through to the input receiver fn](https://github.com/tensorflow/models/compare/feat/export-model?expand=1#diff-6077cc3554f174c70851f0fe7fb70334R414), even though in theory, one might want the savedmodel to request a batch_size of 1 by default. The reason I do that is because the replicate_model_fn ensure_divisible_by_shards complains during model saving if the batch size is one, even just for exporting the model (presumably because the graph gets run through again)? Not sure what the implications of my approach are, or if there is a better way?\r\n\r\n@qlzh727 -- FYI, I envision that ultimately we will want every benchmark run to also export a savedmodel, which can then be used to benchmark TF inference.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-03-26T05:00:34Z",
        "closed_at": "2018-04-12T05:00:29Z",
        "merged_at": "2018-04-12T05:00:29Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 15,
        "changed_files": 1,
        "created_at": "2018-03-26T03:05:36Z",
        "closed_at": "2018-04-09T19:01:25Z",
        "merged_at": "2018-04-09T19:01:25Z",
        "body": "When creat a tf record using purely negative images which have no 'object' in their xmls ,the script gets a key error : for obj in data['object']:  Key Error : 'object'\r\nIn order to fix this , add a 'if ' judegement before it .",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-03-25T12:54:02Z",
        "closed_at": "2019-12-03T07:08:25Z",
        "merged_at": null,
        "body": "The original FastGFile(..., 'b') does not work for Python 3",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-03-25T12:50:47Z",
        "closed_at": "2019-12-03T07:07:42Z",
        "merged_at": null,
        "body": "I've got a lot of type errors here when was launching https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/pascal.md in this line\r\nhttps://github.com/tensorflow/models/blob/master/research/deeplab/datasets/build_voc2012_data.py#L128",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 764,
        "deletions": 39,
        "changed_files": 23,
        "created_at": "2018-03-25T04:40:33Z",
        "closed_at": "2018-03-28T20:47:27Z",
        "merged_at": "2018-03-28T20:47:27Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-03-24T18:26:09Z",
        "closed_at": "2018-03-30T04:53:06Z",
        "merged_at": null,
        "body": "`defaults.items()` in `slim/nets/mobilenet/mobilenet.py` returns `dict_item` in Python 3 rather than a list. `list(defaults.items())` works on both Python versions.\r\n\r\nTo reproduce the original problem run\r\n```bash\r\npython3 deeplab/model_test.py\r\n```\r\nwhich throws the error:\r\n```bash\r\nE...\r\n======================================================================\r\nERROR: testBuildDeepLabv2 (__main__.DeeplabModelTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"deeplab/model_test.py\", line 71, in testBuildDeepLabv2\r\n    inputs, model_options, image_pyramid=image_pyramid)\r\n  ...\r\n  File \"/home/fmannan/workspace/models/research/slim/nets/mobilenet/mobilenet.py\", line 90, in _set_arg_scope_defaults\r\n    func, default_arg = items[0]\r\nTypeError: 'dict_items' object does not support indexing\r\n\r\n======================================================================\r\nERROR: testForwardpassDeepLabv3plus (__main__.DeeplabModelTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"deeplab/model_test.py\", line 105, in testForwardpassDeepLabv3plus\r\n    image_pyramid=[1.0])\r\n  ...\r\n  File \"/home/fmannan/workspace/models/research/slim/nets/mobilenet/mobilenet.py\", line 90, in _set_arg_scope_defaults\r\n    func, default_arg = items[0]\r\nTypeError: 'dict_items' object does not support indexing\r\n\r\n----------------------------------------------------------------------\r\nRan 5 tests in 8.985s\r\n\r\nFAILED (errors=2)\r\n```",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 686,
        "deletions": 0,
        "changed_files": 58,
        "created_at": "2018-03-23T20:33:36Z",
        "closed_at": "2018-03-27T19:51:04Z",
        "merged_at": "2018-03-27T19:51:04Z",
        "body": "Added a simple subclass of tf.test.TestCase to allow specification of reference (gold standard) behavior and detect when layer definitions change. This test class is designed to be less brittle than the previous resnet_test.py by restoring weights instead of relying on tensorflow's RNG which can change with implementation.\r\n\r\nFor instance with respect to the recent batch norm change in TensorFlow, the test issues a warning (since the graph changed), but does not fail.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 0,
        "changed_files": 0,
        "created_at": "2018-03-23T15:18:45Z",
        "closed_at": "2019-02-23T19:55:45Z",
        "merged_at": null,
        "body": "load_image_into_numpy_array(image) raises ValueError when the given image format is png.\r\nThe workaround I found is to convert the image to 'RGB'.",
        "comments": 10
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 3,
        "created_at": "2018-03-23T03:57:02Z",
        "closed_at": "2018-04-03T15:44:48Z",
        "merged_at": "2018-04-03T15:44:48Z",
        "body": "This is a fix for #1467 and a related decoder error, where binary files are parsed as (invalid) UTF-8. The behavior is reproducible with Python 3.6 and Tensorflow 1.6, with the example image provided in the repository, `example.png`.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 660,
        "deletions": 403,
        "changed_files": 16,
        "created_at": "2018-03-23T01:28:22Z",
        "closed_at": "2018-03-23T04:33:52Z",
        "merged_at": "2018-03-23T04:33:52Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 132,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2018-03-22T23:50:33Z",
        "closed_at": "2018-03-26T21:20:12Z",
        "merged_at": "2018-03-26T21:20:12Z",
        "body": "Update for benchmark logger to log most of the local runtime env information.\r\n\r\nSome of the code for CPU and GPU info are borrowed from tf.tools.test, which is not exposed for import. I guess we can dedup this when we port our code to tf core. \r\n\r\nAlso the code is hard to do unit test since the lib to gather CPU and GPU info is not easy to mock. I manually run the test with cifar10 and it works. Let me know if you need more test coverage.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 353,
        "deletions": 0,
        "changed_files": 6,
        "created_at": "2018-03-22T21:49:16Z",
        "closed_at": "2018-03-23T21:27:33Z",
        "merged_at": "2018-03-23T21:27:33Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 132,
        "deletions": 9,
        "changed_files": 7,
        "created_at": "2018-03-22T18:40:51Z",
        "closed_at": "2018-03-23T21:43:16Z",
        "merged_at": "2018-03-23T21:43:16Z",
        "body": "Adding benchmark logging for resnet training and evaluation.\r\n\r\nTested on GCP with GPU for cifar10. Run following command to enable benchmark logging:\r\n# only log the evaluation result.\r\npython official/resnet/cifar10_main.py --benchmark_log_dir /tmp/metric_dir\r\n# also log the training metric\r\npython official/resnet/cifar10_main.py --hooks LoggingTensorHook LoggingMetricHook --benchmark_log_dir /tmp/metric_dir\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 1,
        "changed_files": 8,
        "created_at": "2018-03-22T15:59:19Z",
        "closed_at": "2018-03-22T19:13:42Z",
        "merged_at": "2018-03-22T19:13:42Z",
        "body": "14 new instances in the 17 days since #3520 which was a clean up after #3206 \r\n\r\n@a-dai @nealwu @karmel",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-03-22T14:42:50Z",
        "closed_at": "2018-05-11T15:51:16Z",
        "merged_at": "2018-05-11T15:51:16Z",
        "body": "Filename was wrong",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-03-22T05:02:26Z",
        "closed_at": "2018-03-22T19:15:44Z",
        "merged_at": "2018-03-22T19:15:44Z",
        "body": "Andrew from Minigo was curious what the L2 loss curves for ResNet looked like, so I ran a quick experiment with the code. Realized it would be a nice addition to our TensorBoard as well.\r\n\r\nAlso tested our ImageNet checkpoint with this new code and verified that it's still working as usual.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-03-22T04:36:45Z",
        "closed_at": "2018-03-23T01:31:03Z",
        "merged_at": "2018-03-23T01:31:03Z",
        "body": "Edit comment on folder structure to match actual folder structure.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 5,
        "changed_files": 3,
        "created_at": "2018-03-22T03:35:41Z",
        "closed_at": "2018-03-22T19:16:36Z",
        "merged_at": "2018-03-22T19:16:36Z",
        "body": "Updates to individual official/ README files to make sure users are aware of the PYTHONPATH requirements.\r\n\r\nFixes https://github.com/tensorflow/models/issues/3690",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 430,
        "deletions": 173,
        "changed_files": 9,
        "created_at": "2018-03-21T20:25:34Z",
        "closed_at": "2018-04-09T18:14:59Z",
        "merged_at": "2018-04-09T18:14:59Z",
        "body": "This PR adds fp16 support to official/resnet. The vast majority of the work was already done by Reed a month ago (including wonderful comments), and this just rolls those changes into the current master.\r\n\r\nCurrently training is I/O bound; however synthetic data runs confirm the fp16 accelleration to ~4000 images/sec during training.\r\n\r\nI will update when I have run results.",
        "comments": 13
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-03-21T20:15:38Z",
        "closed_at": "2018-03-23T01:32:41Z",
        "merged_at": "2018-03-23T01:32:41Z",
        "body": "This commit fixes `DeprecationWarning: Please use assertEqual instead.\r\n  self.assertEquals(len(scales_to_logits), expected_num_logits[i])` deprecation warning.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 52,
        "deletions": 51,
        "changed_files": 3,
        "created_at": "2018-03-21T17:44:30Z",
        "closed_at": "2018-03-23T19:50:40Z",
        "merged_at": "2018-03-23T19:50:40Z",
        "body": "This PR replaces tf.app.run() with a simple main(argv) following what has already been done with resnet. It also replaces the parser.parse_known_args() with parser.parse_args() calls so that mistakes in typing args raise errors.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1887,
        "deletions": 4,
        "changed_files": 10,
        "created_at": "2018-03-21T14:47:56Z",
        "closed_at": "2018-03-21T17:36:29Z",
        "merged_at": "2018-03-21T17:36:29Z",
        "body": "This model is an implementation of the noun compound relation classification model described in the NAACL 2018 paper by Vered Shwartz and Chris Waterson.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-03-21T06:08:21Z",
        "closed_at": "2018-03-27T00:27:51Z",
        "merged_at": "2018-03-27T00:27:51Z",
        "body": "Cython is must installed package for building cocoapi. else the build will not initiate.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-03-20T22:35:00Z",
        "closed_at": "2018-03-21T00:07:06Z",
        "merged_at": "2018-03-21T00:07:06Z",
        "body": "Not sure why, but Kokoro's pylint is complaining about a few method names that were okay locally. Fixing the rcfile here.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 13,
        "deletions": 10,
        "changed_files": 2,
        "created_at": "2018-03-20T21:40:50Z",
        "closed_at": "2018-03-20T23:13:40Z",
        "merged_at": "2018-03-20T23:13:40Z",
        "body": "This gives us an extra 0.5% - 1.5% examples/second, depending on the environment, and should not in theory change the model architecture itself. Final accuracy for ImageNet was unchanged at 76.38%, CIFAR-10 92.5%.\r\n\r\nCC @bignamehyp @reedwm ",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-03-20T18:44:11Z",
        "closed_at": "2018-03-21T15:55:25Z",
        "merged_at": null,
        "body": "Fixes broken shell function declaration. See https://stackoverflow.com/a/6212408/6457747",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 338,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2018-03-20T18:11:57Z",
        "closed_at": "2018-03-21T20:53:50Z",
        "merged_at": "2018-03-21T20:53:49Z",
        "body": "Current hook is very similar as the LoggingTensorHook. Some of the\r\nfunction are directly copied since the original one was not\r\nexposed for import. We should seek to eventually move this code to\r\ncore when it is mature enough.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-03-20T16:00:55Z",
        "closed_at": "2018-03-23T04:40:58Z",
        "merged_at": "2018-03-23T04:40:58Z",
        "body": "Probable syntax error in line 43. Remove \"function\" for execution.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-03-20T13:20:33Z",
        "closed_at": "2019-12-03T07:07:41Z",
        "merged_at": null,
        "body": "testEasyExamplesProduceSmallLossComparedToSigmoidXEntropy failed because of rounding error in https://github.com/tensorflow/models/blob/875fcb3b417cc74852454472d660996401fb13f7/research/object_detection/core/losses_test.py#L249-L250\r\n\r\nFurthermore, with this fix, the logit values are symmetric",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2106,
        "deletions": 462,
        "changed_files": 93,
        "created_at": "2018-03-19T23:05:06Z",
        "closed_at": "2018-03-22T17:14:29Z",
        "merged_at": "2018-03-22T17:14:29Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 382,
        "deletions": 162,
        "changed_files": 27,
        "created_at": "2018-03-19T23:04:43Z",
        "closed_at": "2018-03-20T20:10:17Z",
        "merged_at": "2018-03-20T20:10:16Z",
        "body": "So much linting. Please don't introduce any new lint errors after this. Tests will be updated to check as well.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2018-03-19T20:55:25Z",
        "closed_at": "2018-03-20T20:32:12Z",
        "merged_at": "2018-03-20T20:32:12Z",
        "body": "As noted, imagenet can no longer just use the default number of train_epochs. This PR explicitly sets it back to 100, and also fixes a bug related to \"-h\" being inadvertently caught by tf.app.run().",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-03-19T17:53:21Z",
        "closed_at": "2018-03-19T19:24:21Z",
        "merged_at": "2018-03-19T19:24:21Z",
        "body": "As suggested by @random-forests",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 171,
        "deletions": 158,
        "changed_files": 11,
        "created_at": "2018-03-19T17:31:29Z",
        "closed_at": "2018-03-20T18:49:15Z",
        "merged_at": "2018-03-20T18:49:15Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-03-19T06:32:37Z",
        "closed_at": "2018-03-21T00:31:43Z",
        "merged_at": "2018-03-21T00:31:43Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-03-18T14:57:46Z",
        "closed_at": "2018-04-16T16:28:21Z",
        "merged_at": "2018-04-16T16:28:20Z",
        "body": "Some local operations require CPU instead of GPU.\r\nAnd I found a lot of users raised the same issue in tensorflow/tensorflow, like \r\nhttps://github.com/tensorflow/tensorflow/issues/3475  \r\nhttps://github.com/tensorflow/tensorflow/issues/14085  \r\n\r\nAnd in tensorflow/models, #1823 \r\n\r\nI think adding these two lines should help to avoid confusing. \r\n",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-03-18T03:50:59Z",
        "closed_at": "2018-06-04T15:59:23Z",
        "merged_at": "2018-06-04T15:59:23Z",
        "body": "Fix this issue: https://github.com/tensorflow/models/issues/3221#issuecomment-373733696 introduced by my early PR #3112",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-03-18T00:03:34Z",
        "closed_at": "2019-12-03T07:07:41Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 26,
        "deletions": 26,
        "changed_files": 18,
        "created_at": "2018-03-17T18:09:18Z",
        "closed_at": "2019-11-24T23:44:17Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-03-17T07:38:48Z",
        "closed_at": "2018-03-19T16:50:44Z",
        "merged_at": "2018-03-19T16:50:44Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-03-16T01:45:51Z",
        "closed_at": "2018-03-16T03:34:22Z",
        "merged_at": "2018-03-16T03:34:22Z",
        "body": "pkulzc (lzc@google.com) is a member of tensorflow object detection team.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 34,
        "deletions": 35,
        "changed_files": 14,
        "created_at": "2018-03-16T00:51:10Z",
        "closed_at": "2018-03-19T18:41:14Z",
        "merged_at": "2018-03-19T18:41:14Z",
        "body": "Fixes #3608 ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 167,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2018-03-15T20:39:50Z",
        "closed_at": "2018-03-19T20:55:57Z",
        "merged_at": "2018-03-19T20:55:57Z",
        "body": "Currently it only log the metric, which we could use in any of the hooks.",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 28,
        "deletions": 20,
        "changed_files": 3,
        "created_at": "2018-03-15T19:26:48Z",
        "closed_at": "2019-11-24T23:44:16Z",
        "merged_at": null,
        "body": "PiperOrigin-RevId: 189059229\r\n\r\nPiperOrigin-RevId: 189214402\r\n\r\nRemoves dependency on contextlib2 for mobilenet",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-03-15T17:25:26Z",
        "closed_at": "2019-11-24T23:44:16Z",
        "merged_at": null,
        "body": "In research/object_detection/utils/visualization_utils.py, boxes with identical locations are grouped together within visualize_boxes_and_labels_on_image_array(). However, since we are typically processing in order of decreasing score, the color of the boxes and labels are overwritten by lower-scoring classes within a group. As a result, the lowest-scoring class color is what ends up showing through (BAD). This commit fixes the issue.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 28,
        "deletions": 8,
        "changed_files": 2,
        "created_at": "2018-03-15T00:41:22Z",
        "closed_at": "2018-03-15T03:27:43Z",
        "merged_at": "2018-03-15T03:27:43Z",
        "body": "Provide more detailed flag values for different datasets.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-03-14T22:25:32Z",
        "closed_at": "2018-03-14T23:38:39Z",
        "merged_at": "2018-03-14T23:38:39Z",
        "body": "Minor nit with readme formatting.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 131,
        "deletions": 24,
        "changed_files": 9,
        "created_at": "2018-03-14T17:25:01Z",
        "closed_at": "2018-03-16T22:44:24Z",
        "merged_at": "2018-03-16T22:44:24Z",
        "body": "Currently arg parsing is not tested for resnet. This aims to resolve such issues by actually running a trivial train.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-03-14T01:33:06Z",
        "closed_at": "2018-03-15T03:26:13Z",
        "merged_at": "2018-03-15T03:26:13Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 22,
        "deletions": 14,
        "changed_files": 4,
        "created_at": "2018-03-13T22:27:57Z",
        "closed_at": "2018-03-15T00:37:43Z",
        "merged_at": "2018-03-15T00:37:43Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 380,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2018-03-13T22:19:18Z",
        "closed_at": "2018-03-14T23:20:18Z",
        "merged_at": "2018-03-14T23:20:18Z",
        "body": "The current schema contains the entity information about model\r\nand train data metadata, as well as machine config. Future change\r\nwill contain benchmark metric.\r\n\r\nThe json schema can be used to create bigquery table. A sample\r\ntable can be found in\r\nhttps://bigquery.cloud.google.com/table/tf-benchmark-dashboard:test_benchmark.benchmark_run.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 35,
        "deletions": 16,
        "changed_files": 1,
        "created_at": "2018-03-13T22:04:21Z",
        "closed_at": "2018-03-16T17:58:55Z",
        "merged_at": null,
        "body": "Current:\r\n![screenshot from 2018-03-13 15-08-05](https://user-images.githubusercontent.com/13089297/37372566-5da50ab2-26d0-11e8-96d7-6451620010f6.png)\r\n\r\n\r\n\r\nProposed:\r\n![screenshot from 2018-03-13 15-06-46](https://user-images.githubusercontent.com/13089297/37372508-323992b2-26d0-11e8-8098-b9398a84b7c8.png)\r\n![screenshot from 2018-03-13 15-06-50](https://user-images.githubusercontent.com/13089297/37372516-35b29826-26d0-11e8-82e5-0c85636c46bf.png)\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1214,
        "deletions": 35,
        "changed_files": 22,
        "created_at": "2018-03-13T17:59:07Z",
        "closed_at": "2018-03-13T21:03:42Z",
        "merged_at": "2018-03-13T21:03:42Z",
        "body": "Major changes: \r\n1. Enable NasNet as a cloud_tpu model\r\n2. Mobilnet v2\r\n3. Open source float and 8-bit mobilenet v1 training.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-03-13T11:01:36Z",
        "closed_at": "2018-03-13T14:48:39Z",
        "merged_at": "2018-03-13T14:48:39Z",
        "body": "We can directly get `batch_size` by `images.get_shape()[0]` in `inference` method, since maybe we will not use `cifar.inputs` method to build the input.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 4,
        "created_at": "2018-03-13T10:10:42Z",
        "closed_at": "2018-03-13T14:47:10Z",
        "merged_at": "2018-03-13T14:47:10Z",
        "body": "Some python files under models/research, it is wrong to use \"Rather then\" instead of \"Rather than\" in  comments.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2018-03-12T23:15:25Z",
        "closed_at": "2018-03-13T15:56:43Z",
        "merged_at": "2018-03-13T15:56:43Z",
        "body": "The branch in question was merged in #3472 . Also updated the comment, which is no longer true.\r\n\r\n@qlzh727 - for context, these are the files @vishh was using to generate and register a Docker image for this repo.\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 304,
        "deletions": 64,
        "changed_files": 6,
        "created_at": "2018-03-12T20:51:45Z",
        "closed_at": "2018-03-13T23:43:02Z",
        "merged_at": "2018-03-13T23:43:01Z",
        "body": "This PR breaks various groups of common arguments into their own argparse class to enable some degree of standardization among the official models. The resnet argparser is replaced as an example.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-03-12T19:17:33Z",
        "closed_at": "2018-04-05T12:20:53Z",
        "merged_at": null,
        "body": "Repeat of #2849 -- This change seems to have been lost.\r\n\r\nIn Python 2.7, the trailing L is no longer needed and in Python 3, the trailing L is a Syntax Error.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 7,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-03-12T11:45:47Z",
        "closed_at": "2019-11-24T23:44:16Z",
        "merged_at": null,
        "body": "When building the TFRecord of ILSVRC, I get the following error:\r\n```\r\nfile: research/inception/inception/data/build_imagenet_data.py\r\nline: 175: six.binary_type TypeError: str() takes at most 1 argument\r\n```\r\nThis probably due to the incompatible of python2 and python3 even if the author uses the six module.\r\nIn Python3: \r\n`class str(object='', encoding='utf-8', ...)\r\n`\r\nhowever, In Python2:\r\n`class str(object='')`\r\ni.e. It only take one argument.\r\n\r\nI fix this bug by catching the exception and assign the string without encoding.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-03-11T09:47:39Z",
        "closed_at": "2019-11-24T23:44:15Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 12,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-03-11T00:22:10Z",
        "closed_at": "2019-11-24T23:44:15Z",
        "merged_at": null,
        "body": "Added allow_gpu_growth flag in training script to allow reducing gpu memory usage if requested",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-03-10T15:00:08Z",
        "closed_at": "2018-03-12T03:40:09Z",
        "merged_at": "2018-03-12T03:40:09Z",
        "body": "There is no reason to assign template variable in every iteration",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 314,
        "deletions": 247,
        "changed_files": 3,
        "created_at": "2018-03-10T00:46:58Z",
        "closed_at": "2018-03-13T21:48:30Z",
        "merged_at": "2018-03-13T21:48:30Z",
        "body": "These changes bring us to 76+% accuracy, and also improve performance, especially for the 8 GPU case. Notable differences in training:\r\n\r\n* Use the bounding boxes supplied in the ImageNet dataset (accuracy)\r\n* Use the sample_distorted_bounding_box op instead of creating a random box for cropping during training (speed)\r\n* Use the fused op for decoding and cropping instead of two separate ops (speed)\r\n* The fused decoding requires that we resize after cropping\r\n\r\nEval is the same as previously, but cleaned up slightly now that the functions are not used for training as well.\r\n\r\nScreenshot from a run with 4xGPU is below.\r\n\r\nFYI @reedwm @bignamehyp @scott7z @robieta \r\n\r\n\r\n<img width=\"1017\" alt=\"screen shot 2018-03-09 at 4 45 15 pm\" src=\"https://user-images.githubusercontent.com/667809/37236110-6736ef56-23b9-11e8-9723-730e322f8c80.png\">\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 22,
        "deletions": 15,
        "changed_files": 12,
        "created_at": "2018-03-10T00:04:17Z",
        "closed_at": "2018-03-12T21:05:06Z",
        "merged_at": "2018-03-12T21:05:06Z",
        "body": "make /official as a Python module to unify import of utils",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-03-09T04:10:41Z",
        "closed_at": "2018-03-12T23:22:20Z",
        "merged_at": "2018-03-12T23:22:20Z",
        "body": "Deeplab model is merged in PR #3521",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 18,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2018-03-08T17:52:29Z",
        "closed_at": "2018-03-15T19:30:22Z",
        "merged_at": null,
        "body": "Copied from the Google-internal cl/188181162 by request of @dlibenzi ; not my code.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2018-03-08T15:51:30Z",
        "closed_at": "2019-11-24T23:44:15Z",
        "merged_at": null,
        "body": "The prefetcher capacity was hard coded. New commit enables reading this value from the configuration file.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-03-08T03:14:35Z",
        "closed_at": "2018-11-05T09:31:44Z",
        "merged_at": null,
        "body": "line 16 :  self.hidden = self.transfer(tf.add(tf.matmul(self.x + scale * tf.random_normal((n_input,)),\r\nshould change to\r\nself.hidden = self.transfer(tf.add(tf.matmul(self.x + self.scale * tf.random_normal((n_input,)),",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 52,
        "deletions": 54,
        "changed_files": 4,
        "created_at": "2018-03-06T20:36:37Z",
        "closed_at": "2018-03-07T20:03:49Z",
        "merged_at": "2018-03-07T20:03:49Z",
        "body": "Changes made and reasons:\r\n- [ ] In memory.py: Re-arranged pieces of code in `Memory.query` + added `if not output_given: ...` so that passing the `intended_output=None` argument does not fail (e.g. when calling `Memory.predict` with `y=None`);\r\n- [ ] In model.py: Simplified restoring memory (not sure if this is OK, perhaps `tf.placeholder`s for `self.mem_*` attributes served a purpose I didn't see?);\r\n- [ ] In train.py: Validation is performed on `batch_size=1` so I made the `seen_counts` a flat list instead of a nested list of `batch_size` lists. I could have gone in the other direction with this, i.e. make a separate variable `validation_batch_size` and set it by default to 1. But my impression was that you want the batch size to be 1, so that the setup is the same as was in Oriol Vinyals (2016b), referenced in your paper.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 22,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-03-06T18:52:53Z",
        "closed_at": "2018-03-06T23:00:02Z",
        "merged_at": "2018-03-06T23:00:02Z",
        "body": "This incorporates @nhasabni 's commits, and adds allow_soft_placement = True, which is necessary for multi-GPU mode.\r\n\r\ncc @isaprykin ",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-03-06T10:16:27Z",
        "closed_at": "2019-11-24T23:44:15Z",
        "merged_at": null,
        "body": "* fix bug when user specifies input_shape, such as '-1,256,256,3', which program interprets -1 as parameter name not value\r\n* update arg message of input_shape",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-03-06T08:55:40Z",
        "closed_at": "2018-03-06T10:06:13Z",
        "merged_at": null,
        "body": "fix bug when user sets the batch_size of input_shape to -1,  such as '-1,128,128,3'. In this case the program interprets -1 as part of parameter name, not a parameter value.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 6988,
        "deletions": 0,
        "changed_files": 46,
        "created_at": "2018-03-06T00:31:22Z",
        "closed_at": "2018-03-08T22:41:56Z",
        "merged_at": "2018-03-08T22:41:56Z",
        "body": "Implements https://arxiv.org/abs/1802.02611",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 28,
        "deletions": 6,
        "changed_files": 24,
        "created_at": "2018-03-05T23:33:48Z",
        "closed_at": "2018-03-06T00:37:19Z",
        "merged_at": "2018-03-06T00:37:18Z",
        "body": "In the six weeks since #3206 was merged, the Python 2-only function __xrange()__ was introduced into 24 files in this repo.  This PR reapplies the same fix as last time: __from six.moves import xrange__.\r\n\r\nIt would be quite helpful if we could have __flake8 . --select=E901,E999,F821,F822,F823__ added to the test suite to catch these issues compatibility before code is reviewed and merged.  Our current test suite does not flag them.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 452,
        "deletions": 0,
        "changed_files": 6,
        "created_at": "2018-03-05T20:46:29Z",
        "closed_at": "2018-03-13T20:06:45Z",
        "merged_at": "2018-03-13T20:06:45Z",
        "body": "Add examples_per_second_hook and unit tests",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 11,
        "deletions": 10,
        "changed_files": 1,
        "created_at": "2018-03-02T23:30:08Z",
        "closed_at": "2018-03-03T01:30:13Z",
        "merged_at": null,
        "body": "These edits will still fail mnist_test.py",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-03-02T22:29:30Z",
        "closed_at": "2018-03-02T23:48:41Z",
        "merged_at": "2018-03-02T23:48:41Z",
        "body": "Fixes SyntaxError: invalid syntax",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 131,
        "changed_files": 2,
        "created_at": "2018-03-02T00:44:08Z",
        "closed_at": "2018-03-02T16:57:35Z",
        "merged_at": "2018-03-02T16:57:35Z",
        "body": "We have moved to an internal system for running tests. Removing the files for Jenkins.\r\n\r\nThis also supersedes #2804 , as testing will be handled elsewhere.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 59,
        "deletions": 27,
        "changed_files": 6,
        "created_at": "2018-03-01T20:50:46Z",
        "closed_at": "2018-03-05T21:02:28Z",
        "merged_at": "2018-03-05T21:02:28Z",
        "body": "This adds an option to use fake data (instead of the real images) to Resnet. Using synthetic data is useful in depugging performance, as it allows users to remove the input pipeline from the equation.\r\n\r\nCC @tfboyd @reedwm @isaprykin , who may find this useful.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 19,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-03-01T20:39:38Z",
        "closed_at": "2018-03-02T22:54:46Z",
        "merged_at": "2018-03-02T22:54:46Z",
        "body": "Also eliminates unnecessary `tf.pad` call in case when all padding values are 0.",
        "comments": 11
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 0,
        "changed_files": 0,
        "created_at": "2018-03-01T19:58:56Z",
        "closed_at": "2018-03-20T18:10:25Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-03-01T01:15:09Z",
        "closed_at": "2018-03-08T08:46:50Z",
        "merged_at": null,
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1653,
        "deletions": 3287,
        "changed_files": 103,
        "created_at": "2018-02-28T19:29:50Z",
        "closed_at": "2018-03-09T22:20:18Z",
        "merged_at": "2018-03-09T22:20:18Z",
        "body": "187187978  by Zhichao Lu:\r\n\r\n    Only updating hyperparameters if they have non-null values.\r\n\r\n--\r\n187097690  by Zhichao Lu:\r\n\r\n    Rewrite some conditions a bit more clearly.\r\n\r\n--\r\n187085190  by Zhichao Lu:\r\n\r\n    More informative error message.\r\n\r\n--\r\n186935376  by Zhichao Lu:\r\n\r\n    Added option to evaluator.evaluate to use custom evaluator objects.\r\n\r\n--\r\n186808249  by Zhichao Lu:\r\n\r\n    Fix documentation re: number of stages.\r\n\r\n--\r\n186775014  by Zhichao Lu:\r\n\r\n    Change anchor generator interface to return a list of BoxLists containing anchors for different feature map layers.\r\n\r\n--\r\n186729028  by Zhichao Lu:\r\n\r\n    Minor fixes to object detection.\r\n\r\n--\r\n186723716  by Zhichao Lu:\r\n\r\n    Fix tf_example_decoder.py initailization issue.\r\n\r\n--\r\n186668505  by Zhichao Lu:\r\n\r\n    Remove unused import.\r\n\r\n--\r\n186475361  by Zhichao Lu:\r\n\r\n    Update the box predictor interface to return list of predictions - one from each feature map - instead of stacking them into one large tensor.\r\n\r\n--\r\n186410844  by Zhichao Lu:\r\n\r\n    Fix PythonPath Dependencies.\r\n\r\n--\r\n186365384  by Zhichao Lu:\r\n\r\n    Made some of the functions in exporter public so they can be reused.\r\n\r\n--\r\n186341438  by Zhichao Lu:\r\n\r\n    Re-introducing check that label-map-path must be a valid (non-empty) string prior to overwriting pipeline config.\r\n\r\n--\r\n186036984  by Zhichao Lu:\r\n\r\n    Adding default hyperparameters and allowing for overriding them via flags.\r\n\r\n--\r\n186026006  by Zhichao Lu:\r\n\r\n    Strip `eval_` prefix from name argument give to TPUEstimator.evaluate since it adds the same prefix internally.\r\n\r\n--\r\n186016042  by Zhichao Lu:\r\n\r\n    Add an option to evaluate models on training data.\r\n\r\n--\r\n185944986  by Zhichao Lu:\r\n\r\n    let _update_label_map_path go through even if the path is empty\r\n\r\n--\r\n185860781  by Zhichao Lu:\r\n\r\n    Add random normal initializer option to hyperparams builder.\r\n\r\n    Scale the regression losses outside of the box encoder by adjusting huber loss delta and regression loss weight.\r\n\r\n--\r\n185846325  by Zhichao Lu:\r\n\r\n    Add an option to normalize localization loss by the code size(number of box coordinates) in SSD Meta architecture.\r\n\r\n--\r\n185761217  by Zhichao Lu:\r\n\r\n    Change multiscale_grid_anchor_generator to return anchors in normalized coordinates by default and add option to configure it.\r\n\r\n    In SSD meta architecture, TargetAssigner operates in normalized coordinate space (i.e, groundtruth boxes are in normalized coordinates) hence we need the option to generate anchors in normalized coordinates.\r\n\r\n--\r\n185747733  by Zhichao Lu:\r\n\r\n    Change the smooth L1 localization implementationt to use tf.losses.huber_loss and expose the delta parameter in the proto.\r\n\r\n--\r\n185715309  by Zhichao Lu:\r\n\r\n    Obviates the need for prepadding on mobilenet v1 and v2 for fully convolutional models.\r\n\r\n--\r\n185685695  by Zhichao Lu:\r\n\r\n    Fix manual stepping schedule to return first rate when there are no boundaries\r\n\r\n--\r\n185621650  by Zhichao Lu:\r\n\r\n    Added target assigner proto for configuring negative class weights.\r\n\r\n--\r\n\r\nPiperOrigin-RevId: 187187978",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 347,
        "deletions": 44,
        "changed_files": 18,
        "created_at": "2018-02-28T08:18:10Z",
        "closed_at": "2019-11-24T23:44:14Z",
        "merged_at": null,
        "body": "I went through the pet detector tutorial and made some fixes that got the training portion running. I haven't figured out how to get the evaluation code (there's an open issue for pycocotools) or the ipython notebook running. I don't have context on whether the fixes I made here were the correct ones, but they did get the program to the point where it was working for me.\r\n\r\nI hope this contribution helps improve the quality of the tutorials in the future, thank you for maintaining this project!",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 519,
        "deletions": 106,
        "changed_files": 7,
        "created_at": "2018-02-27T21:02:30Z",
        "closed_at": "2018-03-12T21:27:47Z",
        "merged_at": "2018-03-12T21:27:47Z",
        "body": "Previously the official ResNet provided was the \"v2\" version from He, et al., (2016). However the \"v1\" described in He, et al., (2015) is also very popular. This PR allows the official ResNet model to be run using either the v1 or v2 conventions.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-02-27T09:02:39Z",
        "closed_at": "2019-11-24T23:44:14Z",
        "merged_at": null,
        "body": "\u2026hen running train.py\r\n\r\nIn this issue:\r\n\r\nhttps://github.com/tensorflow/models/issues/3476\r\n\r\nI've found that the change in this file from\r\n\r\n    fields.InputDataFields.image: slim_example_decoder.Image(\r\n        image_key='image/encoded', format_key='image/format', channels=3),\r\n\r\nto:\r\n\r\n    fields.InputDataFields.image:\r\n        slim_example_decoder.Image(\r\n            image_key='image/encoded',\r\n            format_key='image/format',\r\n            channels=3,\r\n            dct_method=dct_method),\r\n\r\ncauses an error when running https://github.com/tensorflow/models/blob/master/research/object_detection/train.py\r\n\r\nI think this should be changed back as above.  I should mention in issue 3476 another poster verified experiencing the same concern and verified the same fix, thanks!",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2018-02-27T03:43:56Z",
        "closed_at": "2018-04-17T16:11:45Z",
        "merged_at": "2018-04-17T16:11:45Z",
        "body": "Bugfix for initialization in autoencoder, thanks to @cclauss for raising the issue in #1052 \r\nVerified it runs.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-02-26T23:10:09Z",
        "closed_at": "2018-02-28T16:19:50Z",
        "merged_at": "2018-02-28T16:19:50Z",
        "body": "@swaroopgj please review",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 500,
        "deletions": 26,
        "changed_files": 5,
        "created_at": "2018-02-26T22:05:46Z",
        "closed_at": "2018-02-27T00:54:56Z",
        "merged_at": "2018-02-27T00:54:56Z",
        "body": "Add mobilenet train and eval scripts and update documentation to include quantization support.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 263,
        "deletions": 0,
        "changed_files": 4,
        "created_at": "2018-02-26T22:05:22Z",
        "closed_at": "2019-11-24T23:44:14Z",
        "merged_at": null,
        "body": "This is intended as the reference implementation for a blogpost.\r\n\r\nDO NOT MERGE.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 111,
        "deletions": 22,
        "changed_files": 6,
        "created_at": "2018-02-26T20:02:17Z",
        "closed_at": "2018-03-01T15:52:08Z",
        "merged_at": "2018-03-01T15:52:08Z",
        "body": "Performance on this is still less than expected, but I want to push this in to unblock several other changes. \r\n\r\nNotes:\r\n* I removed the image conversion to a float in the range [0, 1) because it did not affect convergence, but negatively impacted performance. \r\n* The num_gpus flag is included for @tfboyd's use currently; if we decide there is a better way for his testing purposes, that can be removed (in a follow-up if timing requires).\r\n* This duplicates some of the code in MNIST; we will handle that in follow-up PRs as we introduce some shared functions.\r\n\r\nCC @isaprykin @reedwm @tfboyd ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-02-26T19:42:56Z",
        "closed_at": "2018-02-28T02:02:16Z",
        "merged_at": "2018-02-28T02:02:16Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 1074,
        "changed_files": 6,
        "created_at": "2018-02-26T14:52:04Z",
        "closed_at": "2018-02-26T16:25:59Z",
        "merged_at": "2018-02-26T16:25:59Z",
        "body": "This example has been replaced by the [nmt repo](https://github.com/tensorflow/nmt).\r\n\r\nIt's hopelessly out of date, not worth fixing.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 58,
        "deletions": 52,
        "changed_files": 3,
        "created_at": "2018-02-26T14:42:14Z",
        "closed_at": "2019-11-24T23:44:13Z",
        "merged_at": null,
        "body": "Fix #3270 for the SSD architecture.",
        "comments": 12
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-02-24T22:46:53Z",
        "closed_at": "2019-11-24T23:44:13Z",
        "merged_at": null,
        "body": "In case unable encoding.\r\nI use the python3.5",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2018-02-24T20:16:29Z",
        "closed_at": "2018-02-26T19:45:52Z",
        "merged_at": "2018-02-26T19:45:51Z",
        "body": "This fixes #2418, as proposed by @himani-arora.\r\n\r\nPlease let me know (@himani-arora, @ofirnachum, @lukaszkaiser) if this is alright, and if you would like me to add anything more.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-02-24T04:28:27Z",
        "closed_at": "2018-03-02T17:07:29Z",
        "merged_at": "2018-03-02T17:07:29Z",
        "body": "Using a more reliable mirror for MNIST data in the tutorial.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 343,
        "deletions": 106,
        "changed_files": 28,
        "created_at": "2018-02-24T00:25:33Z",
        "closed_at": "2018-02-27T23:28:03Z",
        "merged_at": "2018-02-27T23:28:03Z",
        "body": "186565198  by Sergio Guadarrama:\r\n\r\n    Applied random_hsv_in_yiq in inception_preprocessing.\r\n\r\n--\r\n186501039  by Sergio Guadarrama:\r\n\r\n    Applied random_hsv_in_yiq in inception_preprocessing.\r\n\r\n--\r\n186013907  by Sergio Guadarrama:\r\n\r\n    Internal change\r\n\r\n185715309  by Sergio Guadarrama:\r\n\r\n    Obviates the need for prepadding on mobilenet v1 and v2 for fully convolutional models.\r\n\r\n--\r\n184266252  by Sergio Guadarrama:\r\n\r\n    Give build_nasnet_*() functions an optional flag use_aux_head,\r\n    and add an internal-only arg scope to NasNetA*Cell._apply_drop_path().\r\n\r\n--\r\n183865228  by Sergio Guadarrama:\r\n\r\n    Internal change\r\n\r\n179580924  by Sergio Guadarrama:\r\n\r\n    Internal change\r\n\r\n177320302  by Sergio Guadarrama:\r\n\r\n    Internal change\r\n\r\n177130184  by Sergio Guadarrama:\r\n\r\n    Make slim nets tests faster by using smaller examples of oversized inputs.\r\n\r\n--\r\n176965289  by Sergio Guadarrama:\r\n\r\n    Internal change\r\n\r\n176585260  by Sergio Guadarrama:\r\n\r\n    Internal change\r\n\r\n176534973  by Sergio Guadarrama:\r\n\r\n    Internal change\r\n\r\n175526881  by Sergio Guadarrama:\r\n\r\n    Internal change\r\n\r\n174967704  by Sergio Guadarrama:\r\n\r\n    Treat num_classes=0 same as None in a few slim nets overlooked by the recent\r\n    change.\r\n\r\n--\r\n174443227  by Sergio Guadarrama:\r\n\r\n    Internal change\r\n\r\n174281864  by Sergio Guadarrama:\r\n\r\n    Internal change\r\n\r\n174249903  by Sergio Guadarrama:\r\n\r\n    Fix nasnet image classification and object detection by moving the option to turn ON or OFF batch norm training into it's own arg_scope used only by detection\r\n\r\n--\r\n173954505  by Sergio Guadarrama:\r\n\r\n    Merge pull request #2651 from sguada/tmp1\r\n\r\n    Fixes imports\r\n\r\n    Closes #2636\r\n\r\n    ORIGINAL_AUTHOR=Jon Shlens <shlens@users.noreply.github.com>\r\n    COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/models/pull/2636 from tensorflow:sguada-patch-1 19ff570f52df5ab655c00fb439129b201c5f2dce\r\n\r\n--\r\n173928094  by Sergio Guadarrama:\r\n\r\n    Remove pending imports\r\n\r\n--\r\n\r\nPiperOrigin-RevId: 186565198",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 11,
        "changed_files": 1,
        "created_at": "2018-02-23T23:52:31Z",
        "closed_at": "2018-02-26T19:07:53Z",
        "merged_at": "2018-02-26T19:07:53Z",
        "body": "PiperOrigin-RevId: 186781401",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-02-23T22:30:35Z",
        "closed_at": "2019-02-23T19:55:59Z",
        "merged_at": null,
        "body": "",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2018-02-23T22:25:37Z",
        "closed_at": "2019-11-24T23:44:13Z",
        "merged_at": null,
        "body": "Learning rate is a handy thing to visualize. Is there a cleaner way to do this than `tf.get_default_graph` with a hard-coded tensor name?",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-02-23T15:26:11Z",
        "closed_at": "2019-11-24T23:44:12Z",
        "merged_at": null,
        "body": "Fixes the error below when running `train.py` using python3 with the [default rcnn_inception_v2_coco mask-rcnn config file](https://github.com/tensorflow/models/blob/master/research/object_detection/samples/configs/mask_rcnn_inception_v2_coco.config) linked in the [instance segmentation readme](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/instance_segmentation.md).\r\n\r\n```\r\npython object_detection/train.py     --logtostderr     --pipeline_config_path=\"../../../mask_rcnn_inception_v2_coco.config\" --train_dir=\"../../../train/\"\r\nINFO:tensorflow:Scale of 0 disables regularizer.\r\nINFO:tensorflow:Scale of 0 disables regularizer.\r\nINFO:tensorflow:Scale of 0 disables regularizer.\r\nWARNING:tensorflow:From /home/delcourj/BAM_Telecom_grond/tensorflow/models/research/object_detection/trainer.py:228: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease switch to tf.train.create_global_step\r\nINFO:tensorflow:Scale of 0 disables regularizer.\r\nINFO:tensorflow:Scale of 0 disables regularizer.\r\nINFO:tensorflow:Scale of 0 disables regularizer.\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nWARNING:tensorflow:From /home/delcourj/BAM_Telecom_grond/tensorflow/models/research/object_detection/core/box_predictor.py:391: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nkeep_dims is deprecated, use keepdims instead\r\nWARNING:tensorflow:From /home/delcourj/BAM_Telecom_grond/tensorflow/models/research/object_detection/core/losses.py:306: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\n\r\nFuture major versions of TensorFlow will allow gradients to flow\r\ninto the labels input on backprop by default.\r\n\r\nSee tf.nn.softmax_cross_entropy_with_logits_v2.\r\n\r\nWARNING:tensorflow:From /home/delcourj/BAM_Telecom_grond/tensorflow/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:1851: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nkeep_dims is deprecated, use keepdims instead\r\nTraceback (most recent call last):\r\n  File \"object_detection/train.py\", line 167, in <module>\r\n    tf.app.run()\r\n  File \"/home/delcourj/tfenv/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 124, in run\r\n    _sys.exit(main(argv))\r\n  File \"object_detection/train.py\", line 163, in main\r\n    worker_job_name, is_chief, FLAGS.train_dir)\r\n  File \"/home/delcourj/BAM_Telecom_grond/tensorflow/models/research/object_detection/trainer.py\", line 255, in train\r\n    train_config.optimizer)\r\n  File \"/home/delcourj/BAM_Telecom_grond/tensorflow/models/research/object_detection/builders/optimizer_builder.py\", line 50, in build\r\n    learning_rate = _create_learning_rate(config.learning_rate)\r\n  File \"/home/delcourj/BAM_Telecom_grond/tensorflow/models/research/object_detection/builders/optimizer_builder.py\", line 108, in _create_learning_rate\r\n    learning_rate_sequence)\r\n  File \"/home/delcourj/BAM_Telecom_grond/tensorflow/models/research/object_detection/utils/learning_schedules.py\", line 153, in manual_stepping\r\n    tf.constant(range(num_boundaries), dtype=tf.int32),\r\n  File \"/home/delcourj/tfenv/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 212, in constant\r\n    value, dtype=dtype, shape=shape, verify_shape=verify_shape))\r\n  File \"/home/delcourj/tfenv/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py\", line 413, in make_tensor_proto\r\n    _AssertCompatible(values, dtype)\r\n  File \"/home/delcourj/tfenv/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py\", line 328, in _AssertCompatible\r\n    (dtype.name, repr(mismatch), type(mismatch).__name__))\r\nTypeError: Expected int32, got range(0, 3) of type 'range' instead.\r\n```",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2018-02-23T11:27:36Z",
        "closed_at": "2019-11-24T23:44:12Z",
        "merged_at": null,
        "body": "During predict we should not return None tensor, doing so will cause an exception in dataset.map()\r\nAlso while extracting data from the dataset iterator we should not expect labels since they do not exist in the dataset",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-02-23T09:32:51Z",
        "closed_at": "2019-01-18T06:00:07Z",
        "merged_at": null,
        "body": "Motivated by #3418",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 106,
        "deletions": 12,
        "changed_files": 6,
        "created_at": "2018-02-21T08:41:56Z",
        "closed_at": "2018-02-21T16:36:57Z",
        "merged_at": null,
        "body": "https://github.com/tensorflow/models/tree/master/research/street",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 26,
        "deletions": 179,
        "changed_files": 16,
        "created_at": "2018-02-20T21:33:45Z",
        "closed_at": "2018-02-22T19:25:06Z",
        "merged_at": "2018-02-22T19:25:06Z",
        "body": "PiperOrigin-RevId: 186265033\r\n",
        "comments": 10
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2018-02-19T18:26:06Z",
        "closed_at": "2018-02-20T23:56:20Z",
        "merged_at": "2018-02-20T23:56:20Z",
        "body": "Previously, code block one attempted to import `from object_detection.utils` before the `object_detection` directory was added to the PythonPath via `sys.path.append(\"..\")`.\r\n\r\nThis generated a `ModuleNotFoundError`.\r\n\r\nAccordingly, append `\"..\"` to the PythonPath before attempting to import from `object_detection` as a module, instead of after.",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 3715,
        "deletions": 2,
        "changed_files": 36,
        "created_at": "2018-02-17T15:06:45Z",
        "closed_at": "2019-07-21T14:41:50Z",
        "merged_at": null,
        "body": "Minor fixes to README.md for NASNet for TF Slim.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 50,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2018-02-17T07:04:27Z",
        "closed_at": "2018-02-22T17:34:55Z",
        "merged_at": null,
        "body": "This commit adds the script requested from #3362 for converting images to MNIST-format numpy arrays and includes documentation for use. A user can now call `$ python convert_npy.py --image \"example5.png example3.png\" --batch True --output examples` to generate a file identical to examples.npy, though the pixel values are reversed because the MNIST numbers are white with black background. Also fixed a typo in the readme.",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 94,
        "deletions": 68,
        "changed_files": 14,
        "created_at": "2018-02-17T02:46:08Z",
        "closed_at": "2018-02-20T07:08:27Z",
        "merged_at": "2018-02-20T07:08:27Z",
        "body": "Mostly fixing multiclass classification. Also includes speed/memory optimizations and deadlock fixes.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 306,
        "deletions": 2,
        "changed_files": 4,
        "created_at": "2018-02-16T23:25:43Z",
        "closed_at": "2018-02-17T01:35:39Z",
        "merged_at": "2018-02-17T01:35:39Z",
        "body": "Add an example showing how to train the MNIST model with eager execution\r\nenabled.\r\n\r\n(This change requires changes to TensorFlow made after\r\nthe 1.6 release branch was cut, i.e., will require a build\r\nfrom source or TensorFlow 1.7+)\r\n\r\nFYI @jhseu @guptapriya @fchollet ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 35,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2018-02-16T21:32:14Z",
        "closed_at": "2018-03-02T01:09:16Z",
        "merged_at": "2018-03-02T01:09:16Z",
        "body": "1. These Dockerfiles can be used to generate official docker images that can used for running models in this repo on container based platforms\n2. We can leverage google container builder to build images for every branch, tag and/or HEAD.",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2018-02-16T14:59:37Z",
        "closed_at": "2018-02-23T17:28:32Z",
        "merged_at": null,
        "body": "The intent of #2804 is to catch these issues automatically.  @pkulzc \r\n\r\nObject Detection Code Owners: @jch1 @tombstone @derekjchow @jesu9 @dreamdragon\r\n* https://github.com/tensorflow/models/commit/7a9934df2afdf95be9405b4e9f1f2480d748dc40#r27482046",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 21,
        "changed_files": 1,
        "created_at": "2018-02-16T01:24:25Z",
        "closed_at": "2018-02-16T17:12:53Z",
        "merged_at": null,
        "body": "The iterator to generate batches for imported dataset is missed. ",
        "comments": 12
    },
    {
        "merged": true,
        "additions": 110,
        "deletions": 228,
        "changed_files": 2,
        "created_at": "2018-02-14T18:14:04Z",
        "closed_at": "2018-02-16T21:59:32Z",
        "merged_at": "2018-02-16T21:59:32Z",
        "body": "This PR cleans up and tunes some of the VGG preprocessing code. While the changes below don't have any noticeable effect on training with 1 GPU, the difference becomes substantial with multiple GPUs (where preprocessing and IO become bottlenecks). The changes below should not result in any differences in functionality, and we still converge to 75% (tested on 8 GPUs).\r\n\r\n@asimshankar @k-w-w -- as @nealwu is out for a few weeks, tagging you two for review.\r\n\r\nCC @isaprykin ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 195,
        "deletions": 122,
        "changed_files": 26,
        "created_at": "2018-02-14T00:32:39Z",
        "closed_at": "2018-02-21T20:38:05Z",
        "merged_at": "2018-02-21T20:38:05Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 62,
        "deletions": 57,
        "changed_files": 9,
        "created_at": "2018-02-13T19:29:37Z",
        "closed_at": "2018-02-14T23:54:04Z",
        "merged_at": "2018-02-14T23:54:04Z",
        "body": "PiperOrigin-RevId: 185469605",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 702,
        "deletions": 352,
        "changed_files": 12,
        "created_at": "2018-02-12T21:17:57Z",
        "closed_at": "2018-03-01T01:42:59Z",
        "merged_at": "2018-03-01T01:42:59Z",
        "body": "PiperOrigin-RevId: 185395080",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 698,
        "deletions": 352,
        "changed_files": 12,
        "created_at": "2018-02-12T19:00:54Z",
        "closed_at": "2018-02-12T21:18:20Z",
        "merged_at": null,
        "body": "PiperOrigin-RevId: 185395080\r\n\r\nThe changes are:\r\n- improve tutorial\r\n- fix incorrect eval/inference batchnorm behavior\r\n- improve documentation",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 48,
        "deletions": 23,
        "changed_files": 2,
        "created_at": "2018-02-12T02:25:27Z",
        "closed_at": "2019-11-24T23:44:12Z",
        "merged_at": null,
        "body": "Only calculate the small size if the large size is too big for the max_dimension.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-02-09T20:55:27Z",
        "closed_at": "2018-02-09T22:15:34Z",
        "merged_at": "2018-02-09T22:15:34Z",
        "body": "TF Saver now requires specifying the checkpoint version even when restoring to avoid errors when we specify a path to a checkpoint file instead of a directory.\r\n\r\n@dpwe ",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 21,
        "deletions": 21,
        "changed_files": 4,
        "created_at": "2018-02-09T20:04:37Z",
        "closed_at": "2018-02-09T21:15:33Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 50,
        "deletions": 9,
        "changed_files": 4,
        "created_at": "2018-02-08T07:11:18Z",
        "closed_at": "2018-02-08T20:16:48Z",
        "merged_at": "2018-02-08T20:16:47Z",
        "body": "This enables users to use our predefined ResNet models for datasets other than CIFAR-10 and ImageNet.\r\n\r\nIn addition an internal team uses this model, and this change is needed to fix their tests that broke with the latest copybara sync.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-02-07T20:36:31Z",
        "closed_at": "2018-02-08T01:30:51Z",
        "merged_at": "2018-02-08T01:30:51Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2018-02-07T08:34:26Z",
        "closed_at": "2018-02-08T22:18:32Z",
        "merged_at": "2018-02-08T22:18:32Z",
        "body": "change cPickle to pickle for python3\r\nspecify  encoding='latin1' when call pickle.load()\r\n@nealwu ",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 10,
        "changed_files": 4,
        "created_at": "2018-02-06T20:29:28Z",
        "closed_at": "2018-02-07T20:18:02Z",
        "merged_at": "2018-02-07T20:18:02Z",
        "body": "See https://github.com/tensorflow/models/pull/3300 for reference (thanks @MarkDaoust for letting me know of this API change). Also added a note clarifying that we aim to be compatible with TF1.5 but can't always guarantee it.\r\n\r\nI left official/resnet untouched because it's covered by https://github.com/tensorflow/models/pull/3332.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-02-06T19:04:34Z",
        "closed_at": "2018-02-06T20:09:12Z",
        "merged_at": "2018-02-06T20:09:12Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 115,
        "deletions": 72,
        "changed_files": 4,
        "created_at": "2018-02-06T17:12:34Z",
        "closed_at": "2018-02-06T20:39:07Z",
        "merged_at": "2018-02-06T20:39:07Z",
        "body": "This is one of what may end up being several changes that come out of the multi-GPU Resnet work. We found in testing that training was blocking on input processing, and the changes here serve to (1) unify the cifar/imagenet input pipelines, (2) conform with the advice from @mrry as to input processing, and (3) allow for more parallel calls during the mapping phase.\r\n\r\nAn example configuration: 16xCPU, 1xGPU, training Imagenet-- on master runs at ~5.4 steps/sec; with this branch and --parallel_calls=16, runs at ~5.9 steps/sec. (Stats on CIFAR10 don't move much, but that is expected given the size of the dataset.)\r\n\r\nBoth datasets run; will be convergence testing as we do more multi-GPU work over the next week.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2018-02-05T23:48:51Z",
        "closed_at": "2018-02-06T01:34:40Z",
        "merged_at": "2018-02-06T01:34:40Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2018-02-05T22:58:32Z",
        "closed_at": "2018-02-06T01:35:43Z",
        "merged_at": "2018-02-06T01:35:43Z",
        "body": "This fixes an issue Python 3 users were having, related to opening binary files. Now the DELF code works both for Python 2.7 and Python 3+.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-02-05T09:51:56Z",
        "closed_at": "2018-03-05T19:37:58Z",
        "merged_at": "2018-03-05T19:37:58Z",
        "body": "I've been trying to freeze some layers in my module with Python3, but only one parameter was frozen.\r\nAfter carefully inspection, I found the function `filter()`  in Python3 is  incompatible with Python2 which returns a `iterator`.\r\n\r\n```python\r\nfrom __future__ import print_function\r\nvariables=['a','b','c']\r\nvariables_to_ignore_patterns=filter(None,['1'])\r\nfor var in variables:\r\n    for pattern in variables_to_ignore_patterns:\r\n        print(var,pattern)\r\n```\r\nthe results in Python2 and Python3 are kind of discrepant:\r\n\r\nPython2: \r\n\r\n> a  1\r\n> b  1\r\n> c  1\r\n\r\nPython3:\r\n\r\n> a  1\r\n",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-02-03T18:55:12Z",
        "closed_at": "2018-02-05T20:51:45Z",
        "merged_at": "2018-02-05T20:51:45Z",
        "body": "This addresses #3248 . The released branch Readmes will now link out to `master` versions of research models.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 64,
        "deletions": 26,
        "changed_files": 3,
        "created_at": "2018-02-03T00:34:12Z",
        "closed_at": "2018-02-06T17:28:46Z",
        "merged_at": "2018-02-06T17:28:46Z",
        "body": "Affects research/lfads. @sussillo \r\n\r\n1. For stitched models, the readin matrices and bias vectors are initialized to the\r\n\"alignment\" matrix and bias specified in each dataset's .h5 file. If do_train_readin is\r\nTrue, these will be trainable, and if not, they will be fixed.\r\n2. Initializing readout matrices to readin transpose rather than pseudoinverse.\r\n3. Fixes flag parsing issues with ints vs floats",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 6,
        "changed_files": 3,
        "created_at": "2018-02-02T23:39:08Z",
        "closed_at": "2018-02-06T01:36:05Z",
        "merged_at": "2018-02-06T01:36:05Z",
        "body": "`max_number_of_evaluation` -> `max_number_of_evaluations`.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 3716,
        "deletions": 0,
        "changed_files": 37,
        "created_at": "2018-02-02T13:30:17Z",
        "closed_at": "2018-02-06T01:43:15Z",
        "merged_at": null,
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-02-02T11:16:27Z",
        "closed_at": "2018-02-12T18:23:07Z",
        "merged_at": "2018-02-12T18:23:07Z",
        "body": "Added python-tk in dependency list",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 255,
        "deletions": 272,
        "changed_files": 4,
        "created_at": "2018-02-02T04:37:07Z",
        "closed_at": "2018-02-03T04:46:46Z",
        "merged_at": "2018-02-03T04:46:46Z",
        "body": "As per discussion in #3216 , merging resnet_shared and resnet_model into a single module.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2018-02-01T23:03:39Z",
        "closed_at": "2018-02-06T01:54:06Z",
        "merged_at": "2018-02-06T01:54:06Z",
        "body": "As of r1.5 an `input_fn` can directly return a dataset. \r\n\r\nThis approach is more flexible because it allows the estimator to initialize the dataset, and is less boiler-plate for the user.\r\n\r\nLocal tests pass, training converges.\r\n\r\n> python estimator_test.py \r\n> python premade_estimator.py\r\n> python custom_estimator.py\r\n\r\nLike the `sparse_softmax_cross_entropy` we may eventually want to apply this fix more widely.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 247,
        "deletions": 86,
        "changed_files": 2,
        "created_at": "2018-02-01T23:02:09Z",
        "closed_at": "2018-08-23T21:50:00Z",
        "merged_at": null,
        "body": "There are conflicts and the formatting makes it hard to see.  I will look at it tomorow.  Not hard to figure out.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-02-01T21:44:09Z",
        "closed_at": "2018-02-06T02:55:23Z",
        "merged_at": "2018-02-06T02:55:23Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 18088,
        "deletions": 2798,
        "changed_files": 200,
        "created_at": "2018-02-01T03:12:58Z",
        "closed_at": "2018-02-10T02:38:15Z",
        "merged_at": "2018-02-10T02:38:15Z",
        "body": "184048729  by Zhichao Lu:\r\n\r\n    Modify target_assigner so that it creates regression targets taking keypoints into account.\r\n\r\n--\r\n184027183  by Zhichao Lu:\r\n\r\n    Resnet V1 FPN based feature extractors for SSD meta architecture in Object Detection V2 API.\r\n\r\n--\r\n184004730  by Zhichao Lu:\r\n\r\n    Expose a lever to override the configured mask_type.\r\n\r\n--\r\n183933113  by Zhichao Lu:\r\n\r\n    Weight shared convolutional box predictor as described in https://arxiv.org/abs/1708.02002\r\n\r\n--\r\n183929669  by Zhichao Lu:\r\n\r\n    Expanding box list operations for future data augmentations.\r\n\r\n--\r\n183916792  by Zhichao Lu:\r\n\r\n    Fix unrecognized assertion function in tests.\r\n\r\n--\r\n183906851  by Zhichao Lu:\r\n\r\n    - Change ssd meta architecture to use regression weights to compute loss normalizer.\r\n\r\n--\r\n183871003  by Zhichao Lu:\r\n\r\n    Fix config_util_test wrong dependency.\r\n\r\n--\r\n183782120  by Zhichao Lu:\r\n\r\n    Add __init__ file to third_party directories.\r\n\r\n--\r\n183779109  by Zhichao Lu:\r\n\r\n    Setup regular version sync.\r\n\r\n--\r\n183768772  by Zhichao Lu:\r\n\r\n    Make test compatible with numpy 1.12 and higher\r\n\r\n--\r\n183767893  by Zhichao Lu:\r\n\r\n    Make test compatible with numpy 1.12 and higher\r\n\r\n--\r\n183719318  by Zhichao Lu:\r\n\r\n    Use the new test interface in ssd feature extractor.\r\n\r\n--\r\n183714671  by Zhichao Lu:\r\n\r\n    Use the new test_case interface for all anchor generators.\r\n\r\n--\r\n183708155  by Zhichao Lu:\r\n\r\n    Change variable scopes in ConvolutionalBoxPredictor such that previously trained checkpoints are still compatible after the change in BoxPredictor interface\r\n\r\n--\r\n183705798  by Zhichao Lu:\r\n\r\n    Internal change.\r\n\r\n--\r\n183636023  by Zhichao Lu:\r\n\r\n    Fixing argument name for np_box_list_ops.concatenate() function.\r\n\r\n--\r\n183490404  by Zhichao Lu:\r\n\r\n    Make sure code that relies in SSD older code still works.\r\n\r\n--\r\n183426762  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n183412315  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n183337814  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n183303933  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n183257349  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n183254447  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n183251200  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n183135002  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n182851500  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n182839607  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n182830719  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n182533923  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n182391090  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n182262339  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n182244645  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n182241613  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n182133027  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n182058807  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n181812028  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n181788857  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n181656761  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n181541125  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n181538702  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n181125385  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n180957758  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n180941434  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n180852569  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n180846001  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n180832145  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n180740495  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n180729150  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n180589008  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n180585408  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n180581039  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n180286388  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n179934081  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n179841242  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n179831694  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n179761005  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n179610632  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n179605363  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n179603774  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n179598614  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n179597809  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n179494630  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n179367492  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n179250050  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n179247385  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n179207897  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n179076230  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n178862066  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n178854216  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n178853109  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n178709753  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n178640707  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n178421534  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n178287174  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n178257399  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n177681867  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n177654820  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n177654052  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n177638787  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n177598305  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n177538488  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n177474197  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n177271928  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n177250285  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n177210762  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n177197135  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n177037781  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n176917394  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n176683171  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n176450793  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n176388133  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n176197721  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n176195315  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n176128748  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n175743440  by Zhichao Lu:\r\n\r\n    Use Toggle instead of bool to make the layout optimizer name and usage consistent with other optimizers.\r\n\r\n--\r\n175578178  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n175463518  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n175316616  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n175302470  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n175300323  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n175269680  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n175260574  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n175122281  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n175111708  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n175110183  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n174877166  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n174868399  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n174754200  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n174544534  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n174536143  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n174513795  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n174463713  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n174403525  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n174385170  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n174358498  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n174249903  by Zhichao Lu:\r\n\r\n    Fix nasnet image classification and object detection by moving the option to turn ON or OFF batch norm training into it's own arg_scope used only by detection\r\n\r\n--\r\n174216508  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n174065370  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n174048035  by Zhichao Lu:\r\n\r\n    Fix the pointer for downloading the NAS Faster-RCNN model.\r\n\r\n--\r\n174042677  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173964116  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173790182  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173779919  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173753775  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173753160  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173737519  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173696066  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173611554  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173475124  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173412497  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173404010  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173375014  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173345107  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173298413  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173289754  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173275544  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173273275  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173271885  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173264856  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173263791  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173261215  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173175740  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173010193  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n172815204  by Zhichao Lu:\r\n\r\n    Allow for label maps in tf.Example decoding.\r\n\r\n--\r\n172696028  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n172509113  by Zhichao Lu:\r\n\r\n    Allow for label maps in tf.Example decoding.\r\n\r\n--\r\n172475999  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n172166621  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n172151758  by Zhichao Lu:\r\n\r\n    Minor updates to some README files.\r\n\r\n    As a result of these friendly issues:\r\n    https://github.com/tensorflow/models/issues/2530\r\n    https://github.com/tensorflow/models/issues/2534\r\n\r\n--\r\n172147420  by Zhichao Lu:\r\n\r\n    Fix illegal summary name and move from slim's get_or_create_global_step deprecated use of tf.contrib.framework* to tf.train*.\r\n\r\n--\r\n172111377  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n172004247  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n171996881  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n171835204  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n171826090  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n171784016  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n171699876  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n171053425  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n170905734  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n170889179  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n170734389  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n170705852  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n170401574  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n170352571  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n170215443  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n170184288  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n169936898  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n169763373  by Zhichao Lu:\r\n\r\n    Fix broken GitHub links in tensorflow and tensorflow_models resulting from The Great Models Move (a.k.a. the research subfolder)\r\n\r\n--\r\n169744825  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n169638135  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n169561814  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n169444091  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n169292330  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n169145185  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n168906035  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n168790411  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n168708911  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n168611969  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n168535975  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n168381815  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n168244740  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n168240024  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n168168016  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n168071571  by Zhichao Lu:\r\n\r\n    Move display strings to below the bounding box if they would otherwise be outside the image.\r\n\r\n--\r\n168067771  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n167970950  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n167884533  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n167626173  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n167277422  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n167249393  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n167248954  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n167189395  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n167107797  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n167061250  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n166871147  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n166867617  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n166862112  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n166715648  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n166635615  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n166383182  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n166371326  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n166254711  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n166106294  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n166081204  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n165972262  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n165816702  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n165764471  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n165724134  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n165655829  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n165587904  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n165534540  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n165177692  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n165091822  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n165019730  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n165002942  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n164897728  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n164782618  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n164710379  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n164639237  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n164069251  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n164058169  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n163913796  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n163756696  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n163524665  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n163393399  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n163385733  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n162525065  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n162376984  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n162026661  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n161956004  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n161817520  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n161718688  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n161624398  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n161575120  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n161483997  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n161462189  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n161452968  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n161443992  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n161408607  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n161262084  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n161214023  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n161025667  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n160982216  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n160666760  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n160570489  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n160553112  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n160458261  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n160349302  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n160296092  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n160287348  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n160199279  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n160160156  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n160151954  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n160005404  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159983265  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159819896  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159749419  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159596448  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159587801  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159587342  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159476256  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159463992  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159455585  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159270798  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159256633  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159141989  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159079098  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159078559  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159077055  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159072046  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159071092  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159069262  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159037430  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159035747  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159023868  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158939092  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158912561  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158903825  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158894348  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158884934  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158878010  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158874620  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158869501  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158842623  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158801298  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158775487  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158773668  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158771394  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158668928  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158596865  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158587317  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158586348  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158585707  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158577134  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158459749  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158459678  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158328972  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158324255  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158319576  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158290802  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158273041  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158240477  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158204316  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158154161  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158077203  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158041397  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158029233  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157976306  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157966896  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157945642  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157943135  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157942158  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157897866  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157866667  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157845915  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157842592  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157832761  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157824451  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157816531  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157782130  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157733752  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157654577  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157639285  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157530694  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157518469  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157514626  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157481413  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157267863  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157263616  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157234554  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157174595  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157169681  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157156425  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157024436  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157016195  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156941658  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156880859  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156790636  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156565969  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156522345  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156518570  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156509878  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156509134  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156472497  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156471429  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156470865  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156461563  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156437521  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156334994  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156319604  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156234305  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156226207  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156215347  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156127227  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156120405  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156113752  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156098936  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n155924066  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n155883241  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n155806887  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n155641849  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n155593034  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n155570702  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n155515306  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n155514787  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n155445237  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n155438672  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n155264448  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n155222148  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n155106590  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n155090562  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154973775  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154972880  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154871596  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154835007  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154788175  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154731169  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154721261  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154594626  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154588305  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154578994  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154571515  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154552873  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154549672  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154463631  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154437690  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154412359  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154374026  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154361648  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154310164  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154220862  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154187281  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154186651  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154119783  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154114285  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154095717  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154057972  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154055285  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n153659288  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n153637797  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n153561771  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n153540765  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n153496128  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n153473323  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n153368812  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n153367292  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n153201890  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n153074177  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152980017  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152978434  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152951821  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152904076  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152883703  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152869747  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152827463  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152756886  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152752840  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152736347  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152728184  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152720120  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152710964  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152706735  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152681133  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152517758  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152516381  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152511258  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152319164  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152316404  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152309261  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152308007  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152296551  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152188069  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152158644  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152153578  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152152285  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152055035  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152036778  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152020728  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152014842  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n151848225  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n151741308  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n151740499  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n151736189  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n151612892  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n151599502  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n151538547  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n151496530  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n151476070  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n151448662  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n151411627  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n151397737  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n151169523  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n151148956  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n150944227  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n150276683  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n149986687  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n149218749  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\nPiperOrigin-RevId: 184048729",
        "comments": 8
    },
    {
        "merged": false,
        "additions": 13609,
        "deletions": 2594,
        "changed_files": 177,
        "created_at": "2018-02-01T00:34:19Z",
        "closed_at": "2018-02-01T02:52:13Z",
        "merged_at": null,
        "body": "184048729  by Zhichao Lu:\r\n\r\n    Modify target_assigner so that it creates regression targets taking keypoints into account.\r\n\r\n--\r\n184027183  by Zhichao Lu:\r\n\r\n    Resnet V1 FPN based feature extractors for SSD meta architecture in Object Detection V2 API.\r\n\r\n--\r\n184004730  by Zhichao Lu:\r\n\r\n    Expose a lever to override the configured mask_type.\r\n\r\n--\r\n183933113  by Zhichao Lu:\r\n\r\n    Weight shared convolutional box predictor as described in https://arxiv.org/abs/1708.02002\r\n\r\n--\r\n183929669  by Zhichao Lu:\r\n\r\n    Expanding box list operations for future data augmentations.\r\n\r\n--\r\n183916792  by Zhichao Lu:\r\n\r\n    Fix unrecognized assertion function in tests.\r\n\r\n--\r\n183906851  by Zhichao Lu:\r\n\r\n    - Change ssd meta architecture to use regression weights to compute loss normalizer.\r\n\r\n--\r\n183871003  by Zhichao Lu:\r\n\r\n    Fix config_util_test wrong dependency.\r\n\r\n--\r\n183782120  by Zhichao Lu:\r\n\r\n    Add __init__ file to third_party directories.\r\n\r\n--\r\n183779109  by Zhichao Lu:\r\n\r\n    Setup regular version sync.\r\n\r\n--\r\n183768772  by Zhichao Lu:\r\n\r\n    Make test compatible with numpy 1.12 and higher\r\n\r\n--\r\n183767893  by Zhichao Lu:\r\n\r\n    Make test compatible with numpy 1.12 and higher\r\n\r\n--\r\n183719318  by Zhichao Lu:\r\n\r\n    Use the new test interface in ssd feature extractor.\r\n\r\n--\r\n183714671  by Zhichao Lu:\r\n\r\n    Use the new test_case interface for all anchor generators.\r\n\r\n--\r\n183708155  by Zhichao Lu:\r\n\r\n    Change variable scopes in ConvolutionalBoxPredictor such that previously trained checkpoints are still compatible after the change in BoxPredictor interface\r\n\r\n--\r\n183705798  by Zhichao Lu:\r\n\r\n    Internal change.\r\n\r\n--\r\n183636023  by Zhichao Lu:\r\n\r\n    Fixing argument name for np_box_list_ops.concatenate() function.\r\n\r\n--\r\n183490404  by Zhichao Lu:\r\n\r\n    Make sure code that relies in SSD older code still works.\r\n\r\n--\r\n183426762  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n183412315  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n183337814  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n183303933  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n183257349  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n183254447  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n183251200  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n183135002  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n182851500  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n182839607  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n182830719  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n182533923  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n182391090  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n182262339  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n182244645  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n182241613  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n182133027  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n182058807  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n181812028  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n181788857  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n181656761  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n181541125  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n181538702  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n181125385  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n180957758  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n180941434  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n180852569  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n180846001  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n180832145  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n180740495  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n180729150  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n180589008  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n180585408  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n180581039  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n180286388  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n179934081  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n179841242  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n179831694  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n179761005  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n179610632  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n179605363  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n179603774  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n179598614  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n179597809  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n179494630  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n179367492  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n179250050  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n179247385  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n179207897  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n179076230  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n178862066  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n178854216  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n178853109  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n178709753  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n178640707  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n178421534  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n178287174  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n178257399  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n177681867  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n177654820  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n177654052  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n177638787  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n177598305  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n177538488  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n177474197  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n177271928  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n177250285  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n177210762  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n177197135  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n177037781  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n176917394  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n176683171  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n176450793  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n176388133  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n176197721  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n176195315  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n176128748  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n175743440  by Zhichao Lu:\r\n\r\n    Use Toggle instead of bool to make the layout optimizer name and usage consistent with other optimizers.\r\n\r\n--\r\n175578178  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n175463518  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n175316616  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n175302470  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n175300323  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n175269680  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n175260574  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n175122281  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n175111708  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n175110183  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n174877166  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n174868399  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n174754200  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n174544534  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n174536143  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n174513795  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n174463713  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n174403525  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n174385170  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n174358498  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n174249903  by Zhichao Lu:\r\n\r\n    Fix nasnet image classification and object detection by moving the option to turn ON or OFF batch norm training into it's own arg_scope used only by detection\r\n\r\n--\r\n174216508  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n174065370  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n174048035  by Zhichao Lu:\r\n\r\n    Fix the pointer for downloading the NAS Faster-RCNN model.\r\n\r\n--\r\n174042677  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173964116  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173790182  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173779919  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173753775  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173753160  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173737519  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173696066  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173611554  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173475124  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173412497  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173404010  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173375014  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173345107  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173298413  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173289754  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173275544  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173273275  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173271885  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173264856  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173263791  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173261215  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173175740  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n173010193  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n172815204  by Zhichao Lu:\r\n\r\n    Allow for label maps in tf.Example decoding.\r\n\r\n--\r\n172696028  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n172509113  by Zhichao Lu:\r\n\r\n    Allow for label maps in tf.Example decoding.\r\n\r\n--\r\n172475999  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n172166621  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n172151758  by Zhichao Lu:\r\n\r\n    Minor updates to some README files.\r\n\r\n    As a result of these friendly issues:\r\n    https://github.com/tensorflow/models/issues/2530\r\n    https://github.com/tensorflow/models/issues/2534\r\n\r\n--\r\n172147420  by Zhichao Lu:\r\n\r\n    Fix illegal summary name and move from slim's get_or_create_global_step deprecated use of tf.contrib.framework* to tf.train*.\r\n\r\n--\r\n172111377  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n172004247  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n171996881  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n171835204  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n171826090  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n171784016  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n171699876  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n171053425  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n170905734  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n170889179  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n170734389  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n170705852  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n170401574  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n170352571  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n170215443  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n170184288  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n169936898  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n169763373  by Zhichao Lu:\r\n\r\n    Fix broken GitHub links in tensorflow and tensorflow_models resulting from The Great Models Move (a.k.a. the research subfolder)\r\n\r\n--\r\n169744825  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n169638135  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n169561814  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n169444091  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n169292330  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n169145185  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n168906035  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n168790411  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n168708911  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n168611969  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n168535975  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n168381815  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n168244740  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n168240024  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n168168016  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n168071571  by Zhichao Lu:\r\n\r\n    Move display strings to below the bounding box if they would otherwise be outside the image.\r\n\r\n--\r\n168067771  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n167970950  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n167884533  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n167626173  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n167277422  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n167249393  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n167248954  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n167189395  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n167107797  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n167061250  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n166871147  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n166867617  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n166862112  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n166715648  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n166635615  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n166383182  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n166371326  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n166254711  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n166106294  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n166081204  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n165972262  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n165816702  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n165764471  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n165724134  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n165655829  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n165587904  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n165534540  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n165177692  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n165091822  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n165019730  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n165002942  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n164897728  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n164782618  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n164710379  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n164639237  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n164069251  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n164058169  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n163913796  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n163756696  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n163524665  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n163393399  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n163385733  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n162525065  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n162376984  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n162026661  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n161956004  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n161817520  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n161718688  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n161624398  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n161575120  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n161483997  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n161462189  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n161452968  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n161443992  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n161408607  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n161262084  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n161214023  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n161025667  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n160982216  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n160666760  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n160570489  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n160553112  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n160458261  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n160349302  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n160296092  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n160287348  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n160199279  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n160160156  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n160151954  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n160005404  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159983265  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159819896  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159749419  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159596448  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159587801  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159587342  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159476256  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159463992  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159455585  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159270798  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159256633  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159141989  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159079098  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159078559  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159077055  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159072046  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159071092  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159069262  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159037430  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159035747  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n159023868  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158939092  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158912561  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158903825  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158894348  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158884934  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158878010  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158874620  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158869501  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158842623  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158801298  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158775487  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158773668  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158771394  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158668928  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158596865  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158587317  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158586348  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158585707  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158577134  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158459749  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158459678  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158328972  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158324255  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158319576  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158290802  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158273041  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158240477  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158204316  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158154161  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158077203  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158041397  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n158029233  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157976306  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157966896  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157945642  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157943135  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157942158  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157897866  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157866667  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157845915  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157842592  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157832761  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157824451  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157816531  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157782130  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157733752  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157654577  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157639285  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157530694  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157518469  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157514626  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157481413  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157267863  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157263616  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157234554  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157174595  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157169681  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157156425  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157024436  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n157016195  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156941658  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156880859  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156790636  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156565969  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156522345  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156518570  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156509878  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156509134  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156472497  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156471429  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156470865  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156461563  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156437521  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156334994  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156319604  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156234305  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156226207  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156215347  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156127227  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156120405  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156113752  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n156098936  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n155924066  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n155883241  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n155806887  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n155641849  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n155593034  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n155570702  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n155515306  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n155514787  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n155445237  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n155438672  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n155264448  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n155222148  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n155106590  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n155090562  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154973775  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154972880  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154871596  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154835007  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154788175  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154731169  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154721261  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154594626  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154588305  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154578994  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154571515  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154552873  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154549672  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154463631  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154437690  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154412359  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154374026  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154361648  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154310164  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154220862  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154187281  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154186651  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154119783  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154114285  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154095717  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154057972  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n154055285  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n153659288  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n153637797  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n153561771  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n153540765  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n153496128  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n153473323  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n153368812  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n153367292  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n153201890  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n153074177  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152980017  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152978434  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152951821  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152904076  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152883703  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152869747  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152827463  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152756886  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152752840  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152736347  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152728184  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152720120  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152710964  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152706735  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152681133  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152517758  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152516381  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152511258  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152319164  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152316404  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152309261  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152308007  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152296551  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152188069  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152158644  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152153578  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152152285  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152055035  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152036778  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152020728  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n152014842  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n151848225  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n151741308  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n151740499  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n151736189  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n151612892  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n151599502  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n151538547  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n151496530  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n151476070  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n151448662  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n151411627  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n151397737  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n151169523  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n151148956  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n150944227  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n150276683  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n149986687  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\n149218749  by Zhichao Lu:\r\n\r\n    Internal change\r\n\r\nPiperOrigin-RevId: 184048729",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 13,
        "changed_files": 4,
        "created_at": "2018-01-31T22:09:23Z",
        "closed_at": "2018-02-01T05:59:20Z",
        "merged_at": "2018-02-01T05:59:20Z",
        "body": "Reapplies PR #3227, with fix (second commit).\r\n\r\n(A remaining `tf.argmax(labels)` was converting the label index to 0)\r\n\r\nTest passes. Training _and evaluation_ are converging.\r\n\r\n```\r\npython mnist.py --train_epochs=2\r\n```\r\n\r\n```\r\nINFO:tensorflow:train_accuracy = 0.96666664 (12.616 sec)\r\n...\r\n\r\nEvaluation results:\r\n\t{'loss': 0.056986738, 'global_step': 1200, 'accuracy': 0.982}\r\n```",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 5,
        "changed_files": 5,
        "created_at": "2018-01-31T19:00:13Z",
        "closed_at": "2018-01-31T20:35:03Z",
        "merged_at": "2018-01-31T20:35:03Z",
        "body": "",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-01-31T01:43:41Z",
        "closed_at": "2018-01-31T17:48:55Z",
        "merged_at": "2018-01-31T17:48:55Z",
        "body": "__six__ is used on lines 174 and 175 but is never imported or defined.  @nealwu ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2018-01-31T00:30:49Z",
        "closed_at": "2018-01-31T18:45:15Z",
        "merged_at": "2018-01-31T18:45:15Z",
        "body": "While using this file as a starting point for some other work, I noticed some redundancy in the regularization code. The fourth argument to `_variable_with_weight_decay()` is supposed to be `None` for variables with no regularization. Instead the script uses the value `0.0`, which results in the creation of some regularization losses that are always zero. This PR changes those `0.0`'s to `None`'s.\r\n\r\nAfter this change, training runs about 2% faster, and the checkpoint files are a tiny bit smaller. The script's behavior is otherwise unchanged.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-01-30T20:54:22Z",
        "closed_at": "2019-11-24T23:44:11Z",
        "merged_at": null,
        "body": "new numpy does not allow float values for the reshape dimensions.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 33,
        "deletions": 33,
        "changed_files": 1,
        "created_at": "2018-01-30T11:03:41Z",
        "closed_at": "2018-06-25T10:35:56Z",
        "merged_at": null,
        "body": "First reported in  #1981 ...\r\n\r\n__is_training__ is an undefined name [inside the function __visit_count_fc()__](https://github.com/tensorflow/models/blob/master/research/cognitive_mapping_and_planning/tfcode/vision_baseline_lstm.py#L135-L153) because the function takes 5 parameters and none of them is called __is_training__.  Undefined names might raise NameError at runtime.\r\n\r\nflake8 testing of https://github.com/tensorflow/models\r\n\r\n$ __flake8 . --count --select=E901,E999,F821,F822,F823 --show-source --statistics__\r\n```\r\n./research/cognitive_mapping_and_planning/tfcode/vision_baseline_lstm.py:152:21: F821 undefined name 'is_training'\r\n        is_training=is_training)\r\n                    ^\r\n```\r\n\r\nIn the tensorflow/models repo, there is [only one caller](visit_count_fc) of the function __visit_count_fc()__ and that caller passes 6 parameters and the last one is called __is_training__.\r\n\r\nThe proposed fix is to add __is_training__ as the sixth parameter of __visit_count_fc()__ to match both the caller and the internals of the function and thereby eliminate the undefined name.",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2018-01-30T10:45:19Z",
        "closed_at": "2019-11-24T23:44:11Z",
        "merged_at": null,
        "body": "Current code in create_kitti_tf_record.py requires input files to have names in a form of 000123.txt with continuous numeration. It is easy to leverage this restriction and have more semantically meaningful code.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-01-30T09:43:50Z",
        "closed_at": "2018-02-24T17:32:49Z",
        "merged_at": "2018-02-24T17:32:49Z",
        "body": "__rgb_resnet_v2_50_path__ is defined on line 28.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-01-30T09:23:17Z",
        "closed_at": "2018-02-06T01:26:55Z",
        "merged_at": "2018-02-06T01:26:55Z",
        "body": "flake8 testing of https://github.com/tensorflow/models on Python 3.6.4\r\n\r\n$ __flake8 . --count --select=E901,E999,F821,F822,F823 --show-source --statistics__\r\n```\r\n../research/tcn/data_providers.py:168:37: F821 undefined name 'v'\r\n  seq_len = tf.shape(sequence_parse[v])[0]\r\n                                    ^\r\n```\r\n\r\nThe issue here is that variable scoping is more restrictive in Python 3 than it is in Python 2.  Variables created inside a list comprehension are not visible outside of that comprehension as can be seen in this simplification:\r\n```\r\n>>> my_word = 'TensorFlow'\r\n>>> letters = [letter for letter in my_word]\r\n>>> print(my_word[-1])  # --> 'w' in both Python 2 and Python 3\r\n>>> print(letters[-1])  # --> 'w' in both Python 2 and Python 3\r\n>>> print(letter)       # --> 'w' in Python2 and NameError in Python 3\r\n```\r\n\r\nThe fix proposed here is a _literal translation_ of the current Python 2 functionality: __v__ is the last item of __view_names__.  This appears to be a safe change given the assertion on the line just above that all __view_names__ must have the same shape.\r\n\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-01-30T08:53:35Z",
        "closed_at": "2019-11-24T23:44:11Z",
        "merged_at": null,
        "body": "Here is a patch to deal with missing DEFINE_list #3239 ",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-01-29T18:51:05Z",
        "closed_at": "2018-02-03T15:34:49Z",
        "merged_at": null,
        "body": "Possible solution to problem described in https://github.com/tensorflow/models/issues/2861",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 3716,
        "deletions": 0,
        "changed_files": 37,
        "created_at": "2018-01-29T18:09:42Z",
        "closed_at": "2018-02-01T16:11:14Z",
        "merged_at": null,
        "body": "Adds the subdirectory research/capsules which contains the capsNet code for \"Dynamic Routing Between Capsules\" paper. ",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 142,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-01-27T17:49:23Z",
        "closed_at": "2018-03-18T15:36:04Z",
        "merged_at": null,
        "body": "A Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\r\nThis example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\r\nLinks:\r\n    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\r\n    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\r\n\r\nTraining and evaluation log:\r\nExtracting /tmp/mnist_data/train-images-idx3-ubyte.gz\r\nExtracting /tmp/mnist_data/train-labels-idx1-ubyte.gz\r\nExtracting /tmp/mnist_data/t10k-images-idx3-ubyte.gz\r\nExtracting /tmp/mnist_data/t10k-labels-idx1-ubyte.gz\r\nStep 1, Minibatch Loss= 2.5586, Training Accuracy= 0.258\r\nStep 200, Minibatch Loss= 0.2419, Training Accuracy= 0.930\r\nStep 400, Minibatch Loss= 0.1863, Training Accuracy= 0.938\r\nStep 600, Minibatch Loss= 0.1000, Training Accuracy= 0.969\r\nStep 800, Minibatch Loss= 0.0935, Training Accuracy= 0.977\r\nStep 1000, Minibatch Loss= 0.0773, Training Accuracy= 0.969\r\nStep 1200, Minibatch Loss= 0.0500, Training Accuracy= 0.984\r\nStep 1400, Minibatch Loss= 0.0550, Training Accuracy= 0.977\r\nStep 1600, Minibatch Loss= 0.0615, Training Accuracy= 0.984\r\nStep 1800, Minibatch Loss= 0.0635, Training Accuracy= 0.977\r\nStep 2000, Minibatch Loss= 0.0550, Training Accuracy= 0.992\r\nTraining Finished!\r\nTesting Accuracy: 0.992188",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-01-27T17:47:58Z",
        "closed_at": "2019-11-24T23:44:10Z",
        "merged_at": null,
        "body": "Corrected \"Sentosa\" to \"Setosa\"",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2018-01-27T13:57:48Z",
        "closed_at": "2018-03-12T03:29:32Z",
        "merged_at": "2018-03-12T03:29:32Z",
        "body": "Fix a typo. Change to a pythonic function name",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 9,
        "changed_files": 3,
        "created_at": "2018-01-26T23:35:02Z",
        "closed_at": "2018-01-30T03:34:33Z",
        "merged_at": "2018-01-30T03:34:33Z",
        "body": "Resolves the following five undefined names:\r\n\r\nflake8 testing of https://github.com/tensorflow/models on Python 2.7.14\r\n\r\n$ flake8 . --count --select=E901,E999,F821,F822,F823 --show-source --statistics\r\n```\r\n./research/cognitive_mapping_and_planning/src/depth_utils.py:26:19: F821 undefined name 'utils'\r\n  camera_matrix = utils.Foo(xc=xc, zc=zc, f=f)\r\n                  ^\r\n./research/cognitive_mapping_and_planning/src/file_utils.py:37:14: F821 undefined name 'file_name'\r\n  with fopen(file_name, 'r') as f:\r\n             ^\r\n./research/cognitive_mapping_and_planning/src/graph_utils.py:469:14: F821 undefined name 'get_path_ids'\r\n      path = get_path_ids(start_node_ids[i], end_node_ids[i], pred_map)\r\n             ^\r\n./research/cognitive_mapping_and_planning/src/graph_utils.py:518:14: F821 undefined name 'get_path_ids'\r\n      path = get_path_ids(start_node_ids[i], end_node_ids[i], pred_map)\r\n             ^\r\n./research/cognitive_mapping_and_planning/src/graph_utils.py:548:14: F821 undefined name 'get_path_ids'\r\n      path = get_path_ids(start_node_ids[i], end_node_ids[i], pred_map)\r\n             ^\r\n```\r\n\r\n@nealwu @s-gupta Your thoughts?",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2018-01-26T19:41:20Z",
        "closed_at": "2018-01-26T23:17:04Z",
        "merged_at": "2018-01-26T23:17:04Z",
        "body": "As per new release strategy.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2018-01-25T17:51:33Z",
        "closed_at": "2018-02-02T17:22:29Z",
        "merged_at": null,
        "body": "This PR should break tests. Do not merge, do not review.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-01-25T17:28:18Z",
        "closed_at": "2018-01-26T23:13:11Z",
        "merged_at": "2018-01-26T23:13:11Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 112,
        "deletions": 1,
        "changed_files": 4,
        "created_at": "2018-01-25T17:11:18Z",
        "closed_at": "2018-03-16T22:27:34Z",
        "merged_at": null,
        "body": "Add implementation for mobilenet v2 and add to available options in [ TensorFlow-Slim image classification model library](https://github.com/tensorflow/models/tree/master/research/slim).\r\n\r\nThe model was tested on Cifar10 and achieved accuracy 0.9315 after 15 hours of training on 2 GPUs.\r\n\r\nAlso available here: https://github.com/ohadlights/mobilenetv2\r\n\r\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 24,
        "deletions": 7,
        "changed_files": 2,
        "created_at": "2018-01-24T08:02:44Z",
        "closed_at": "2018-06-25T10:36:17Z",
        "merged_at": null,
        "body": "The following files contain calls to __unicode()__ which was removed in Python 3 because all str are Unicode with a default encoding of 'utf-8':\r\n* ./research/neural_programmer/wiki_data.py - 1 instance of __unicode()__\r\n* ./research/syntaxnet/dragnn/python/visualization.py - 1 instance of __unicode()__\r\n* ./research/syntaxnet/dragnn/python/render_parse_tree_graphviz.py - 5 instances of __unicode()__\r\n\r\nThis PR proposed a fix for __render_parse_tree_graphviz.py__ but leaves the two other files untouched because I was not confident in my solutions.  Fixing them is a TODO for Python 3 compatibility.\r\n\r\n$ __python3 -m flake8 --count --select=E901,E999,F821,F822,F823 --show-source --statistics__\r\n```\r\n./research/neural_programmer/wiki_data.py:40:7: F821 undefined name 'unicode'\r\n  u = unicode(s, \"utf-8\")\r\n      ^\r\n./research/syntaxnet/dragnn/python/render_parse_tree_graphviz.py:56:9: F821 undefined name 'unicode'\r\n  svg = unicode(svg, \"utf-8\")\r\n        ^\r\n./research/syntaxnet/dragnn/python/visualization.py:73:11: F821 undefined name 'unicode'\r\n          unicode(step_trace.caption, 'utf-8')\r\n          ^\r\n./research/syntaxnet/dragnn/python/visualization.py:140:10: F821 undefined name 'unicode'\r\n  return unicode(as_str, 'utf-8') if convert_to_unicode else as_str\r\n         ^\r\n./research/syntaxnet/dragnn/python/visualization.py:161:23: F821 undefined name 'unicode'\r\n  if isinstance(html, unicode):\r\n                      ^\r\n./research/syntaxnet/dragnn/python/visualization.py:219:12: F821 undefined name 'unicode'\r\n    return unicode(html, 'utf-8')  # IPython expects unicode.\r\n           ^\r\n./research/syntaxnet/dragnn/python/visualization.py:242:12: F821 undefined name 'unicode'\r\n    return unicode(html, 'utf-8')  # IPython expects unicode.\r\n           ^\r\n```",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-01-24T02:59:27Z",
        "closed_at": "2018-01-26T03:01:11Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-01-24T01:41:08Z",
        "closed_at": "2018-01-24T02:52:26Z",
        "merged_at": "2018-01-24T02:52:26Z",
        "body": "In Python 2 the string and the r-string behave the same:\r\n$ __python2__\r\n```\r\n>>> '$\\Uparrow$ '\r\n'$\\\\Uparrow$ '\r\n>>> r'$\\Uparrow$ '\r\n'$\\\\Uparrow$ '\r\n>>> '$\\Uparrow$ ' == r'$\\Uparrow$ '\r\nTrue\r\n```\r\n\r\nIn Python 3 the string raises a Syntax Error while the r-string works just like Python 2.\r\n$ __python3__\r\n```\r\n>>> '$\\Uparrow$ '\r\n  File \"<stdin>\", line 1\r\nSyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 1-2: truncated \\UXXXXXXXX escape\r\n>>> r'$\\Uparrow$ '\r\n'$\\\\Uparrow$ '\r\n```",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 3,
        "created_at": "2018-01-24T01:11:25Z",
        "closed_at": "2018-01-24T02:28:38Z",
        "merged_at": "2018-01-24T02:28:38Z",
        "body": "@nealwu The general advise is http://python-future.org/compatible_idioms.html#file but my sense is that just replacing __file()__ with __open()__ is OK for these use cases.  Your thoughts?",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-01-24T00:51:03Z",
        "closed_at": "2018-01-24T18:04:10Z",
        "merged_at": "2018-01-24T18:04:10Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-01-23T19:36:57Z",
        "closed_at": "2018-01-24T00:55:26Z",
        "merged_at": "2018-01-24T00:55:25Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 12,
        "changed_files": 4,
        "created_at": "2018-01-23T18:20:40Z",
        "closed_at": "2018-01-29T21:37:30Z",
        "merged_at": "2018-01-29T21:37:30Z",
        "body": "The `sparse` version is more efficient anyway.\r\n\r\nI'm returning the labels shape [1] instead of []\r\nbecause tf.accuracy fails otherwise.\r\n\r\nmnist_test.py passes.\r\nI manually ran both `mnist.py` and `mnist_tpu.py` with a reduced dataset to confirm they haven't broken .",
        "comments": 12
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 6,
        "changed_files": 4,
        "created_at": "2018-01-22T23:18:59Z",
        "closed_at": "2018-01-23T20:26:04Z",
        "merged_at": "2018-01-23T20:26:04Z",
        "body": "__long__ was [removed](https://docs.python.org/3/whatsnew/3.0.html#integers) from Python 3 in favor of __int__.\r\n\r\n@nealwu Like we did for __xrange()__ in #3206 but this time for the builtin type __long__.\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-01-22T18:26:21Z",
        "closed_at": "2019-11-24T23:44:10Z",
        "merged_at": null,
        "body": "This fixes the bug described in https://github.com/tensorflow/models/issues/2774",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 518,
        "deletions": 455,
        "changed_files": 5,
        "created_at": "2018-01-22T17:02:12Z",
        "closed_at": "2018-02-02T02:46:01Z",
        "merged_at": "2018-02-02T02:46:01Z",
        "body": "I started trying to add multi-GPU mode to Resnet, but I realized I couldn't do that cleanly without refactoring some of the Cifar10/Imagenet code. But I couldn't really refactor cleanly knowing that the conversion to class-based models was coming, so I attempted to refactor into class-based models here.\r\n\r\n### Notes\r\n\r\n* I tried not to touch data-processing, input functions, or the layer-assembly functions in this refactor, except to standardize the naming of a few variables. If you note differences... that is probably a mistake.\r\n* This is intended as a true refactor, so no functionality should have changed, though some of the function names did do to the creation of the Model class.\r\n* This appears to work with Cifar10, but Imagenet is still running as of ~2 days ago, so it will take a little while to confirm that that still converges. (See details on performance/accuracy below.)\r\n\r\n### Open questions\r\n\r\n- [ ] For the ease of review, I kept the functions in resnet_model.py and resnet_shared.py separate, but, given the length/purpose of the files, it might make sense to combine them into a single module, as in MNIST. Thoughts?\r\n- [x] One known difference that I still have to resolve: in the original Imagenet, loss was calculated over all trainable vars [EXCEPT those with 'batch_normalization' in the name](https://github.com/tensorflow/models/blob/master/official/resnet/imagenet_main.py#L189), with a comment saying this was better for accuracy. I have not yet added this in, as I'm not sure the best solution here-- some choices: (1) Remove it for both datasets; (2) add it for both datasets; (3) add a param that indicates whether batch_normalization vars should be excluded; (4) add a more flexible means of excluding arbitrary vars from the loss. Opinions as to which of these is the best path for both these particular models and overall model usability?\r\n\r\n### Appendix\r\n\r\nCifar10 trains on a single GPU to comparable accuracy as master, and in comparable time:\r\n\r\n```\r\nINFO:tensorflow:learning_rate = 1e-04, cross_entropy = 0.0043777777, train_accuracy = 0.99919873 (10.313 sec)\r\nINFO:tensorflow:loss = 0.15030411, step = 97569 (10.313 sec)\r\nINFO:tensorflow:global_step/sec: 9.71699\r\nINFO:tensorflow:learning_rate = 1e-04, cross_entropy = 0.00943729, train_accuracy = 0.99921876 (10.291 sec)\r\nINFO:tensorflow:loss = 0.15535825, step = 97669 (10.291 sec)\r\n...\r\nINFO:tensorflow:Saving dict for global step 97675: accuracy = 0.9285, global_step = 97675, loss = 0.46341026\r\n{'loss': 0.46341026, 'global_step': 97675, 'accuracy': 0.9285}\r\n```\r\n\r\nImagenet is still training on a single GPU. Current status:\r\n\r\n```\r\nINFO:tensorflow:loss = 3.966461, step = 216786 (66.835 sec)\r\nINFO:tensorflow:global_step/sec: 1.49444\r\nINFO:tensorflow:learning_rate = 0.0125, cross_entropy = 2.3299885, train_accuracy = 0.39620537 (66.915 sec)\r\n```\r\n\r\nI tested that these run on CPU, but did not wait for them to complete.",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-01-22T16:38:54Z",
        "closed_at": "2019-11-24T23:44:10Z",
        "merged_at": null,
        "body": "Since these files are autogenerated, they don't need to be show in git output. So instead of:\r\n\r\n```\r\n$git status\r\nOn branch master\r\nYour branch is up-to-date with 'origin/master'.\r\nUntracked files:\r\n  (use \"git add <file>...\" to include in what will be committed)\r\n\tresearch/object_detection/protos/anchor_generator_pb2.py\r\n\tresearch/object_detection/protos/argmax_matcher_pb2.py\r\n\tresearch/object_detection/protos/bipartite_matcher_pb2.py\r\n\tresearch/object_detection/protos/box_coder_pb2.py\r\n\tresearch/object_detection/protos/box_predictor_pb2.py\r\n\tresearch/object_detection/protos/eval_pb2.py\r\n\tresearch/object_detection/protos/faster_rcnn_box_coder_pb2.py\r\n\tresearch/object_detection/protos/faster_rcnn_pb2.py\r\n\tresearch/object_detection/protos/grid_anchor_generator_pb2.py\r\n\tresearch/object_detection/protos/hyperparams_pb2.py\r\n\tresearch/object_detection/protos/image_resizer_pb2.py\r\n\tresearch/object_detection/protos/input_reader_pb2.py\r\n\tresearch/object_detection/protos/keypoint_box_coder_pb2.py\r\n\tresearch/object_detection/protos/losses_pb2.py\r\n\tresearch/object_detection/protos/matcher_pb2.py\r\n\tresearch/object_detection/protos/mean_stddev_box_coder_pb2.py\r\n\tresearch/object_detection/protos/model_pb2.py\r\n\tresearch/object_detection/protos/optimizer_pb2.py\r\n\tresearch/object_detection/protos/pipeline_pb2.py\r\n\tresearch/object_detection/protos/post_processing_pb2.py\r\n\tresearch/object_detection/protos/preprocessor_pb2.py\r\n\tresearch/object_detection/protos/region_similarity_calculator_pb2.py\r\n\tresearch/object_detection/protos/square_box_coder_pb2.py\r\n\tresearch/object_detection/protos/ssd_anchor_generator_pb2.py\r\n\tresearch/object_detection/protos/ssd_pb2.py\r\n\tresearch/object_detection/protos/string_int_label_map_pb2.py\r\n\tresearch/object_detection/protos/train_pb2.py\r\n```\r\n\r\nthe user sees only\r\n\r\n```\r\n$git status\r\nOn branch master\r\nYour branch is up-to-date with 'origin/master'.\r\nUntracked files:\r\n  (use \"git add <file>...\" to include in what will be committed)\r\n```",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-01-21T16:20:49Z",
        "closed_at": "2018-01-23T21:36:51Z",
        "merged_at": null,
        "body": "from six.moves import integer_types",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-01-21T16:02:16Z",
        "closed_at": "2018-01-23T20:26:35Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2018-01-20T20:34:39Z",
        "closed_at": "2018-01-24T00:57:21Z",
        "merged_at": null,
        "body": "Old style exceptions were removed from Python 3 because that syntax was too ambiguous.\r\n\r\nSee: http://python-future.org/compatible_idioms.html#catching-exceptions\r\n\r\n@nealwu @panyx0718 ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 82,
        "deletions": 22,
        "changed_files": 74,
        "created_at": "2018-01-20T14:11:03Z",
        "closed_at": "2018-01-22T21:44:31Z",
        "merged_at": "2018-01-22T21:44:31Z",
        "body": "@nealwu As requested at https://github.com/tensorflow/models/issues/3103#issuecomment-356150374\r\n\r\nFor all files that use the Python 2-only builtin function __xrange()__, add the line __from six.moves import xrange__ for compatibility with Python 3.",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-01-19T17:16:22Z",
        "closed_at": "2018-01-22T22:21:42Z",
        "merged_at": "2018-01-22T22:21:42Z",
        "body": "CC @random-forests",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 95,
        "deletions": 36,
        "changed_files": 2,
        "created_at": "2018-01-19T00:49:13Z",
        "closed_at": "2018-01-22T16:40:25Z",
        "merged_at": "2018-01-22T16:40:25Z",
        "body": "Adding multi-GPU functionality to MNIST, all in the main loop now. I extracted/refactored some functions in order to keep consistent with some refactoring that will be necessary with what I do with Resnet.\r\n\r\n",
        "comments": 10
    },
    {
        "merged": false,
        "additions": 42,
        "deletions": 7,
        "changed_files": 2,
        "created_at": "2018-01-18T16:11:35Z",
        "closed_at": "2019-11-24T23:44:09Z",
        "merged_at": null,
        "body": "Add pr_curve for object detection api for issue #3081.\r\n\r\nChange few functions mentioned in issue #3081 without add new ones. Tested with the newest tensorboard.",
        "comments": 30
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2018-01-18T09:37:41Z",
        "closed_at": "2018-01-18T19:25:23Z",
        "merged_at": "2018-01-18T19:25:23Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1557,
        "deletions": 137,
        "changed_files": 17,
        "created_at": "2018-01-18T06:01:14Z",
        "closed_at": "2018-01-18T15:33:29Z",
        "merged_at": null,
        "body": "",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-01-17T23:58:50Z",
        "closed_at": "2019-11-24T23:44:09Z",
        "merged_at": null,
        "body": "Fixed what was probably a type:\r\n`show_groundtruth` now uses `ignore_groundtruth` instead of unrelated `visualization_export_dir`.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-01-17T14:36:59Z",
        "closed_at": "2018-01-17T15:59:10Z",
        "merged_at": "2018-01-17T15:59:10Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-01-17T09:30:06Z",
        "closed_at": "2019-11-24T23:43:26Z",
        "merged_at": null,
        "body": "Ref: [Distributed Training on the Oxford-IIIT Pets Dataset on Google Cloud](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_pets.md)\r\n\r\n---\r\n\r\nThe names of the datasets should be:\r\n- `pet_train.record`\r\n- `pet_val.record`\r\n\r\nBut, the script outputs the datasets with the names of:\r\n- `pet_train_with_masks.record`\r\n- `pet_val_with_masks.record`\r\n\r\nDefault value for `faces_only` is `True`.\r\n\r\n- [research/object_detection/dataset_tools/create_pet_tf_record.py#L49](https://github.com/tensorflow/models/blob/master/research/object_detection/dataset_tools/create_pet_tf_record.py#L49)\r\n\r\n---\r\n\r\n*NOTE: I am not a \ud83d\udcaf sure about this change as I started just 2 days using this repository.*",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 154,
        "deletions": 45,
        "changed_files": 2,
        "created_at": "2018-01-17T04:21:19Z",
        "closed_at": "2018-01-18T22:16:39Z",
        "merged_at": null,
        "body": "Allow MNIST to run on multiple GPUs.\r\n\r\n* Adds a script that runs MNIST in multi-GPU mode using `replicate_model_fn`, currently in contrib. \r\n* To facilitate running with multiple GPUs, minimally refactors the existing MNIST script.\r\n\r\nCC @petermattson , @isaprykin ",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 342,
        "deletions": 40,
        "changed_files": 4,
        "created_at": "2018-01-16T23:30:01Z",
        "closed_at": "2019-11-24T23:43:26Z",
        "merged_at": null,
        "body": "",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 894,
        "deletions": 2,
        "changed_files": 7,
        "created_at": "2018-01-14T13:03:40Z",
        "closed_at": "2019-11-24T23:43:25Z",
        "merged_at": null,
        "body": "This is a partially complete work of the YOLO object detection model. Since the YOLO model does not fit neatly into the meta architecture / feature extractor format, we have done our best to follow the same - the actual model, has been implemented as yolov1_feature_extractor.py and the preprocessing, postprocessing and loss functions have been implemented as yolov1_meta_arch.py. All of our implementation is based off the origin paper by Joseph Redmon.\r\n\r\nWe have not implemented the pipeline that allows to train this model hence, we are opening this pull request so that others who have better knowledge about the same can add on to our work and complete the same.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 182,
        "deletions": 96,
        "changed_files": 7,
        "created_at": "2018-01-13T18:57:13Z",
        "closed_at": "2018-01-16T18:15:25Z",
        "merged_at": "2018-01-16T18:15:25Z",
        "body": "This pull request introduces some minor updates to the pcl_rl directory.  The directory now more closely matches the techniques for training Trust-PCL (off-policy) as discussed in the most recent version of the Trust-PCL paper.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2559,
        "deletions": 0,
        "changed_files": 24,
        "created_at": "2018-01-13T02:36:31Z",
        "closed_at": "2018-01-16T19:53:03Z",
        "merged_at": "2018-01-16T19:53:03Z",
        "body": "FYI @mhyttsten ",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 955,
        "deletions": 0,
        "changed_files": 8,
        "created_at": "2018-01-12T18:34:15Z",
        "closed_at": "2019-01-18T05:35:56Z",
        "merged_at": null,
        "body": "Hi Asim, can you review the PTB model? I followed the object-oriented style, tests and benchmarks from the MNIST model. \r\n\r\nThanks!",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 60,
        "deletions": 58,
        "changed_files": 1,
        "created_at": "2018-01-12T17:47:17Z",
        "closed_at": "2018-01-29T23:16:01Z",
        "merged_at": "2018-01-29T23:16:01Z",
        "body": "I put the data augmentation into a name_scope named data_augmentation so the tensorboard graph is easier to read and more meaningful. Before this change, the graph is all data augmentation and a long string of conditionals for IsVariableInitialized. The convs and layers are all on the right side as separate blocks. This small change makes the graph much better and easier to read.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-01-12T09:15:57Z",
        "closed_at": "2019-10-31T08:43:55Z",
        "merged_at": null,
        "body": "In the `get_class_name_from_filename` function, give a readable error when the regex failed to match the filename.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-01-12T07:05:23Z",
        "closed_at": "2018-01-13T03:12:49Z",
        "merged_at": "2018-01-13T03:12:49Z",
        "body": "Opening gzipped datasets in binary, read-only mode fixes the issue",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-01-11T02:22:59Z",
        "closed_at": "2019-11-24T23:43:25Z",
        "merged_at": null,
        "body": "Since the functionality to use floating point indices was deprecated in numpy>1.11.0, a TypeError \"'numpy.float64' object cannot be interpreted as an index\" may occur when calling `add_cdf_image_summary` function. It happens when using numpy>=1.12.0, where `height` and `width` can be floating point numbers which makes `np.reshape` to fail. Forcing `height` and `width` to be integer can make the code more robust.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-01-10T18:53:39Z",
        "closed_at": "2018-01-24T18:53:14Z",
        "merged_at": "2018-01-24T18:53:14Z",
        "body": "@shlens ",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-01-10T17:17:54Z",
        "closed_at": "2018-01-16T18:15:46Z",
        "merged_at": "2018-01-16T18:15:46Z",
        "body": "Added an 'env' parameter to env_step function since one an unreferenced one is used in the function.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-01-09T21:31:54Z",
        "closed_at": "2018-01-11T02:38:04Z",
        "merged_at": "2018-01-11T02:38:04Z",
        "body": "Re-opening this, as I would like to see PRs for official, and other solutions don't seem to do what I want. \r\n\r\ncc @nealwu @k-w-w ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-01-08T08:44:21Z",
        "closed_at": "2018-01-09T17:39:59Z",
        "merged_at": "2018-01-09T17:39:59Z",
        "body": "Here's the error I got before making this fix:\r\n\r\n```\r\nTensorFlow version: 1.5.0-rc0\r\nTraceback (most recent call last):\r\n  File \"/Users/timmolter/workspaces/workspace_tf/models/samples/outreach/blogs/blog_estimators_dataset.py\", line 86, in <module>\r\n    next_batch = my_input_fn(FILE_TRAIN, True)  # Will return 32 random elements\r\n  File \"/Users/timmolter/workspaces/workspace_tf/models/samples/outreach/blogs/blog_estimators_dataset.py\", line 76, in my_input_fn\r\n    .map(decode_csv))  # Transform each elem by applying decode_csv fn\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 780, in map\r\n    return MapDataset(self, map_func)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1583, in __init__\r\n    self._map_func.add_to_graph(ops.get_default_graph())\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/function.py\", line 486, in add_to_graph\r\n    self._create_definition_if_needed()\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/function.py\", line 321, in _create_definition_if_needed\r\n    self._create_definition_if_needed_impl()\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/function.py\", line 338, in _create_definition_if_needed_impl\r\n    outputs = self._func(*inputs)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1571, in tf_map_func\r\n    ret, [t.get_shape() for t in nest.flatten(ret)])\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1571, in <listcomp>\r\n    ret, [t.get_shape() for t in nest.flatten(ret)])\r\nAttributeError: 'list' object has no attribute 'get_shape'\r\n```",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-01-07T21:41:36Z",
        "closed_at": "2019-10-28T18:34:18Z",
        "merged_at": null,
        "body": "Let's not create a `raw_data` variable just for sake of creating an extra variable.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-01-07T06:39:36Z",
        "closed_at": "2019-10-28T18:34:17Z",
        "merged_at": null,
        "body": "The parameter `second_stage_batch_size` is required in configuration files but is missing.\r\nA Value error is being raised as a result of which.\r\nFixes #2668\r\nThanks to @mattryles for the solution.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 142,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2018-01-06T01:47:58Z",
        "closed_at": "2018-01-10T20:34:38Z",
        "merged_at": "2018-01-10T20:34:38Z",
        "body": "This is a step towards merging the example in\r\nhttps://github.com/tensorflow/tpu-demos/tree/master/cloud_tpu/models/mnist\r\nwith this repository, so we have a single model definition for\r\ntraining across CPU/GPU/eager execution/TPU.\r\n\r\nThe change to dataset.py is so that the raw data can be read\r\nfrom cloud storage systems (like GCS and S3).",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-01-05T09:19:23Z",
        "closed_at": "2018-01-30T18:08:44Z",
        "merged_at": "2018-01-30T18:08:44Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-01-04T15:45:15Z",
        "closed_at": "2019-10-28T18:34:17Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-01-04T11:57:39Z",
        "closed_at": "2018-01-10T21:04:57Z",
        "merged_at": "2018-01-10T21:04:57Z",
        "body": "According to issues [#2861](https://github.com/tensorflow/models/issues/2861) and [#3053](https://github.com/tensorflow/models/issues/3053) , the call to `freeze_graph_with_def_protos` method in `exporter.py` breaks on line [71](https://github.com/tensorflow/models/blob/master/research/object_detection/exporter.py#L71) because of wrong parameter variable mentioned. Current tensorflow version has the corresponding variable called - `layout_optimizer`. Made the corresponding change in exporter.py",
        "comments": 9
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-01-04T11:52:56Z",
        "closed_at": "2019-10-28T18:34:16Z",
        "merged_at": null,
        "body": "fix issue:Evaluation in Object Detection hanging #2225",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2018-01-04T10:51:00Z",
        "closed_at": "2019-10-28T18:34:16Z",
        "merged_at": null,
        "body": "fix issue: Evaluation in Object Detection hanging #2225",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 669,
        "deletions": 570,
        "changed_files": 5,
        "created_at": "2018-01-03T14:34:03Z",
        "closed_at": "2018-02-07T10:25:53Z",
        "merged_at": null,
        "body": "At the moment the IoU Threshold used for the evaluation is fixed to 0.5. This pull requests adds another parameter to the EvalConfig and uses it in the constructor of the evaluation metric. \r\nThis allows different IoU thresholds for the evaluation without changing the object_detection code.",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2018-01-03T12:00:39Z",
        "closed_at": "2018-01-10T22:46:50Z",
        "merged_at": "2018-01-10T22:46:50Z",
        "body": "Update README.md compile instructions.\r\n\r\nFix from [adding_an_op](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/extend/adding_an_op.md).\r\n\r\nTested: compiled using the modified instructions and ran `python word2vec_optimized_test.py`.\r\n\r\nFixes tensorflow/tensorflow#14620",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2018-01-03T06:16:31Z",
        "closed_at": "2019-10-28T18:34:16Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-01-03T06:15:03Z",
        "closed_at": "2018-01-03T12:18:08Z",
        "merged_at": "2018-01-03T12:18:08Z",
        "body": "Fix AudioSet url",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 118,
        "deletions": 17,
        "changed_files": 2,
        "created_at": "2018-01-02T22:04:45Z",
        "closed_at": "2018-01-03T01:31:51Z",
        "merged_at": "2018-01-03T01:31:50Z",
        "body": "- Prior to this change, the use of tf.data.Dataset essentially embedded\r\n  the entire training/evaluation dataset into the graph as a constant,\r\n  leading to unnecessarily humungous graphs (Fixes #3017)\r\n- Also, use batching on the evaluation dataset to allow\r\n  evaluation on GPUs that cannot fit the entire evaluation dataset in\r\n  memory (Fixes #3046)\r\n\r\nUsing FixedLengthRecordDataset also provides an opportunity to use the same input pipeline code for the TPU demos (https://github.com/tensorflow/tpu-demos/tree/42a987e/cloud_tpu/models/mnist) without having to convert the raw data to TFRecords.",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2018-01-01T19:12:35Z",
        "closed_at": "2018-01-18T16:43:57Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-12-30T19:06:06Z",
        "closed_at": "2017-12-30T23:31:53Z",
        "merged_at": "2017-12-30T23:31:53Z",
        "body": "Fix typo: \"the most is mostly converged\" vs \"the model is mostly converged\"",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1158,
        "deletions": 0,
        "changed_files": 5,
        "created_at": "2017-12-29T14:57:19Z",
        "closed_at": "2018-02-06T08:08:35Z",
        "merged_at": null,
        "body": "Tetris AI trained using the deepQ algorithm.\r\nContains model code and training code.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-12-29T03:44:13Z",
        "closed_at": "2018-01-19T22:30:50Z",
        "merged_at": "2018-01-19T22:30:50Z",
        "body": "as far as i can tell this is a python2/3 thing",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-12-28T19:39:28Z",
        "closed_at": "2019-10-28T18:34:15Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-12-27T18:04:14Z",
        "closed_at": "2018-01-19T22:32:36Z",
        "merged_at": "2018-01-19T22:32:36Z",
        "body": "Because its nearly 2018 :)",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2017-12-27T00:44:22Z",
        "closed_at": "2018-01-19T22:33:52Z",
        "merged_at": "2018-01-19T22:33:52Z",
        "body": "Updates path to img2txt\r\nMentions specific nltk data package to download\r\nadds unzip as a requirement ",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2017-12-26T23:24:20Z",
        "closed_at": "2017-12-27T00:41:50Z",
        "merged_at": null,
        "body": "The current readme refers to a directory tensorflow-models which is not in the current directory structure ",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-12-26T18:37:26Z",
        "closed_at": "2019-10-28T18:34:15Z",
        "merged_at": null,
        "body": "it is easy to make mistakes in protobuf config and therefore mistakenly think, that augmentation was used but acutally was never applied to training. Logging will prevent this mistake more easily. \r\n\r\nRoot cause:\r\nIn protobuf config, data_augmentation_options can only contain one option per item, but if more, only last one silently applied, all others are ignored.",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-12-25T09:50:22Z",
        "closed_at": "2018-01-22T17:27:41Z",
        "merged_at": "2018-01-22T17:27:41Z",
        "body": "Fix issue #3055 ",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-12-21T17:09:53Z",
        "closed_at": "2018-01-23T21:37:47Z",
        "merged_at": null,
        "body": "__long__ was removed from Python 3",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 23,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2017-12-21T10:01:42Z",
        "closed_at": "2019-10-28T18:34:15Z",
        "merged_at": null,
        "body": "Squeeze Operation is not supported yet in the TFLite.\r\nThis patch replaces the squeeze operation to a Reshape operation.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-12-21T02:40:00Z",
        "closed_at": "2017-12-21T19:52:27Z",
        "merged_at": "2017-12-21T19:52:26Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-12-21T02:37:27Z",
        "closed_at": "2017-12-21T19:53:44Z",
        "merged_at": "2017-12-21T19:53:44Z",
        "body": "(specifically for multi-GPU)",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-12-20T01:16:38Z",
        "closed_at": "2017-12-22T05:16:35Z",
        "merged_at": "2017-12-22T05:16:35Z",
        "body": "Make sure it's compatible with tensorflow latest version 1.4.1.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2017-12-19T23:57:15Z",
        "closed_at": "2017-12-20T13:28:36Z",
        "merged_at": "2017-12-20T13:28:36Z",
        "body": "Added correct link to blogpost\r\nChanged Sentosa to Setosa in a couple of places",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 189,
        "deletions": 143,
        "changed_files": 3,
        "created_at": "2017-12-19T01:15:43Z",
        "closed_at": "2017-12-21T00:34:24Z",
        "merged_at": "2017-12-21T00:34:24Z",
        "body": "- Use the object-oriented tf.layers API instead of the functional one.\r\n  The object-oriented API is particularly useful when using the model\r\n  with eager execution.\r\n- Update unittest to train, evaluate, and predict using the model.\r\n- Add a micro-benchmark for measuring step-time.\r\n  The parameters (batch_size, num_steps etc.) have NOT been tuned,\r\n  the purpose with this code is mostly to illustrate how model\r\n  benchmarks may be written.\r\n\r\nThese changes are made as a step towards consolidating model definitions\r\nfor different TensorFlow features (like eager execution and support for\r\nTPUs in\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples/mnist\r\nand\r\nhttps://github.com/tensorflow/tpu-demos/tree/master/cloud_tpu/models/mnist)\r\n\r\nCC @martinwicke @jhseu @ispirmustafa ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 241,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-12-18T23:36:59Z",
        "closed_at": "2017-12-19T15:54:44Z",
        "merged_at": "2017-12-19T15:54:44Z",
        "body": "New example file for a new blogpost",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 340,
        "deletions": 23,
        "changed_files": 2,
        "created_at": "2017-12-17T21:13:21Z",
        "closed_at": "2019-10-28T18:34:14Z",
        "merged_at": null,
        "body": "To answer issue #2771 ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 43,
        "deletions": 43,
        "changed_files": 1,
        "created_at": "2017-12-16T02:00:46Z",
        "closed_at": "2017-12-18T19:05:44Z",
        "merged_at": "2017-12-18T19:05:44Z",
        "body": "See https://help.github.com/articles/about-codeowners/ for details on CODEOWNERS syntax.\r\n\r\nIn particular we should change from this pattern:\r\n```\r\n# The `docs/*` pattern will match files like\r\n# `docs/getting-started.md` but not further nested files like\r\n# `docs/build-app/troubleshooting.md`.\r\ndocs/*  docs@example.com\r\n\r\n# In this example, @octocat owns any file in an apps directory\r\n# anywhere in your repository.\r\napps/ @octocat\r\n```\r\n\r\nto this pattern:\r\n```\r\n# In this example, @doctocat owns any files in the build/logs\r\n# directory at the root of the repository and any of its\r\n# subdirectories.\r\n/build/logs/ @doctocat\r\n```\r\n\r\nThe first pattern will only produce a match when a top-level file within a folder is modified, which is not the case for most pull requests, meaning that most PRs will not receive a reviewer.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-12-15T20:45:18Z",
        "closed_at": "2017-12-15T22:04:12Z",
        "merged_at": null,
        "body": "cc @nealwu @k-w-w ",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 278,
        "deletions": 0,
        "changed_files": 4,
        "created_at": "2017-12-14T21:07:44Z",
        "closed_at": "2019-10-28T18:34:14Z",
        "merged_at": null,
        "body": "Added a Keras Resnet model that works with tf.Dataset\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-12-14T14:40:29Z",
        "closed_at": "2017-12-14T18:34:19Z",
        "merged_at": "2017-12-14T18:34:19Z",
        "body": "`eval_training_data` flag seems no effect.\r\nSince no code handles `eval_training_data` flag, `input_config = configs['eval_input_config']` will be always executed, even though \u2018eval_training_data\u2019 is set to `Ture`.\r\nWhen \u2018eval_training_data\u2019 is set to `Ture`, `input_config` should be `configs['train_input_config']`.\r\nI fix the bug in pull request.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 8,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2017-12-14T11:43:33Z",
        "closed_at": "2019-10-28T18:34:13Z",
        "merged_at": null,
        "body": "1. add a flag so we can choose if go with fast preprocessing or aggressive preprocessing\r\n2. update .gitignore. so the python file generate from proto file will be ignored by git.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-12-14T01:58:44Z",
        "closed_at": "2017-12-14T18:53:36Z",
        "merged_at": "2017-12-14T18:53:36Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-12-13T06:50:10Z",
        "closed_at": "2019-01-03T14:43:29Z",
        "merged_at": null,
        "body": "I found a typo in the comment in lenet.py \r\n\r\nFrom:\r\n    def lent(..)\r\n    \"\"\r\n    ...\r\n        Returns: \r\n            ... , or the inon-dropped-out nput  ...   \r\n    \"\"\r\nTo:\r\n    def lent(..)\r\n    \"\"\r\n    ...\r\n        Returns: \r\n            ... , or the non-dropped-out input  ...   \r\n    \"\"\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2017-12-12T21:36:49Z",
        "closed_at": "2019-10-28T18:34:13Z",
        "merged_at": null,
        "body": "We can use `tf.summary.text` since [TensorFlow 1.2.0](https://github.com/tensorflow/tensorflow/releases/tag/v1.2.0), \r\n\r\nI found this text very useful during training, so it may help others too.\r\n\r\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-12-11T13:57:42Z",
        "closed_at": "2019-10-28T18:34:13Z",
        "merged_at": null,
        "body": "I spent a lot of time looking for a fix for -\r\n`fatal error: external/nccl_archive/src/nccl.h: No such file or directory `\r\n\r\nDocumenting the installation of `nvcc` saves a lot of set-up time for beginners.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-12-08T14:25:54Z",
        "closed_at": "2017-12-11T18:29:32Z",
        "merged_at": "2017-12-11T18:29:32Z",
        "body": "",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 61,
        "deletions": 185,
        "changed_files": 3,
        "created_at": "2017-12-08T01:56:59Z",
        "closed_at": "2017-12-11T21:32:47Z",
        "merged_at": "2017-12-11T21:32:47Z",
        "body": "- Remove `convert_to_records.py` and instead create `tf.data.Dataset`\r\n  objects directly from the numpy arrays.\r\n- Format the Google Python Style (https://github.com/google/yapf/)",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 500,
        "deletions": 273,
        "changed_files": 45,
        "created_at": "2017-12-07T19:12:22Z",
        "closed_at": "2018-01-05T03:24:23Z",
        "merged_at": null,
        "body": "Before the fix the demo_inference.py used batch_norm and it did the normalization of input image implicitly. If at the inference time the batch_norm was disabled the inference produced incorrect results.\r\n\r\nThis fix:\r\n1. does the proper input image normalization and disables the batch_norm at inference time. \r\n2. introduces demo_inference_test.py to make sure the demo_inference works correctly\r\n3. numerous auto formatting changes.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-12-07T16:05:53Z",
        "closed_at": "2019-10-28T18:34:12Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2017-12-07T12:25:52Z",
        "closed_at": "2019-10-28T18:34:12Z",
        "merged_at": null,
        "body": "For python users using virtualenv or pyenv to use their own python this causes unexpected error.\r\n\r\nUsing python set by environment variable would fix ",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 50,
        "deletions": 1,
        "changed_files": 5,
        "created_at": "2017-12-06T08:54:20Z",
        "closed_at": "2017-12-18T21:47:43Z",
        "merged_at": "2017-12-18T21:47:43Z",
        "body": "Allow users to export this model in TF's SavedModel format. ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-12-06T02:38:10Z",
        "closed_at": "2017-12-16T00:18:25Z",
        "merged_at": "2017-12-16T00:18:25Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 633,
        "deletions": 0,
        "changed_files": 4,
        "created_at": "2017-12-06T02:06:35Z",
        "closed_at": "2017-12-06T05:03:36Z",
        "merged_at": "2017-12-06T05:03:36Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2017-12-05T23:26:27Z",
        "closed_at": "2018-01-03T17:07:49Z",
        "merged_at": "2018-01-03T17:07:49Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-12-05T08:47:51Z",
        "closed_at": "2019-10-28T18:34:12Z",
        "merged_at": null,
        "body": "add mobilenet_v1_075 mobilenet_v1_050 mobilenet_v1_025 in slim preprocessing_factory",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 996,
        "deletions": 7,
        "changed_files": 9,
        "created_at": "2017-12-04T16:51:55Z",
        "closed_at": "2018-01-11T12:43:17Z",
        "merged_at": null,
        "body": " to samples/core/get_started",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 121,
        "deletions": 127,
        "changed_files": 4,
        "created_at": "2017-12-04T16:05:34Z",
        "closed_at": "2017-12-11T14:50:37Z",
        "merged_at": "2017-12-11T14:50:37Z",
        "body": "Also:\r\n\r\n  * Add a minimal dataset csv parser example\r\n  * Switch to use sparse cross-entropy (to clear the warning). ",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 36,
        "deletions": 8,
        "changed_files": 2,
        "created_at": "2017-12-01T19:22:33Z",
        "closed_at": "2019-10-28T18:34:11Z",
        "merged_at": null,
        "body": "In the documentation of Cloud ML Engine, you should add an instance key in your SavedModel signature to match the output instances to the input instances of batch prediction.\r\nhttps://cloud.google.com/ml-engine/docs/prediction-overview#instance_keys\r\n\r\n[This Blog Post](https://cloud.google.com/blog/big-data/2017/09/performing-prediction-with-tensorflow-object-detection-models-on-google-cloud-machine-learning-engine) shows how to run Tensorflow object detection model batch prediction on Cloud ML Engine, but the results doesn't have instance keys.\r\n\r\nThis pull-request add the option `--instance_key_type` to `object_detection/export_inference_graph.py` to add instance key in SavedModel signatures. It's optional. The default behavior is not changed.\r\nYou can choose type of instance key from `int32`, `int64`, `string`.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-12-01T13:02:05Z",
        "closed_at": "2017-12-11T18:44:35Z",
        "merged_at": "2017-12-11T18:44:35Z",
        "body": "Conflicts with comment on following line, the comment is correct.",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 0,
        "changed_files": 0,
        "created_at": "2017-12-01T05:54:36Z",
        "closed_at": "2019-10-28T18:34:11Z",
        "merged_at": null,
        "body": "klj",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 9,
        "changed_files": 1,
        "created_at": "2017-11-30T22:37:41Z",
        "closed_at": "2019-10-28T18:34:10Z",
        "merged_at": null,
        "body": "Remove empty code cell in notebook",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 433,
        "deletions": 0,
        "changed_files": 5,
        "created_at": "2017-11-30T17:53:39Z",
        "closed_at": "2017-12-01T20:53:08Z",
        "merged_at": "2017-12-01T20:53:08Z",
        "body": "PiperOrigin-RevId: 176969064\r\n\r\nCorresponds to cl/176969064.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 28,
        "deletions": 6,
        "changed_files": 3,
        "created_at": "2017-11-30T03:39:29Z",
        "closed_at": "2017-12-21T09:36:56Z",
        "merged_at": null,
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1999,
        "deletions": 0,
        "changed_files": 15,
        "created_at": "2017-11-30T00:06:46Z",
        "closed_at": "2017-12-01T03:49:48Z",
        "merged_at": "2017-12-01T03:49:48Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-11-29T20:32:50Z",
        "closed_at": "2017-11-29T22:03:34Z",
        "merged_at": "2017-11-29T22:03:34Z",
        "body": "Fix slim script usage in image compression.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 983,
        "deletions": 74,
        "changed_files": 18,
        "created_at": "2017-11-28T16:59:04Z",
        "closed_at": "2017-11-29T00:05:52Z",
        "merged_at": "2017-11-29T00:05:52Z",
        "body": "PiperOrigin-RevId: 177165761\r\n\r\nRefresh github tensorflow_models/gan.\r\n\r\n@nealwu @shlens @sguada \r\n1) Add image compression example\r\n2) Update tests to use cleaner patch mechanism",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 26,
        "deletions": 1,
        "changed_files": 3,
        "created_at": "2017-11-27T20:20:36Z",
        "closed_at": "2019-10-28T18:34:10Z",
        "merged_at": null,
        "body": "The data loader was failing when I tried to load files containing extra whitespace in blank lines. I added trims to avoid this in the future. Let me know if there is an implementation of trim that I should be using; I added functions from stackoverflow to util (the existing ones are for tensorflow strings rather than `std::string`).\r\n\r\nI also made the relevant error message more informative, printing the line number and line.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 4,
        "changed_files": 3,
        "created_at": "2017-11-27T19:29:04Z",
        "closed_at": "2019-10-28T18:34:09Z",
        "merged_at": null,
        "body": "I had an issue running the pet tutorial having to do with the new faces_only option. I think my changes resolve the issue and give the desired behavior? Updating the tutorial to reflect the updated path the create_pet_tf_records.py file while I'm at it. ",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2017-11-27T01:38:57Z",
        "closed_at": "2017-11-28T15:53:32Z",
        "merged_at": "2017-11-28T15:53:32Z",
        "body": "@nealwu @sguada \r\n1) Fix word dir\r\n2) Fix download url\r\n\r\nCorresponds to cl/176965289.",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 6,
        "changed_files": 2,
        "created_at": "2017-11-27T01:37:03Z",
        "closed_at": "2019-10-28T18:34:09Z",
        "merged_at": null,
        "body": "Related with issue #1497 \r\n\r\nI tested with resnet_v2_152 on my local environment.\r\nI found out that document is correct and code is wrong.\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 27,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2017-11-26T04:57:09Z",
        "closed_at": "2018-02-09T18:21:48Z",
        "merged_at": "2018-02-09T18:21:48Z",
        "body": "Changes allow one to train an lfads model while only allowing modifications to the weights of the encoder. This could be useful to training a model on a certain set of conditions, and then only training the encoder on a set of held-out conditions, to see if the original generator's dynamics are capable of describing the held-out conditions.\r\n\r\nATTN: @sussillo ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 21,
        "deletions": 42,
        "changed_files": 1,
        "created_at": "2017-11-25T19:56:56Z",
        "closed_at": "2017-11-27T08:46:57Z",
        "merged_at": "2017-11-27T08:46:57Z",
        "body": "@nealwu This corresponds to cl/176659312.\r\n\r\nNote that this is the same convention as the slim tutorial's TOC. It renders properly, but doesn't actually like to sections in the jupyter notebook. ",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-11-25T19:25:59Z",
        "closed_at": "2017-11-29T00:02:39Z",
        "merged_at": "2017-11-29T00:02:39Z",
        "body": "@nealwu Change internal google addresses to public github ones.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 170066,
        "deletions": 5891,
        "changed_files": 1510,
        "created_at": "2017-11-25T16:34:37Z",
        "closed_at": "2017-11-26T04:43:25Z",
        "merged_at": null,
        "body": "Allows one to train only the encoder weights of an LFADS model\r\nUseful when testing whether learned generator dynamics generalize to held-out conditions\r\n\r\n@sussillo ",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-11-25T14:22:40Z",
        "closed_at": "2017-11-25T18:27:14Z",
        "merged_at": "2017-11-25T18:27:14Z",
        "body": "@nealwu @martinwicke  Add my github account to CODEOWNERS.\r\n\r\nNote: I think some of the entries in CODEOWNERS are `@google` email addresses and some are github accounts. It might make sense to standardize at some point.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 14,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2017-11-25T01:32:06Z",
        "closed_at": "2017-11-25T14:21:24Z",
        "merged_at": null,
        "body": "@nealwu @martinwicke Add myself to tensorflow/models/gan/* code owners.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 472,
        "deletions": 5,
        "changed_files": 8,
        "created_at": "2017-11-24T11:47:15Z",
        "closed_at": "2019-10-28T18:34:08Z",
        "merged_at": null,
        "body": "Creates TFRecord files for training and validation for any generic dataset using following command.\r\n\r\npython download_and_convert_data.py --dataset_name=generic --dataset_dir=/dataset/tensorflow/flowers/ --source_dir=/dataset/flowers/\r\n\r\nHere in this example\r\n--source_dir contains flowers dataset but any other dataset can be input.\r\n\r\nThen train for given dataset using following command.\r\n\r\npython train_image_classifier.py --train_dir=/workspace/models/generic --dataset_name=generic --dataset_split_name=train --dataset_dir=/dataset/tensorflow/flowers --model_name=inception_v3 --save_interval_secs=600 --save_summaries_secs=120 --log_every_n_steps=50 --max_number_of_steps=200\r\n\r\nFinally evaluate using following command.\r\n\r\npython eval_image_classifier.py --checkpoint_path=/workspace/models/generic --eval_dir=/workspace/models/generic --dataset_name=generic --dataset_split_name=validation --dataset_dir=/dataset/tensorflow/flowers --model_name=inception_v3\r\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 133,
        "deletions": 36,
        "changed_files": 4,
        "created_at": "2017-11-24T08:55:47Z",
        "closed_at": "2019-10-28T18:34:08Z",
        "merged_at": null,
        "body": "As described in issue #2561 it is not immediately clear for beginners on how to restore a model, so I added this functionality so that you can also continue training. Additionally, I completed the Tensorboard support, so that you can easily see the words in the embedding space in Tensorboard.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 12,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2017-11-22T23:41:09Z",
        "closed_at": "2017-12-16T00:27:10Z",
        "merged_at": null,
        "body": "The bug is causing the weights to be shared shared between layers.\r\n\r\nWithout this patch, if you train the model (--size=small) and take a look at tf.trainable_variables() after each epoch, you'll see that there is only one set of weights, even though the model has two layers. Note that the default configuration of the model will not currently run (at least it doesn't for me), you have to add --rnn_mode=basic or --rnn_mode=block to the command line (that is an independent issue).\r\n\r\nWhen the medium and large (--size=medium and --size=large) size models are trained, there *does* seem to be an independent set of weights per layer, at least in the training and validation models, and so the bug seems to be masked by the LSTM cells being wrapped with DropoutWrapper in those cases. However, I believe that there is only one set of weights in the test model (which doesn't apply DropoutWrapper), but I have not confirmed this. This bug-masking effect seems to be related to a difference between how DropoutWrapper and BasicLSTMCell (and the other LSTM cells) inherit from RNNCell -- DropoutWrapper overrides `__call__()` whereas the LSTM cells do not. I don't understand how wrapping with DropoutWrapper masks the bug. The way it currently is, the model should consistently, and incorrectly, share weights between layers. \r\n\r\nI believe that this patch makes the model use the LSTM cells and DropoutWrapper correctly, as they are used in other models, including tensorflow/models/translate/seq2seq_model.py and tensorflow/nmt, by instantiating an independent instance of the cell for each layer. *Therefore I think that this patch should be applied even though the bug is masked in model configurations that use dropout*.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 445,
        "deletions": 0,
        "changed_files": 7,
        "created_at": "2017-11-22T11:28:03Z",
        "closed_at": "2017-11-24T16:59:42Z",
        "merged_at": null,
        "body": "Creates TFRecord files for training and validation for any generic dataset using following command.\r\n\r\npython download_and_convert_data.py --dataset_name=generic --dataset_dir=/dataset/tensorflow/flowers/ --source_dir=/dataset/flowers/\r\n \r\nHere in this example  \r\n--source_dir contains flowers dataset but any other dataset can be input.\r\n\r\nThen train for given dataset using following command.\r\n\r\npython train_image_classifier.py --train_dir=/workspace/models/generic --dataset_name=generic --dataset_split_name=train --dataset_dir=/dataset/tensorflow/flowers --model_name=inception_v3 --save_interval_secs=600 --save_summaries_secs=120 --log_every_n_steps=50 --max_number_of_steps=200\r\n\r\nFinally evaluate using following command.\r\n\r\npython eval_image_classifier.py --checkpoint_path=/workspace/models/generic --eval_dir=/workspace/models/generic --dataset_name=generic --dataset_split_name=validation --dataset_dir=/dataset/tensorflow/flowers --model_name=inception_v3",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2017-11-22T02:31:34Z",
        "closed_at": "2017-11-22T05:30:46Z",
        "merged_at": "2017-11-22T05:30:46Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2017-11-22T00:13:32Z",
        "closed_at": "2018-01-26T20:06:15Z",
        "merged_at": "2018-01-26T20:06:15Z",
        "body": "graph_utils.py -- __logging__ is used on lines 454 and 512 but it is never imported.\r\n\r\nmap_utils.py -- __logging__ is used on line 144 but it is never imported.\r\n\r\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-11-22T00:05:53Z",
        "closed_at": "2018-01-26T19:57:29Z",
        "merged_at": "2018-01-26T19:57:28Z",
        "body": "np is used on line 39 but is never imported.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-11-21T22:34:04Z",
        "closed_at": "2019-10-28T18:33:50Z",
        "merged_at": null,
        "body": "Resolve #2861 exporter.py issue.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 16,
        "deletions": 14,
        "changed_files": 9,
        "created_at": "2017-11-21T22:29:14Z",
        "closed_at": "2017-11-22T09:44:48Z",
        "merged_at": "2017-11-22T09:44:48Z",
        "body": "PiperOrigin-RevId: 176561168\r\n\r\nFix tensorflow/models/gan README internal links.\r\n\r\n@nealwu ",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-11-21T20:51:21Z",
        "closed_at": "2018-01-15T21:13:26Z",
        "merged_at": null,
        "body": "Fix doc-string for samples/core/get_started/custom_estimator.py",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 5181,
        "deletions": 0,
        "changed_files": 35,
        "created_at": "2017-11-21T10:46:23Z",
        "closed_at": "2017-11-21T21:17:20Z",
        "merged_at": null,
        "body": "PiperOrigin-RevId: 175826086\r\n\r\nI thought this was already submitted, but I can't find any history of it. Launch entry #207179\r\n\r\n@martinwicke @nealwu",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2017-11-21T05:46:03Z",
        "closed_at": "2017-11-21T23:12:38Z",
        "merged_at": "2017-11-21T23:12:38Z",
        "body": "Replaces #2183  Python 2.7 no longer needs the trailing L and Python 3 treats it as a Syntax Error.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-11-21T05:35:38Z",
        "closed_at": "2017-11-21T23:09:30Z",
        "merged_at": "2017-11-21T23:09:30Z",
        "body": "xrange() was removed in Python 3 in favor of range()",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-11-21T05:27:49Z",
        "closed_at": "2017-11-21T23:10:06Z",
        "merged_at": "2017-11-21T23:10:06Z",
        "body": "xrange() was removed in Python 3 in favor of range()",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-11-21T05:12:42Z",
        "closed_at": "2017-11-21T23:10:45Z",
        "merged_at": "2017-11-21T23:10:45Z",
        "body": "Replaces #2117 \r\n\r\nxrange() was removed from Python 3 in favor of range().\r\n\r\n@wookayin Please review this change.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2017-11-20T22:01:34Z",
        "closed_at": "2017-11-21T06:37:44Z",
        "merged_at": "2017-11-21T06:37:44Z",
        "body": "@martinwicke @sguada Removes `import google3` from slim/nets, which is invalid in open source.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2017-11-18T15:34:05Z",
        "closed_at": "2019-10-28T18:33:50Z",
        "merged_at": null,
        "body": "- Set default value for \"min_score_thresh\" to 0 in object detection visualization.\r\n- Draw groundtruth bounding box by default.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 453,
        "deletions": 0,
        "changed_files": 4,
        "created_at": "2017-11-17T23:52:25Z",
        "closed_at": "2017-11-18T02:46:52Z",
        "merged_at": "2017-11-18T02:46:52Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 627,
        "deletions": 0,
        "changed_files": 5,
        "created_at": "2017-11-17T23:43:31Z",
        "closed_at": "2017-11-18T02:44:30Z",
        "merged_at": "2017-11-18T02:44:30Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 135,
        "deletions": 78,
        "changed_files": 3,
        "created_at": "2017-11-17T17:17:10Z",
        "closed_at": "2017-11-17T18:43:58Z",
        "merged_at": "2017-11-17T18:43:58Z",
        "body": "Cleanup and Sync with Get Started docs.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2379,
        "deletions": 178,
        "changed_files": 28,
        "created_at": "2017-11-17T03:52:11Z",
        "closed_at": "2019-10-28T18:33:50Z",
        "merged_at": null,
        "body": "merger from tensorflow/model",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-11-16T09:13:31Z",
        "closed_at": "2017-12-11T18:48:53Z",
        "merged_at": null,
        "body": "Updated so that commented path matches path in markdown.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-11-15T19:34:06Z",
        "closed_at": "2017-11-17T01:40:09Z",
        "merged_at": "2017-11-17T01:40:09Z",
        "body": "Right now the large NASNet-A model, when evaluated with the default batch_size of 100, runs into a bug. This change will allow the NASNet-A model to work with the default values. See #2778 for details.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 5181,
        "deletions": 2,
        "changed_files": 37,
        "created_at": "2017-11-15T18:53:52Z",
        "closed_at": "2017-11-22T08:05:00Z",
        "merged_at": null,
        "body": "@sguada @martinwicke \r\n\r\nThere might be a problem with the current slim copybara, so I made this change manually to unblock part of the image compression TFGAN example.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 330,
        "deletions": 23,
        "changed_files": 2,
        "created_at": "2017-11-15T18:47:02Z",
        "closed_at": "2019-10-28T18:33:49Z",
        "merged_at": null,
        "body": "Sometimes labels are overlapping each others.",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-11-15T16:51:17Z",
        "closed_at": "2018-03-02T17:29:16Z",
        "merged_at": null,
        "body": "http://flake8.readthedocs.io/en/latest/user/error-codes.html#error-violation-codes says:\r\n* _We report __E999__ when we fail to compile a file into an Abstract Syntax Tree_...",
        "comments": 10
    },
    {
        "merged": false,
        "additions": 260,
        "deletions": 197,
        "changed_files": 64,
        "created_at": "2017-11-15T15:43:20Z",
        "closed_at": "2018-01-24T01:48:25Z",
        "merged_at": null,
        "body": "Another attempt at #2390 which has become out of date with all the changes across the codebase.\r\n\r\nMake the minimal, safe changes required to convert the repo's code to be syntax compatible with both Python 2 and Python 3. There would _definitely_ be much more work required to complete the port to Python 3 but this is a minimal, safe first step.\r\n\r\nRun: `futurize --stage1 -w **/*.py`\r\n* See Stage 1: \"safe\" fixes http://python-future.org/automatic_conversion.html#stage-1-safe-fixes\r\n\r\n$ `pip install future`\r\n$ `git checkout -b modernize-python2-code`\r\n$ `futurize --stage1 -w **/*.py` # done in zsh for ** globbing\r\n$ `git commit --all -m \"Modernize Python 2 code to get ready for Python 3\"`\r\n$ `git push --set-upstream origin modernize-python2-code`",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 8,
        "changed_files": 7,
        "created_at": "2017-11-15T03:23:36Z",
        "closed_at": "2017-11-20T21:27:10Z",
        "merged_at": "2017-11-20T21:27:10Z",
        "body": "https://www.tensorflow.org/api_docs/python/tf/contrib/framework/get_or_create_global_step\r\n\r\ntf.contrib.framework.get_or_create_global_step -> tf.train.get_or_create_global_step",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-11-14T21:57:58Z",
        "closed_at": "2017-11-15T18:01:55Z",
        "merged_at": "2017-11-15T18:01:55Z",
        "body": "New bulk component tests fail with the latest version of autograd (1.2), which was rewritten and no longer contains the `containers` module. They pass with v1.1.13, which is the latest pre-1.2 version available in pip.",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-11-14T08:13:55Z",
        "closed_at": "2019-10-28T18:33:49Z",
        "merged_at": null,
        "body": "Fix unrecognized arguments when run with arguments defined in cifar10_train or cifar10_eval",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-11-13T16:08:48Z",
        "closed_at": "2018-05-03T12:57:53Z",
        "merged_at": null,
        "body": "Fix warning message (tf version 1.4.0): \r\n```\r\nWARNING:tensorflow:From nasnet_utils.py:414: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease switch to tf.train.get_or_create_global_step\r\n```",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-11-12T08:29:14Z",
        "closed_at": "2017-11-13T17:16:02Z",
        "merged_at": "2017-11-13T17:16:02Z",
        "body": "In the current implementation the inception_v3_base was not using is_training variable somehow. So the model mistakenly used batch normalization and dropout for inference time.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-11-11T02:32:49Z",
        "closed_at": "2019-10-21T13:01:10Z",
        "merged_at": null,
        "body": "The current use of `filter` is *not* Python 3 compatible.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 51,
        "deletions": 19,
        "changed_files": 2,
        "created_at": "2017-11-10T08:24:23Z",
        "closed_at": "2017-11-10T16:22:26Z",
        "merged_at": "2017-11-10T16:22:25Z",
        "body": "fixes #2753",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 286,
        "deletions": 97,
        "changed_files": 5,
        "created_at": "2017-11-09T20:12:38Z",
        "closed_at": "2017-11-16T17:02:06Z",
        "merged_at": null,
        "body": "Factor out `iris_data` and add `savedmodel_estimator`. \r\n\r\ncc: @jugglerix",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 19,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2017-11-09T01:46:10Z",
        "closed_at": "2019-10-28T18:33:48Z",
        "merged_at": null,
        "body": "create_pascal_tf_record_test.py will fail on python 3 due to comparing bytes with unicode issue.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-11-08T23:03:19Z",
        "closed_at": "2017-11-09T02:19:26Z",
        "merged_at": "2017-11-09T02:19:26Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-11-08T21:35:49Z",
        "closed_at": "2017-11-08T22:35:55Z",
        "merged_at": "2017-11-08T22:35:55Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-11-08T19:59:22Z",
        "closed_at": "2017-11-08T22:35:20Z",
        "merged_at": "2017-11-08T22:35:20Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-11-08T06:08:49Z",
        "closed_at": "2019-10-28T18:33:48Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-11-08T05:31:41Z",
        "closed_at": "2019-10-28T18:33:48Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-11-08T02:28:10Z",
        "closed_at": "2017-11-08T19:21:54Z",
        "merged_at": "2017-11-08T19:21:54Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2017-11-08T00:45:24Z",
        "closed_at": "2017-11-08T02:39:33Z",
        "merged_at": "2017-11-08T02:39:33Z",
        "body": "Also renamed dataset_parser to record_parser.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 611,
        "deletions": 69,
        "changed_files": 8,
        "created_at": "2017-11-07T23:37:50Z",
        "closed_at": "2017-11-18T02:42:40Z",
        "merged_at": "2017-11-18T02:42:40Z",
        "body": "- Move dataset tools into a subfolder.\r\n- Add a script to create kitti dataset",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 780,
        "deletions": 146,
        "changed_files": 10,
        "created_at": "2017-11-07T19:31:26Z",
        "closed_at": "2017-11-09T21:55:01Z",
        "merged_at": "2017-11-09T21:55:01Z",
        "body": "* Update multigrid_anchor_genertor to support custom scales and aspect ratios. Since this change modifies the order of anchors, the ssd models in the zoo are updated to work with this change. \r\n* Re export all the models in the zoo to fix the import error reported in #2674 \r\n* Adds configs corresponding to new models in the zoo.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2017-11-07T16:28:24Z",
        "closed_at": "2017-11-13T21:43:36Z",
        "merged_at": "2017-11-13T21:43:36Z",
        "body": "Dockerfile build was failing. Detail of the fix is  :\r\n\r\n* `libpng12-dev` is not present in repositories anymore. My guess is a change from based image `open-jdk8`\r\n* add `patch` package to make bazel work with @opt\r\n* CI configured is trying to get git version, which leads to failing since the parents' folders are not copied. I changed to use the simpler configure script\r\n* bazel version was too old for the new tensorflow version\r\n* bazel not finding PYTHON_BIN_PATH, add ENV command as a workaround\r\n\r\nDocker builds and can run the image on this PR. However, the common error with `Duplicate tensor` is still present, preventing from a correct usage, the goal of this PR is not to solve this problem since it has already been worked on in different issues.\r\n\r\nThis PR obviously fix my issue #2715",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-11-07T08:24:29Z",
        "closed_at": "2019-10-28T18:33:48Z",
        "merged_at": null,
        "body": "it looks better now",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 18,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2017-11-07T03:42:37Z",
        "closed_at": "2017-11-07T19:27:03Z",
        "merged_at": "2017-11-07T19:27:03Z",
        "body": "- Added more >50K examples to wide_deep_test.csv to result in a 50-50 overall split.\r\n- We train for 100 epochs now, which results in numbers that should beat the initial numbers by a landslide.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 11,
        "changed_files": 2,
        "created_at": "2017-11-06T18:12:23Z",
        "closed_at": "2017-11-09T20:13:22Z",
        "merged_at": null,
        "body": "cc: @jugglerix",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 44,
        "deletions": 44,
        "changed_files": 5,
        "created_at": "2017-11-03T22:26:07Z",
        "closed_at": "2017-11-06T19:26:07Z",
        "merged_at": "2017-11-06T19:26:07Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 14,
        "changed_files": 1,
        "created_at": "2017-11-03T20:16:23Z",
        "closed_at": "2017-11-06T19:24:38Z",
        "merged_at": "2017-11-06T19:24:38Z",
        "body": "    $> grep imports85 -r samples/cookbook/ | wc -l\r\n         0\r\n\r\nAlso: \r\n\r\n+Removed try-except on `import pandas`, pandas is no longer optional here.\r\n+Fixed some inconsistencies. ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2017-11-03T15:47:33Z",
        "closed_at": "2017-11-03T17:47:51Z",
        "merged_at": "2017-11-03T17:47:51Z",
        "body": "Fixes #2652 \r\n\r\nChange dict.iteritems() to dict.items()",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2017-11-03T13:17:05Z",
        "closed_at": "2019-10-28T18:33:47Z",
        "merged_at": null,
        "body": "",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-11-03T00:35:06Z",
        "closed_at": "2017-11-03T19:57:30Z",
        "merged_at": "2017-11-03T19:57:30Z",
        "body": "cc @k-w-w",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 49,
        "deletions": 47,
        "changed_files": 5,
        "created_at": "2017-11-02T19:14:22Z",
        "closed_at": "2017-11-07T18:01:16Z",
        "merged_at": "2017-11-07T18:01:16Z",
        "body": "",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2017-11-02T15:11:16Z",
        "closed_at": "2017-11-02T20:29:50Z",
        "merged_at": "2017-11-02T20:29:50Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 36,
        "deletions": 32,
        "changed_files": 3,
        "created_at": "2017-11-02T07:25:17Z",
        "closed_at": "2019-10-28T18:33:47Z",
        "merged_at": null,
        "body": "",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 19,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2017-11-02T03:13:10Z",
        "closed_at": "2019-10-28T18:33:46Z",
        "merged_at": null,
        "body": "the code to parse a string: [-1, 100, 200, 3] to list is this:\r\n\r\n```\r\n   input_shape = [\r\n        int(dim) if dim != '-1' else None\r\n        for dim in FLAGS.input_shape.split(',')\r\n```\r\nbut by splitting this with split, this will end up with [-1, 100, 200, 3. I use RE to parse this input.\r\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 78,
        "deletions": 62,
        "changed_files": 1,
        "created_at": "2017-11-01T15:25:27Z",
        "closed_at": "2017-11-11T23:12:34Z",
        "merged_at": "2017-11-11T23:12:34Z",
        "body": "There are several py_library(), py_binary() and py_test() claimed deps on \"//tensorflow\" explicitly. This causes the BUILD failed. This is discussed in the issue submitted earlier at [tensorflow/models 2571](https://github.com/tensorflow/models/issues/2571).\r\n\r\nAs my understanding, the `deps = [ \"//tensorflow\" ]` is looking for a directory tensorflow under the slim, which doesn't exist. Remove the deps fixed the issue, as long as the tensorflow is built and available.\r\n\r\nAnother approach might define the tensorflow library in workspace, by linking it to outside github repo? However, in this way, it could lead to replicated tensorflow modules?\r\n\r\nThank you.",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 11,
        "deletions": 14,
        "changed_files": 1,
        "created_at": "2017-10-31T19:03:52Z",
        "closed_at": "2019-10-28T18:33:46Z",
        "merged_at": null,
        "body": "A few notes, there are breaking API changes from TF 0.10 to 1.4 namely tf.multiply replaces tf.mul etc. so I wouldn't recommend TF 0.10.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2017-10-31T09:26:01Z",
        "closed_at": "2019-10-28T18:33:46Z",
        "merged_at": null,
        "body": "Hi ! When using Delf with python3 I found some issues.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-10-30T16:45:44Z",
        "closed_at": "2017-10-30T18:59:17Z",
        "merged_at": "2017-10-30T18:59:17Z",
        "body": "Add __init__.py file in nasnet directory. Fixed #2638.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-10-30T15:32:38Z",
        "closed_at": "2017-10-30T17:22:01Z",
        "merged_at": "2017-10-30T17:22:00Z",
        "body": "Remove google3 dependency on opensourced NASNet. Fixed #2646.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 301510,
        "deletions": 49196,
        "changed_files": 2272,
        "created_at": "2017-10-30T14:24:46Z",
        "closed_at": "2018-12-16T12:32:19Z",
        "merged_at": null,
        "body": "It may occasionally not be possible to evaluate the various models from start (first checkpoint) to finish (last checkpoint) while simultaneously training the model (limited resources). I've added a new flag, 'eval_from_ckpt', which when set will evaluate all checkpoints from and including the specified one.\r\n\r\nExample usage:\r\n`python C:/.../object_detection/eval.py \\ --logtostderr \\ --pipeline_config_path=C:/.../models/name.config \\ --eval_dir=C:/.../testing \\ --checkpoint_dir=C:/.../training \\ --eval_from_ckpt=840`\r\n\r\nIn this case, all checkpoints from checkpoint 840 to 'latest_checkpoint' will be evaluated.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-10-30T10:30:49Z",
        "closed_at": "2017-10-30T19:55:01Z",
        "merged_at": null,
        "body": "Removing unnecessary parenthesis in function definition",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 208,
        "deletions": 50,
        "changed_files": 3,
        "created_at": "2017-10-30T02:22:22Z",
        "closed_at": "2017-10-30T05:10:30Z",
        "merged_at": "2017-10-30T05:10:30Z",
        "body": "Update tf example decoder that was forgotten in the previous commits causing failures in input reader builder tests",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 185,
        "deletions": 20,
        "changed_files": 4,
        "created_at": "2017-10-29T17:59:24Z",
        "closed_at": "2017-10-30T01:41:36Z",
        "merged_at": "2017-10-30T01:41:36Z",
        "body": "* Contains config file for Faster RCNN NAS.\r\n* Faster RCNN NAS model\r\n* Release info",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-10-29T16:51:15Z",
        "closed_at": "2017-10-31T19:45:41Z",
        "merged_at": "2017-10-31T19:45:41Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-10-29T13:43:24Z",
        "closed_at": "2017-10-30T18:47:24Z",
        "merged_at": "2017-10-30T18:47:24Z",
        "body": "Also fixes issue #2628 \r\n\r\nFix was done according to https://www.python.org/dev/peps/pep-3113/#transition-plan",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 814,
        "deletions": 0,
        "changed_files": 5,
        "created_at": "2017-10-28T21:29:03Z",
        "closed_at": "2017-11-07T23:43:17Z",
        "merged_at": null,
        "body": "config files for ssd_inception_v3, embedded_ssd_mobilenet_v1 and faster_rcnn_nasnet ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1920,
        "deletions": 102,
        "changed_files": 23,
        "created_at": "2017-10-28T20:37:34Z",
        "closed_at": "2017-10-29T17:02:54Z",
        "merged_at": "2017-10-29T17:02:54Z",
        "body": "* add ssd_inception_v3, faster_rcnn_inception_v2, embedded_ssd_mobilenet_v1 feature extractors.\r\n* make corresponding updates to model builders.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 3766,
        "deletions": 226,
        "changed_files": 54,
        "created_at": "2017-10-28T19:39:39Z",
        "closed_at": "2017-10-28T22:35:56Z",
        "merged_at": null,
        "body": "Includes new gan nets by Joel Shor @joelshoer\r\n\r\nPix2Pix\r\nDCGAN\r\nCycleGAN\r\nIncludes new NasNet models by Barret Zoph @BarretZoph\r\n\r\nNASNet-A_Mobile_224\r\nNASNet-A_Large_331\r\nAdded global_pool option to nets by Arno Eigenwillig @arnoegw\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1026,
        "deletions": 265,
        "changed_files": 12,
        "created_at": "2017-10-28T19:28:46Z",
        "closed_at": "2017-10-29T16:48:44Z",
        "merged_at": "2017-10-29T16:48:44Z",
        "body": "* add support for keypoints in batch_multi_class_non_max_suppression\r\n* add temperature T in softmax activation and changes to post processing builder.\r\n* minor updates to all meta architectures to use the new batch_multi_class_non_max_suppression signature,\r\n\r\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 3766,
        "deletions": 226,
        "changed_files": 54,
        "created_at": "2017-10-28T15:23:01Z",
        "closed_at": "2017-10-28T21:11:12Z",
        "merged_at": "2017-10-28T21:11:12Z",
        "body": "Includes new gan nets by Joel Shor @joelshoer\r\n- Pix2Pix\r\n- DCGAN\r\n- CycleGAN\r\n\r\nIncludes new NasNet models by Barret Zoph @barretzoph\r\n- NASNet-A_Mobile_224\r\n- NASNet-A_Large_331\r\n\r\nAdded global_pool option to nets by Arno Eigenwillig @arnoegw\r\n\r\nPiperOrigin-RevId: 173772097",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 196,
        "deletions": 40,
        "changed_files": 3,
        "created_at": "2017-10-28T02:51:20Z",
        "closed_at": "2017-10-28T05:24:05Z",
        "merged_at": "2017-10-28T05:24:05Z",
        "body": "* Fix a bug that prevented model export with moving averages!\r\n* Add a new input_size flag\r\n* Mark some flags as required.\r\n* Options to add additional intermediate nodes to the exported graph.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 318,
        "deletions": 356,
        "changed_files": 4,
        "created_at": "2017-10-28T00:55:16Z",
        "closed_at": "2017-10-28T02:10:02Z",
        "merged_at": "2017-10-28T02:10:01Z",
        "body": "* Use new eval interface defined in utils/object_detection_evaluation.py which clean up a lot of the clutter in eval.pu\r\n* Update eval.py to use routines from utils/config_utils.py to parse config files.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 251,
        "deletions": 24,
        "changed_files": 15,
        "created_at": "2017-10-27T21:07:03Z",
        "closed_at": "2017-10-27T22:30:49Z",
        "merged_at": "2017-10-27T22:30:49Z",
        "body": "Bulk update for object_detection/protos. ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2135,
        "deletions": 327,
        "changed_files": 14,
        "created_at": "2017-10-27T19:21:41Z",
        "closed_at": "2017-10-27T22:25:05Z",
        "merged_at": "2017-10-27T22:25:05Z",
        "body": "Bulk update for object_detection/core directory. Here's a list of major changes:\r\n\r\n* Add new data_parser interface for reading and computing offline metrics.\r\n* make max normalized value configurable in box_list_ops.to_absolute_coordinates.\r\n* allow setting a bias term for class predictions in box_predictor.py\r\n* add new preprocesing ops for keypoints - flip_vertical and rotate 90 deg\r\n* add new preprocesing ops - random flip vertical and random rotate by 90 deg.\r\n* experimental implementation losses.\r\n* Add detection result fields to standard_fields.py",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2272,
        "deletions": 132,
        "changed_files": 17,
        "created_at": "2017-10-27T18:14:44Z",
        "closed_at": "2017-10-27T22:33:51Z",
        "merged_at": "2017-10-27T22:33:51Z",
        "body": "Bulk upstream update for object_detection/utils. A list of major changes.\r\n\r\n* Create a config_utils module to help parse/manipulate config files.\r\n* Add cosine learning rate with warmup\r\n* Introduce new interface for object detection evaluation that will help clean up some of the logic in object_detection/evaluator.py\r\n* introduces a few new visualization methods.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 257,
        "deletions": 99,
        "changed_files": 4,
        "created_at": "2017-10-27T16:42:48Z",
        "closed_at": "2017-11-07T23:43:12Z",
        "merged_at": null,
        "body": "add interpolated scale at a give aspect ratio. This change breaks\r\nthe existing checkpoints because the anchor orders are different.\r\n\r\nThis change should be merged along newly generated frozen ssd models.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2734,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2017-10-27T16:15:19Z",
        "closed_at": "2017-10-27T22:27:57Z",
        "merged_at": "2017-10-27T22:27:57Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-10-27T15:58:35Z",
        "closed_at": "2017-10-27T22:15:34Z",
        "merged_at": "2017-10-27T22:15:34Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 0,
        "changed_files": 0,
        "created_at": "2017-10-27T06:47:27Z",
        "closed_at": "2017-10-27T15:52:24Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-10-27T04:13:12Z",
        "closed_at": "2019-10-28T18:33:45Z",
        "merged_at": null,
        "body": "* Download the data to a local temporary directory so that data_dir\r\n  can be a remote path like GCS.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 9,
        "changed_files": 2,
        "created_at": "2017-10-27T01:58:50Z",
        "closed_at": "2017-11-11T02:44:31Z",
        "merged_at": "2017-11-11T02:44:31Z",
        "body": "Make the progress printed from the adversarial crypto example print columns in a consistently-formatted way. Fix a few other minor formatting details.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 111,
        "deletions": 87,
        "changed_files": 7,
        "created_at": "2017-10-27T00:50:05Z",
        "closed_at": "2017-10-27T21:53:32Z",
        "merged_at": "2017-10-27T21:53:32Z",
        "body": "This maintains better abstractions and makes it easier to unit test specific functions from our models.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2017-10-26T19:06:18Z",
        "closed_at": "2019-10-28T18:33:45Z",
        "merged_at": null,
        "body": "you have copied and pasted from [Python .gitignore](https://github.com/github/gitignore/blob/master/Python.gitignore) without filtering the useless lines\r\n\r\nthere is no need for flask and django .gitignore code\r\n\r\nthis is not a django or flask project",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-10-25T04:43:22Z",
        "closed_at": "2017-10-29T16:09:09Z",
        "merged_at": "2017-10-29T16:09:09Z",
        "body": "Example word2vec code was break-ing instead of returning when candidate was found, making the \"unknown\" error message show regardless.",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 47,
        "deletions": 12,
        "changed_files": 6,
        "created_at": "2017-10-25T01:56:45Z",
        "closed_at": "2017-10-25T20:32:22Z",
        "merged_at": "2017-10-25T20:32:22Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 31,
        "deletions": 37,
        "changed_files": 5,
        "created_at": "2017-10-24T22:17:14Z",
        "closed_at": "2017-10-25T00:52:09Z",
        "merged_at": "2017-10-25T00:52:09Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 25,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2017-10-24T12:33:07Z",
        "closed_at": "2017-10-24T17:53:54Z",
        "merged_at": "2017-10-24T17:53:54Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2017-10-21T01:50:11Z",
        "closed_at": "2017-11-07T23:24:17Z",
        "merged_at": null,
        "body": "Switch Dataset from contrib.data to tf.data.\r\n\r\nFix shuffle: The shuffle is only executed in graph, not when the method is called. If you create two iterators you get two different shuffles.\r\n\r\nIt's also important to have the shuffle before the batch so that you:\r\n\r\nShuffle 1e5 examples, not 1e5 batches.\r\nDifferent items are batched together each epoch.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 52,
        "deletions": 43,
        "changed_files": 4,
        "created_at": "2017-10-20T23:28:28Z",
        "closed_at": "2019-10-28T18:33:45Z",
        "merged_at": null,
        "body": "The way flags were handled actually did not allow to pass the `--train_dir` parameter to the script `cifar10_train.py` because the flags were parsed in `cifar10.py` before this argument was added.\r\n\r\nI use explicitly the `tf.flags._global_parser` as parser and I am able to pass both the `--train_dir` and the `--data_dir` parameters to the script `cifar10_train.py`.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 7,
        "changed_files": 5,
        "created_at": "2017-10-20T17:50:12Z",
        "closed_at": "2017-11-11T09:19:24Z",
        "merged_at": "2017-11-11T09:19:24Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 21,
        "deletions": 9,
        "changed_files": 1,
        "created_at": "2017-10-20T16:20:42Z",
        "closed_at": "2019-10-28T18:33:44Z",
        "merged_at": null,
        "body": "Just a step in making the install a little more automated.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-10-20T08:46:38Z",
        "closed_at": "2019-10-28T18:33:44Z",
        "merged_at": null,
        "body": "fix candidate activation expression",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-10-20T02:35:08Z",
        "closed_at": "2019-10-28T18:33:44Z",
        "merged_at": null,
        "body": "change streaming_recall_at_k to streaming_sparse_recall_at_k",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 10,
        "deletions": 10,
        "changed_files": 2,
        "created_at": "2017-10-19T04:43:36Z",
        "closed_at": "2019-10-28T18:33:44Z",
        "merged_at": null,
        "body": "Fixes #2545 \r\n\r\nThis PR corrects the 3x3 convolutions to 5x5 convolutions in Inception v1.\r\n\r\nI have run the tests in `inception_v1_test.py` and ensured that they pass following these changes.",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 487,
        "deletions": 1,
        "changed_files": 8,
        "created_at": "2017-10-19T02:33:39Z",
        "closed_at": "2017-10-19T19:47:44Z",
        "merged_at": "2017-10-19T19:47:44Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 66,
        "deletions": 75,
        "changed_files": 2,
        "created_at": "2017-10-18T20:27:36Z",
        "closed_at": "2017-10-19T01:53:42Z",
        "merged_at": "2017-10-19T01:53:42Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2219,
        "deletions": 0,
        "changed_files": 12,
        "created_at": "2017-10-17T23:47:06Z",
        "closed_at": "2017-11-01T21:40:33Z",
        "merged_at": "2017-11-01T21:40:33Z",
        "body": "This PR pulls files from a few other places, initializing the directory structure Magnus was talking about. \r\n\r\nInto `examples/outreach/blogs`:\r\n* https://github.com/mhyttsten/Misc \r\n\r\nInto `examples/cookbook/regression`:\r\n* https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/get_started/regression\r\n\r\nInto `examples/core/get_started`:\r\n* https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/iris.py\r\n* https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/learn/iris_custom_model.py\r\n\r\nNo files were changed (I renamed the iris files).\r\n\r\nI've cleaned-up and added tests for core/get_started examples and cookbook/regression",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-10-15T14:58:01Z",
        "closed_at": "2017-10-16T13:55:09Z",
        "merged_at": "2017-10-16T13:55:09Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 3827,
        "deletions": 928716,
        "changed_files": 1370,
        "created_at": "2017-10-13T23:51:36Z",
        "closed_at": "2017-10-28T00:22:41Z",
        "merged_at": null,
        "body": "This addition contains the code for the NASNet-A model from the paper Learning Transferable Architectures for Scalable Image Recognition by Zoph et al. In nasnet.py there are three different configurations of NASNet-A that are implemented.",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-10-13T13:00:49Z",
        "closed_at": "2017-12-16T00:40:04Z",
        "merged_at": "2017-12-16T00:40:04Z",
        "body": "CIFAR website is now using https.\r\nSince urllib does not follow the http to https redirection and thus never retrieves any data, the data URL needs an update.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-10-12T18:33:38Z",
        "closed_at": "2018-08-30T00:14:50Z",
        "merged_at": null,
        "body": "Fixed the pre-trained inception_resnet_v2 checkpoint filename.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2017-10-12T04:38:17Z",
        "closed_at": "2017-10-12T13:31:00Z",
        "merged_at": "2017-10-12T13:31:00Z",
        "body": "Also added 'sudo' to installation instructions.\r\n\r\nFixes #2420 ",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 50,
        "deletions": 47,
        "changed_files": 2,
        "created_at": "2017-10-11T23:02:27Z",
        "closed_at": "2019-10-28T18:33:43Z",
        "merged_at": null,
        "body": "\r\n@nealwu, @protoget\r\n\r\n- https://github.com/Utumno/models/commit/34e9041f196b412a1b0930ee74580786a6de8dae addresses https://github.com/tensorflow/models/pull/2276#issuecomment-329885088\r\n - https://github.com/Utumno/models/commit/cdd82c7bf7de8a9069a8cc1f9607936ff70132bd addresses this: https://github.com/tensorflow/models/issues/2505#issuecomment-334936514 and also adds argparse",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-10-11T22:50:31Z",
        "closed_at": "2017-10-12T00:27:22Z",
        "merged_at": null,
        "body": "",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-10-11T22:30:49Z",
        "closed_at": "2017-10-16T20:52:16Z",
        "merged_at": "2017-10-16T20:52:16Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-10-10T14:58:26Z",
        "closed_at": "2017-10-12T17:40:44Z",
        "merged_at": "2017-10-12T17:40:44Z",
        "body": "The currently used version of Tensorflow contains an outdated version of protobuf which is not compatible with the upcoming Bazel 0.8.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2017-10-10T09:41:39Z",
        "closed_at": "2019-10-28T18:33:43Z",
        "merged_at": null,
        "body": "These changes make vgsl_model_test.py pass for current version of TF",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-10-09T21:02:56Z",
        "closed_at": "2017-10-11T23:18:30Z",
        "merged_at": "2017-10-11T23:18:30Z",
        "body": "Without this change, Bazel will draw an error.\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 7,
        "changed_files": 3,
        "created_at": "2017-10-05T18:42:07Z",
        "closed_at": "2017-10-05T19:58:23Z",
        "merged_at": "2017-10-05T19:58:23Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 16,
        "deletions": 6,
        "changed_files": 2,
        "created_at": "2017-10-05T18:41:57Z",
        "closed_at": "2018-01-29T19:06:16Z",
        "merged_at": null,
        "body": "",
        "comments": 9
    },
    {
        "merged": false,
        "additions": 15,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2017-10-05T00:26:58Z",
        "closed_at": "2017-10-05T18:09:09Z",
        "merged_at": null,
        "body": "",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-10-04T23:59:30Z",
        "closed_at": "2017-10-05T18:08:56Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 18,
        "deletions": 5,
        "changed_files": 3,
        "created_at": "2017-10-04T21:11:22Z",
        "closed_at": "2017-10-04T23:17:20Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-10-04T02:55:11Z",
        "closed_at": "2017-10-10T18:55:34Z",
        "merged_at": "2017-10-10T18:55:34Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 335,
        "changed_files": 2,
        "created_at": "2017-10-02T21:40:44Z",
        "closed_at": "2017-10-03T00:06:37Z",
        "merged_at": "2017-10-03T00:06:37Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2017-09-28T15:47:09Z",
        "closed_at": "2019-10-28T18:33:43Z",
        "merged_at": null,
        "body": "The imagenet download and preprocess script failed due to some bug in bazel file path parsing system. If I re-run the imagenet download and preprocess script, it throws an error saying-\r\n\r\nOSError: [Errno 17] File exists:\r\nbecause some of the dataset was previously extracted.\r\n\r\nIdeally the script should only try to create a directory if it does not exist.\r\n\r\nMy commit fixes just this problem and has just one line of code added.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1209,
        "deletions": 0,
        "changed_files": 13,
        "created_at": "2017-09-27T14:56:03Z",
        "closed_at": "2019-10-28T18:33:43Z",
        "merged_at": null,
        "body": "This MR requests has the idea of creating a common structure for any word embedding model that should be added to the project.\r\n\r\nIn order to do that, I have created a base word embedding class in python to provide common method for  any word embedding model, such as a method to evaluate the model or to train models concurrently. The  second file is a C++ class used to provide base methods to parse a corpus and creates the vocabulary,  word frequency count and word to id dictionary. \r\n\r\nBoth of these classes were created based on the implementation of the [word2vec model](https://github.com/tensorflow/models/tree/master/tutorials/embedding). They were also the base for how the GloVe model should be implemented.\r\n\r\nThe GloVe model created is an example of how using both of these base class can simplify the creation of word embedding models. In the Glove model it was necessary only to implement the forward pass and the loss function related to GloVe. And to create the examples batches, it was necessary only to implement the Co-Ocurrence matrix in C++ and create the batches in a similar way to the word2vec model.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 97,
        "deletions": 44,
        "changed_files": 4,
        "created_at": "2017-09-27T01:44:35Z",
        "closed_at": "2017-09-27T19:16:06Z",
        "merged_at": "2017-09-27T19:16:06Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-09-27T00:06:48Z",
        "closed_at": "2017-10-04T23:58:44Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 31,
        "deletions": 31,
        "changed_files": 9,
        "created_at": "2017-09-26T13:29:54Z",
        "closed_at": "2017-10-12T05:32:36Z",
        "merged_at": null,
        "body": "This patch fixes the paths of imported modules in research/object_detection/protos. Without this patch, the following command fails:\r\n$ protoc research/object_detection/protos/*.proto --python_out=.\r\nThis is due to a restructuring that occurred in this repository that moved libraries from the root directory.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2017-09-25T19:25:25Z",
        "closed_at": "2017-09-26T23:49:38Z",
        "merged_at": "2017-09-26T23:49:38Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-09-25T13:57:57Z",
        "closed_at": "2017-09-25T19:10:18Z",
        "merged_at": "2017-09-25T19:10:18Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-09-24T05:00:47Z",
        "closed_at": "2017-09-26T23:53:53Z",
        "merged_at": "2017-09-26T23:53:53Z",
        "body": "I have a large number of files where the file-names are autogenerated using a script and they contain the name of the PNG file they were generated from.\r\n\r\nSo a filename could look like: \"xxxxxxxxx.png_xxxxxxxxx.jpg\"\r\n\r\nThis breaks the existing check. So tweaking it a bit to fix this.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 0,
        "changed_files": 0,
        "created_at": "2017-09-22T22:51:35Z",
        "closed_at": "2017-09-25T18:44:14Z",
        "merged_at": "2017-09-25T18:44:14Z",
        "body": "removing unnecessary imports",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 22,
        "changed_files": 1,
        "created_at": "2017-09-22T15:20:31Z",
        "closed_at": "2019-10-28T18:30:05Z",
        "merged_at": null,
        "body": "This PR simplifies the object detection tutorial a little by removing the helper function for converting PIL/Pillow images to numpy arrays by using the numpy array interface on the PIL.Image object (introduced PIL 1.1.6). Which seems to be the preferred method for converting between the two [1] [2].\r\n\r\n[1] [https://stackoverflow.com/a/384926](https://stackoverflow.com/a/384926)\r\n[2] [http://effbot.org/zone/pil-changes-116.htm](http://effbot.org/zone/pil-changes-116.htm)",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 37,
        "deletions": 37,
        "changed_files": 8,
        "created_at": "2017-09-22T14:04:58Z",
        "closed_at": "2017-09-22T20:10:05Z",
        "merged_at": "2017-09-22T20:10:05Z",
        "body": "(most things now under research/ for slim links).  Fixes\r\ndocs and breakage in the inception download script.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-09-22T13:15:48Z",
        "closed_at": "2017-09-26T23:51:47Z",
        "merged_at": null,
        "body": "There is a broken link (maybe more than one) because of the move of the models into the research subdirectory.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-09-22T10:04:49Z",
        "closed_at": "2017-09-26T07:59:33Z",
        "merged_at": null,
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 38,
        "deletions": 37,
        "changed_files": 8,
        "created_at": "2017-09-22T04:45:20Z",
        "closed_at": "2017-09-22T20:08:41Z",
        "merged_at": "2017-09-22T20:08:40Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 86,
        "deletions": 78,
        "changed_files": 1283,
        "created_at": "2017-09-21T18:13:14Z",
        "closed_at": "2017-09-21T19:58:21Z",
        "merged_at": "2017-09-21T19:58:21Z",
        "body": "Because the models repository is growing well past what the TensorFlow team can maintain (currently housing 36 top-level folders), we will be making a major restructure of the models repository:\r\n\r\n- First, we will be starting an official, supported collection of models in the repo. These models will be implemented with high-level TensorFlow APIs, fast performance, and other best practices that we think newer TensorFlow users should see. The first few models are already available [here](https://github.com/tensorflow/models/tree/master/official).\r\n\r\n- Second, we will be moving all of the current models in the repository to a subfolder called 'research'. This will clean up the repository significantly by cutting down the number of top-level folders.\r\n\r\nMoving forward, the TensorFlow team will only support issues/PRs on the official models. For the research models we encourage the individual researchers to support them, but we cannot guarantee support.\r\n\r\nUnfortunately, the main pain of this restructure is that all existing links to models within the repo will be broken. For those of you who own models in the repo, we know that it will take some effort to correct all of your links, but we hope you'll help us work to quickly get to a cleaner models repository for our users.",
        "comments": 8
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2017-09-21T03:36:21Z",
        "closed_at": "2019-10-28T18:30:04Z",
        "merged_at": null,
        "body": "Found a bug maybe... I think the inference phase should pre-process the images first, as same as the training phase",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 6,
        "changed_files": 6,
        "created_at": "2017-09-21T01:10:30Z",
        "closed_at": "2017-09-21T18:11:35Z",
        "merged_at": "2017-09-21T18:11:35Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-09-19T06:28:47Z",
        "closed_at": "2017-11-29T22:15:29Z",
        "merged_at": "2017-11-29T22:15:29Z",
        "body": "Fix #2240 identified by @mees ",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-09-19T06:19:07Z",
        "closed_at": "2017-11-29T22:15:02Z",
        "merged_at": "2017-11-29T22:15:02Z",
        "body": "Fix #2219 identified by @mees ",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-09-19T05:34:11Z",
        "closed_at": "2017-09-19T21:08:05Z",
        "merged_at": "2017-09-19T21:08:05Z",
        "body": "evaulated -> evaluated from **eval.py**",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2017-09-19T05:27:47Z",
        "closed_at": "2019-10-28T18:30:04Z",
        "merged_at": null,
        "body": "To configure **min_score_thresh** and **max_num_predictions** from **eval_config** of config file, it needs to add those variables into **eval.proto** and add default params into **eval_util.visualize_detection_results()** from **evaluator.py**. \r\nThose default values are .5(for **min_score_thresh**) and 20(for  **max_num_predictions**) which are for default values of **eval_util.visualize_detection_results()** as below. \r\n\r\n```\r\ndef visualize_detection_results(result_dict,\r\n                                tag,\r\n                                global_step,\r\n                                categories,\r\n                                summary_dir='',\r\n                                export_dir='',\r\n                                agnostic_mode=False,\r\n                                show_groundtruth=False,\r\n                                min_score_thresh=.5,\r\n                                max_num_predictions=20):\r\n```",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 7,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2017-09-19T03:12:43Z",
        "closed_at": "2019-10-28T18:30:04Z",
        "merged_at": null,
        "body": "Fix the typo, FLAGS.momentum should be defined as float type.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-09-17T18:38:15Z",
        "closed_at": "2017-10-11T17:57:59Z",
        "merged_at": "2017-10-11T17:57:59Z",
        "body": "Replace dict.iteritems with dict.items.  In both cases the dict is\r\nvery small, so the optimization that `iteritems` provides on Python 2\r\ndoesn't matter.\r\n\r\nWith this fix, the model works smoothly for me on CPython 3.5.3.",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 20,
        "deletions": 19,
        "changed_files": 1,
        "created_at": "2017-09-17T10:00:03Z",
        "closed_at": "2019-10-28T18:30:03Z",
        "merged_at": null,
        "body": "Fix issue #2400\r\n- Add column for links to graph def files for pre-trained model\r\n- Included links for mobilenet models and Inception v3\r\n- Addresses this feature request https://github.com/tensorflow/models/issues/",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-09-17T03:39:46Z",
        "closed_at": "2017-09-18T20:03:52Z",
        "merged_at": "2017-09-18T20:03:52Z",
        "body": "Following the generated warning message, changed the deprecated `all_variables` to `global_variables` \r\n```\r\n[...] all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\r\nInstructions for updating:\r\nPlease use tf.global_variables instead.\r\n```",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-09-16T17:53:16Z",
        "closed_at": "2018-02-28T03:33:24Z",
        "merged_at": "2018-02-28T03:33:24Z",
        "body": "fix #1262 ",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2017-09-16T00:51:08Z",
        "closed_at": "2017-09-19T23:19:32Z",
        "merged_at": "2017-09-19T23:19:32Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-09-14T18:27:22Z",
        "closed_at": "2017-09-26T18:38:52Z",
        "merged_at": null,
        "body": "",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 260,
        "deletions": 199,
        "changed_files": 62,
        "created_at": "2017-09-14T15:34:56Z",
        "closed_at": "2017-11-15T15:24:16Z",
        "merged_at": null,
        "body": "Make the minimal, safe changes required to convert the repo's code to be syntax compatible with both Python 2 and Python 3. There would _definitely_ be much more work required to complete the port to Python 3 but this is a minimal, safe first step.\r\n\r\n1. Run: `futurize --stage1 -w **/*.py`\r\n\r\nSee Stage 1: \"safe\" fixes http://python-future.org/automatic_conversion.html#stage-1-safe-fixes\r\n\r\n$ `pip install future`\r\n$ `git checkout -b modernize-python2-code`\r\n$ `futurize --stage1 -w **/*.py` # done in zsh for ** globbing\r\n$ `git commit --all -m \"Modernize Python 2 code to get ready for Python 3\"`\r\n$ `git push --set-upstream origin modernize-python2-code`\r\n\r\n2. Make the changes in #2389 to fix a few Python 3 syntax errors",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 26,
        "deletions": 24,
        "changed_files": 2,
        "created_at": "2017-09-14T15:12:17Z",
        "closed_at": "2018-01-22T22:42:38Z",
        "merged_at": null,
        "body": "Also convert ur'strings' to u'strings' to prepare for Python 3.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2487,
        "deletions": 0,
        "changed_files": 20,
        "created_at": "2017-09-14T05:28:24Z",
        "closed_at": "2017-09-21T00:56:37Z",
        "merged_at": "2017-09-21T00:56:37Z",
        "body": "@jhseu @itsmeolivia @shivaniag @av8ramit @puneith",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-09-13T12:21:29Z",
        "closed_at": "2017-09-18T20:39:37Z",
        "merged_at": "2017-09-18T20:39:37Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-09-13T02:56:41Z",
        "closed_at": "2017-09-18T20:05:17Z",
        "merged_at": null,
        "body": "the WORK_DIR seems incorrect, it was inconsistent with the directory structure, maybe it should be \r\n`\"..\"`",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-09-12T19:26:26Z",
        "closed_at": "2017-09-18T17:39:55Z",
        "merged_at": "2017-09-18T17:39:55Z",
        "body": "Updated documentation. Command for exporting model checkpoint to frozen graph.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-09-12T08:52:40Z",
        "closed_at": "2017-09-12T15:00:21Z",
        "merged_at": "2017-09-12T15:00:21Z",
        "body": "In order to help address issue #5987, I'm adding references to the evaluation loop example. I'm also making it more obvious that this is not the main TF-Slim page and adding another reference to that page in the introductory paragraph.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-09-11T22:08:52Z",
        "closed_at": "2019-10-28T18:30:03Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 4,
        "changed_files": 4,
        "created_at": "2017-09-11T22:04:26Z",
        "closed_at": "2017-09-18T20:04:32Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-09-11T13:26:26Z",
        "closed_at": "2019-10-28T18:30:03Z",
        "merged_at": null,
        "body": "when I training the data with tensorflow 1.3\uff0c the console print the warning text \u201dlearning rate is illegal\u201c .  so i find and changed this word",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 24,
        "deletions": 21,
        "changed_files": 4,
        "created_at": "2017-09-11T08:09:16Z",
        "closed_at": "2017-09-11T16:29:13Z",
        "merged_at": "2017-09-11T16:29:13Z",
        "body": "Fixed typos in object_detection/meta_architectures/ docstrings, i.e., fixed the dimensions of the tensors in the doc strings ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-09-06T21:59:50Z",
        "closed_at": "2017-09-21T01:13:05Z",
        "merged_at": "2017-09-21T01:13:05Z",
        "body": "Change this line to say \"The total loss is the user's loss ...\"\r\n\r\nThe total loss is the uers's loss plus any regularization losses.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-09-06T03:35:51Z",
        "closed_at": "2017-12-11T21:53:08Z",
        "merged_at": null,
        "body": "The base path for this should be `tensorflow/models` not `tensorflow/models/object_detection`",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-09-06T03:09:11Z",
        "closed_at": "2017-09-18T21:45:05Z",
        "merged_at": "2017-09-18T21:45:05Z",
        "body": "Fixed typo of `object_detection/g3doc/exporting_models.md`\r\n\r\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 22,
        "changed_files": 1,
        "created_at": "2017-09-06T01:04:41Z",
        "closed_at": "2017-09-15T20:21:52Z",
        "merged_at": "2017-09-15T20:21:52Z",
        "body": "If I understand correctly, `SyncReplicasOptimizer.make_session_run_hook`s output is supposed to be run on every worker, with the provided `is_chief` flag determining whether aggregation is performed. \r\n\r\nThis PR fixes that (it also moves other hooks inside the model_fn so that you can refer to logging tensors by reference rather than by name which is fragile). \r\n\r\n@tfboyd @isaprykin ",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 23,
        "deletions": 5,
        "changed_files": 5,
        "created_at": "2017-09-05T13:55:09Z",
        "closed_at": "2019-10-28T18:30:02Z",
        "merged_at": null,
        "body": "**Subfolder**: object_detection\r\n**Use Case**:\r\nI want to follow the accuracy over time during training. I run train.py and eval.py at the same time. train.py is directly allocating all GPU VRAM so eval.py can't restore the graph anymore and results in OOM (since I use one GPU).\r\n\r\n**Changed method definition**:\r\nAn additional parameter is added in eval_util.py (method repeated_checkpoint_run and run_checkpoint_once). If this is problematic then I would suggest leaving the config option for eval and only add the option to train.proto.\r\n\r\n(Original [PR](https://github.com/tensorflow/models/pull/2318))",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-09-05T00:25:42Z",
        "closed_at": "2017-09-05T16:53:10Z",
        "merged_at": "2017-09-05T16:53:10Z",
        "body": "Fixed description of `Returns` for `get_class_name_from_filename(file_name)` in `create_pet_tf_record.py` as below. \r\n\r\n`example: The converted tf.Example.` -> `A string of the class name.`",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 13,
        "deletions": 11,
        "changed_files": 1,
        "created_at": "2017-09-04T04:48:31Z",
        "closed_at": "2017-09-04T06:18:02Z",
        "merged_at": "2017-09-04T06:18:02Z",
        "body": "I move all detection_graph.get_tensor_by_name outside detection loop, since detection_graph.get_tensor_by_name only need to run once and do not need to run in every loop.\r\nI change all Tensor's names, since names of Tenor and numpy array should be difference, otherwise, it will confuse someone with Tenor and numpy array. ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-09-03T20:31:33Z",
        "closed_at": "2017-09-04T06:19:32Z",
        "merged_at": "2017-09-04T06:19:32Z",
        "body": "see example usage in https://github.com/tensorflow/models/blob/master/object_detection/export_inference_graph.py#L51\r\nissue https://github.com/tensorflow/models/issues/2329",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-09-01T07:01:41Z",
        "closed_at": "2017-09-09T02:26:38Z",
        "merged_at": "2017-09-09T02:26:38Z",
        "body": "Tested on python2.7 tensorflow-gpu==1.2.0\r\n\r\n```\r\npython ptb_word_lm.py --data_path=simple-examples/data/ --model small --num_gpus=2\r\n```\r\n\r\n| config | epochs | train | valid | test | wps |\r\n|-------|-----|-----|-----|-----|-----|\r\n| small | 13 | 38.109 | 141.901 | 135.217 | 45k |\r\n\r\n\r\nThe tutorial can not run on python3, look like #1922 need to be reverted.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-09-01T00:25:52Z",
        "closed_at": "2018-02-14T22:13:36Z",
        "merged_at": null,
        "body": "I was having issues running build_imagenet_data.py due to an unresolved dependency 'google3'.\r\nHere, google3 is imported but never used, so this patch removes that import statement.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 100456,
        "deletions": 1548,
        "changed_files": 284,
        "created_at": "2017-08-31T09:22:06Z",
        "closed_at": "2017-09-05T12:47:25Z",
        "merged_at": null,
        "body": "**Subfolder**: object_detection\r\n**Use Case**:\r\nI want to follow the accuracy over time during training. I run train.py and eval.py at the same time. train.py is directly allocating all GPU VRAM so eval.py can't restore the graph anymore and results in OOM (since I use one GPU).\r\n\r\n**Changed method definition:**\r\nAn additional parameter is added in eval_util.py (method repeated_checkpoint_run and run_checkpoint_once). If this is problematic then I would suggest leaving the config option for eval and only add the option to train.proto.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-08-31T08:02:35Z",
        "closed_at": "2017-10-10T18:57:47Z",
        "merged_at": null,
        "body": "Just a simple change. ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-08-30T21:32:57Z",
        "closed_at": "2017-09-18T21:43:48Z",
        "merged_at": "2017-09-18T21:43:48Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 11,
        "changed_files": 5,
        "created_at": "2017-08-30T17:15:20Z",
        "closed_at": "2017-08-30T20:09:49Z",
        "merged_at": "2017-08-30T20:09:49Z",
        "body": "Should fix tests that fail due to incompatibility with the old version of tensorflow that uses an old version of rules_closure.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2017-08-30T13:01:27Z",
        "closed_at": "2017-08-30T16:25:49Z",
        "merged_at": "2017-08-30T16:25:49Z",
        "body": "This change is required for compatibility with Bazel 0.6+\r\n\r\nSee also https://github.com/tensorflow/tensorflow/pull/12685",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-08-30T10:14:38Z",
        "closed_at": "2019-10-28T18:30:02Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 571,
        "deletions": 0,
        "changed_files": 5,
        "created_at": "2017-08-30T10:01:36Z",
        "closed_at": "2019-10-28T18:30:02Z",
        "merged_at": null,
        "body": "I implemented slim models for DenseNet and FC-DenseNet, based on the original lasagne/theano code made available by the authors of FC-DenseNets. Hope it will be useful. \r\n- [Densely Connected Convolutional Networks](https://arxiv.org/pdf/1608.06993.pdf)\r\n- [The One Hundred Layers Tiramisu: Fully Convolutional\r\n  DenseNets for Semantic Segmentation](https://arxiv.org/pdf/1611.09326.pdf) - [code](https://github.com/SimJeg/FC-DenseNet/blob/master/FC-DenseNet.py)\r\n\r\n\r\n\r\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 39,
        "deletions": 33,
        "changed_files": 5,
        "created_at": "2017-08-30T01:22:58Z",
        "closed_at": "2017-08-31T23:20:57Z",
        "merged_at": "2017-08-31T23:20:57Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-08-29T09:47:10Z",
        "closed_at": "2019-10-28T18:30:01Z",
        "merged_at": null,
        "body": "We now link to the instructions to download and convert imagenet to\r\nTFrecords contained in the slim README instead of the inception\r\nREADME.\r\n\r\nThe build script in the inception folder does not create a\r\nlabels.txt file and so it is no longer compatible with the slim\r\ntrain script.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-08-29T09:38:40Z",
        "closed_at": "2019-10-28T18:30:01Z",
        "merged_at": null,
        "body": "Add a `cd` command in the instructions for downloading and converting imagenet. This lets users unfamiliar with bazel (which is most of them) know they shouldn't be in the slim folder when running the command. The directory is different for these instructions compared with the [instructions in the inception folder](inception#getting-started), which the slim README also [links to and tells you to follow](slim#downloading-and-converting-to-tfrecord-format).\r\n\r\nI have written the instruction in the same manner as the [instructions for installation in the inception folder](inception#getting-started).",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-08-28T12:52:45Z",
        "closed_at": "2019-10-28T18:30:00Z",
        "merged_at": null,
        "body": "The Python extension is missing in the BUILD_SCRIPT string.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2017-08-28T12:17:10Z",
        "closed_at": "2018-03-03T18:45:13Z",
        "merged_at": "2018-03-03T18:45:13Z",
        "body": "In [`download_imagenet.sh`](inception/inception/data/download_imagenet.sh), the path to the `$SYNSETS_FILE` resource (`imagenet_2012_validation_synset_labels.txt`) was not working due to a `cd` earlier in the script.\r\n\r\nThis is fixed by prepending the initial directory path to the path to the resource file (`$SYNSETS_FILE`) when we try to access it.\r\n\r\nFixes #682.",
        "comments": 9
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2017-08-28T12:11:05Z",
        "closed_at": "2019-10-28T18:30:00Z",
        "merged_at": null,
        "body": "Fixes two links in [`slim/README.md`](slim/README.md).\r\n\r\n1. Point to correct shell script for downloading ImageNet to TFrecords (was incorrectly [`download_and_preprocess_imagenet.sh`](slim/datasets/download_and_preprocess_imagenet.sh), now correctly [`download_and_convert_imagenet.sh`](slim/datasets/download_and_convert_imagenet.sh)).\r\n2. Fix broken markdown for a link to ImageNet (text and URL were split by a line-break). Subsequent text in the paragraph is line-wrapped appropriately following this change.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-08-28T09:18:10Z",
        "closed_at": "2019-10-28T18:30:00Z",
        "merged_at": null,
        "body": "Since the export_inference_graph.py was changed in [this pull request](https://github.com/tensorflow/models/pull/2053/files), the corresponding [markdown file](https://github.com/yatendragoel/models/blob/master/object_detection/g3doc/exporting_models.md) also had to be changed",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-08-28T08:59:56Z",
        "closed_at": "2017-09-19T03:43:33Z",
        "merged_at": "2017-09-19T03:43:33Z",
        "body": "example_pos_ is the cursor to current position when reading the corpus file. When corpus file is very big, the corpus_size_ may bigger than max of int32, then example_pos_ became negative, and cause `corpus_[example_pos_]` to `Segmentation Fault`.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 0,
        "changed_files": 0,
        "created_at": "2017-08-28T08:26:37Z",
        "closed_at": "2017-08-29T16:25:22Z",
        "merged_at": null,
        "body": "Since the export_inference_graph.py was changed in [this pull request](https://github.com/tensorflow/models/pull/2053/files), the corresponding [markdown file](https://github.com/yatendragoel/models/blob/master/object_detection/g3doc/exporting_models.md) also had to be changed",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 910,
        "deletions": 100,
        "changed_files": 18,
        "created_at": "2017-08-25T09:43:43Z",
        "closed_at": "2019-10-28T18:29:59Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 118,
        "deletions": 105,
        "changed_files": 3,
        "created_at": "2017-08-24T17:39:59Z",
        "closed_at": "2017-08-25T14:18:23Z",
        "merged_at": "2017-08-25T14:18:23Z",
        "body": "Updated to ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-08-24T14:32:38Z",
        "closed_at": "2017-09-19T05:12:54Z",
        "merged_at": "2017-09-19T05:12:54Z",
        "body": "fixes IOU computation for issue #2239",
        "comments": 12
    },
    {
        "merged": true,
        "additions": 894,
        "deletions": 0,
        "changed_files": 5,
        "created_at": "2017-08-24T00:34:01Z",
        "closed_at": "2017-08-24T02:02:05Z",
        "merged_at": "2017-08-24T02:02:05Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-08-23T22:55:40Z",
        "closed_at": "2018-03-14T21:22:57Z",
        "merged_at": null,
        "body": "download_and_preprocess_imagenet.sh invokes download_imagenet.sh with incorrect WORK_DIR passed as argument. This breaks download_imagenet.sh with a file-not-found error.\r\nIt breaks because WORK_DIR is relative path, but should be fully qualified.",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 302,
        "deletions": 67,
        "changed_files": 4,
        "created_at": "2017-08-23T20:36:57Z",
        "closed_at": "2017-08-29T22:02:27Z",
        "merged_at": "2017-08-29T22:02:27Z",
        "body": "Add different rnn implementation modes to ptb tutorial using CudnnLSTM and LSTMBlockCell. \r\n\r\nrnn_mode == CUDNN\r\n===================================================\r\n| config | epochs | train | valid  | test   | wps\r\n====================================================\r\n| small  | 13     | 40.50 | 116.60 | 112.13 | 49k\r\n| medium | 39     | 22.58 | 123.83 | 118.69 | 24.2k\r\n| large  | 55     |  8.03 | 129.78 | 126.03 | 10.5k\r\n====================================================\r\nIn fact, the params tensor layout for cudnn_lstm is so different from canonical LSTM,\r\nwe need a complete different set of init_scale and learning rate parameters.\r\n\r\nrnn_mode == BLOCK\r\n===================================================\r\n| config | epochs | train | valid  | test   | wps\r\n====================================================\r\n| small  | 13     | 40.55 | 120.70 | 115.52 | 17.2k\r\n| medium | 39     | 45.68 |  86.97 |  83.47 | 13.6k\r\n| large  | 55     | 37.94 |  82.75 |  78.49 | 5.0k\r\n====================================================\r\n\r\nWps before this cl for small, medium, large models are\r\n15.6k, 12.6k, and 5.0k, respectively.\r\n\r\nBenchmarking platform: E5-2690 v4, Titan X.",
        "comments": 16
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-08-23T08:14:23Z",
        "closed_at": "2018-09-26T05:55:09Z",
        "merged_at": null,
        "body": "replace use of deprecated functions in eval_image_classifier.py",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 96,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2017-08-22T13:13:49Z",
        "closed_at": "2019-10-28T18:29:59Z",
        "merged_at": null,
        "body": "I added one more test where you have two classes on one image so that it is more explicit that the bounding boxes are a list of xmins, ymins, xmaxs, ymaxs etc and also made it python 3 compatible.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-08-22T03:43:03Z",
        "closed_at": "2019-10-28T18:29:59Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 11,
        "deletions": 55,
        "changed_files": 5,
        "created_at": "2017-08-20T06:09:57Z",
        "closed_at": "2018-09-26T05:55:38Z",
        "merged_at": null,
        "body": "newly added scripts for download and convert ImageNet dataset don't work. Mostly because of  different path.",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 65,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2017-08-19T12:52:37Z",
        "closed_at": "2019-10-28T18:29:59Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-08-19T12:35:17Z",
        "closed_at": "2017-09-09T02:27:46Z",
        "merged_at": "2017-09-09T02:27:46Z",
        "body": "`str` object doesn't have `decode` method and so `tutorials/rnn/ptb/reader.py` doesn't work on Python3.\r\n\r\nActually we don't have to call `decode` method even if we use Python2 because the data used in the tutorial only include ascii characters.\r\nI wrote the code which have `if` condition for `Py3` to apply this code to some texts include non-ascii characters.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-08-19T10:39:47Z",
        "closed_at": "2019-10-28T18:29:58Z",
        "merged_at": null,
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 58,
        "deletions": 31,
        "changed_files": 4,
        "created_at": "2017-08-18T21:41:19Z",
        "closed_at": "2017-08-27T03:51:43Z",
        "merged_at": "2017-08-27T03:51:43Z",
        "body": "-Fix styling of print statements\r\n-Added Python 2 compatibility\r\n-Fixed code according to PEP 8",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-08-18T10:34:15Z",
        "closed_at": "2017-10-01T09:26:55Z",
        "merged_at": null,
        "body": "now it use `trained_checkpoint_prefix` and `output_directory`",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 28,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-08-18T10:31:21Z",
        "closed_at": "2017-08-18T18:01:27Z",
        "merged_at": "2017-08-18T18:01:26Z",
        "body": "This PR fixes the known bug when evaluating the rotator model in models/ptn. #2240 \r\n\r\nPlease check this out @arkanath @mees ",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-08-18T09:25:39Z",
        "closed_at": "2017-08-22T16:22:13Z",
        "merged_at": "2017-08-22T16:22:13Z",
        "body": "@yuyuz http://python-future.org/compatible_idioms.html?highlight=file#file\r\n\r\nAlso import Queue class in both Python 2 and Python 3  http://python-future.org/compatible_idioms.html?highlight=queue#queue",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 28,
        "deletions": 18,
        "changed_files": 4,
        "created_at": "2017-08-18T09:01:04Z",
        "closed_at": "2017-08-19T19:25:02Z",
        "merged_at": "2017-08-19T19:25:02Z",
        "body": "Used https://pythonhosted.org/six as discussed in #2105 ",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-08-17T21:26:12Z",
        "closed_at": "2019-10-28T18:29:58Z",
        "merged_at": null,
        "body": "Fixes the documentation to reflect the deprecation of is_training as an argument to resnet_arg_scope and moves is_training to be passed into the network directly.'",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2017-08-17T15:21:37Z",
        "closed_at": "2017-08-18T03:12:34Z",
        "merged_at": "2017-08-18T03:12:34Z",
        "body": "Non-existant flag was used to point to the dataset.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-08-16T17:42:14Z",
        "closed_at": "2019-10-28T18:29:58Z",
        "merged_at": null,
        "body": "Removing the extra argument `save_relative_paths` in the exporter API function call. \r\n\r\n------\r\n```Traceback (most recent call last):\r\n  File \"object_detection/export_inference_graph.py\", line 106, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"object_detection/export_inference_graph.py\", line 102, in main\r\n    FLAGS.output_directory)\r\n  File \"/home/ubuntu/yixuan-li/object_detection/exporter.py\", line 376, in export_inference_graph\r\n    optimize_graph, output_collection_name)\r\n  File \"/home/ubuntu/yixuan-li/object_detection/exporter.py\", line 336, in _export_inference_graph\r\n    trained_checkpoint_prefix=trained_checkpoint_prefix)\r\n  File \"/home/ubuntu/yixuan-li/object_detection/exporter.py\", line 294, in _write_graph_and_checkpoint\r\n    save_relative_paths=True)\r\nTypeError: __init__() got an unexpected keyword argument 'save_relative_paths'\r\n```",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 249,
        "deletions": 10,
        "changed_files": 5,
        "created_at": "2017-08-16T05:10:14Z",
        "closed_at": "2019-10-28T18:29:58Z",
        "merged_at": null,
        "body": "Add random vertical flip during image preprocessing",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2017-08-15T14:17:36Z",
        "closed_at": "2017-08-18T03:12:09Z",
        "merged_at": "2017-08-18T03:12:09Z",
        "body": "Fixes bug #2140. Adds bazel workspace file to enable running perspective transformer networks.\r\n\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-08-14T16:07:25Z",
        "closed_at": "2017-11-19T10:26:50Z",
        "merged_at": null,
        "body": "There is a discrepancy between parameters' names: see https://github.com/tensorflow/models/blob/master/object_detection/export_inference_graph.py#L77-L86 and https://github.com/tensorflow/models/blob/master/object_detection/g3doc/running_pets.md#exporting-the-tensorflow-graph .",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-08-14T12:12:36Z",
        "closed_at": "2019-10-28T18:29:57Z",
        "merged_at": null,
        "body": "On default, GFile.read() returns a python string which would depend on the python version. Set GFile to bytes mode and the function will work on both python 2.x and 3.x.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-08-14T04:31:12Z",
        "closed_at": "2019-10-28T18:29:29Z",
        "merged_at": null,
        "body": "_NUM_CLASSES can be derived from labels_to_names dictionary. ",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-08-11T13:02:13Z",
        "closed_at": "2017-09-07T04:49:51Z",
        "merged_at": "2017-09-07T04:49:51Z",
        "body": "Fixes broken visualization in Perspective Transformer Nets, bug #2197.",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2017-08-11T12:17:57Z",
        "closed_at": "2019-10-28T18:29:29Z",
        "merged_at": null,
        "body": "As the script uses the '-c' flag with wget, it allows wget to continue downloading from where the previous download stopped. By skipping the download all-together when the file already exists it renders this flag meaningless, and would render the script broken if a previous download has failed before finishing.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 18,
        "deletions": 12,
        "changed_files": 1,
        "created_at": "2017-08-11T08:21:43Z",
        "closed_at": "2019-10-28T18:29:28Z",
        "merged_at": null,
        "body": "In `FasFasterRCNN`, the input image spatial size (height or width) should be not less than 33. It is checked in `FasterRCNNResnetV1FeatureExtractor._extract_proposal_features`, but missed in `FasterRCNNInceptionResnetV2FeatureExtractor`.\r\nFurthermore, the comments of `FasterRCNNInceptionResnetV2FeatureExtractor._extract_proposal_features` contains this assertion, but the code missed.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-08-11T02:28:52Z",
        "closed_at": "2017-08-20T02:33:32Z",
        "merged_at": null,
        "body": "and add clarifying comment about the last layer bias terms",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2017-08-10T23:56:45Z",
        "closed_at": "2017-08-11T07:19:38Z",
        "merged_at": "2017-08-11T07:19:38Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-08-10T15:32:51Z",
        "closed_at": "2017-11-21T05:46:18Z",
        "merged_at": null,
        "body": "Python 2.7 no longer needs the trailing L and Python 3 treats it as a Syntax Error.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-08-10T13:44:27Z",
        "closed_at": "2019-10-28T18:29:28Z",
        "merged_at": null,
        "body": "To resolve the issue (https://github.com/tensorflow/models/issues/1698).\r\n\r\nDue to this, object detection tests gives import errors.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-08-10T12:48:07Z",
        "closed_at": "2018-01-22T22:43:48Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-08-10T12:33:17Z",
        "closed_at": "2018-01-22T22:45:12Z",
        "merged_at": null,
        "body": "",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 32,
        "deletions": 26,
        "changed_files": 9,
        "created_at": "2017-08-10T10:40:13Z",
        "closed_at": "2018-01-22T22:37:51Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2017-08-10T09:54:14Z",
        "closed_at": "2017-08-14T17:41:58Z",
        "merged_at": "2017-08-14T17:41:58Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-08-09T14:18:59Z",
        "closed_at": "2017-08-17T02:53:56Z",
        "merged_at": "2017-08-17T02:53:56Z",
        "body": "Due to a matplotlib multi-threading issue, the decoder training crashed, see issue ##2160.\r\nThis PR should fix the issue.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-08-09T09:02:50Z",
        "closed_at": "2019-10-28T18:29:28Z",
        "merged_at": null,
        "body": "The previous word2vec load function is depreacted(not warning, occurring error) in the latest gensim.\r\n\r\n```\r\n# deprecate \r\ngensim.models.Word2Vec.load_word2vec_format\r\n# allowed function in the latest gensim\r\ngensim.models.keyedvectors.KeyedVectors.load_word2vec_format\r\n\r\nix deprecated word2vec load function in skip_thougths",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2017-08-09T06:24:25Z",
        "closed_at": "2017-08-09T22:23:14Z",
        "merged_at": "2017-08-09T22:23:14Z",
        "body": "The existing checkpoint for the model\r\nhttp://download.tensorflow.org/models/attention_ocr_2017_05_17.tar.gz\r\nis now broken because of tensor name changes in the attention decoder.\r\nI applied the fix and sent request to @martinwicke to upload it as http://download.tensorflow.org/models/attention_ocr_2017_05_17.fixed.tar.gz",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 147,
        "deletions": 28,
        "changed_files": 3,
        "created_at": "2017-08-08T23:00:18Z",
        "closed_at": "2017-09-06T16:19:40Z",
        "merged_at": "2017-09-06T16:19:40Z",
        "body": "There were several requests to help to run a trained model on a set of images:\r\nhttps://stackoverflow.com/questions/45551656\r\nhttps://stackoverflow.com/questions/45151907\r\nhttps://github.com/tensorflow/models/issues/2137\r\n\r\nThis script serves as an examples how to do it.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-08-08T13:27:02Z",
        "closed_at": "2019-10-28T18:29:27Z",
        "merged_at": null,
        "body": " bug #2157 didn't load the pretrained decoder when training  the volumetric decoder. This patch loads the latest checkpoint model from the given folder.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 0,
        "changed_files": 0,
        "created_at": "2017-08-08T10:08:01Z",
        "closed_at": "2017-08-09T14:13:28Z",
        "merged_at": null,
        "body": "Fixes issue #2140.",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2017-08-08T10:00:34Z",
        "closed_at": "2019-10-28T18:29:27Z",
        "merged_at": null,
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 698,
        "deletions": 512,
        "changed_files": 8,
        "created_at": "2017-08-08T00:13:44Z",
        "closed_at": "2017-08-24T17:05:08Z",
        "merged_at": "2017-08-24T17:05:08Z",
        "body": "Import paths are necessary for this code to work when packaged as a tar with sdist (which is the distribution strategy for CMLE).\r\n\r\nAlso explicit relative imports are considered best practices (and required when `__future__.absolute_import` is used)\r\n\r\nFinally there was a broken property assignment before message initialization in the config options.\r\n\r\nWould it be possible to add an `__init__.py` to this directory as well? (this would prevent users from having to add their own for CMLE).\r\n\r\nWith all these working, I've verified that this works using the following `job_config.yaml`:\r\n\r\n```\r\ntrainingInput:\r\n  scaleTier: CUSTOM\r\n  masterType: complex_model_m_gpu\r\n  workerType: complex_model_m_gpu\r\n  parameterServerType: complex_model_m\r\n```\r\n\r\nAnd the following command:\r\n\r\n```\r\ngcloud ml-engine jobs submit training cifarmultigpu6 \\\r\n    --runtime-version 1.2 \\\r\n    --staging-bucket gs://cifarmultigpu \\\r\n    --config cifar10_estimator/job_config.yaml \\\r\n    --package-path cifar10_estimator/ \\\r\n    --region us-central1 \\\r\n    --module-name cifar10_estimator.cifar10_main \\\r\n    -- \\\r\n    --data_dir=gs://cifarmultigpu/train_data \\\r\n    --model_dir=gs://cifarmultigpu/modeldirs/6 \\\r\n    --is_cpu_ps=True \\\r\n    --force_gpu_compatible=True \\\r\n    --num_gpus=4 \\\r\n    --train_steps=1000 \\\r\n    --run_experiment=True\r\n```\r\n\r\nSome other recommendations to make this more idiomatic:\r\n* use argparse not FLAGS, so that flags will use `-`\r\n* What's the purpose of run_experiment? It should work fine on single worker so no flag is necessary\r\n* Can GPU number not be detected from the environment? Maybe can be passed as a Tensor using `tf.Scaffold`?\r\n\r\n@mari-linhares \r\n\r\n",
        "comments": 22
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 17,
        "changed_files": 1,
        "created_at": "2017-08-07T21:53:40Z",
        "closed_at": "2017-08-24T17:05:33Z",
        "merged_at": "2017-08-24T17:05:33Z",
        "body": "Just a little nit, as I was caught by this edge case.\r\n\r\nAlso, changed open to `tf.gfile.Open` to support reading input data from GCS or HDFS, etc.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 25,
        "deletions": 26,
        "changed_files": 2,
        "created_at": "2017-08-07T14:37:49Z",
        "closed_at": "2019-10-28T18:29:27Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 21,
        "deletions": 21,
        "changed_files": 1,
        "created_at": "2017-08-07T10:10:57Z",
        "closed_at": "2018-04-20T22:44:40Z",
        "merged_at": "2018-04-20T22:44:40Z",
        "body": "This removes clipping operation in preprocessor.py because models require input to be in fixed-point representation.",
        "comments": 20
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-08-06T12:32:13Z",
        "closed_at": "2019-10-28T18:29:27Z",
        "merged_at": null,
        "body": "Evaluation should use 'validation' (not 'train' datasets) datasets in the last part (Apply fine tuned model to some images.) of this walkthrough file.",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 1538,
        "deletions": 0,
        "changed_files": 13,
        "created_at": "2017-08-04T17:32:50Z",
        "closed_at": "2017-08-07T16:13:12Z",
        "merged_at": "2017-08-07T16:13:12Z",
        "body": "Please review the PR @panyx0718 ",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 31,
        "deletions": 34,
        "changed_files": 1,
        "created_at": "2017-08-04T13:50:43Z",
        "closed_at": "2017-08-04T15:02:18Z",
        "merged_at": "2017-08-04T15:02:18Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-08-04T06:34:23Z",
        "closed_at": "2018-02-06T01:30:30Z",
        "merged_at": null,
        "body": "Is [six](https://pythonhosted.org/six/) the way that we want advise contributors to use to achieve compatibility with both Python 2 and Python 3?\r\n\r\nExplicit is better than implicit.  See #2105",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2017-08-04T00:55:24Z",
        "closed_at": "2017-11-21T05:07:34Z",
        "merged_at": null,
        "body": "Also a dict comprehension.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 4,
        "changed_files": 3,
        "created_at": "2017-08-04T00:42:51Z",
        "closed_at": "2017-08-21T17:08:28Z",
        "merged_at": "2017-08-21T17:08:28Z",
        "body": "Also removed `app.run()` from `utils.py` and defined `xrange()` for Python 3",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 7,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2017-08-03T21:20:09Z",
        "closed_at": "2018-06-09T17:49:12Z",
        "merged_at": null,
        "body": "Fixed inconsistency between instructions and scripts",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 131,
        "deletions": 28,
        "changed_files": 5,
        "created_at": "2017-08-03T21:05:55Z",
        "closed_at": "2017-08-10T18:07:39Z",
        "merged_at": "2017-08-10T18:07:39Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-08-03T14:59:36Z",
        "closed_at": "2019-10-28T18:29:27Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-08-03T14:42:38Z",
        "closed_at": "2019-10-28T18:29:26Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-08-03T11:26:41Z",
        "closed_at": "2017-09-05T12:48:43Z",
        "merged_at": "2017-09-05T12:48:43Z",
        "body": "* eve_optimizer --> ac.eve_optimizer\r\n* reset_eve_vars --> ac.reset_eve_vars\r\n* eve_optimizer --> ac.eve_optimizer\r\n\r\nWhy make these changes?  flake8 testing of https://github.com/tensorflow/models on Python 2.7.13\r\n\r\n$ __flake8 . --count --select=E901,E999,F821,F822,F823 --show-source --statistics__\r\n\r\n```\r\n./adversarial_crypto/train_eval.py:252:15: F821 undefined name 'eve_optimizer'\r\n        s.run(eve_optimizer)\r\n              ^\r\n\r\n./adversarial_crypto/train_eval.py:257:15: F821 undefined name 'reset_eve_vars'\r\n        s.run(reset_eve_vars)\r\n              ^\r\n\r\n./adversarial_crypto/train_eval.py:262:19: F821 undefined name 'eve_optimizer'\r\n            s.run(eve_optimizer)\r\n                  ^\r\n```",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-08-03T10:09:19Z",
        "closed_at": "2018-05-22T18:26:48Z",
        "merged_at": null,
        "body": "Minor typo",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 7,
        "deletions": 9,
        "changed_files": 3,
        "created_at": "2017-08-03T08:53:58Z",
        "closed_at": "2018-01-22T22:37:06Z",
        "merged_at": null,
        "body": "* `xrange()` was removed in Python 3\r\n* Also use six to define `long` in Python 3 in a way that works for linters\r\n\r\n@derekjchow Your thoughts on these mods?",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-08-03T08:11:55Z",
        "closed_at": "2017-08-03T23:52:37Z",
        "merged_at": "2017-08-03T23:52:37Z",
        "body": "Spun out of #1981 as [requested](https://github.com/tensorflow/models/pull/1981#issuecomment-316833033) by @derekjchow\r\n\r\nAlso, should there be __commas__ at the end of lines: 82, 84, 86, 88, 90, 92, and 94?",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 13251,
        "deletions": 0,
        "changed_files": 51,
        "created_at": "2017-08-03T07:53:05Z",
        "closed_at": "2019-10-28T18:29:26Z",
        "merged_at": null,
        "body": "I implemented PathNet with Tensorflow, which is to learn a huge neural networks with sparse activation and evolution channel selection, https://arxiv.org/abs/1701.08734.\r\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 153,
        "deletions": 46,
        "changed_files": 5,
        "created_at": "2017-08-02T17:28:28Z",
        "closed_at": "2017-08-03T20:52:02Z",
        "merged_at": "2017-08-03T20:52:02Z",
        "body": "- Corrects some formatting/lint issues.\r\n- Adds seperable convolutions to inception v2.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2017-08-02T13:05:39Z",
        "closed_at": "2019-10-28T18:29:26Z",
        "merged_at": null,
        "body": "Parameter names are different now",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 137,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-08-02T08:45:32Z",
        "closed_at": "2019-10-28T18:29:25Z",
        "merged_at": null,
        "body": "This script performs the following operations:\r\n1. Downloads the Flowers dataset\r\n2. Fine-tunes a MobilenetV1 model on the Flowers training set.\r\n3. Evaluates the model on the Flowers validation set.\r\n\r\nUsage:\r\ncd slim\r\n./scripts/finetune_mobilenet_v1_on_flowers.sh\r\n    default: 1.0 224\r\n./scripts/finetune_mobilenet_v1_on_flowers.sh {1.0,0.75,0.50,0.25}\r\n    {1.0,0.75,0.50,0.25} 224\r\n./scripts/finetune_mobilenet_v1_on_flowers.sh {1.0,0.75,0.50,0.25} {224,192,160,128}",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 10,
        "deletions": 8,
        "changed_files": 1,
        "created_at": "2017-08-02T08:18:15Z",
        "closed_at": "2019-10-28T18:29:25Z",
        "merged_at": null,
        "body": "TensorFlow-Slim use ReLU activations by default for convolution, deconvolution and fully-connected transformations.\r\n\r\nAfter speaking with @cbfinn, the ReLU were unintentional. They were introduced after open-sourcing the code and using TensorFlow-Slim.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 24,
        "deletions": 13,
        "changed_files": 2,
        "created_at": "2017-08-02T00:27:05Z",
        "closed_at": "2017-08-02T23:33:54Z",
        "merged_at": "2017-08-02T23:33:54Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 448,
        "deletions": 13,
        "changed_files": 1,
        "created_at": "2017-08-01T23:07:22Z",
        "closed_at": "2017-08-04T15:04:36Z",
        "merged_at": "2017-08-04T15:04:36Z",
        "body": "Adding instructions on the README about how to run in a distributed mode and how to visualize the model and metrics on TensorBoard",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 16,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2017-08-01T10:43:27Z",
        "closed_at": "2018-05-09T03:23:14Z",
        "merged_at": null,
        "body": "With the recent changes in `export_inference_graph.py`, this PR makes the exporting models documentation up-to-date.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-08-01T07:58:15Z",
        "closed_at": "2019-10-28T18:29:25Z",
        "merged_at": null,
        "body": "Fix for #2079.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 27,
        "deletions": 25,
        "changed_files": 2,
        "created_at": "2017-08-01T00:05:48Z",
        "closed_at": "2017-08-02T21:33:29Z",
        "merged_at": "2017-08-02T21:33:29Z",
        "body": "Changing file to follow examples/how_tos/reading_data/convert_to_records.py",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-07-29T21:02:06Z",
        "closed_at": "2019-10-28T18:29:25Z",
        "merged_at": null,
        "body": "Filename and classes_text need to be of type byte in the cat example and the input of the encoded image is wrong. This is confusing for readers.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 76,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2017-07-28T01:03:08Z",
        "closed_at": "2017-08-16T17:01:45Z",
        "merged_at": null,
        "body": "Adds hook that prints examples per second and a loss hook to view loss more often as that aspect of estimator is hard coded to only show loss every 100 steps, which is painful for CPU.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 109,
        "deletions": 128,
        "changed_files": 2,
        "created_at": "2017-07-28T00:56:59Z",
        "closed_at": "2017-08-29T21:15:28Z",
        "merged_at": "2017-08-29T21:15:28Z",
        "body": "Adds MKL support to the script by allowing the users to force the data_format.  \r\n\r\nI also formatted and fixed all the pylint issues in these files so in the future merging will be clearning.\r\n\r\nUp next I will remove almost all of the wrapper functions and leverage params for everything as that is what is suggested for estimators, e.g. num_gpus, variable_strategy and such.   ",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 19,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-07-28T00:51:21Z",
        "closed_at": "2017-08-28T17:05:38Z",
        "merged_at": null,
        "body": "Add data_format flag to allow forcing a specific data_format without taking away the logic that makes the script \"just work\".",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 7,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-07-28T00:45:06Z",
        "closed_at": "2017-08-03T17:24:03Z",
        "merged_at": null,
        "body": "Adding a batch_size knob to export_inference_graph to allow user to specify batch size for their exported model.\r\n\r\nDefaulted to None so batch size can be decided at model runtime. ",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1334,
        "deletions": 831,
        "changed_files": 23,
        "created_at": "2017-07-27T22:07:21Z",
        "closed_at": "2017-07-28T06:13:34Z",
        "merged_at": "2017-07-28T06:13:34Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 15,
        "changed_files": 6,
        "created_at": "2017-07-27T21:55:34Z",
        "closed_at": "2017-07-28T19:00:24Z",
        "merged_at": "2017-07-28T19:00:24Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2017-07-27T21:00:17Z",
        "closed_at": "2017-07-28T16:31:07Z",
        "merged_at": "2017-07-28T16:31:07Z",
        "body": "For the /lfads model, this fixes an issue when using the \"stitching\" feature (involving the alignment bias vectors across recording sessions). Attn @sussillo ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 19,
        "deletions": 13,
        "changed_files": 1,
        "created_at": "2017-07-26T15:21:36Z",
        "closed_at": "2017-07-27T16:44:44Z",
        "merged_at": "2017-07-27T16:44:44Z",
        "body": "Renaming ParamServerDeviceSetter to GpuParamServerDeviceSetter made my performance guide easier to follow.  I also moved FLAGS.num_gpus up a level so remove all \"global\" variables from the functions do the device setting.  This will make it easier for people to cut and paste.\r\n\r\nI also added excessive comments.  \r\n\r\nI also removed the b/.  This will is one of our simple examples and we will update it over time, not need to leave a TODO for code that does not exist yet.  ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-07-25T19:21:20Z",
        "closed_at": "2017-07-27T22:11:46Z",
        "merged_at": "2017-07-27T22:11:46Z",
        "body": "Updated March 13 to r1.0, README implementation reference to r0.7 obsolete and potentially misleading",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-07-25T19:06:34Z",
        "closed_at": "2017-07-25T20:33:14Z",
        "merged_at": null,
        "body": "https://github.com/tensorflow/models/issues/2040",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-07-25T14:52:30Z",
        "closed_at": "2019-10-28T18:29:24Z",
        "merged_at": null,
        "body": "For the denoising autoencoder, I think it should be 'self.scale' not 'scale' in the graph. If not ,I think it unnecessary to fefine placeholder of scale because it is not connected wtih any node.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-07-25T00:00:22Z",
        "closed_at": "2019-10-28T18:29:24Z",
        "merged_at": null,
        "body": "it is not used",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-07-24T17:33:06Z",
        "closed_at": "2017-07-25T06:24:33Z",
        "merged_at": "2017-07-25T06:24:33Z",
        "body": "```label_offset + label_bytes``` gives the correct offset for both cifar10 and cifar100",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 92,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-07-24T07:03:36Z",
        "closed_at": "2019-10-28T18:29:24Z",
        "merged_at": null,
        "body": "I signed it!",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 0,
        "changed_files": 0,
        "created_at": "2017-07-22T10:43:52Z",
        "closed_at": "2019-10-28T18:29:24Z",
        "merged_at": null,
        "body": "2017-06-23",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-07-21T17:04:12Z",
        "closed_at": "2019-10-28T18:29:23Z",
        "merged_at": null,
        "body": "When clone.scope is empty a warning(info) like below occurs.\r\n```\r\nINFO:tensorflow:Summary name /clone_loss is illegal; using clone_loss instead.\r\n```\r\n\r\nSince '/' is contained in clone.scope, removed it from '/clone_loss' string.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 12,
        "deletions": 97,
        "changed_files": 2,
        "created_at": "2017-07-21T16:32:59Z",
        "closed_at": "2019-10-28T18:29:22Z",
        "merged_at": null,
        "body": "This commit fixes the bug described in issue #1976; it also makes the download_and_preprocess_flowers_mac.sh script redundant by checking whether shuf or gshuf are available. \r\n\r\nWould 2 different PRs be preferred? I could do that, too.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2017-07-21T13:34:43Z",
        "closed_at": "2019-10-28T18:29:22Z",
        "merged_at": null,
        "body": "The [\"using your own dataset\" tutorial](https://github.com/tensorflow/models/blob/master/object_detection/g3doc/using_your_own_dataset.md) says \"Label maps should always start from id 1.\" However, the current code still has some inconsistencies.\r\n\r\nRight now, the default value for `label_id_offset` in `eval_util.py`'s [`evaluate_detection_results_pascal_voc` method](https://github.com/tensorflow/models/blob/master/object_detection/eval_util.py#L111-L125) is 0 (instead of 1). When I run an evaluation using a pre-trained model on the PASCAL VOC, for example, `num_classes` will be 21 instead of 20, giving me the following warning.\r\n\r\n```bash\r\nWARNING:root:The following classes have no ground truth examples: 0\r\n```\r\nChanging the default value of `label_id_offset` to 1 will fix it.\r\n\r\n### Questions\r\nShould the comment in L111 (\"Pascal VOC evaluator assumes foreground index starts from zero.\") also change from \"zero\" to \"one\"?\r\n\r\nBy the way, what is allowed as the `categories`?\r\n- At least, the ids should start from 1. The `label_id_offset` can allow for other cases.\r\n- Maybe they should also be in an increasing order and consecutive? I'm not sure whether anything will break if this condition is not satisfied (e.g. the label map is 1=cat1, 5=cat5, 3=cat3). It seems like some codes are making these assumptions?\r\nIf these should be satisfied, maybe some checks can be added in `label_map_util.py`'s [`_validate_label_map` method](https://github.com/tensorflow/models/blob/master/object_detection/utils/label_map_util.py#L25).\r\n\r\nPossibly related issues: #1856, #1936 \r\n\r\n@derekjchow Could you please take a look? Thank you!",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 7,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-07-21T08:01:20Z",
        "closed_at": "2018-10-31T22:54:04Z",
        "merged_at": null,
        "body": "As described in https://github.com/tensorflow/tensorflow/issues/11184 , the script `download_and_convert_flowers.py` could attempt to convert the hidden image index file `.DS_Store` that OSX creates whenever a user opens a Finder window on a directory containing images (for example, because the user was monitoring the status of the script's target directory). This patch adds some filename filtering to the script to prevent the script from picking up .DS_Store. It also prevents the script from picking up any other hidden files (at least for files that are hidden because their names start with \".\") or non-JPEG files that might appear in the temporary directory.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3518,
        "deletions": 21,
        "changed_files": 21,
        "created_at": "2017-07-21T02:12:54Z",
        "closed_at": "2017-07-21T04:01:22Z",
        "merged_at": "2017-07-21T04:01:22Z",
        "body": "This open sources the code for Unsupervised Pixel-Level Domain Adaptation with Generative Adversarial Networks (https://arxiv.org/abs/1612.05424) in preparation for CVPR.  I've tested the code with bazel & tensorflow 1.1, and was able to set it up and reproduce results from scratch.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 19,
        "deletions": 52,
        "changed_files": 1,
        "created_at": "2017-07-21T01:30:21Z",
        "closed_at": "2019-10-28T18:29:22Z",
        "merged_at": null,
        "body": "Perform more efficient per-example gradient calculation with respect to filters of conv2d operations",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 3015,
        "deletions": 0,
        "changed_files": 24,
        "created_at": "2017-07-21T00:32:20Z",
        "closed_at": "2017-07-21T03:51:34Z",
        "merged_at": "2017-07-21T03:51:34Z",
        "body": "This is the pull request for adding the ptn directory in tensorflow/models",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-07-20T21:27:25Z",
        "closed_at": "2017-07-21T02:02:52Z",
        "merged_at": "2017-07-21T02:02:52Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 60,
        "deletions": 10,
        "changed_files": 3,
        "created_at": "2017-07-20T08:33:15Z",
        "closed_at": "2018-05-09T03:25:15Z",
        "merged_at": null,
        "body": "The ResizeImage configuration in Preprocess allows to choose the resize method, however the method used when using ImageResizer is always bilinear.\r\n\r\nThis PR allows the user to configure the method to use in ImageResizer, and adds a flag `random_method` to use a random resize method.\r\n\r\nA few things I am not sure though:\r\n- The `random_method` flag conflicts with the `method` configuration: what should the user expect to happen when both are set? Do you see a better way to have both features?\r\n- There is some code that is duplicated with ResizeImage and ImageResizer. Should it be merged into a single configuration?\r\n\r\nLet me know if I need to change anything :)",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 18,
        "deletions": 11,
        "changed_files": 1,
        "created_at": "2017-07-19T11:12:43Z",
        "closed_at": "2018-05-09T03:24:50Z",
        "merged_at": null,
        "body": "Trying to force the matches when there is no proposal will raise an error.\r\nI changed the `_match_when_rows_are_non_empty` function to only force the matches when the number of anchors is greater than 0. Otherwise, we use the previous matches value.\r\n\r\nThis is fixing: https://stackoverflow.com/questions/44995679/reduction-axis-1-is-empty-in-shape-x-0",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-07-18T18:36:25Z",
        "closed_at": "2017-07-18T19:41:55Z",
        "merged_at": "2017-07-18T19:41:55Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 87,
        "deletions": 71,
        "changed_files": 6,
        "created_at": "2017-07-18T18:34:48Z",
        "closed_at": "2018-01-27T00:14:47Z",
        "merged_at": null,
        "body": "flake8 testing of https://github.com/tensorflow/models on Python 2.7.13\r\n\r\n$ __flake8 . --count --select=E901,E999,F821,F822,F823 --show-source --statistics__\r\n\r\n```\r\n./cognitive_mapping_and_planning/cfgs/config_distill.py:94:33: F821 undefined name 'resnet_v2_50_path'\r\n  args.solver.pretrained_path = resnet_v2_50_path\r\n                                ^\r\n\r\n./cognitive_mapping_and_planning/src/depth_utils.py:26:19: F821 undefined name 'utils'\r\n  camera_matrix = utils.Foo(xc=xc, zc=zc, f=f)\r\n                  ^\r\n\r\n./cognitive_mapping_and_planning/src/file_utils.py:36:14: F821 undefined name 'file_name'\r\n  with fopen(file_name, 'r') as f:\r\n             ^\r\n\r\n./cognitive_mapping_and_planning/src/file_utils.py:38:10: F821 undefined name 'np'\r\n    II = np.array(I)\r\n         ^\r\n\r\n./cognitive_mapping_and_planning/src/graph_utils.py:453:7: F821 undefined name 'logging'\r\n      logging.error('Did not find any good nodes.')\r\n      ^\r\n\r\n./cognitive_mapping_and_planning/src/graph_utils.py:468:14: F821 undefined name 'get_path_ids'\r\n      path = get_path_ids(start_node_ids[i], end_node_ids[i], pred_map)\r\n             ^\r\n\r\n./cognitive_mapping_and_planning/src/graph_utils.py:511:7: F821 undefined name 'logging'\r\n      logging.error('Did not find any good nodes.')\r\n      ^\r\n\r\n./cognitive_mapping_and_planning/src/graph_utils.py:517:14: F821 undefined name 'get_path_ids'\r\n      path = get_path_ids(start_node_ids[i], end_node_ids[i], pred_map)\r\n             ^\r\n\r\n./cognitive_mapping_and_planning/src/graph_utils.py:547:14: F821 undefined name 'get_path_ids'\r\n      path = get_path_ids(start_node_ids[i], end_node_ids[i], pred_map)\r\n             ^\r\n\r\n./cognitive_mapping_and_planning/src/map_utils.py:143:7: F821 undefined name 'logging'\r\n      logging.error('Unknown resizing method')\r\n      ^\r\n\r\n./cognitive_mapping_and_planning/tfcode/vision_baseline_lstm.py:152:21: F821 undefined name 'is_training'\r\n        is_training=is_training)\r\n                    ^\r\n```",
        "comments": 9
    },
    {
        "merged": false,
        "additions": 27,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-07-18T18:14:47Z",
        "closed_at": "2018-01-29T20:37:09Z",
        "merged_at": null,
        "body": "The owner of the tensorflow GitHub ID would need to go to https://travis-ci.org/profile and flip on the repository switch.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 8,
        "deletions": 7,
        "changed_files": 2,
        "created_at": "2017-07-18T16:11:45Z",
        "closed_at": "2019-10-28T18:28:43Z",
        "merged_at": null,
        "body": "As of 444310f2, download_imagenet.sh expects an absolute path the synsets file. But,\r\ndownload_and_preprocess_imagenet.sh specifies the synsets file as a relative path.\r\n\r\nAlso, there were a couple of fixes to download_image.sh that are also needed in\r\ndownload_imagenet.sh (dd983ea6, 9997b250).",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-07-18T14:22:11Z",
        "closed_at": "2017-08-09T09:02:08Z",
        "merged_at": null,
        "body": "The previous word2vec load function is depreacted(not warning, occurring error) in the latest gensim.\r\n\r\n```\r\n# deprecate \r\ngensim.models.Word2Vec.load_word2vec_format\r\n# allowed function in the latest gensim\r\ngensim.models.keyedvectors.KeyedVectors.load_word2vec_format",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-07-17T02:41:01Z",
        "closed_at": "2019-10-28T18:28:43Z",
        "merged_at": null,
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2017-07-16T02:18:27Z",
        "closed_at": "2017-07-27T22:05:00Z",
        "merged_at": "2017-07-27T22:05:00Z",
        "body": "Fix for #1960. Fix pre-trained model download instructions in cognitive_mapping_and_planning/README.md.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 9,
        "changed_files": 2,
        "created_at": "2017-07-15T14:49:05Z",
        "closed_at": "2017-07-17T16:28:42Z",
        "merged_at": "2017-07-17T16:28:42Z",
        "body": "- Make the indentation in python code blocks consistent by changing 4 spaces to 2 spaces. (Some are already correct.)\r\n- Minor typo\r\n\r\nRepeat #1955 due to a problem with CLA",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-07-15T02:21:18Z",
        "closed_at": "2017-07-17T17:26:26Z",
        "merged_at": "2017-07-17T17:26:26Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-07-14T20:48:08Z",
        "closed_at": "2019-10-28T18:28:43Z",
        "merged_at": null,
        "body": "Remove_invalid_boxes breaks when the detected_boxes is empty. The fix checks if there is any detected_boxes as an input.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 247,
        "deletions": 45,
        "changed_files": 7,
        "created_at": "2017-07-14T19:19:29Z",
        "closed_at": "2017-07-17T17:41:32Z",
        "merged_at": "2017-07-17T17:41:32Z",
        "body": "This change adds an op that will take a text vocabulary file, read\r\nit, and use it to create a pre-computed word embedding vector.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 9,
        "changed_files": 2,
        "created_at": "2017-07-14T07:47:06Z",
        "closed_at": "2017-07-15T14:47:44Z",
        "merged_at": null,
        "body": "Make the indentation in python code blocks consistent by changing 4 spaces to 2 spaces. (Some are already correct.)",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-07-14T07:30:48Z",
        "closed_at": "2017-07-27T22:05:51Z",
        "merged_at": "2017-07-27T22:05:51Z",
        "body": "From #1874:\r\n\r\n> does slim support the tensorboard? I did not find any tutorial on it.\r\n\r\nHopefully, this will make the tutorial clearer.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-07-14T02:41:17Z",
        "closed_at": "2017-07-17T16:31:22Z",
        "merged_at": "2017-07-17T16:31:22Z",
        "body": "Fixes #1841",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1319,
        "deletions": 832,
        "changed_files": 23,
        "created_at": "2017-07-13T23:55:10Z",
        "closed_at": "2017-07-19T17:29:50Z",
        "merged_at": null,
        "body": "- Fix long lines in inception_v1\r\n- Add option in inception_v2 to use seperable convolution\r\n- Change flag overriding image size in export_inference_graph",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-07-13T16:51:58Z",
        "closed_at": "2019-10-28T18:28:43Z",
        "merged_at": null,
        "body": "Convert `means` parameter of `subtract_channel_mean` function from type `RepeatedScalarContainer` to a list of floats.\r\n\r\nFix `TypeError: Expected float32, got <google.protobuf.pyext._message.RepeatedScalarContainer object at 0x7fb7e6d65618> of type 'RepeatedScalarContainer' instead.`",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-07-13T15:33:49Z",
        "closed_at": "2017-07-27T22:06:55Z",
        "merged_at": "2017-07-27T22:06:55Z",
        "body": "- 2 CPUs -> 2 GPUs\r\n- is_cpu_ps=True",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-07-13T03:02:49Z",
        "closed_at": "2017-07-13T18:26:18Z",
        "merged_at": "2017-07-13T18:26:18Z",
        "body": "Same as #1837, but this is an example in `slim/export_inference_graph.py` instead of `slim/README.md`.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 33,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-07-11T15:25:42Z",
        "closed_at": "2017-07-12T17:50:58Z",
        "merged_at": "2017-07-12T17:50:58Z",
        "body": "Extracted from first commit for each directory. Should be a reasonably good proxy.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2017-07-11T07:26:11Z",
        "closed_at": "2017-07-18T20:12:09Z",
        "merged_at": "2017-07-18T20:12:09Z",
        "body": "In reader.py, GFile returns an object of type bytes independently from the Python version. Therefore, the object must be decoded as string in any case. Removed the check of Python version",
        "comments": 13
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-07-11T03:53:43Z",
        "closed_at": "2019-10-28T18:28:42Z",
        "merged_at": null,
        "body": "This pull request is according to [#issue1916](https://github.com/tensorflow/models/issues/1916)",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 30,
        "deletions": 17,
        "changed_files": 2,
        "created_at": "2017-07-11T03:19:07Z",
        "closed_at": "2017-07-13T16:38:47Z",
        "merged_at": "2017-07-13T16:38:47Z",
        "body": "Like #1893, the directories to run from should be the root of the git directory, i.e. `tensorflow/models`. This PR is fixing `preparing_inputs.md` for consistency.\r\n\r\nHowever, now that we run `create_pet_tf_record.py` from the root directory, this introduces some complication. Now we need to specify the flag `--label_map_path=object_detection/data/pet_label_map.pbtxt`, because its default value is `data/pet_label_map.pbtxt` (see [here](https://github.com/tensorflow/models/blob/master/object_detection/create_pet_tf_record.py#L45)). This makes sense because the file is in the `object_detection` directory, and if the script is run from there, the default value will work fine.\r\n\r\nBut does it make sense to edit the default value to `object_detection/data/pet_label_map.pbtxt` so that it's cleaner in the tutorials (but then it wouldn't be the relative path from the file itself)?\r\n\r\n@derekjchow Could you please take a look? Thank you!",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 59,
        "deletions": 20,
        "changed_files": 6,
        "created_at": "2017-07-10T23:29:07Z",
        "closed_at": "2017-07-13T00:03:15Z",
        "merged_at": "2017-07-13T00:03:15Z",
        "body": "- Set spatial squeeze to true for resnets\r\n- Make activations configurable for resnets\r\n- Make batch norm configurable for resnets\r\n- Fix some bad comment wrapping in vgg.py.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 34,
        "deletions": 15,
        "changed_files": 4,
        "created_at": "2017-07-10T16:27:46Z",
        "closed_at": "2019-06-17T19:58:45Z",
        "merged_at": null,
        "body": "",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 10,
        "changed_files": 3,
        "created_at": "2017-07-10T05:56:31Z",
        "closed_at": "2017-07-11T02:49:08Z",
        "merged_at": "2017-07-11T02:49:08Z",
        "body": "\u2026using own data to train object recognition models.\r\n\r\n\r\nSix was erroneously removed when it is still used in the file.  Running /object_detection/eval.py will give an error and not run because of this.  \r\n\r\nAlso, this commit (https://github.com/tensorflow/models/commit/88a05515fcc13d6a6fb8224b5c4465414d0d53c2) created the function _validate_label_map in object_detection/utils/label_map_util.py which makes sure that label_map ids are greater than zero, but in the two object detection examples (the pets and pascal datasets) still use items with an id of zero.  I haven't run these examples, but this will give an error if you have items of id 0 like in these two instances.",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-07-08T02:10:58Z",
        "closed_at": "2017-07-27T22:10:46Z",
        "merged_at": null,
        "body": "Single word change and removed the TODO.  How variables are managed will change dramatically after the API update.  I am ok adding the TODO back.  I might have been hasty.  \r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-07-07T22:20:33Z",
        "closed_at": "2019-10-28T18:28:42Z",
        "merged_at": null,
        "body": "The method load_batch has an argument is_training which is passed on to the inception pre-processing code (which does two different versions of preprocessing for training vs. eval). This should set to true in example where we're training something.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-07-07T15:53:10Z",
        "closed_at": "2017-07-07T22:44:07Z",
        "merged_at": "2017-07-07T22:44:07Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 298,
        "deletions": 76,
        "changed_files": 4,
        "created_at": "2017-07-07T15:39:38Z",
        "closed_at": "2017-07-28T22:30:49Z",
        "merged_at": "2017-07-28T22:30:49Z",
        "body": "",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-07-07T14:30:03Z",
        "closed_at": "2017-07-08T13:21:15Z",
        "merged_at": null,
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 3371,
        "deletions": 0,
        "changed_files": 15,
        "created_at": "2017-07-06T17:54:01Z",
        "closed_at": "2017-07-06T19:23:42Z",
        "merged_at": "2017-07-06T19:23:42Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2017-07-06T09:23:41Z",
        "closed_at": "2019-10-28T18:28:42Z",
        "merged_at": null,
        "body": "1. tf.constant could not accept a proto field correctly. 2. height/width should be int32 instead of float",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-07-06T06:57:49Z",
        "closed_at": "2017-07-13T00:09:21Z",
        "merged_at": "2017-07-13T00:09:21Z",
        "body": "Change the hard-coded split name in slim's [`export_inference_graph.py`](https://github.com/tensorflow/models/blob/master/slim/export_inference_graph.py) from \"validation\" to \"train\" to support the MNIST and CIFAR10 datasets.\r\n\r\nThe current code uses the \"validation\" split to `get_dataset` from `dataset_factory`. While the ImageNet and flowers datasets have \"train\" and \"validation\" splits, the MNIST and CIFAR10 datasets only have \"train\" and \"test\" splits. Therefore, using `export_inference_graph.py` with MNIST or CIFAR10 results in an error.\r\n\r\nSince `dataset = dataset_factory.get_dataset(...)` is called just to get `dataset.num_classes` for the next line, the choice of split should not matter. I changed to \"train\" because it's the only split that exists for all four datasets.\r\n\r\n@sguada",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 5,
        "changed_files": 3,
        "created_at": "2017-07-06T06:38:12Z",
        "closed_at": "2017-07-07T22:40:21Z",
        "merged_at": "2017-07-07T22:40:21Z",
        "body": "A previous commit fixed the runtime code, this PR fixes the compatibility issues for the unit tests.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 2,
        "changed_files": 3,
        "created_at": "2017-07-06T01:49:06Z",
        "closed_at": "2017-07-06T23:34:24Z",
        "merged_at": "2017-07-06T23:34:24Z",
        "body": "Fixes the reversions that were merged in https://github.com/tensorflow/models/pull/1551",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 121,
        "deletions": 4,
        "changed_files": 3,
        "created_at": "2017-07-05T21:11:43Z",
        "closed_at": "2017-07-13T00:08:18Z",
        "merged_at": "2017-07-13T00:08:18Z",
        "body": "The spatial attention mechanism described in [the paper](https://arxiv.org/abs/1704.03549), but was missing in the initial open source release. This pull request fills the gap. It is disabled by default to make the default configuration compatible with already released checkpoints.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 27,
        "deletions": 24,
        "changed_files": 1,
        "created_at": "2017-07-05T17:16:12Z",
        "closed_at": "2017-07-10T14:25:28Z",
        "merged_at": "2017-07-10T14:25:28Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 206,
        "deletions": 2,
        "changed_files": 5,
        "created_at": "2017-07-05T16:46:40Z",
        "closed_at": "2017-07-07T20:19:27Z",
        "merged_at": "2017-07-07T20:19:27Z",
        "body": "Correct documentation so all commands should be run from the root\r\nof the git directory.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-07-05T16:37:19Z",
        "closed_at": "2017-07-13T00:12:41Z",
        "merged_at": "2017-07-13T00:12:41Z",
        "body": "Update the install instructions to provide the correct pip command to install the gpu version of tensorflow.\r\n\r\nAlso addresses a concern from issue #1849 from a user who couldn't install tensorflow correctly.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-07-05T04:25:09Z",
        "closed_at": "2017-07-05T16:30:14Z",
        "merged_at": "2017-07-05T16:30:14Z",
        "body": "iteritems -> items\r\n\r\nI've tried Pets Dataset tutorial locally (not using GCP) with Python 3.6.0.\r\nhttps://github.com/tensorflow/models/blob/master/object_detection/g3doc/running_pets.md\r\n\r\nAnd I got error like below.\r\n```\r\nAttributeError: \u2018dict\u2019 object has no attribute \u2018iteritems\u2019\r\n```",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-07-04T13:02:18Z",
        "closed_at": "2017-07-07T22:50:03Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-07-04T11:44:38Z",
        "closed_at": "2017-07-13T00:13:22Z",
        "merged_at": "2017-07-13T00:13:21Z",
        "body": "The last line in slim/download_and_convert_data.py maybe wrong, I believe the right thing should be dataset_name instead of dataset_dir, a small problem. Wish you a good day!",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-07-04T02:42:15Z",
        "closed_at": "2017-07-10T14:26:00Z",
        "merged_at": "2017-07-10T14:26:00Z",
        "body": "* We do this because we want rules outside of slim to be able to depend on it in order to pull in slim models.\r\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2017-07-03T15:41:47Z",
        "closed_at": "2017-07-10T18:20:09Z",
        "merged_at": null,
        "body": "Fixed the .md to use 'object_detection' directory instead of 'models' as the text implied",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-07-03T03:09:51Z",
        "closed_at": "2017-07-13T00:16:58Z",
        "merged_at": "2017-07-13T00:16:58Z",
        "body": "--logtostderr causes the following error: E tensorflow/examples/label_image/main.cc:319] Unknown argument --logtostderr",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 15,
        "deletions": 25,
        "changed_files": 12,
        "created_at": "2017-06-30T23:31:55Z",
        "closed_at": "2019-06-17T19:57:05Z",
        "merged_at": null,
        "body": "This PR fixes issues flagged by lgtm.com code queries. Some are minors and some should fix errors or unintentional code behaviour.\r\n\r\nI think the suggested fixes make sense but someone more familiar with the code base and what was the initial intention may suggest an alternative way. In particular there seem to be many `if` `elif` blocks that look like they could throw errors due to non initialised variables.\r\n\r\nThe standard lgtm engineering analytics highlights dependencies, vulnerabilities and currently flag [184 alerts](https://lgtm.com/projects/g/tensorflow/models/alerts/) but you can investigate further by writing [your own custom queries](https://lgtm.com/docs/ql/about-ql) to explore your code base.\r\n\r\nI personally find lgtm alerts most useful when using [PR integration](https://lgtm.com/docs/lgtm/config/pr-integration) as it allows to check and deal with potential issues before they find their way into master - for instance several of the alerts fixed by this PR were introduced in recent commits (notably 5b9d9097cc255becef4b5460c4b951c143d7a380 and 3a65897989c4711c2b0d8544a1a8a455ac654cec).\r\n\r\nFull disclosure: I work on lgtm.com (and play with tensorflow), hence my interest!\r\n\r\nHope that helps, any question please ask.",
        "comments": 15
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2017-06-30T11:16:38Z",
        "closed_at": "2017-06-30T16:33:17Z",
        "merged_at": "2017-06-30T16:33:17Z",
        "body": "A lot of people (including me!) seemed to miss the [installation instruction](https://github.com/tensorflow/models/blob/master/object_detection/g3doc/installation.md), especially the Protobuf compilation step, when trying out the [tutorial](https://github.com/tensorflow/models/blob/master/object_detection/object_detection_tutorial.ipynb) or other files for the first time. I hope this would make the tutorial clearer and avoid future confusion.\r\n\r\nRelated issues: #1562, #1591, #1595, #1604",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-06-30T06:38:13Z",
        "closed_at": "2017-06-30T16:34:07Z",
        "merged_at": "2017-06-30T16:34:07Z",
        "body": "Closes #1807 ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 16,
        "deletions": 12,
        "changed_files": 1,
        "created_at": "2017-06-30T01:14:50Z",
        "closed_at": "2017-06-30T23:45:35Z",
        "merged_at": "2017-06-30T23:45:35Z",
        "body": "- Fix CDNA transformation bug where transformed channels of color and masks were combined incorrectly.\r\n- Remove for loop over batch size in implementation of CDNA transformation. This speeds up the building of the graph.\r\n\r\n@cbfinn ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 849,
        "deletions": 0,
        "changed_files": 5,
        "created_at": "2017-06-29T22:23:51Z",
        "closed_at": "2017-07-06T00:22:41Z",
        "merged_at": "2017-07-06T00:22:41Z",
        "body": "Approved internally. Now a PR to merge into models to pair with incoming new TF performance tutorial.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-06-29T09:08:30Z",
        "closed_at": "2017-06-29T16:38:51Z",
        "merged_at": "2017-06-29T16:38:51Z",
        "body": "Fixed a small typo which I ran into while trying to setup prediction on clouML.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 1,
        "changed_files": 8,
        "created_at": "2017-06-28T23:01:58Z",
        "closed_at": "2017-06-29T20:51:46Z",
        "merged_at": "2017-06-29T20:51:46Z",
        "body": "During evaluation, should not shuffle and num_reader should be 1. Or only (num_examples / num_reader) distinct samples are evaluated. ",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-06-28T21:26:26Z",
        "closed_at": "2017-07-27T22:13:30Z",
        "merged_at": "2017-07-27T22:13:30Z",
        "body": "10 character change to make cell 28 run without erroring in slim_walkthrough notebook ",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 142,
        "deletions": 7,
        "changed_files": 4,
        "created_at": "2017-06-28T18:51:04Z",
        "closed_at": "2017-07-22T01:42:22Z",
        "merged_at": "2017-07-22T01:42:22Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 13,
        "deletions": 14,
        "changed_files": 5,
        "created_at": "2017-06-27T20:16:57Z",
        "closed_at": "2017-06-27T21:56:18Z",
        "merged_at": "2017-06-27T21:56:18Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-06-27T06:24:34Z",
        "closed_at": "2017-06-28T01:04:47Z",
        "merged_at": "2017-06-28T01:04:47Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-06-27T06:01:26Z",
        "closed_at": "2017-06-30T18:03:25Z",
        "merged_at": "2017-06-30T18:03:25Z",
        "body": "",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 33,
        "deletions": 33,
        "changed_files": 2,
        "created_at": "2017-06-27T03:54:03Z",
        "closed_at": "2017-06-28T06:30:46Z",
        "merged_at": "2017-06-28T06:30:46Z",
        "body": "- `preparing_inputs.md`: The second `--data_dir` flag for preparing PASCAL VOC dataset is incorrect and inconsistent with the first one.\r\n- `running_pets.md`: Fix typos and wrong links.\r\n- Both: Fix styles, especially `inline code` for file/directory names to improve readability.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-06-26T23:17:41Z",
        "closed_at": "2019-10-28T18:28:42Z",
        "merged_at": null,
        "body": "If `WORK_DIR` is not absolute, the `download_imagenet.sh` shell might not be able to locate synsets.txt",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-06-26T17:55:19Z",
        "closed_at": "2017-06-27T16:30:08Z",
        "merged_at": "2017-06-27T16:30:08Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-06-26T09:27:50Z",
        "closed_at": "2017-06-27T21:04:25Z",
        "merged_at": "2017-06-27T21:04:25Z",
        "body": "iteritems() -> items()",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 71,
        "deletions": 2,
        "changed_files": 4,
        "created_at": "2017-06-26T07:44:17Z",
        "closed_at": "2017-07-04T08:25:48Z",
        "merged_at": null,
        "body": "MobileNet has two hyperparameters. One is the input image size,\r\nthe other is the depth multiplier. Some modifications are needed\r\nso that we can use export_inference_graph.py to export all the\r\ngraphs for current available MobileNet Models.\r\n\r\n1. --override_default_image_size=true: allowing changing image size to\r\n   192, 160, and 128\r\n2. mobilenet_v1_0.75, mobilenet_v1_0.5, and mobilenet_v1_0.25 for depth\r\n   multipler = 0.75, 0.5, and 0.25",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-06-26T05:18:46Z",
        "closed_at": "2017-07-14T22:01:59Z",
        "merged_at": null,
        "body": "",
        "comments": 12
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-06-25T12:47:04Z",
        "closed_at": "2017-06-29T16:42:50Z",
        "merged_at": null,
        "body": "As described in https://github.com/tensorflow/models/pull/1610#issuecomment-310883904, the previous PR https://github.com/tensorflow/models/pull/1593 is not compatible with `master` branch.\r\n\r\nProblem comes from that `str` and `tuple` object in the same container cannot be sorted in Python3.\r\n- So my solution is to make `tuple` key merged into one single `str` and make them separated by defined character.\r\n- (also  another solution for that https://github.com/tensorflow/tensorflow/pull/11039)",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 4,
        "changed_files": 4,
        "created_at": "2017-06-25T05:20:49Z",
        "closed_at": "2017-06-28T20:57:59Z",
        "merged_at": "2017-06-28T20:57:59Z",
        "body": "With these changes the new `object_detection/eval.py` script runs under python 3.\r\n\r\nBTW, the `train.py` script has python 3 compat issues as well but they seem to be problems in tensorflow itself when I have opened [another PR](https://github.com/tensorflow/tensorflow/pull/11039) for.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2017-06-25T03:54:33Z",
        "closed_at": "2017-07-17T06:57:48Z",
        "merged_at": null,
        "body": "spatial_squeeze should be True like resnet_v1.py ,  or the tf.losses.softmax_cross_entropy will get shape error!",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-06-24T23:50:34Z",
        "closed_at": "2017-06-25T06:52:18Z",
        "merged_at": "2017-06-25T06:52:18Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-06-24T22:21:43Z",
        "closed_at": "2017-06-25T06:54:06Z",
        "merged_at": "2017-06-25T06:54:06Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-06-23T10:15:01Z",
        "closed_at": "2017-06-23T23:19:11Z",
        "merged_at": "2017-06-23T23:19:11Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-06-23T07:23:19Z",
        "closed_at": "2017-07-14T22:02:17Z",
        "merged_at": null,
        "body": "There is a little path ambiguity.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-06-23T01:48:51Z",
        "closed_at": "2017-06-28T01:06:10Z",
        "merged_at": "2017-06-28T01:06:10Z",
        "body": "According to the code below:\r\n\r\n```python\r\nif key is not None:\r\n      combined_message = tf.concat(axis=1, values=[message, key])\r\nelse:\r\n      combined_message = message\r\n```\r\n\r\nIf the key=None, combined_message is just message, not the key.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4887,
        "deletions": 0,
        "changed_files": 15,
        "created_at": "2017-06-22T22:41:53Z",
        "closed_at": "2017-06-23T16:47:51Z",
        "merged_at": "2017-06-23T16:47:51Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-06-22T20:33:13Z",
        "closed_at": "2017-06-22T23:04:29Z",
        "merged_at": "2017-06-22T23:04:29Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 9,
        "changed_files": 1,
        "created_at": "2017-06-22T03:48:46Z",
        "closed_at": "2019-10-28T18:28:41Z",
        "merged_at": null,
        "body": "See #1725 for explanation",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2017-06-22T03:19:13Z",
        "closed_at": "2017-06-23T05:56:08Z",
        "merged_at": "2017-06-23T05:56:08Z",
        "body": "- pascal_voc_train.record, \r\n- pascal_voc_val.record, \r\n- pascal_voc_label_map.pbxt\r\n\r\n**naming is not consistent with:**\r\n\r\n- Default label map filename for VOC (object_detection/data/pascal_label_map.pbtxt), and\r\n- Preparing input documentation markdown file: \r\nhttps://github.com/tensorflow/models/blob/master/object_detection/g3doc/preparing_inputs.md\r\n\r\n\r\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 23,
        "deletions": 7,
        "changed_files": 2,
        "created_at": "2017-06-21T03:27:56Z",
        "closed_at": "2019-06-17T19:59:04Z",
        "merged_at": null,
        "body": "When running train.py, it was a bit hard to see if the loss is decreasing.\r\nBy adding the log, we will be able to see the loss for each buckets on tensorboard.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 32,
        "deletions": 60,
        "changed_files": 1,
        "created_at": "2017-06-20T15:07:34Z",
        "closed_at": "2019-10-28T18:28:41Z",
        "merged_at": null,
        "body": "1. Since the `slim.evaluation.evaluation()` has been removed from `evaluation.py` (see commits fafc8b7 in tensorflow), if we call slim.evaluation.evaluation() then will get: `TypeError: 'module' object is not callable`, so this should be modified to `slim.evaluation.evaluate_once()` and accordingly, some parameters modification.\r\n2. The return value of `evaluate_once()` is a dict not a list, so the `for loop` which is to show the `metric_values` results should be modified.\r\n3. Minors comments modification, such as explaining cannot get exact result of `1` suming the probabilities across all classes when run on GPU.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 18,
        "deletions": 14,
        "changed_files": 2,
        "created_at": "2017-06-19T18:32:37Z",
        "closed_at": "2017-06-20T16:44:15Z",
        "merged_at": "2017-06-20T16:44:15Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 9,
        "changed_files": 5,
        "created_at": "2017-06-19T14:08:28Z",
        "closed_at": "2017-06-21T18:35:49Z",
        "merged_at": "2017-06-21T18:35:49Z",
        "body": "Modify these lines to make `object_detection/trainer_test.py` pass in Python 3.\r\n- `items()` and `iteritems()` issue in `core/batcher.py` and `core/post_processing.py`\r\n- `keys()` of `dict()` behaves different between Python 2 and 3, make it explicitly convert to list.\r\n- Related to #1594. However, I think `six` is a better choice for checking Python version.\r\n- Division behaves differently in `util/ops.py`.\r\n- Python3 use `from unittest import mock` instead of Python2's `import mock`.",
        "comments": 12
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-06-18T01:10:43Z",
        "closed_at": "2017-06-19T17:17:44Z",
        "merged_at": "2017-06-19T17:17:44Z",
        "body": "from Google internal link to external link.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 135,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2017-06-17T19:42:09Z",
        "closed_at": "2018-04-15T15:24:19Z",
        "merged_at": null,
        "body": "For the OSX compatibility issue listed below:\r\n[issue #52 ](https://github.com/tensorflow/models/issues/52)\r\n\r\nAlso accept related path now.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-06-17T13:29:17Z",
        "closed_at": "2019-06-17T19:57:38Z",
        "merged_at": null,
        "body": "'long' is no longer in py3",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2017-06-17T13:25:40Z",
        "closed_at": "2017-06-29T16:40:37Z",
        "merged_at": "2017-06-29T16:40:37Z",
        "body": "dictionary having both 'tuple' and 'str' keys cannot be 'sorted'",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-06-17T05:38:54Z",
        "closed_at": "2019-10-28T18:28:41Z",
        "merged_at": null,
        "body": "",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-06-16T19:26:00Z",
        "closed_at": "2017-06-16T21:53:19Z",
        "merged_at": "2017-06-16T21:53:18Z",
        "body": "Thanks for the good work!",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-06-16T09:48:57Z",
        "closed_at": "2017-06-17T01:41:02Z",
        "merged_at": null,
        "body": "I found that object_detection_tutorial.ipynb couldn't run on Python3 due to iteritems function. This change will make it run without problem.",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-06-16T05:00:55Z",
        "closed_at": "2017-06-17T01:14:51Z",
        "merged_at": "2017-06-17T01:14:51Z",
        "body": "iteritems -> items",
        "comments": 8
    },
    {
        "merged": false,
        "additions": 41346,
        "deletions": 418,
        "changed_files": 262,
        "created_at": "2017-06-16T03:07:59Z",
        "closed_at": "2017-06-16T04:54:29Z",
        "merged_at": null,
        "body": "Fix compatibility with py35",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 49,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2017-06-16T02:08:15Z",
        "closed_at": "2017-06-16T17:11:42Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2017-06-15T17:27:51Z",
        "closed_at": "2017-06-15T23:34:53Z",
        "merged_at": "2017-06-15T23:34:53Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 40616,
        "deletions": 0,
        "changed_files": 224,
        "created_at": "2017-06-15T02:38:48Z",
        "closed_at": "2017-06-15T04:06:39Z",
        "merged_at": "2017-06-15T04:06:39Z",
        "body": "For details see our paper:\r\n\"Speed/accuracy trade-offs for modern convolutional object detectors.\"\r\nHuang J, Rathod V, Sun C, Zhu M, Korattikara A, Fathi A, Fischer I,\r\nWojna Z, Song Y, Guadarrama S, Murphy K, CVPR 2017\r\nhttps://arxiv.org/abs/1611.10012",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 208,
        "deletions": 116,
        "changed_files": 17,
        "created_at": "2017-06-15T01:54:51Z",
        "closed_at": "2017-06-15T21:55:56Z",
        "merged_at": "2017-06-15T21:55:56Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 143,
        "deletions": 146,
        "changed_files": 5,
        "created_at": "2017-06-15T00:05:55Z",
        "closed_at": "2017-06-15T02:33:20Z",
        "merged_at": "2017-06-15T02:33:20Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-06-14T23:02:01Z",
        "closed_at": "2017-06-15T21:52:37Z",
        "merged_at": "2017-06-15T21:52:37Z",
        "body": "The code currently loads the checkpoint and then initializes the variables resulting to random weights. \r\nSwapping the order fixes the loading checkpoint issue.",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 14,
        "changed_files": 2,
        "created_at": "2017-06-14T18:40:44Z",
        "closed_at": "2017-06-14T20:31:36Z",
        "merged_at": "2017-06-14T20:31:36Z",
        "body": "Tested by running model_deploy_test.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 332,
        "deletions": 125,
        "changed_files": 3,
        "created_at": "2017-06-14T16:43:25Z",
        "closed_at": "2017-06-14T18:11:13Z",
        "merged_at": "2017-06-14T18:11:13Z",
        "body": "- Add inception_resnet_v2_base\r\n- Provide option to use SAME padding for all inception resnet v2\r\n  layers. This is to align feature maps sizes.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-06-14T11:36:19Z",
        "closed_at": "2017-06-14T18:10:06Z",
        "merged_at": "2017-06-14T18:10:06Z",
        "body": "There was an extra comma so the image didn't show up. Also change to use a relative link for the image instead.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 931,
        "deletions": 16,
        "changed_files": 8,
        "created_at": "2017-06-14T02:13:28Z",
        "closed_at": "2017-06-14T04:57:48Z",
        "merged_at": "2017-06-14T04:57:48Z",
        "body": "Initial MobileNet v1 check in.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 4148,
        "deletions": 0,
        "changed_files": 40,
        "created_at": "2017-06-12T19:00:14Z",
        "closed_at": "2019-06-17T19:53:38Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-06-11T16:23:44Z",
        "closed_at": "2017-06-12T18:32:26Z",
        "merged_at": "2017-06-12T18:32:26Z",
        "body": "Fixed the error message.",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-06-10T15:07:21Z",
        "closed_at": "2019-06-17T19:55:39Z",
        "merged_at": null,
        "body": "The \u2019cpu_count\u2018 is imported to replace the number '16'.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-06-10T02:43:37Z",
        "closed_at": "2017-06-13T02:10:05Z",
        "merged_at": null,
        "body": "Maintaining only for Tensorflow version 0.10 ",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2017-06-08T17:14:00Z",
        "closed_at": "2017-06-09T07:48:58Z",
        "merged_at": "2017-06-09T07:48:58Z",
        "body": "I also fixed the multi-GPU example which was creating multiple queues, which was incorrect.  Reading from one queue will also speedup multi-GPU even beyond using CPU:0 but I did not test extensively.  ",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 16,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-06-07T18:13:27Z",
        "closed_at": "2017-06-15T21:51:37Z",
        "merged_at": "2017-06-15T21:51:36Z",
        "body": "A TODO was stated for adding LRN - Pending GPU support.\r\nLRN was implemented by tensorflow/tensorflow@35df3ed43edabbc4ad1b2439bbc7de8917026d6e\r\n\r\nHyper-parameters taken from http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks\r\nAdditionally the location and architecture linking of the LRN layers was taken from Section 3.5 of the above paper, as best as can be deciphered.\r\n\r\nNote: Individual CLA has been submitted, appropriately linking this GitHub Account.",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 9,
        "changed_files": 3,
        "created_at": "2017-06-07T02:24:13Z",
        "closed_at": "2017-06-14T18:11:42Z",
        "merged_at": "2017-06-14T18:11:42Z",
        "body": "Commands in _Preparing the Datasets_ section of `slim/README.md` cannot be followed due to Python 3 compatibility issues, mainly cPickle and str/bytes.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2017-06-06T09:49:02Z",
        "closed_at": "2017-06-06T19:40:32Z",
        "merged_at": "2017-06-06T19:40:32Z",
        "body": "When attempting to run the adversarial crypto model, I got the following errors:\r\n\r\n```\r\nline 302, in _AssertCompatible\r\n    (dtype.name, repr(mismatch), type(mismatch).__name__))\r\nTypeError: Expected int32, got list containing Tensors of type '_Message' instead.\r\nline 126, in model\r\n```\r\n\r\n```\r\n    [tf.contrib.layers.fully_connected, tf.contrib.layers.convolution],\r\nAttributeError: 'module' object has no attribute 'convolution'\r\n```\r\n\r\nIt appears that the arguments for tf.concat were in the opposite order of the API documentation, and that the \"tf.contrib.layers.convolution2d\" method was called as \"convolution\". I have corrected both of these issues in this pull request.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-06-05T04:40:21Z",
        "closed_at": "2017-06-05T21:47:12Z",
        "merged_at": "2017-06-05T21:47:12Z",
        "body": "model_deploy_test.py contains 5 failures. This fixes all the tests.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 86,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2017-06-03T00:07:32Z",
        "closed_at": "2019-10-28T18:28:41Z",
        "merged_at": null,
        "body": "",
        "comments": 11
    },
    {
        "merged": false,
        "additions": 425,
        "deletions": 342,
        "changed_files": 4,
        "created_at": "2017-06-02T21:56:36Z",
        "closed_at": "2017-06-02T23:50:06Z",
        "merged_at": null,
        "body": "The accuracy for each batch is calculated and will be stored in the summaries.\r\nThis function help the user to realize what is the overall performance on training set.",
        "comments": 11
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-06-02T07:59:16Z",
        "closed_at": "2017-06-09T18:59:57Z",
        "merged_at": "2017-06-09T18:59:57Z",
        "body": "'elipson' should be 'epsilon'",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2017-06-01T00:05:17Z",
        "closed_at": "2017-06-01T03:09:25Z",
        "merged_at": "2017-06-01T03:09:25Z",
        "body": "download_and_preprocess_imagenet.sh (lines 78 and 86) tries to run the python scripts preprocess_imagenet_validation_data.py and process_bounding_boxes.py by simply calling them from the script without invoking the python CLI tool. This only works if the python scripts are marked executable, and this makes that change.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-05-28T13:01:15Z",
        "closed_at": "2017-05-30T21:13:29Z",
        "merged_at": "2017-05-30T21:13:29Z",
        "body": "As the links was `[[link]]` the last `]` was included in the url.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-05-28T08:52:36Z",
        "closed_at": "2017-06-01T20:21:21Z",
        "merged_at": null,
        "body": "",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-05-27T08:06:43Z",
        "closed_at": "2017-06-01T20:38:40Z",
        "merged_at": null,
        "body": "@nealwu ",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 32,
        "deletions": 16,
        "changed_files": 3,
        "created_at": "2017-05-27T06:13:54Z",
        "closed_at": "2017-05-28T16:39:43Z",
        "merged_at": "2017-05-28T16:39:43Z",
        "body": "Fixes tensorflow/tensorflow#10239",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 7093,
        "deletions": 0,
        "changed_files": 6,
        "created_at": "2017-05-26T16:12:42Z",
        "closed_at": "2019-06-17T19:58:12Z",
        "merged_at": null,
        "body": "We design a solution, named DeepTrade, including history data representation, neural network construction and trading optimization methods, which could maximizing our profit based on passed experience.",
        "comments": 26
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-05-25T05:51:56Z",
        "closed_at": "2019-06-17T19:53:23Z",
        "merged_at": null,
        "body": "Update the model to inception_v3",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 5,
        "changed_files": 4,
        "created_at": "2017-05-24T13:12:46Z",
        "closed_at": "2017-05-24T15:24:52Z",
        "merged_at": "2017-05-24T15:24:52Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-05-23T18:19:23Z",
        "closed_at": "2017-05-24T00:06:53Z",
        "merged_at": "2017-05-24T00:06:53Z",
        "body": "Changed flowers to ImageNet.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3477,
        "deletions": 0,
        "changed_files": 37,
        "created_at": "2017-05-22T12:09:07Z",
        "closed_at": "2017-05-22T15:43:57Z",
        "merged_at": "2017-05-22T15:43:57Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-05-21T23:40:14Z",
        "closed_at": "2017-05-23T01:14:00Z",
        "merged_at": "2017-05-23T01:14:00Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-05-21T23:03:57Z",
        "closed_at": "2017-05-22T13:57:17Z",
        "merged_at": "2017-05-22T13:57:17Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-05-20T01:16:55Z",
        "closed_at": "2017-06-02T11:11:37Z",
        "merged_at": "2017-06-02T11:11:37Z",
        "body": "Updates protobuf version as previous (3.0.0b2) was no longer compatible and resulted in failing bazel tests during setup process.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 31,
        "changed_files": 4,
        "created_at": "2017-05-18T23:58:45Z",
        "closed_at": "2017-05-23T01:06:30Z",
        "merged_at": "2017-05-23T01:06:30Z",
        "body": "Note: I found other instances of `control_flow_ops` but wasn't sure what to do with them. Examples: https://github.com/tensorflow/models/blob/master/slim/preprocessing/inception_preprocessing.py#L40 and https://github.com/tensorflow/models/blob/master/syntaxnet/syntaxnet/structured_graph_builder.py#L57.\r\n\r\nAlso, a few of the conversions turned out a bit strange. I ended up having a few lines that assigned a variable to itself (`output = output`), and I wasn't sure what to do with the calls that used the `name` argument of `control_flow_ops.with_dependencies()`.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-05-18T18:26:46Z",
        "closed_at": "2017-05-18T19:47:30Z",
        "merged_at": "2017-05-18T19:47:30Z",
        "body": "Dicts don't have \"iteritems\" attribute. It should be \"items\"",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-05-18T13:31:32Z",
        "closed_at": "2017-05-18T19:54:43Z",
        "merged_at": "2017-05-18T19:54:43Z",
        "body": "Corrected documentation word \"cropt\" -> \"crop\"",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 24,
        "deletions": 13,
        "changed_files": 1,
        "created_at": "2017-05-17T20:17:41Z",
        "closed_at": "2017-05-18T00:34:05Z",
        "merged_at": "2017-05-18T00:34:05Z",
        "body": "A minor update for attention_ocr/README.md instructions to address Issue #1476.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-05-17T16:16:35Z",
        "closed_at": "2017-05-18T00:37:10Z",
        "merged_at": "2017-05-18T00:37:10Z",
        "body": "Running `python neural_gpu_trainer.py --problem bmul --rnn_baseline=True` fails with:\r\n\r\n`ValueError: Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x7f5ae993d190> with a different variable scope than its first use.  First use of cell was with scope 'encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell', this attempt is with scope 'encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell'.  Please create a new instance of the cell if you would like it to use a different set of weights.  If before you were using: MultiRNNCell([BasicLSTMCell(...)] * num_layers), change to: MultiRNNCell([BasicLSTMCell(...) for _ in range(num_layers)]).  If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).  In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)`\r\n\r\nThis is the first part of a fix for this, fixing the MultiRNNCell parameters.\r\n\r\nHowever, there's a second bug which I don't fix here - the same instances are still used in the forward and reverse cells, so this error goes, but is replaced by:\r\n\r\n`ValueError: Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x7f7584639050> with a different variable scope than its first use.  First use of cell was with scope 'encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell', this attempt is with scope 'decoder/multi_rnn_cell/cell_0/basic_lstm_cell'.  Please create a new instance of the cell if you would like it to use a different set of weights.  If before you were using: MultiRNNCell([BasicLSTMCell(...)] * num_layers), change to: MultiRNNCell([BasicLSTMCell(...) for _ in range(num_layers)]).  If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).  In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)`\r\n\r\nSomeone who knows the code better will need to fix that second part too to get it actually working again.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-05-17T15:01:08Z",
        "closed_at": "2017-06-14T18:12:55Z",
        "merged_at": "2017-06-14T18:12:55Z",
        "body": "This patch assigns dequeue node to inputs_device. And nolonger shows\r\n\"Ignoring device specification /device:GPU:X for node\r\n'clone_X/fifo_queue_Dequeue'\" message.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-05-17T11:29:42Z",
        "closed_at": "2017-06-29T23:37:29Z",
        "merged_at": "2017-06-29T23:37:29Z",
        "body": "This is more efficient implementation for PerformRightArc().",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2017-05-15T21:05:35Z",
        "closed_at": "2017-05-16T21:45:47Z",
        "merged_at": "2017-05-16T21:45:47Z",
        "body": "Fix several Typos, GPU's -> GPUs.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-05-14T09:31:52Z",
        "closed_at": "2017-05-15T18:25:52Z",
        "merged_at": "2017-05-15T18:25:52Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2017-05-11T19:23:39Z",
        "closed_at": "2017-06-16T19:09:14Z",
        "merged_at": "2017-06-16T19:09:14Z",
        "body": "Hi - this PR updates the reference from the legacy_seq2seq sequence loss by example to the seq2seq sequence loss in the RNN Penn Treebank tutorial. ",
        "comments": 11
    },
    {
        "merged": false,
        "additions": 74,
        "deletions": 48,
        "changed_files": 2,
        "created_at": "2017-05-10T06:20:22Z",
        "closed_at": "2019-06-17T19:53:05Z",
        "merged_at": null,
        "body": "resnet_model.py:\r\n- Replaced _batch_norm function with tf.layers.batch_normalization\r\nIt was also one of TODOs as code comment.\r\n\r\n- resnet_model.py, resnet_main.py\r\nAdded hyperparameter options for dropout on identity and conv branch going to addition block with residual cell. As also noted in Wide Resnet Paper (https://arxiv.org/pdf/1605.07146.pdf) that dropout was found to be counter-productive on the identity branch. Authors recommend to implement it between conv layers instead. in my experiment however dropout on conv branch just before the addition actually improves test accuracy (92.98 in ~70.0k steps, keep_prob=0.9). I thought it could useful for other explorers.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2017-05-09T14:59:13Z",
        "closed_at": "2017-05-09T20:12:21Z",
        "merged_at": null,
        "body": "Please use the forum for Swivel discussions instead of contacting the authors directly... thank you!",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-05-08T20:25:43Z",
        "closed_at": "2017-05-10T04:12:44Z",
        "merged_at": "2017-05-10T04:12:44Z",
        "body": "Correct the format of the percentages in slim_walkthrough.ipynb.\r\nThe probability is shown as percentage thus should be scaled correctly.",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-05-07T04:42:47Z",
        "closed_at": "2019-06-17T19:56:37Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 80,
        "deletions": 59,
        "changed_files": 9,
        "created_at": "2017-05-06T16:31:41Z",
        "closed_at": "2017-06-15T22:01:59Z",
        "merged_at": null,
        "body": "Hi @rsepassi,\r\nThis is Takeru Miyato, who is author of the paper \"Adversarial Training Methods for Semi-Supervised Text Classification\".\r\nThank you very much for your time and effort on making this open-sourced code!\r\n\r\nI found some mistakes on the code:\r\n- https://github.com/tensorflow/models/blob/f98cd28461bb51741d9c41742187e8e675c3cfda/adversarial_text/adversarial_losses.py#L228 I found that the shape of ```kl``` is shape (N, 1) and the shape of ```weights``` are shape (N). so ```weights * kl``` broadcasted to (N, N) shape. The resulting loss is N times as much as the correct loss.\r\n\r\n- https://github.com/tensorflow/models/compare/master...takerum:reproduction?expand=1#diff-1fbce96d365468a32829d2a35e62435dL137 here the weights is calculated with ```input.labels``` , but the weights should be 1.0 on \\<eos\\> in input tokens, not label. If using ```input.labels``` for calculating weights, the weights are 1.0 on the position previous to the \\<eos\\> in ```inputs.tokens```.\r\n\r\nI fixed the above points, and also changed some lines which are different from my original implementation.\r\n\r\nNow I get 6.1, 6.3 and 7.2 % validation error rate on the committed version, which are the almost same performance as I got before. \r\nAlso I get 5.9% test error rate with full training set (training + validation).\r\nPlease take a look at my commits and merge to master.",
        "comments": 23
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2017-05-04T15:15:59Z",
        "closed_at": "2017-05-06T00:07:38Z",
        "merged_at": "2017-05-06T00:07:38Z",
        "body": "Fix several typos.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 469,
        "deletions": 338,
        "changed_files": 3,
        "created_at": "2017-05-04T06:21:11Z",
        "closed_at": "2017-05-05T18:59:50Z",
        "merged_at": "2017-05-05T18:59:50Z",
        "body": "This refactors swivel.py so that it uses the distributed TF API to run on a TF cluster. It can still be run single-threaded.  A sample shell script is included that launches a parameter server and several workers.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 35,
        "deletions": 20,
        "changed_files": 3,
        "created_at": "2017-05-03T20:47:56Z",
        "closed_at": "2017-05-04T17:22:10Z",
        "merged_at": "2017-05-04T17:22:10Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 3193,
        "deletions": 0,
        "changed_files": 24,
        "created_at": "2017-05-01T22:06:45Z",
        "closed_at": "2017-05-02T01:51:46Z",
        "merged_at": "2017-05-02T01:51:46Z",
        "body": "A new model for text recognition on real-world images.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-05-01T14:06:24Z",
        "closed_at": "2019-06-17T19:52:27Z",
        "merged_at": null,
        "body": "Fixes #1361 ",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-04-29T20:39:45Z",
        "closed_at": "2017-05-01T20:47:57Z",
        "merged_at": "2017-05-01T20:47:57Z",
        "body": "`outputs` is a list of `num_steps` tensors, each shaped `(batch_size, size)`. \r\n\r\nIt makes more sense to stack them to a `(batch_size, num_steps, size)` tensor, instead of concatenating them to a `(batch_size, size*num_steps)` tensor, although it makes no difference to the result.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-04-28T21:31:25Z",
        "closed_at": "2019-06-17T19:52:15Z",
        "merged_at": null,
        "body": "To solve [issue #1419](https://github.com/tensorflow/models/issues/1419) there we get the exception:\r\n`ValueError: When using replicas, all Variables must have their device set: name: \"global_step\"`\r\nFor when using multiple worker replicas, i.e. running distributed TensorFlow.\r\n\r\nSolved with the accepted answer from: http://stackoverflow.com/questions/38793718/distributed-tensorflow-valueerror-when-when-using-replicas-all-variables-mus",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2017-04-28T17:39:08Z",
        "closed_at": "2017-05-10T02:22:32Z",
        "merged_at": "2017-05-10T02:22:32Z",
        "body": "Solve Python 3 compatibility:\r\n- replacing xrange to range\r\n- add .decode() after f.read() to get strings instead of bytes when reading text file",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-04-28T03:13:41Z",
        "closed_at": "2017-04-29T06:18:58Z",
        "merged_at": "2017-04-29T06:18:58Z",
        "body": "Fix num_residual_units for w28-10",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 0,
        "changed_files": 0,
        "created_at": "2017-04-27T12:57:44Z",
        "closed_at": "2017-06-23T02:12:16Z",
        "merged_at": null,
        "body": "With tensorflow 1.1 I experienced the following exception with code that was working fine with tensorflow 1.0.\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"eval_for_features.py\", line 266, in <module>\r\n    tf.app.run()\r\n  File \"/home/aeberle/.local/lib/python3.4/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"eval_for_features.py\", line 118, in main\r\n    evaluate_split('query')\r\n  File \"eval_for_features.py\", line 142, in evaluate_split\r\n    FLAGS.dataset_name, split_name, FLAGS.dataset_dir)\r\n  File \"/home/aeberle/development/masters/tensorflow-models/slim/datasets/dataset_factory.py\", line 59, in get_dataset\r\n    reader)\r\n  File \"/home/aeberle/development/masters/tensorflow-models/slim/datasets/market1501.py\", line 86, in get_split\r\n    labels_to_names = dataset_utils.read_label_file(dataset_dir)\r\n  File \"/home/aeberle/development/masters/tensorflow-models/slim/datasets/dataset_utils.py\", line 129, in read_label_file\r\n    lines = f.read().decode()\r\nAttributeError: 'str' object has no attribute 'decode'\r\n```\r\n\r\nWith this PR, I remove the decode() operation which no longer seems to be needed.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-04-27T10:19:06Z",
        "closed_at": "2017-04-27T18:16:43Z",
        "merged_at": "2017-04-27T18:16:43Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-04-26T13:17:12Z",
        "closed_at": "2019-06-17T19:52:03Z",
        "merged_at": null,
        "body": "This could be made into just a comment instead, because as it stands it could **break loading of the existing checkpoint** (if done by name).\r\n\r\nI noticed this because I was creating an equivalent Keras version, which generated the 'inception blocks' via a subroutine, making the naming completely uniform.\r\n\r\n\r\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 78,
        "deletions": 78,
        "changed_files": 5,
        "created_at": "2017-04-25T22:08:29Z",
        "closed_at": "2017-04-26T16:30:18Z",
        "merged_at": "2017-04-26T16:30:17Z",
        "body": "Added `$` to the beginning of the terminal commands to clarify which lines are actually commands.\r\n\r\nFixed some typos and removed trailing whitespaces.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-04-25T15:20:20Z",
        "closed_at": "2017-04-26T20:19:38Z",
        "merged_at": "2017-04-26T20:19:38Z",
        "body": "I ran into a bug under zsh with `--train_data=cifar10/data_batch*`.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 79747,
        "deletions": 0,
        "changed_files": 34,
        "created_at": "2017-04-25T13:10:00Z",
        "closed_at": "2017-04-26T08:51:29Z",
        "merged_at": null,
        "body": "This work is almost identical to the Inception\r\nV3 (inception folder) in terms of its python wrappers,\r\nImagenet dataset and wrapper and its use of slim to\r\nbuild the model. the slim folder contains the VGG-16\r\nmodel (can be easily expanded to the other version of VGG)\r\nand the vgg contains the programs for running the Imagenet\r\n2012 set (evaluating and training with single/multiple nodes).\r\n\r\n@drpngx @bkovalev @junshi15 @jhseu @anfeng \r\nThis is needed mostly for performance evaluation of a large network (~ x10 number of parameters than Inception V3) and comparison between different communication protocols.",
        "comments": 16
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 1,
        "changed_files": 3,
        "created_at": "2017-04-25T11:04:49Z",
        "closed_at": "2017-04-25T17:50:47Z",
        "merged_at": "2017-04-25T17:50:47Z",
        "body": "Default is TensorFlow default of 'grpc' communication protocol.\r\nIf TensorFlow was complied with Verbs support 'grpc+verbs' can be\r\nused to accelerate the tensor passing communication.\r\n\r\n@drpngx @junshi15 @bkovalev",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1340,
        "deletions": 4,
        "changed_files": 3,
        "created_at": "2017-04-24T19:13:16Z",
        "closed_at": "2017-04-27T22:54:44Z",
        "merged_at": "2017-04-27T22:54:43Z",
        "body": "Currently the FSNS dataset is distributed as a description how to generate URLs to download files. This change adds a simple script to generate a text file with all URLs which is compatible with aria2c download manager, which can download all files in parallel and supports multiple retries and continue an aborted download modes.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-04-23T16:08:46Z",
        "closed_at": "2017-05-11T20:47:14Z",
        "merged_at": null,
        "body": "next() does not work in Python3. Attempting to train returns error. Changing all instances of gen.next( ) to gen.__next__( ) fixed the problem.",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-04-22T04:47:01Z",
        "closed_at": "2017-04-22T07:25:13Z",
        "merged_at": "2017-04-22T07:25:13Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 9,
        "changed_files": 1,
        "created_at": "2017-04-22T02:27:17Z",
        "closed_at": "2017-04-22T07:31:41Z",
        "merged_at": "2017-04-22T07:31:41Z",
        "body": "Variable summaries and the learning rate are added elsewhere in the\r\ncode.  A quick search also shows that this function is never called.\r\n\r\nLearning rate gets added to summary at https://github.com/r2d4/models/blob/fd6e2d29577247a79a8010ded72d78811882db2d/slim/train_image_classifier.py#L510\r\n\r\nVariables get added to summary at\r\nhttps://github.com/r2d4/models/blob/fd6e2d29577247a79a8010ded72d78811882db2d/slim/train_image_classifier.py#L491-L492",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-04-21T16:17:43Z",
        "closed_at": "2017-04-21T20:17:30Z",
        "merged_at": "2017-04-21T20:17:30Z",
        "body": "'xrange' was used in multiple places. In this setting it provided no measurable gain in terms of performance or memory, but broke python3 compatibility. It was replaced with 'range'",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 36,
        "deletions": 29,
        "changed_files": 2,
        "created_at": "2017-04-21T06:56:52Z",
        "closed_at": "2017-05-26T00:53:25Z",
        "merged_at": null,
        "body": "fix error: open too many files when runing prep.py\r\nopen with utf-8 decode for Chinese texts",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 8476,
        "deletions": 0,
        "changed_files": 51,
        "created_at": "2017-04-21T04:46:15Z",
        "closed_at": "2017-04-21T23:48:23Z",
        "merged_at": "2017-04-21T23:48:23Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2017-04-20T23:24:27Z",
        "closed_at": "2017-04-25T21:09:31Z",
        "merged_at": "2017-04-25T21:09:31Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 112,
        "deletions": 66,
        "changed_files": 1,
        "created_at": "2017-04-20T13:52:50Z",
        "closed_at": "2017-07-11T17:01:55Z",
        "merged_at": null,
        "body": "Currently, optimizer is hardcoded: Adagrad. It corresponds to the paper. However, there are newer optimizers available, e.g. Adadelta or RMSProp and it is fun to see how they influence the training.\r\n\r\nFor some reason summaries are present in the code but `FileWriter` is not used - I fix it. Besides, I added the most frequent 10k visualization in TB's embedding projector.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-04-20T12:26:07Z",
        "closed_at": "2017-04-20T20:29:15Z",
        "merged_at": "2017-04-20T20:29:15Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-04-18T22:14:43Z",
        "closed_at": "2019-06-17T19:51:53Z",
        "merged_at": null,
        "body": "The variable named as `tune_corpus` indicate that the treebank will be used to tune the params. While the original name `dev_corpus` suggests to use the development corpus that [should not be used for training proper](http://universaldependencies.org/conll17/data.html). One suggestion is to take 5% of the train corpus to make a tune corpus, that can be downloaded [here](https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-1990).",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-04-18T20:21:36Z",
        "closed_at": "2017-04-20T00:56:39Z",
        "merged_at": "2017-04-20T00:56:39Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2017-04-18T19:51:47Z",
        "closed_at": "2017-04-20T00:57:43Z",
        "merged_at": "2017-04-20T00:57:43Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 12,
        "changed_files": 2,
        "created_at": "2017-04-18T14:59:17Z",
        "closed_at": "2017-04-20T01:02:38Z",
        "merged_at": "2017-04-20T01:02:38Z",
        "body": "Shows images in resnet/README.md and next_frame_prediction/README.md",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-04-18T06:36:30Z",
        "closed_at": "2017-06-01T20:38:19Z",
        "merged_at": null,
        "body": "Modify the \u2018headline\u2019  to 'abstract' in  line 40 of models/textsum/seq2seq_attention.py.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-04-18T01:59:52Z",
        "closed_at": "2017-04-20T01:07:33Z",
        "merged_at": "2017-04-20T01:07:33Z",
        "body": "iteritems() in python3 is removed\r\nitems() is in python2/3",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-04-17T22:11:04Z",
        "closed_at": "2017-04-20T01:15:40Z",
        "merged_at": "2017-04-20T01:15:40Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 11,
        "changed_files": 1,
        "created_at": "2017-04-15T06:12:19Z",
        "closed_at": "2017-06-09T21:40:57Z",
        "merged_at": null,
        "body": "Using reg_search=False to use re.match to mirror the 'startswith' logic\r\nbeing replaced.\r\n\r\ncc @sguada ",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-04-15T05:09:59Z",
        "closed_at": "2017-04-20T01:16:56Z",
        "merged_at": "2017-04-20T01:16:56Z",
        "body": "The flag description for the momentum flag states that it is \r\n> The momentum for the MomentumOptimizer and RMSPropOptimizer\r\n\r\nhowever its not actually used in the RMSPropOptimizer.  Instead, a separate\r\n`--rmsprop_momentum` flag was used.  This deletes that flag for\r\ncorrectness of the `--momentum` flag description and simplicity.  \r\nIt was not referenced anywhere else in the repo.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 168,
        "deletions": 129,
        "changed_files": 3,
        "created_at": "2017-04-14T03:33:19Z",
        "closed_at": "2019-06-17T19:51:39Z",
        "merged_at": null,
        "body": "I have been using python 3.5 and had some issues I sorted out.  THought I would add them back so others wouldn't have the same Issues I have.\r\n\r\nFor example< I kept getting the `TypeError: 'jpg' has type <class 'str'>, but expected one of: ((<class 'bytes'>,),)` error.  All I had to do was to prefix the jpg in  `slim/datasets/download_and_convert_flowers.py`.\r\n\r\nThe other change was to change `slim/datasets/download_and_convert_cifar10.py` where it imports cPickle as this was bombing in python 3.5.\r\n\r\nThe rest are just spacing changes for PEP8 compliance. ",
        "comments": 9
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-04-13T01:41:28Z",
        "closed_at": "2019-06-17T19:51:13Z",
        "merged_at": null,
        "body": "Fix a TODO using batch_norm in contrib/layers/python/layers/layers.py in Resnet model.",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-04-12T05:35:56Z",
        "closed_at": "2017-04-20T01:19:16Z",
        "merged_at": null,
        "body": "Number of steps after which checkpoints are saved in inception_train.py",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 15,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2017-04-11T13:53:55Z",
        "closed_at": "2017-04-13T01:40:01Z",
        "merged_at": null,
        "body": "Using batch_norm in contrib/layers/python/layers/layers.py in Resnet model to Fix a TODO in Resnet model.",
        "comments": 10
    },
    {
        "merged": false,
        "additions": 92,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-04-11T04:33:37Z",
        "closed_at": "2017-06-09T21:41:04Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 0,
        "changed_files": 5,
        "created_at": "2017-04-11T03:59:05Z",
        "closed_at": "2017-05-12T22:39:04Z",
        "merged_at": "2017-05-12T22:39:04Z",
        "body": "These scripts should exit immediately if a command exits with a non-zero status.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 19,
        "changed_files": 2,
        "created_at": "2017-04-10T18:18:41Z",
        "closed_at": "2017-04-10T22:55:33Z",
        "merged_at": "2017-04-10T22:55:33Z",
        "body": "@cbfinn\r\nIn `prediction.train.py`, explicitly pass in prefix name to Model instance because summary names can no longer take in placeholder strings (at least for now, see [tensorflow/models#6603](https://github.com/tensorflow/tensorflow/issues/6603)).\r\nIn `lstm_ops.py`, directly use `inferred_batch_size` because the initializer cannot take shapes made of tensors.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2017-04-09T01:56:30Z",
        "closed_at": "2017-04-10T21:44:13Z",
        "merged_at": "2017-04-10T21:44:13Z",
        "body": "This broke the bazel build of `inception/download_and_preprocess_flowers`\r\nThe way that this script is written doesn't actually allow it to be ran\r\noutside bazel, and it might be difficult to support running it standalone and \r\nin the bazel context.\r\n\r\nIt should be ran using\r\n\r\n```\r\nbazel build inception/download_and_preprocess_flowers\r\n\r\nbazel-bin/inception/download_and_preprocess_flowers \"${FLOWERS_DATA_DIR}\"\r\n```\r\n\r\nref #1292 cc @nealwu @lababidi ",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-04-07T08:08:16Z",
        "closed_at": "2017-04-07T22:00:07Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-04-06T17:32:41Z",
        "closed_at": "2017-04-06T19:56:35Z",
        "merged_at": "2017-04-06T19:56:35Z",
        "body": "Without this change, users get an error message `[C 17:30:11.563 NotebookApp] Running as root is not recommended. Use --allow-root to bypass.` that will cause the `docker run` to exit with status code 1.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-04-06T03:20:38Z",
        "closed_at": "2017-04-06T20:12:11Z",
        "merged_at": "2017-04-06T20:12:11Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2017-04-05T06:45:21Z",
        "closed_at": "2017-04-06T23:41:27Z",
        "merged_at": "2017-04-06T23:41:27Z",
        "body": "",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-04-05T00:15:02Z",
        "closed_at": "2017-04-05T15:29:56Z",
        "merged_at": "2017-04-05T15:29:56Z",
        "body": "I had to figure this one out on my own. Probably belongs in the manual install notes.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 29,
        "deletions": 31,
        "changed_files": 1,
        "created_at": "2017-04-03T23:27:40Z",
        "closed_at": "2017-04-04T00:28:55Z",
        "merged_at": "2017-04-04T00:28:54Z",
        "body": "Fixes https://github.com/tensorflow/models/issues/1293",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 13,
        "changed_files": 2,
        "created_at": "2017-04-03T15:44:03Z",
        "closed_at": "2017-04-04T18:37:34Z",
        "merged_at": "2017-04-04T18:37:34Z",
        "body": "",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 2883,
        "deletions": 1,
        "changed_files": 27,
        "created_at": "2017-04-02T14:44:20Z",
        "closed_at": "2017-04-06T00:00:37Z",
        "merged_at": "2017-04-06T00:00:37Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-04-01T08:55:18Z",
        "closed_at": "2017-04-02T07:43:47Z",
        "merged_at": "2017-04-02T07:43:47Z",
        "body": "Fix the comment in ptb_word_lm that still using old version API.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 178,
        "deletions": 173,
        "changed_files": 5,
        "created_at": "2017-03-31T03:42:58Z",
        "closed_at": "2017-04-20T01:20:00Z",
        "merged_at": null,
        "body": "Hello everyone\r\n\r\nI have used python 2to3 to make changes to the Neural GPU model. After the automated changes were made, there were some issues, which I manually fixed. These issues were mainly centered around the integer division of indices. True division( using / ) would yield a float which would cause run time errors. I have made changes to operations acting on array indices, to ensure that they remain as integers. (i.e. changed / to //)\r\n\r\nPlease let me know if any further changes are needed and if any issues are seen. Thanks",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-03-30T20:44:39Z",
        "closed_at": "2017-03-31T18:33:39Z",
        "merged_at": "2017-03-31T18:33:39Z",
        "body": "We've been getting lots of issues submitted where users can't run function calls in the models because they aren't on TF 1.0. This should alleviate that.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 13,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-03-27T21:06:00Z",
        "closed_at": "2017-03-28T00:56:57Z",
        "merged_at": "2017-03-28T00:56:57Z",
        "body": "while maintaining backwards compatibility with TF 1.0\r\n\r\nSee https://github.com/tensorflow/models/pull/1131. cc @tongda ",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 2,
        "changed_files": 3,
        "created_at": "2017-03-25T21:18:57Z",
        "closed_at": "2017-03-27T20:52:27Z",
        "merged_at": "2017-03-27T20:52:27Z",
        "body": "I was going through the flower retraining example.\r\n\r\nI needed to make these changes to the scripts, and to the sample code in the README, for them to work with the tensorflow/tensorflow:1.0.1-devel docker image, since it includes `curl` but not `wget`.\r\n\r\nThey would also be needed on stock Mac, which includes curl but not wget. This is especially relevant for the script intended to run only on a Mac.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 38,
        "deletions": 68,
        "changed_files": 8,
        "created_at": "2017-03-25T05:37:57Z",
        "closed_at": "2017-03-27T22:09:52Z",
        "merged_at": "2017-03-27T22:09:52Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 5,
        "changed_files": 4,
        "created_at": "2017-03-25T04:03:13Z",
        "closed_at": "2017-03-27T18:48:15Z",
        "merged_at": "2017-03-27T18:48:15Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-03-25T00:24:15Z",
        "closed_at": "2017-03-27T20:40:55Z",
        "merged_at": "2017-03-27T20:40:55Z",
        "body": "\u2026an z_mean)\r\n\r\nA follow on to a previous update to remove external dependencies from the autoencoder models, and to solve [the following issue](https://github.com/tensorflow/models/issues/1199#issuecomment-289022533). Below is a sample image created from the output of the generate function. \r\n\r\n![img1](https://cloud.githubusercontent.com/assets/10055613/24317626/0e566732-10c7-11e7-8a78-5690741c1180.png)",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 13,
        "changed_files": 1,
        "created_at": "2017-03-23T11:31:12Z",
        "closed_at": "2017-03-24T00:06:27Z",
        "merged_at": "2017-03-24T00:06:27Z",
        "body": "This cost me many hours of debugging when my network failed to converge when applying `build_image_data.py` to a new dataset. Turns out I didn't read the `build_image_data.py` comments carefully and missed the part about the background class being labeled 0. The [one_hot_encoding](https://github.com/tensorflow/models/blob/master/slim/train_image_classifier.py#L455) in train_image_classifier does not take into account of out-of-range inputs. Therefore in my 3 classes dataset, my labels of `[3 2 2 1]` are converted to these one hot labels:\r\n```\r\n[[0 0 0]\r\n [0 0 1]\r\n [0 0 1]\r\n [0 1 0]]\r\n```\r\nThe NN will always classify class 3 as 'wrong'. I fixed this by changing [label_index](https://github.com/tensorflow/models/blob/master/inception/inception/data/build_image_data.py#L375) to 0 so my classes will now numerate `[0,2]`. (alternatively can add `tf.subtract(labels, 1)`). \r\n\r\nAdditionally, I think that the background class is unnecessary since the script is referred to quite often in the README as a general data converter to TFRecords. The background class seems to be a relic of the ImageNet dataset that does not generalize well to other types of data. In any case, I hope this addition will emphasize this nuance to future README readers.\r\n\r\nFix shell script to match example.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 7,
        "deletions": 4,
        "changed_files": 4,
        "created_at": "2017-03-23T03:38:32Z",
        "closed_at": "2017-03-25T04:00:10Z",
        "merged_at": null,
        "body": "Add Python 3 compatibility in textsum (while maintaining Python 2 compatibility):\r\nAdd the compatibility of the builtin function \u2018xrange\u2019 and \u2018Queue\u2019. Now you can run the textsum in both Python 2 and Python 3.\r\n\u2018compat.py\u2019 is the compatibility script, it should be added in the other scripts\u2019 front, as follows:\r\n\u2018from compat import *\u2019\r\n\r\nPS: In Python 3 environment, the prerequisite is \u2018pip install six\u2019\r\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 3527,
        "deletions": 192,
        "changed_files": 115,
        "created_at": "2017-03-23T01:47:53Z",
        "closed_at": "2017-03-23T17:44:45Z",
        "merged_at": "2017-03-23T17:44:45Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 40,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2017-03-21T18:30:55Z",
        "closed_at": "2017-03-21T19:44:38Z",
        "merged_at": null,
        "body": "(line 235,line 237 )Better explanation of embeddings.\r\n(line 285) tf.mul is not supported now...changed it to tf.multiply",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-03-21T08:38:46Z",
        "closed_at": "2017-03-21T15:47:09Z",
        "merged_at": "2017-03-21T15:47:09Z",
        "body": "SyntaxNet does not compile with gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.4). This leads to the error in #1194.\r\n\r\nIncluding `cmath` and using the `std` namespace for `isnan` solves this problem.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 9,
        "changed_files": 1,
        "created_at": "2017-03-20T14:48:30Z",
        "closed_at": "2017-03-27T20:48:09Z",
        "merged_at": "2017-03-27T20:48:09Z",
        "body": "- Removed replica_id which was removed from SyncReplicaOptimizer in V1.\r\n- Removed call for get_clean_up_op which was removed from optimizer in V1.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-03-20T09:05:10Z",
        "closed_at": "2017-03-20T19:40:24Z",
        "merged_at": "2017-03-20T19:40:24Z",
        "body": "for the tf 1.0 usage:\r\ntf.nn.softmax_cross_entropy_with_logits(_sentinel=None, labels=None, logits=None, dim=-1, name=None)\r\nupdate targets to labels\r\n\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2017-03-19T15:06:36Z",
        "closed_at": "2017-03-19T19:42:16Z",
        "merged_at": "2017-03-19T19:42:16Z",
        "body": "The commands to extract the pretrained skip_thoughts models were a little off.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-03-19T04:06:25Z",
        "closed_at": "2017-03-20T19:45:10Z",
        "merged_at": "2017-03-20T19:45:10Z",
        "body": "I use this script to create TFRecord file for other image datasets. Sometimes these datasets have corrupted JPEG files. Printing file names help pinpoint corrupted files.\r\n\r\nAlso, the exception bubbles up to the thread that is looping over JPEG files and causes the TFRecord shard to be halted prematurely. The thread is also stuck in limbo. Skipping corrupted files allows the thread to continue to execute to completion.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-03-19T02:46:05Z",
        "closed_at": "2017-03-20T19:41:09Z",
        "merged_at": "2017-03-20T19:41:09Z",
        "body": "Corrected issue listed below.\r\n\r\n`INFO:tensorflow:Summary name learning rate is illegal; using learning_rate instead.`",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-03-18T23:31:58Z",
        "closed_at": "2017-03-20T19:46:15Z",
        "merged_at": "2017-03-20T19:46:15Z",
        "body": "Second row had an extra set of dashes, making the markdown invalid and falling back to raw text instead of the intended table.\r\n\r\nTo see the result, look at the rendered markdown file.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 10,
        "changed_files": 1,
        "created_at": "2017-03-18T18:21:34Z",
        "closed_at": "2017-03-20T19:47:58Z",
        "merged_at": "2017-03-20T19:47:58Z",
        "body": "Hey,\r\nI noticed that the images in the im2text Readme.md would not be displayed properly (the raw markdown is displayed instead of the image)\r\nRemoving the center tag fixes this.",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 27,
        "deletions": 41,
        "changed_files": 8,
        "created_at": "2017-03-17T21:27:24Z",
        "closed_at": "2017-03-20T22:29:31Z",
        "merged_at": "2017-03-20T22:29:31Z",
        "body": "This is a follow on the pull request #1058. \r\n\r\n- Xavier initialization was being implemented from scratch while TF has the capability to do this. I changed the model to use the built in functionality.\r\n\r\n- Numpy was being used to generate random normal variables. I instead used TF and removed the import.\r\n\r\n- Minor modifications to the imports were made (I am not sure how they were working prior)\r\n\r\n- Printing was edited to be compatible with python3",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 86578,
        "deletions": 4360,
        "changed_files": 71,
        "created_at": "2017-03-17T01:47:28Z",
        "closed_at": "2017-03-17T03:17:11Z",
        "merged_at": "2017-03-17T03:17:11Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2874,
        "deletions": 0,
        "changed_files": 23,
        "created_at": "2017-03-17T00:22:41Z",
        "closed_at": "2017-03-17T16:56:56Z",
        "merged_at": "2017-03-17T16:56:56Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-03-15T22:26:06Z",
        "closed_at": "2017-03-17T19:40:56Z",
        "merged_at": null,
        "body": "Fix a small typo.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-03-14T08:08:50Z",
        "closed_at": "2017-03-14T22:53:38Z",
        "merged_at": null,
        "body": "Though the values are of  `QUEUE_NUM_BATCH` and `BUCKET_CACHE_BATCH` are same, but since we are assigning value to `_bucket_input_queue` the value passed must be  `BUCKET_CACHE_BATCH`",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 92,
        "changed_files": 6,
        "created_at": "2017-03-14T02:51:10Z",
        "closed_at": "2017-03-14T19:52:45Z",
        "merged_at": "2017-03-14T19:52:45Z",
        "body": "cc @tfboyd ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 8,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-03-14T02:42:52Z",
        "closed_at": "2017-03-14T16:23:38Z",
        "merged_at": "2017-03-14T16:23:38Z",
        "body": "See https://github.com/tensorflow/models/issues/1009",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 72,
        "deletions": 25,
        "changed_files": 4,
        "created_at": "2017-03-12T12:52:03Z",
        "closed_at": "2017-03-14T22:49:37Z",
        "merged_at": null,
        "body": "Works fine in python3, cuda8, cudnn5.1, tf1.0. Have been tested, sucessfully get the hoped result.\r\nMakes all the functions satisfied for tf1.0 version,including concat, split, summary fucntion and some others.\r\n\r\n \r\n",
        "comments": 20
    },
    {
        "merged": false,
        "additions": 56,
        "deletions": 54,
        "changed_files": 9,
        "created_at": "2017-03-12T01:12:59Z",
        "closed_at": "2017-03-14T02:18:17Z",
        "merged_at": null,
        "body": "Single GPU tested along with Tensorboard.  See individual commits.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 22,
        "deletions": 22,
        "changed_files": 3,
        "created_at": "2017-03-11T22:25:03Z",
        "closed_at": "2017-03-14T02:16:49Z",
        "merged_at": null,
        "body": "- Ran 1 GPU with imagenet for a few minutes and training worked as expected.  There are still some deprecation warnings and this works where as it did not before with TF 1.0.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 9,
        "changed_files": 1,
        "created_at": "2017-03-11T20:27:50Z",
        "closed_at": "2017-03-14T22:52:22Z",
        "merged_at": null,
        "body": "\r\n1) replace \"tf.pack\" with \"tf.stack\"\r\n2) tf.concat..(change the oder)\r\n3) change \"tf.batch_matmul\" to \"tf.matmul\"",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 20,
        "deletions": 24,
        "changed_files": 4,
        "created_at": "2017-03-11T05:40:38Z",
        "closed_at": "2017-03-14T22:53:04Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-03-10T16:56:35Z",
        "closed_at": "2017-03-14T22:53:50Z",
        "merged_at": null,
        "body": "Replaced old summery writer function with newer tf.summary.FileWriter function with TF 1.0 compatibility",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 11,
        "deletions": 11,
        "changed_files": 3,
        "created_at": "2017-03-10T12:33:16Z",
        "closed_at": "2017-03-14T22:57:41Z",
        "merged_at": null,
        "body": "\u2026 1.0",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 36,
        "deletions": 37,
        "changed_files": 1,
        "created_at": "2017-03-10T05:35:33Z",
        "closed_at": "2017-03-14T22:58:10Z",
        "merged_at": null,
        "body": "branch: master\r\nmodel: neural_programmer\r\n1.change the order of params of `tf.concat`\r\n2.replace `tf.mul` by `tf.multiply`\r\n3.replace `tf.sub` by `tf.subtract`\r\n4.replace `tf.select` by `tf.where`",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-03-09T02:03:46Z",
        "closed_at": "2017-03-14T23:01:15Z",
        "merged_at": null,
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-03-08T16:56:14Z",
        "closed_at": "2017-03-15T08:22:29Z",
        "merged_at": "2017-03-15T08:22:29Z",
        "body": "To fix the issue mentioned in [#8191](https://github.com/tensorflow/tensorflow/issues/8191) caused by the [recent commit](https://github.com/tensorflow/tensorflow/commit/54d50ffec8df4f748694632dbe5ebde9971e2c9e) of TensorFlow master branch. As the commit message says:\r\n\r\n> Make all RNNCells in tf.contrib.rnn act like tf.layers Layers, but with stricter semantics for now:\r\n>\r\n>    1. Upon first use of __call__, the used scope is stored in the cell. The RNNCell tries to create weights in that scope but if some are already set, an error is raised unless the RNNCell was constructed with argument reuse=True.\r\n>\r\n>    2. A subsequent use of __call__ of the same cell instance must be in the same scope.\r\n>       If it is not, an error is raised.",
        "comments": 19
    },
    {
        "merged": false,
        "additions": 321,
        "deletions": 328,
        "changed_files": 73,
        "created_at": "2017-03-08T16:46:49Z",
        "closed_at": "2017-03-14T02:21:03Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2017-03-08T13:19:42Z",
        "closed_at": "2017-03-16T01:23:05Z",
        "merged_at": "2017-03-16T01:23:05Z",
        "body": "2. Fixed accuracy when calcuting logs more than 10 steps",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 166,
        "deletions": 103,
        "changed_files": 1,
        "created_at": "2017-03-07T13:05:17Z",
        "closed_at": "2017-03-08T03:04:44Z",
        "merged_at": "2017-03-08T03:04:44Z",
        "body": "This speeds up the training accordingly. Here are my changes:\r\n\r\n* `import argparse` is redundant and was removed.\r\n* all `print` calls were replaced with `tf.logging.info`. This effectively eliminates `sys.stdout.flush()`.\r\n* number of protobuf readers is now configurable via `--num_readers`.\r\n* by default, `per_process_gpu_memory_fraction` is 0 now which means `allow_growth=True`.\r\n* `--num_gpus` sets the number of GPUs to use. The default value is 0 which means using all available GPUs.\r\n* The computational graph is split into 2 parts: CPU and GPU (actually, one subgraph per each GPU). CPU owns the embeddings and applies the gradients. GPU performs inference and the training. This split will allow us to implement the distributed version in the future.\r\n* The elapsed time is printed in the end.\r\n* The current loss is printed as the part of the status message. It is weighted exponential average with decay 0.8.\r\n* The status reporting was fixed. Due to the concurrent nature, global_step is sometimes never % 100 == 0. Changed to the better approach with comparison with the previous ratio.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 55,
        "deletions": 45,
        "changed_files": 7,
        "created_at": "2017-03-06T09:15:41Z",
        "closed_at": "2017-03-20T23:26:57Z",
        "merged_at": null,
        "body": "The textsum only works for Python2.x and TensoFlow0.x. In order to change the version to py3.x and tf1.x, I have made the necessary modifications. The modified files are:\r\n--data_convert_example.py\r\n--batch_reader.py\r\n--beam_search.py\r\n--seq2seq_attention.py\r\n--seq2seq_attention_model.py\r\n--seq2seq_attention_decode.py\r\n--seq2seq_lib.py\r\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 21,
        "deletions": 26,
        "changed_files": 4,
        "created_at": "2017-03-06T06:01:04Z",
        "closed_at": "2017-03-14T23:14:10Z",
        "merged_at": null,
        "body": "Updated method calls in slim image classifier to be compatible with\r\nTensorflow v1.0",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-03-04T19:28:58Z",
        "closed_at": "2017-03-14T23:23:59Z",
        "merged_at": "2017-03-14T23:23:59Z",
        "body": "this fixes the issue in #1083 ",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 33,
        "deletions": 36,
        "changed_files": 1,
        "created_at": "2017-03-03T18:50:23Z",
        "closed_at": "2017-03-03T20:55:02Z",
        "merged_at": "2017-03-03T20:55:02Z",
        "body": "TF 1.0 (and even 0.12) support doing embedding ops on GPU.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1778,
        "deletions": 82,
        "changed_files": 3,
        "created_at": "2017-03-03T17:30:31Z",
        "closed_at": "2017-07-11T17:02:23Z",
        "merged_at": null,
        "body": "This speeds up vocabulary parsing 2x for me.\r\n\r\nI mmap 8x PAGE_SIZE. Some care was required on buffer boundaries and in the file end.",
        "comments": 16
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2017-03-03T17:24:20Z",
        "closed_at": "2017-03-04T17:05:34Z",
        "merged_at": "2017-03-04T17:05:34Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 20,
        "changed_files": 1,
        "created_at": "2017-03-03T17:22:02Z",
        "closed_at": "2017-03-04T17:06:21Z",
        "merged_at": "2017-03-04T17:06:21Z",
        "body": "As discussed in https://groups.google.com/d/msgid/swivel-embeddings/c254faca-b35c-4e04-a347-095e4b467300%40googlegroups.com",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 9,
        "changed_files": 1,
        "created_at": "2017-03-02T17:55:54Z",
        "closed_at": "2017-03-03T00:57:25Z",
        "merged_at": "2017-03-03T00:57:25Z",
        "body": "Related PRs:\r\n\r\nhttps://github.com/tensorflow/models/pull/1081\r\nhttps://github.com/tensorflow/models/pull/1090",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1231,
        "deletions": 0,
        "changed_files": 5,
        "created_at": "2017-03-02T02:07:59Z",
        "closed_at": "2017-03-02T03:49:31Z",
        "merged_at": "2017-03-02T03:49:31Z",
        "body": "This adds the memory module based on the paper \"Learning to Remember Rare Events\".",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-03-01T14:03:38Z",
        "closed_at": "2017-03-02T18:09:08Z",
        "merged_at": "2017-03-02T18:09:07Z",
        "body": "+add the docs about num_threads",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-03-01T12:55:57Z",
        "closed_at": "2017-03-14T23:28:07Z",
        "merged_at": null,
        "body": "Updated method calls in line 249 of word2vec.py in tutorials/embedding to be compatible with Tensorflow v1.0",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-03-01T10:22:40Z",
        "closed_at": "2017-03-01T12:43:18Z",
        "merged_at": null,
        "body": "Updated method calls in line 249 of word2vec.py in tutorials/embedding to be compatible with Tensorflow v1.0",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-03-01T08:26:48Z",
        "closed_at": "2017-03-14T23:29:30Z",
        "merged_at": null,
        "body": "Updated two method calls in lines 174 and 175 of evaluate.py in im2txt to be compatible with Tensorflow v1.0\r\n\r\nIssue #1078 ",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 26,
        "deletions": 53,
        "changed_files": 1,
        "created_at": "2017-02-28T14:47:18Z",
        "closed_at": "2017-03-02T18:14:13Z",
        "merged_at": "2017-03-02T18:14:12Z",
        "body": "There is no need to build Tensorflow from scratch, fastprep successfully links with the Python wrapper from pip and system protobuf v3. Tested this on Ubuntu.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-02-27T07:25:23Z",
        "closed_at": "2017-02-28T06:11:38Z",
        "merged_at": null,
        "body": "Adding hook to command-line argument for data/checkpoint save frequency and maximum checkpoint to keep.\r\nThis is helpful in-case for get time to accuracy measurements. For this measurement we want to specify how often we need to save the checkpoint - may be for every epoch, which depends on the batch-size. And also we want to keep all the checkpoint, not only five, to get the accuracy at the end of complete run. Printing log at the checkpoint-step will help to calculate the elapsed time.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-02-26T11:37:29Z",
        "closed_at": "2017-03-16T21:11:00Z",
        "merged_at": "2017-03-16T21:11:00Z",
        "body": "Add case for compiling ops if tensorflow was compiled from source using gcc >= 5.0",
        "comments": 11
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 11,
        "changed_files": 2,
        "created_at": "2017-02-26T07:51:14Z",
        "closed_at": "2017-03-08T20:37:01Z",
        "merged_at": "2017-03-08T20:37:01Z",
        "body": "Will now work with Tensorflow 1.0\r\n\r\nReference Info: 34467734 Update namignizer to work with recent versions of TF",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 21,
        "deletions": 13,
        "changed_files": 1,
        "created_at": "2017-02-24T19:07:20Z",
        "closed_at": "2017-03-14T23:44:31Z",
        "merged_at": "2017-03-14T23:44:31Z",
        "body": "Update README.md for added models.",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 20,
        "deletions": 20,
        "changed_files": 3,
        "created_at": "2017-02-24T16:35:29Z",
        "closed_at": "2017-03-14T23:46:02Z",
        "merged_at": null,
        "body": "",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 324,
        "deletions": 323,
        "changed_files": 73,
        "created_at": "2017-02-24T09:52:15Z",
        "closed_at": "2017-03-14T02:21:03Z",
        "merged_at": null,
        "body": "@nealwu @theraysmith \n  Drops now redundant name parameter in new tf.summary.scalar calls\n  Transposes ctc_loss params as in updated API\n  Hooks RegisterShape to @ops instead of @tf\nPasses Ray's unit tests and runs all confidence tests.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 318,
        "deletions": 323,
        "changed_files": 72,
        "created_at": "2017-02-23T22:32:21Z",
        "closed_at": "2017-03-14T02:14:41Z",
        "merged_at": "2017-03-14T02:14:41Z",
        "body": "",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 18,
        "deletions": 29,
        "changed_files": 8,
        "created_at": "2017-02-23T02:37:07Z",
        "closed_at": "2017-03-25T01:24:49Z",
        "merged_at": null,
        "body": "For the autoencoder models,\r\n\r\n- Xavier initialization was being implemented from scratch while TF has the capability to do this. I changed the model to use the built in functionality. \r\n\r\n- Numpy was being used to generate random normal variables. I instead used TF and removed the import. \r\n\r\n- I was unable to run the models without making the modification to the import (I am not sure how they were working prior)\r\n\r\n- The same performance is reached for all auto encoder models \ud83d\udc4d ",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-02-22T07:21:59Z",
        "closed_at": "2017-03-15T00:17:10Z",
        "merged_at": "2017-03-15T00:17:10Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 53,
        "deletions": 53,
        "changed_files": 12,
        "created_at": "2017-02-22T07:08:05Z",
        "closed_at": "2017-03-15T00:25:37Z",
        "merged_at": null,
        "body": "Several functions are modified such that the Inception code can be executed under the environment of TensorFlow version 1.0, e.g., tf.op_scope->tf.name_scope, tf.image_summary->tf.summary.image, etc..",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 102,
        "deletions": 100,
        "changed_files": 18,
        "created_at": "2017-02-22T02:24:55Z",
        "closed_at": "2017-03-14T02:14:26Z",
        "merged_at": "2017-03-14T02:14:26Z",
        "body": "Mostly generated with the TF 1.0 conversion script, plus a number of manual fixes that were necessary to get the models running.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 48,
        "deletions": 23,
        "changed_files": 2,
        "created_at": "2017-02-22T02:03:26Z",
        "closed_at": "2018-02-26T17:11:58Z",
        "merged_at": "2018-02-26T17:11:58Z",
        "body": "Autoencoder was hardcoded to have only one hidden layer. This PR updates the implementation to be of arbitrary depth based on input parameters. Runner is update accordingly.",
        "comments": 13
    },
    {
        "merged": false,
        "additions": 5138,
        "deletions": 1117,
        "changed_files": 119,
        "created_at": "2017-02-22T00:19:45Z",
        "closed_at": "2017-03-15T01:34:36Z",
        "merged_at": null,
        "body": "The files have been converted to **TensorFlow 1.0 format** using the **\"tf_upgrade.py\"** file provided by TensorFlow. Some incompatibilities have been resolved manually because \"tf_upgrade.py\" could not handle all of them.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-02-21T13:02:47Z",
        "closed_at": "2017-02-22T01:02:35Z",
        "merged_at": "2017-02-22T01:02:35Z",
        "body": "This patch adds the file `__init__.py` in the directory `models/slim`. This makes the folder slim a python packages. This allows to cleanly integrate slim model code as part of your project.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 23,
        "deletions": 15,
        "changed_files": 3,
        "created_at": "2017-02-21T08:48:41Z",
        "closed_at": "2017-04-10T23:50:57Z",
        "merged_at": null,
        "body": "Modify _normalize_digits_ to be a command line parameter",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-02-21T06:11:12Z",
        "closed_at": "2017-02-22T01:05:21Z",
        "merged_at": "2017-02-22T01:05:21Z",
        "body": "Running the compression encoder example in python3 causes the error:\r\n`TypeError: Expected an input array of integer or boolean data type`\r\n\r\n`int_codes` is divided by 2, but in python3 this converts it from an `int8` to `float64` array.\r\n\r\nI am running the gpu version of tensorflow on Windows 10.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-02-21T04:24:55Z",
        "closed_at": "2017-03-14T00:16:16Z",
        "merged_at": "2017-03-14T00:16:16Z",
        "body": "Fixes https://github.com/tensorflow/models/issues/668",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 70,
        "deletions": 70,
        "changed_files": 30,
        "created_at": "2017-02-20T20:44:31Z",
        "closed_at": "2017-02-22T01:01:28Z",
        "merged_at": "2017-02-22T01:01:28Z",
        "body": "\u2026es_initializer()\r\n\r\nThis only removes a lot of warning.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2017-02-20T00:54:51Z",
        "closed_at": "2017-02-22T01:06:49Z",
        "merged_at": "2017-02-22T01:06:49Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 10,
        "changed_files": 1,
        "created_at": "2017-02-18T15:07:45Z",
        "closed_at": "2017-02-19T17:22:44Z",
        "merged_at": "2017-02-19T17:22:44Z",
        "body": "- TF1.0 has breaking changes for tf.concat\r\n- Replace deprecated summary api\r\n- Replace to be deprecated initialize_all_variables",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-02-18T02:51:08Z",
        "closed_at": "2017-03-15T01:35:28Z",
        "merged_at": "2017-03-15T01:35:28Z",
        "body": "noticed the link was broken",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 7,
        "changed_files": 4,
        "created_at": "2017-02-18T01:43:59Z",
        "closed_at": "2017-02-23T02:44:17Z",
        "merged_at": "2017-02-23T02:44:17Z",
        "body": "",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 836,
        "deletions": 46,
        "changed_files": 14,
        "created_at": "2017-02-17T10:51:37Z",
        "closed_at": "2017-02-22T01:11:46Z",
        "merged_at": null,
        "body": "I signed it!",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 101,
        "deletions": 99,
        "changed_files": 19,
        "created_at": "2017-02-16T22:04:57Z",
        "closed_at": "2017-03-15T01:35:56Z",
        "merged_at": null,
        "body": "TF1.0 has breaking changes like tf.concat\r\n(https://www.tensorflow.org/install/migration)\r\nI just applied the script in https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/compatibility\r\nto this directory.",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-02-16T16:09:01Z",
        "closed_at": "2017-02-22T01:09:44Z",
        "merged_at": "2017-02-22T01:09:44Z",
        "body": "Updated concat_v2 to concat for version 1.0 compatibility for breaking changes introduced in version 1.0\r\n\"tf.concat now takes arguments in reversed order and with different keywords. In particular we now match NumPy order as tf.concat(values, axis, name)\"",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-02-15T07:39:55Z",
        "closed_at": "2017-03-15T01:36:39Z",
        "merged_at": "2017-03-15T01:36:39Z",
        "body": "The average pool is used but named 'MaxPool_0a_7x7'.\r\nChange it to 'AvgPool_0a_7x7'.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2552,
        "deletions": 0,
        "changed_files": 14,
        "created_at": "2017-02-15T07:31:45Z",
        "closed_at": "2017-03-20T19:23:44Z",
        "merged_at": null,
        "body": "1. \r\n\r\nIn _models/autoencoder/AdditiveGaussianNoiseAutoencoderRunner.py :46_\r\nChanging\r\n   ```\r\n # Display logs per epoch step\r\n    if epoch % display_step == 0:\r\n        print \"Epoch:\", '%04d' % (epoch + 1), \\\r\n            \"cost=\", \"{:.9f}\".format(avg_cost)\r\n\r\nprint \"Total cost: \" + str(autoencoder.calc_total_cost(X_test))\r\n\r\n```\r\nto\r\n```\r\n    # Display logs per epoch step\r\n    if epoch % display_step == 0:\r\n        print(\"Epoch:\", '%04d' % (epoch + 1), \\\r\n            \"cost=\", \"{:.9f}\".format(avg_cost))\r\n\r\nprint(\"Total cost: \" + str(autoencoder.calc_total_cost(X_test)))\r\n```\r\nAlso for _models/autoencoder/AutoencoderRunner.py , MaskingNoiseAutoencoderRunner.py and VariationalAutoencoderRunner.py_\r\n\r\n2. \r\nIn _models/autoencoder/autoencoder_models/Autoencoder.py :24_\r\nChanging\r\n    ` init = tf.initialize_all_variables()`\r\nto\r\n    `init = tf.global_variables_initializer()`\r\n\r\nAlso for _models/autoencoder/autoencoder_models/DenoisingAutoencoder.py and models/autoencoder/autoencoder_models/VariationalAutoencoder.py ._\r\n\r\nBecause \r\n**tf.initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\r\nInstructions for updating:\r\nUse tf.global_variables_initializer instead.**\r\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2017-02-15T01:29:27Z",
        "closed_at": "2017-02-15T19:04:15Z",
        "merged_at": "2017-02-15T19:04:15Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-02-14T19:12:38Z",
        "closed_at": "2017-03-15T01:38:27Z",
        "merged_at": null,
        "body": "`tf.concat(concat_dim, values, name='concat')` is the new API under r0.12",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-02-14T06:09:36Z",
        "closed_at": "2017-03-15T01:40:09Z",
        "merged_at": "2017-03-15T01:40:09Z",
        "body": "correct small mistake. I think it is better to change order for precise code.\r\nhttps://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_input.py#L239\r\n\r\nchange order of arguments\r\n[reshaped_image, width, height] -> [reshaped_image, height, width]\r\n\r\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 20,
        "changed_files": 5,
        "created_at": "2017-02-13T21:42:11Z",
        "closed_at": "2017-02-13T22:45:56Z",
        "merged_at": "2017-02-13T22:45:56Z",
        "body": "Settles an issue raised by @JavidPack in https://github.com/tensorflow/models/pull/948.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1156,
        "deletions": 1026,
        "changed_files": 102,
        "created_at": "2017-02-10T23:46:00Z",
        "closed_at": "2017-02-22T00:16:28Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-02-09T12:36:21Z",
        "closed_at": "2017-02-22T01:42:09Z",
        "merged_at": "2017-02-22T01:42:09Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 2,
        "changed_files": 3,
        "created_at": "2017-02-07T07:30:17Z",
        "closed_at": "2017-04-11T22:21:08Z",
        "merged_at": "2017-04-11T22:21:08Z",
        "body": "The arg_scope of the network_fn was being determined when get_network_fn was called. Thus, the network_fn 'escaped' back to the closure (I hope I'm using that term right?) in which it was originally created, ignoring the arg-scope stack created afterwards by the clone. When the first clone called the network_fn, the weights were put on the default device. So for two GPUs (and two clones), the weights would be assigned to first clone / first GPU, and the second clone would have to read the weights from the first clone's memory.\r\n\r\nI simply moved the call to create the model's arg_scope from the outer get_network_fn to the inner network_fn. This way, when network_fn gets called, the model's arg_scope is properly nested within the arg_scopes created by the clones.\r\n\r\nEdit: Related to this issue: https://github.com/tensorflow/models/issues/677",
        "comments": 11
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-02-07T01:09:09Z",
        "closed_at": "2017-02-22T01:43:17Z",
        "merged_at": "2017-02-22T01:43:17Z",
        "body": "Remove the deprecated `scalar_summary` and use `summary.scalar` instead. \r\n\r\nThe current program gets the following warning:\r\n> WARNING:tensorflow:\r\nbuild_graph.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\r\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 24,
        "deletions": 25,
        "changed_files": 4,
        "created_at": "2017-02-05T19:59:17Z",
        "closed_at": "2017-03-15T01:39:03Z",
        "merged_at": null,
        "body": "Make Inception (v3) trainable on Tensorflow 1.0RC1.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-02-05T15:05:57Z",
        "closed_at": "2017-03-16T00:13:40Z",
        "merged_at": "2017-03-16T00:13:40Z",
        "body": "One of the main changes is swapping the arguments of the function sampled_loss(). Also made appropriate changes to package reference so it is able to run with the tensorflow's version available in the repo.\r\n\r\nThanks\r\nArvind",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-02-04T21:10:04Z",
        "closed_at": "2017-03-15T01:43:01Z",
        "merged_at": null,
        "body": "",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-02-03T15:38:55Z",
        "closed_at": "2017-03-15T01:43:37Z",
        "merged_at": null,
        "body": "",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 13,
        "changed_files": 3,
        "created_at": "2017-01-28T12:30:44Z",
        "closed_at": "2017-02-06T06:26:53Z",
        "merged_at": null,
        "body": "for the master branch tensorflow, there is no `tf.image_summary` and will cause a bug,\r\nso this need to be change to `tf.summary.image`, since tensorflow 1.0 use this and will be a stable api, update all these kind of api changes (also a tf.mul -> tf.multiply)",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 20,
        "deletions": 18,
        "changed_files": 3,
        "created_at": "2017-01-27T19:24:06Z",
        "closed_at": "2017-03-15T01:44:40Z",
        "merged_at": null,
        "body": "* tf.histogram_summary -> tf.summary.histogram\r\n* tf.scalar_summary -> tf.summary.scalar\r\n* tf.image_summary -> tf.summary.imageq\r\n* adjust tf.strided_slice",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 2615,
        "deletions": 607,
        "changed_files": 6,
        "created_at": "2017-01-25T19:27:15Z",
        "closed_at": "2017-01-27T04:02:01Z",
        "merged_at": "2017-01-27T04:02:01Z",
        "body": "This updates the Neural GPU to work with TF 1.0 API, adds program synthesis, and the extended version for WMT.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 195,
        "deletions": 171,
        "changed_files": 43,
        "created_at": "2017-01-24T22:24:47Z",
        "closed_at": "2017-01-25T17:58:41Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 14,
        "changed_files": 3,
        "created_at": "2017-01-24T19:49:11Z",
        "closed_at": "2017-01-30T23:54:16Z",
        "merged_at": "2017-01-30T23:54:16Z",
        "body": "",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2017-01-24T05:04:18Z",
        "closed_at": "2017-03-15T01:45:01Z",
        "merged_at": null,
        "body": "This prevents issues with new versions of TF.\r\nMinor self explanatory changes.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-01-23T21:27:34Z",
        "closed_at": "2017-03-16T00:25:03Z",
        "merged_at": null,
        "body": "The to vocabulary shares the same name with the from one, can not be loaded when decoding.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-01-22T23:51:10Z",
        "closed_at": "2017-01-25T19:34:44Z",
        "merged_at": null,
        "body": "Echo command requires one more newline to answer CUDA support question.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 70,
        "deletions": 73,
        "changed_files": 7,
        "created_at": "2017-01-20T19:37:02Z",
        "closed_at": "2017-01-20T23:47:10Z",
        "merged_at": "2017-01-20T23:47:10Z",
        "body": "replace tf.op_scope with tf.name_scope and tf.variable_op_scope with tf.variable_scope; fix the order of arguments for tf.concat; replace tf.mul with tf.multiply.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 15,
        "deletions": 10,
        "changed_files": 2,
        "created_at": "2017-01-20T19:23:51Z",
        "closed_at": "2017-01-20T21:00:02Z",
        "merged_at": "2017-01-20T21:00:02Z",
        "body": "Fixes changes from https://github.com/tensorflow/models/commit/c902a86785052291083682c4b833747e7ea52597",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 17,
        "changed_files": 16,
        "created_at": "2017-01-19T09:27:52Z",
        "closed_at": "2017-03-15T01:46:35Z",
        "merged_at": "2017-03-15T01:46:35Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-01-19T04:01:27Z",
        "closed_at": "2017-04-06T01:04:59Z",
        "merged_at": null,
        "body": "This small edit should close #910 \r\n\r\nIt replaces gfile with standard OS functions",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-01-17T22:46:10Z",
        "closed_at": "2017-01-18T00:55:10Z",
        "merged_at": "2017-01-18T00:55:10Z",
        "body": "See https://github.com/tensorflow/models/issues/914\r\n\r\nTested this on my Macbook as well. Also changed the `wget` commands to `curl` since I think that should work out of the box on both Linux and Mac.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 20,
        "deletions": 19,
        "changed_files": 1,
        "created_at": "2017-01-17T03:18:03Z",
        "closed_at": "2017-02-13T23:46:27Z",
        "merged_at": "2017-02-13T23:46:27Z",
        "body": "Make the cifar10 example (especially, multi_gpu_train) work in the recent master version. This PR includes two updates:\r\n\r\n- Replace `tf.mul` (which was removed) with `tf.multiply` (#901).\r\n- Correct the usage of variable_scope around the part multi-gpu model construction, so that \"reuse\" on the variable scope becomes not leaky (tensorflow/tensorflow#6220).",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 20,
        "deletions": 15,
        "changed_files": 3,
        "created_at": "2017-01-16T14:46:43Z",
        "closed_at": "2017-03-15T01:50:56Z",
        "merged_at": null,
        "body": "I have updated the cifar10 example to work with tensorflow 0.12.1",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 10,
        "deletions": 10,
        "changed_files": 2,
        "created_at": "2017-01-16T08:12:50Z",
        "closed_at": "2017-03-15T01:51:05Z",
        "merged_at": null,
        "body": "cifar10 scripts don't work with tensorflow r0.12.\r\nThat's why I modified the code a bit by changing the name of the functions.\r\nAnd I also resolved the deprecated.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 15,
        "changed_files": 1,
        "created_at": "2017-01-15T23:55:38Z",
        "closed_at": "2017-01-16T02:07:08Z",
        "merged_at": "2017-01-16T02:07:08Z",
        "body": "This documentation seems to have fallen out of date. I don't see any evidence that syntaxnet requires an older version of Bazel than TensorFlow uses. If it legitimately does, that's a separate bug. It's probably better to remove this documentation so it doesn't drift from the official ones.\r\n\r\nFixes #657 ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-01-15T22:47:36Z",
        "closed_at": "2017-01-16T02:08:35Z",
        "merged_at": "2017-01-16T02:08:35Z",
        "body": "Fixed #903 ",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 58,
        "deletions": 58,
        "changed_files": 5,
        "created_at": "2017-01-14T17:58:27Z",
        "closed_at": "2017-03-15T01:40:43Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 37,
        "deletions": 23,
        "changed_files": 2,
        "created_at": "2017-01-14T10:04:37Z",
        "closed_at": "2017-03-15T01:51:27Z",
        "merged_at": null,
        "body": "",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-01-14T04:49:05Z",
        "closed_at": "2017-01-15T08:54:53Z",
        "merged_at": "2017-01-15T08:54:53Z",
        "body": "This will fix #793.",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-01-14T00:47:29Z",
        "closed_at": "2017-03-15T01:50:24Z",
        "merged_at": null,
        "body": "Method named \"per_image_whitening\" not available in latest tensorflow distribution. This Pull request aims to to fix this issue.\r\n\r\nP.S. Created new pull request because of missing commit email.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-01-13T22:46:51Z",
        "closed_at": "2017-01-14T00:05:19Z",
        "merged_at": "2017-01-14T00:05:19Z",
        "body": "Fixes https://github.com/tensorflow/models/issues/870",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-01-12T10:46:28Z",
        "closed_at": "2017-03-16T01:33:24Z",
        "merged_at": "2017-03-16T01:33:24Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2017-01-11T22:52:32Z",
        "closed_at": "2017-01-12T01:22:50Z",
        "merged_at": null,
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2689,
        "deletions": 0,
        "changed_files": 7,
        "created_at": "2017-01-11T22:02:43Z",
        "closed_at": "2017-01-12T20:00:34Z",
        "merged_at": "2017-01-12T20:00:34Z",
        "body": "Code for the [*Density estimation using Real NVP*](https://arxiv.org/abs/1605.08803) paper I did in collaboration with Jascha and Samy at Google Brain.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-01-11T11:20:48Z",
        "closed_at": "2017-01-14T02:19:03Z",
        "merged_at": "2017-01-14T02:19:03Z",
        "body": "The neural programmer model fails the first time it's run, if the output directory folder does not already exist. In this case \"../model\" does not exist and the function fails because the mkdir function doesn't appear to create parent folders. \r\nError: \r\ntensorflow.python.framework.errors_impl.NotFoundError: ../model//modeltemp/",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-01-10T10:50:42Z",
        "closed_at": "2017-01-14T01:59:54Z",
        "merged_at": "2017-01-14T01:59:54Z",
        "body": "Update based on the error message:\r\n WARNING:tensorflow:From ./neural_programmer/parameters.py:75 in parameters.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2017-01-09T19:51:56Z",
        "closed_at": "2017-01-09T23:10:17Z",
        "merged_at": "2017-01-09T23:10:17Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 11,
        "deletions": 12,
        "changed_files": 2,
        "created_at": "2017-01-07T07:02:11Z",
        "closed_at": "2017-03-15T01:51:36Z",
        "merged_at": null,
        "body": "1. Update to new tensor summary API.\r\n2. Replace strided_slice with slice to avoid errors caused by different number of default arguments of strided_slice in various TensorFlow versions.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 125,
        "changed_files": 1,
        "created_at": "2017-01-06T00:55:01Z",
        "closed_at": "2017-01-06T02:00:49Z",
        "merged_at": "2017-01-06T02:00:49Z",
        "body": "See https://github.com/tensorflow/models/issues/831",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-01-06T00:25:26Z",
        "closed_at": "2017-01-06T01:41:38Z",
        "merged_at": "2017-01-06T01:41:38Z",
        "body": "The tutorial models currently have code that is not compatible with the r0.12 release of TensorFlow due to breaking API changes.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2017-01-05T07:28:54Z",
        "closed_at": "2017-03-15T01:51:59Z",
        "merged_at": "2017-03-15T01:51:59Z",
        "body": "They should point right paths!",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2017-01-05T07:17:57Z",
        "closed_at": "2017-01-18T21:55:53Z",
        "merged_at": "2017-01-18T21:55:53Z",
        "body": "Seems like there was something wrong while copy and paste \ud83d\ude04 ",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 17,
        "changed_files": 2,
        "created_at": "2017-01-05T05:22:44Z",
        "closed_at": "2017-01-09T01:36:53Z",
        "merged_at": null,
        "body": "This change:\r\n\r\n * Adds missing parameters to strided_slice() calls, and\r\n * Replaces deprecated summary APIs with new ones.\r\n\r\nNote that both of these changes are upward compatible\r\nto future versions.",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2017-01-03T02:11:30Z",
        "closed_at": "2017-01-13T16:05:30Z",
        "merged_at": "2017-01-13T16:05:30Z",
        "body": "Fix of #839.\r\n\r\nClass `Caption` is not comparable on Python3, because `cmp` is deprecated.\r\n\r\nSo I added `lt` and `eq`.\r\n\r\nBy the way, `xrange`is renamed to `range` on Python3, so I had to change them as well.\r\n\r\nHow do we make it both 2 and 3 compatible?",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2017-01-02T16:56:47Z",
        "closed_at": "2017-04-10T23:48:45Z",
        "merged_at": null,
        "body": "",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2016-12-30T07:17:41Z",
        "closed_at": "2017-01-05T08:40:36Z",
        "merged_at": "2017-01-05T08:40:36Z",
        "body": "_bytes_feature excepted class bytes, but in python3 in class str,so use tf.compat.as_bytes for compatibility !",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 7,
        "changed_files": 3,
        "created_at": "2016-12-29T23:07:34Z",
        "closed_at": "2017-01-16T03:21:25Z",
        "merged_at": "2017-01-16T03:21:25Z",
        "body": "1. tf.image.per_image_whitening -> tf.image.per_image_standardization\r\n2. Use tf.summary to replace tf.image_summary, tf.scalar_summary, tf.merge_all_summaries.\r\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 9,
        "deletions": 9,
        "changed_files": 2,
        "created_at": "2016-12-28T07:28:33Z",
        "closed_at": "2017-03-15T01:53:06Z",
        "merged_at": null,
        "body": "tutorial/rnn/ptb is not working on TensorFlow 0.12.1\r\n\r\nEvidences:\r\n\r\nhttps://github.com/tensorflow/tensorflow/pull/6200#issuecomment-266135026 complains about `sequence_loss_by_example` been moved to `tf.nn.seq2seq.sequence_loss_by_example`\r\nhttps://github.com/tensorflow/tensorflow/issues/6468 complains about `strided_slice() takes at least 4 arguments (3 given)`\r\nhttps://github.com/tensorflow/tensorflow/issues/6432 complains about `MultiRNNCell` been moved to `tf.nn.rnn_cell`\r\n\r\nAnd I also replaced deprecated `tf.contrib.deprecated.scalar_summary` with `tf.summary.scalar`.\r\n\r\nIt works now on 0.12.1.\r\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2016-12-28T00:52:10Z",
        "closed_at": "2016-12-28T23:39:07Z",
        "merged_at": "2016-12-28T23:39:07Z",
        "body": "Fix for https://github.com/tensorflow/models/issues/771",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-12-27T00:25:59Z",
        "closed_at": "2016-12-27T20:58:11Z",
        "merged_at": "2016-12-27T20:58:11Z",
        "body": "\"resisual\" => \"residual\"",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 13,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2016-12-25T16:33:04Z",
        "closed_at": "2017-01-18T19:27:34Z",
        "merged_at": "2017-01-18T19:27:34Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-12-25T15:16:28Z",
        "closed_at": "2017-04-11T00:03:10Z",
        "merged_at": null,
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-12-24T15:47:26Z",
        "closed_at": "2016-12-27T20:59:53Z",
        "merged_at": "2016-12-27T20:59:53Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 96,
        "deletions": 44,
        "changed_files": 3,
        "created_at": "2016-12-23T22:01:44Z",
        "closed_at": "2017-01-14T21:55:36Z",
        "merged_at": "2017-01-14T21:55:36Z",
        "body": "Fix for #748 \r\n\r\nWith these changes, anyone should be able to train a translation model with any input data, and not only for Eng/Fre pair. Training the model with own data now can be done by executing:\r\n\r\n```\r\npython translate.py\r\n  --data_dir=\".\" \\\r\n  --from_train_data=train.a \\\r\n  --to_train_data=train.b \\\r\n  --from_dev_data=train.a \\\r\n  --to_dev_data=train.b \\\r\n  --steps_per_checkpoint=10\r\n```\r\n\r\nThe detailed example of how the logic can be used: https://blog.kovalevskyi.com/rnn-based-chatbot-for-6-hours-b847d2d92c43#.2cbxvmtxx \r\n\r\nAlso, the pull-request includes fixes for the code that are required for the code to be workable. Current implementation is not working with the latest TF r0.12 (so no one at the moment can actually use it as is). For example, current implementation have references to the  ```tf.contrib.legacy_seq2seq``` wich is no longer exists starting TF 0.12.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-12-23T20:45:22Z",
        "closed_at": "2016-12-27T21:02:27Z",
        "merged_at": null,
        "body": "remove unused import statement\r\n<pre><code>\r\nimport gzip\r\n</code></pre>",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 14,
        "changed_files": 4,
        "created_at": "2016-12-23T02:04:19Z",
        "closed_at": "2016-12-28T00:23:20Z",
        "merged_at": "2016-12-28T00:23:20Z",
        "body": "It doesn't seem possible to get this code to run using bazel unfortunately. I believe this is because when bazel calls `load(\"//tensorflow:tensorflow.bzl\", \"tf_gen_op_wrapper_py\")`, it's unable to continue recursively loading within the TensorFlow repo, even after adding the TensorFlow repo into this repo's WORKSPACE file. This prevents us from being able to use `tf_gen_op_wrapper_py` and import the ops as needed.\r\n\r\nI was finally able to get this model working by following the [TensorFlow tutorial for adding a new op](https://www.tensorflow.org/how_tos/adding_an_op/#building_the_op_library) and instructing the users to compile the ops on their own before running.\r\n\r\nUnfortunately, this results in the Python code having to load word2vec_ops.so, which is not ideal and not cross-platform friendly. If you have other ideas for how to solve this, definitely let me know.",
        "comments": 16
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-12-21T12:34:11Z",
        "closed_at": "2017-02-07T06:57:28Z",
        "merged_at": null,
        "body": "\r\nThe arg_scope of the network_fn was being determined when get_network_fn was called. Thus, the network_fn 'escaped' back to the closure (I hope I'm using that term right?) in which it was originally created, ignoring the arg-scope stack created afterwards by the clone. When the first clone called the network_fn, the weights were put on the default device.  So for two GPUs (and two clones), the weights would be assigned to first clone / first GPU, and the second clone would have to read the weights from the first clone's memory.\r\n\r\nI simply moved the call to create the model's arg_scope from the outer get_network_fn to the inner network_fn.  This way, when network_fn gets called, the model's arg_scope is properly nested within the arg_scopes created by the clones.",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 17,
        "deletions": 17,
        "changed_files": 5,
        "created_at": "2016-12-21T08:05:05Z",
        "closed_at": "2017-01-18T19:14:21Z",
        "merged_at": "2017-01-18T19:14:21Z",
        "body": "according to #784  after upgrading tf version to 0.12 tf.contrib.deprecated has been eliminated. This pull request fixes the code to make it work with tf version 0.12.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 5,
        "changed_files": 2,
        "created_at": "2016-12-21T05:00:58Z",
        "closed_at": "2017-03-16T04:37:51Z",
        "merged_at": "2017-03-16T04:37:51Z",
        "body": "Fix deprecation of sum_of_squares so the notebook works with TF 0.12.\r\n\r\n#782 ",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 8,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-12-21T04:25:45Z",
        "closed_at": "2017-01-14T02:03:06Z",
        "merged_at": null,
        "body": "Otherwise breaks with `TypeError: unorderable types: Caption() < Caption()` in Python 3.5",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2016-12-20T17:02:50Z",
        "closed_at": "2017-01-11T19:29:11Z",
        "merged_at": "2017-01-11T19:29:11Z",
        "body": "When I ran the inception model with `num_gpus=2`, it gave me the following error: \r\n  ```\r\n  ValueError: Variable tower_1/tower_1/CrossEntropyLoss/value/avg/biased does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?\r\n  ```\r\n\r\nThere is also a similar issue: https://github.com/tensorflow/models/issues/767.\r\n\r\nI guess the variables defined in ExponentialMovingAverage could be unshared. This makes the model train but I am not sure whether it changes the result. Please advise. ",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2016-12-20T16:48:28Z",
        "closed_at": "2016-12-21T07:52:22Z",
        "merged_at": "2016-12-21T07:52:22Z",
        "body": "Without the change, when I run the inception model with command \r\n  ```\r\n  bazel-bin/inception/imagenet_train --num_gpus=1 --batch_size=32 --train_dir=/tmp/imagenet_train --data_dir=/tmp/imagenet-data\r\n  ```\r\nit would fail with the error\r\n  ```\r\n  Traceback (most recent call last):\r\n  File \"/home/ubuntu/2nd/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/imagenet_train.py\", line 41, in <module>\r\n    tf.app.run()\r\n  File \"/home/ubuntu/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 43, in run\r\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\r\n  File \"/home/ubuntu/2nd/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/imagenet_train.py\", line 37, in main\r\n    inception_train.train(dataset)\r\n  File \"/home/ubuntu/2nd/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/inception_train.py\", line 239, in train\r\n    scope)\r\n  File \"/home/ubuntu/2nd/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/inception_train.py\", line 108, in _tower_loss\r\n    scope=scope)\r\n  File \"/home/ubuntu/2nd/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/inception_model.py\", line 87, in inference\r\n    scope=scope)\r\n  File \"/home/ubuntu/2nd/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/slim/inception_model.py\", line 87, in inception_v3\r\n    scope='conv0')\r\n  File \"/home/ubuntu/2nd/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/slim/scopes.py\", line 155, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"/home/ubuntu/2nd/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/slim/ops.py\", line 234, in conv2d\r\n    outputs = batch_norm(conv, **batch_norm_params)\r\n  File \"/home/ubuntu/2nd/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/slim/scopes.py\", line 155, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"/home/ubuntu/2nd/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/slim/ops.py\", line 111, in batch_norm\r\n    collections=moving_collections)\r\n  File \"/home/ubuntu/2nd/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/slim/scopes.py\", line 155, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"/home/ubuntu/2nd/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/slim/variables.py\", line 289, in variable\r\n    trainable=trainable, collections=collections)\r\n  File \"/home/ubuntu/.local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1024, in get_variable\r\n    custom_getter=custom_getter)\r\n  File \"/home/ubuntu/.local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 850, in get_variable\r\n    custom_getter=custom_getter)\r\n  File \"/home/ubuntu/.local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 346, in get_variable\r\n    validate_shape=validate_shape)\r\n  File \"/home/ubuntu/.local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 331, in _true_getter\r\n    caching_device=caching_device, validate_shape=validate_shape)\r\n  File \"/home/ubuntu/.local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 677, in _get_single_variable\r\n    expected_shape=shape)\r\n  File \"/home/ubuntu/.local/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 224, in __init__\r\n    expected_shape=expected_shape)\r\n  File \"/home/ubuntu/.local/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 327, in _init_from_args\r\n    initial_value(), name=\"initial_value\", dtype=dtype)\r\n  File \"/home/ubuntu/.local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 665, in <lambda>\r\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\r\nTypeError: ones_initializer() got multiple values for keyword argument 'dtype'\r\n  ```",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-12-20T00:38:04Z",
        "closed_at": "2016-12-20T22:39:00Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2016-12-19T16:44:38Z",
        "closed_at": "2017-06-01T20:37:45Z",
        "merged_at": null,
        "body": "Changed the `_meshgrid` function to use the new `tf.meshgrid` and `tf.linspace` available from tensorflow rc.0.10 +",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2016-12-19T05:44:00Z",
        "closed_at": "2017-03-15T01:53:31Z",
        "merged_at": null,
        "body": "I'm working with `models/tutorials/image/cifar10/`.\r\n\r\nThere is an error `strided_slice() missing 1 required positional argument: 'strides'` when I run the command `python cifar10_train.py` under the version of 0.12.0-rc1. Although the [document](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/api_docs/python/functions_and_classes/shard8/tf.strided_slice.md) said `strides` is optional.\r\n\r\nSo I replaced `strided_slice` with `slice` to make it work as a temporary solution.",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 12,
        "deletions": 12,
        "changed_files": 5,
        "created_at": "2016-12-15T10:25:55Z",
        "closed_at": "2017-01-14T02:05:04Z",
        "merged_at": "2017-01-14T02:05:04Z",
        "body": "This PR makes it possible to use some inception scripts with python 3.\r\n\r\nRegarding python 3, the problems were essentially:\r\n\r\nxrange => range\r\nx=range(l); random.suffle(x) => x=list(range(l)); ...\r\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-12-15T06:45:53Z",
        "closed_at": "2016-12-27T21:03:46Z",
        "merged_at": null,
        "body": "",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 14,
        "deletions": 16,
        "changed_files": 3,
        "created_at": "2016-12-14T07:29:32Z",
        "closed_at": "2017-03-15T01:59:14Z",
        "merged_at": null,
        "body": "Verified working on tensorflow 0.12rc1",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 105,
        "deletions": 7,
        "changed_files": 6,
        "created_at": "2016-12-13T16:52:55Z",
        "closed_at": "2017-03-16T02:08:46Z",
        "merged_at": "2017-03-16T02:08:46Z",
        "body": "Align model slim/resnet to slim/inception (set spatial_squeeze and default_image_size).\r\nAlso add a sample script for training resnet_v1_50 on flower set.\r\n\r\nThis solves #690 ",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 16,
        "deletions": 11,
        "changed_files": 4,
        "created_at": "2016-12-13T12:37:47Z",
        "closed_at": "2017-03-16T01:51:28Z",
        "merged_at": null,
        "body": "The '--pretrained_model_checkpoint_path' specify the file of a checkpoint and the new checkpoint V2 is not support read from file. \r\nBecause of the changes to tf.all_variables() and tf.GraphKeys, the collection name is changed and the necessary parameters in checkpoint cannot be saved in training process which cause checkpoint not able to be read to continue training. ",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 78,
        "deletions": 9,
        "changed_files": 2,
        "created_at": "2016-12-13T10:03:21Z",
        "closed_at": "2016-12-16T18:31:55Z",
        "merged_at": null,
        "body": "With this pull request you can easily translate/test a batch of sentences, which makes it easier to see how good your trained model is.\r\n\r\nIf you specify a filename this functionality is used, if you don't specify anything the script continues to function as it used to.",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 13,
        "changed_files": 6,
        "created_at": "2016-12-12T19:22:02Z",
        "closed_at": "2017-03-15T01:54:14Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-12-12T15:17:06Z",
        "closed_at": "2017-01-18T19:25:47Z",
        "merged_at": null,
        "body": "fixed broken url link",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-12-12T12:20:28Z",
        "closed_at": "2017-01-14T01:58:36Z",
        "merged_at": null,
        "body": "All the words became `_UNK` since the keys of `vocab` were in `str` type.\r\nThe problem occurred in Python 3.5",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 17,
        "deletions": 18,
        "changed_files": 5,
        "created_at": "2016-12-11T02:50:38Z",
        "closed_at": "2017-03-15T01:54:24Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 7,
        "deletions": 7,
        "changed_files": 2,
        "created_at": "2016-12-10T23:59:23Z",
        "closed_at": "2017-03-16T04:25:16Z",
        "merged_at": null,
        "body": "1. Thanks for @cshallue 's [solution](https://github.com/tensorflow/models/commit/946c75e5b531691e40905e86c5a937052e2a6596) for im2txt to fix the global_step uninitialized error in distributed mode.\r\n2. In inception model, change ones_intializer to ones_initializer() to fit the new tensorflow python API.",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2016-12-10T19:53:37Z",
        "closed_at": "2017-03-15T01:56:00Z",
        "merged_at": null,
        "body": "https://www.tensorflow.org/code/tensorflow/contrib/losses/python/losses/loss_ops.py was refactored and now when running script produces a WARNING.\r\n\r\n```\r\nWARNING:tensorflow:From train_image_classifier.py:477 in clone_fn.: calling softmax_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) with weight is deprecated and will be removed after 2016-11-25.\r\nInstructions for updating:\r\n`weight` is being deprecated, use `weights`\r\n```",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 5867,
        "deletions": 0,
        "changed_files": 45,
        "created_at": "2016-12-10T02:39:41Z",
        "closed_at": "2016-12-10T08:28:25Z",
        "merged_at": "2016-12-10T08:28:25Z",
        "body": "Also brought everything up to date with the internal version.",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 9,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2016-12-08T15:52:16Z",
        "closed_at": "2016-12-08T17:49:51Z",
        "merged_at": "2016-12-08T17:49:51Z",
        "body": "Necessary vocabulary tokens are now checked using CheckVocab method in Class Vocab.\r\nAn AssertionError is raised if the necessary token is not present in Vocabulary.\r\nFixes #621 ",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2016-12-07T17:19:29Z",
        "closed_at": "2016-12-27T21:05:02Z",
        "merged_at": "2016-12-27T21:05:02Z",
        "body": "Fixed typos in folders paths",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2016-12-06T08:32:32Z",
        "closed_at": "2016-12-14T04:29:18Z",
        "merged_at": null,
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2016-11-25T20:43:55Z",
        "closed_at": "2016-12-09T22:10:30Z",
        "merged_at": "2016-12-09T22:10:30Z",
        "body": "Simple edits to the README file, updating location of data etc.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 11,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2016-11-24T13:55:41Z",
        "closed_at": "2017-03-15T02:00:00Z",
        "merged_at": null,
        "body": "The `resize_images` APIs of TensorFlow 10 and 11 are different as follow.\r\n```python\r\n  if resize_height:\r\n    try:\r\n      image = tf.image.resize_images(image,\r\n             size=[resize_height, resize_width],\r\n             method=tf.image.ResizeMethod.BILINEAR)\r\n    except:\r\n      image = tf.image.resize_images(image,     \r\n             new_height=resize_height,\r\n             new_width=resize_width,\r\n             method=tf.image.ResizeMethod.BILINEAR)\r\n```",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 24,
        "deletions": 6,
        "changed_files": 1,
        "created_at": "2016-11-24T01:17:10Z",
        "closed_at": "2017-04-10T23:32:37Z",
        "merged_at": "2017-04-10T23:32:37Z",
        "body": "Hello,\r\n\r\nThe original implementation of VGG models has fully connected layers implemented as convolution.\r\n\r\nIt gives predictable results when the network is used for classification.\r\n\r\nIt is also possible to apply the network in a fully convolutional manner like it is described in the paper\r\n\"fully convolutional networks for Image Segmentation\".This part also works except one small detail -- \r\nthe padding that is specified for the fc layer that is implemented as convolution is specified to be 'VALID'.\r\nThis gives the downsampled ouput of (input / 32) - 6. To be able to apply the network like it was\r\ndescribed in the paper the ouput should be (input / 32). This can be achieved by using 'SAME' padding.\r\nThis makes it possible to upsample the ouput by 32 and get predictions of the same size as an input image. Here are examples where I have applied the vgg network in a fully convolutional manner\r\n, giving prediction map for 1000 classes of Imagenet:\r\n\r\nInput\r\n![image](http://warmspringwinds.github.io/assets/img/Untitled1_13_0.png)\r\n\r\nValid padding\r\n![image](https://cloud.githubusercontent.com/assets/2501383/20583547/4efb0bd4-b1eb-11e6-90b6-ad51c285c51f.png)\r\n\r\nSame padding\r\n![image](http://warmspringwinds.github.io/assets/img/Untitled3_17_1.png)\r\n\r\nYou can see that in the second picture the image was downsampled by 32 while on the first one\r\nwe also lost 6 pixels.\r\n\r\n\r\nI suggest to add one more argument to the definition of models to be able to switch between those two\r\ntypes of paddings depending on what user wants to do.",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 1069,
        "deletions": 0,
        "changed_files": 7,
        "created_at": "2016-11-21T22:39:11Z",
        "closed_at": "2017-03-16T16:20:18Z",
        "merged_at": null,
        "body": "https://arxiv.org/abs/1506.06726",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2016-11-21T18:23:28Z",
        "closed_at": "2017-03-15T02:00:30Z",
        "merged_at": "2017-03-15T02:00:30Z",
        "body": "Two shards, so the shard pattern should be `?????-of-00002`.",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 523,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-11-18T16:52:52Z",
        "closed_at": "2017-03-21T15:53:36Z",
        "merged_at": null,
        "body": "I've added an adaptation of the flowers retraining demo but for multiple GPUs, so you can train all of the models in Slim now making full use of a GPU array.",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 16,
        "deletions": 20,
        "changed_files": 1,
        "created_at": "2016-11-17T19:47:12Z",
        "closed_at": "2018-02-07T23:29:51Z",
        "merged_at": null,
        "body": "I had issue described in #193, in both 42x42 -> 28x28 and 28x28 -> 42x42 cases (size of input to STN -> size of STN output), where I always had a black border of a few pixels on down/right side.\r\n\r\nI basically looked at Lasagne changes of [1] and backported those in here.\r\n\r\nI've only tested with identity transformation which now works as expected (no black border).\r\n\r\n[1] https://github.com/Lasagne/Lasagne/blob/master/lasagne/layers/special.py",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-11-17T09:03:43Z",
        "closed_at": "2017-03-16T04:03:03Z",
        "merged_at": "2017-03-16T04:03:03Z",
        "body": "In some XML annotation files, point values [xmin, ymin, xmax, ymax] relative to bounding box are string type look like a float number. So if want to use int() convert those string to int. The program will raise an ValueError.Such as:\r\n`ValueError: invalid literal for int() with base 10: '64.0994'`\r\n\r\nSo I fixed this bug by adding an float function before int function.",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 11,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-11-16T22:36:32Z",
        "closed_at": "2016-11-17T18:15:10Z",
        "merged_at": "2016-11-17T18:15:10Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 184,
        "deletions": 4,
        "changed_files": 5,
        "created_at": "2016-11-16T17:00:54Z",
        "closed_at": "2017-06-01T20:28:29Z",
        "merged_at": null,
        "body": "",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2016-11-16T15:08:25Z",
        "closed_at": "2017-03-16T04:51:28Z",
        "merged_at": null,
        "body": "Otherwise there is no Size() in GFile anymore and it causes the downloading failure.",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2016-11-15T15:30:51Z",
        "closed_at": "2017-03-16T00:35:15Z",
        "merged_at": null,
        "body": "# Description\r\n\r\nI was getting the following error while trying to run **namignizer** model with `Python 2.7.12` and `TensorFlow 0.11.0`:\r\n```\r\nTraceback (most recent call last):\r\n  File \"names.py\", line 257, in <module>\r\n    train(\"data/SmallNames.txt\", \"model/namignizer\", SmallConfig)\r\n  File \"names.py\", line 171, in train\r\n    verbose=True)\r\n  File \"names.py\", line 125, in run_epoch\r\n    m.initial_state: m.initial_state.eval(),\r\nAttributeError: 'tuple' object has no attribute 'eval'\r\n```\r\nThe problem was when doing `m.initial_state.eval()`. I changed it to `session.run(m.initial_state)` (which I guess makes more sense) and now it's working.\r\n\r\nThanks!",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-11-14T18:13:55Z",
        "closed_at": "2017-03-16T01:35:59Z",
        "merged_at": "2017-03-16T01:35:59Z",
        "body": "Fix comment. Address issue: https://github.com/tensorflow/models/issues/634#issuecomment-260399899",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-11-14T14:47:39Z",
        "closed_at": "2017-03-16T01:37:45Z",
        "merged_at": null,
        "body": "",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 40,
        "deletions": 43,
        "changed_files": 5,
        "created_at": "2016-11-14T14:36:31Z",
        "closed_at": "2017-01-17T11:53:40Z",
        "merged_at": null,
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2016-11-10T13:13:44Z",
        "closed_at": "2017-03-16T02:11:48Z",
        "merged_at": "2017-03-16T02:11:48Z",
        "body": "Addresses issue #619.",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-11-09T15:51:57Z",
        "closed_at": "2016-11-09T19:43:18Z",
        "merged_at": "2016-11-09T19:43:18Z",
        "body": "@cshallue it seems validation captions are pointing to the training file.  This looks like a quick fix.",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 1958,
        "changed_files": 9,
        "created_at": "2016-11-04T21:30:02Z",
        "closed_at": "2016-11-08T20:56:54Z",
        "merged_at": "2016-11-08T20:56:54Z",
        "body": "Now differential_privacy and privacy are\r\nunder the same project.",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 301,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-11-02T11:02:20Z",
        "closed_at": "2017-06-01T20:30:07Z",
        "merged_at": null,
        "body": "The defined class provides interface to the LM_1B model through it's methods:\r\n- eval model\r\n- sample_text\r\n- dump_embeddings\r\n- encode_text",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-10-31T06:55:35Z",
        "closed_at": "2016-10-31T20:36:02Z",
        "merged_at": "2016-10-31T20:36:02Z",
        "body": "it should be cd $HOME/workspace/models/slim",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 100,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2016-10-27T18:51:30Z",
        "closed_at": "2017-03-02T17:45:54Z",
        "merged_at": "2017-03-02T17:45:54Z",
        "body": "A small update that makes it easier for end-users to understand the difference of how to\nmake inference with models that were trained using 1000 classes and 1001 classes on imagenet.\n\nI faced this problem when I plugged-in VGG-19 model into Inception v1 code and got wrong predictions\nbecause of the shift in class names.\nhttps://github.com/tensorflow/tensorflow/issues/5228\n\nThe pull request adds example of evaluation of VGG-19 with correct name shift.\n",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-10-25T06:44:33Z",
        "closed_at": "2017-03-15T02:03:50Z",
        "merged_at": null,
        "body": "Add entry in the repo README for the video prediction model (model was merged in PR https://github.com/tensorflow/models/pull/511)\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-10-21T12:50:11Z",
        "closed_at": "2016-10-21T14:34:13Z",
        "merged_at": null,
        "body": "Now runs again on gpu.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2016-10-21T03:00:43Z",
        "closed_at": "2016-10-21T19:13:14Z",
        "merged_at": "2016-10-21T19:13:14Z",
        "body": "reference https://github.com/tensorflow/tensorflow/issues/4759 and https://github.com/tensorflow/models/pull/520\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 2208,
        "deletions": 0,
        "changed_files": 13,
        "created_at": "2016-10-20T17:11:43Z",
        "closed_at": "2016-10-21T17:13:52Z",
        "merged_at": "2016-10-21T17:13:52Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 309,
        "deletions": 4,
        "changed_files": 3,
        "created_at": "2016-10-19T19:26:59Z",
        "closed_at": "2016-11-01T16:20:57Z",
        "merged_at": "2016-11-01T16:20:57Z",
        "body": "This is related to my summer internship project with ulfar@ and abadi@. These PR adds the privacy analysis script used in our paper https://arxiv.org/abs/1610.05755 to compute the differential privacy bounds, and also releases some of the label files required to compute these bounds.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-10-19T09:10:12Z",
        "closed_at": "2016-10-19T12:54:26Z",
        "merged_at": "2016-10-19T12:54:26Z",
        "body": "For English News Corpus,\n[Ling et al. (2015)](http://www.cs.cmu.edu/~lingwang/papers/emnlp2015.pdf)'s score is \n97.78 -> 97.44 (lower than SyntaxNet and Parsey Mcparseface)\naccording to [Andor et al. (2016)](http://arxiv.org/abs/1603.06042).\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 7,
        "deletions": 7,
        "changed_files": 5,
        "created_at": "2016-10-18T14:36:54Z",
        "closed_at": "2016-10-21T05:39:16Z",
        "merged_at": "2016-10-21T05:39:16Z",
        "body": "Fixes the TF slim models to be compatible with the change in TF 0.11 (https://github.com/tensorflow/tensorflow/commit/5247ebbe24465563bdd4ef46f1cecc34f256f76b)\n\nOtherwise, running vgg/alexnet etc models gives the following error:\n\n``` txt\nend_points = dict(tf.get_collection(end_points_collection))\nTypeError: cannot convert dictionary update sequence element #0 to a sequence\n```\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-10-18T08:51:44Z",
        "closed_at": "2016-10-23T17:11:16Z",
        "merged_at": "2016-10-23T17:11:16Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-10-17T17:50:42Z",
        "closed_at": "2017-03-16T00:34:26Z",
        "merged_at": "2017-03-16T00:34:26Z",
        "body": "Add a list wrapper will make it run properly in Python3 as well as Python2.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2016-10-15T12:51:12Z",
        "closed_at": "2016-10-19T19:43:59Z",
        "merged_at": "2016-10-19T19:43:59Z",
        "body": "Just fix comments.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 3,
        "changed_files": 3,
        "created_at": "2016-10-15T05:32:13Z",
        "closed_at": "2016-10-15T06:45:51Z",
        "merged_at": "2016-10-15T06:45:51Z",
        "body": "PTAL @rohan100jain \n\nThis reverts commit c6a4f783080c5310ce0e3244daa31af57df12def.\n\nFixed tensorflow/tensorflow#4981\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-10-15T04:34:16Z",
        "closed_at": "2016-10-18T03:42:10Z",
        "merged_at": "2016-10-18T03:42:09Z",
        "body": "This is to fix #529.\n\nI wrote this script to check that there aren't any other broken links. In the future, this should possibly be added as a Bazel rule test or something, so we can catch problems like these in the future. \n\n``` py\nimport os\nimport re\nimport sys\n\ndef find_markdown_files():\n  for path, dirs, files in os.walk('.'):\n    for f in files:\n      if f.endswith('.md'):\n        yield os.path.join(path, f)\n\nfor markdown in find_markdown_files():\n  for m in re.finditer(r'\\]\\((.*?)[\\s)]', open(markdown).read()):\n    path = m.group(1)\n    if path.startswith(('#', 'http')):\n      continue\n    if not os.path.exists(os.path.join(os.path.dirname(markdown), path)):\n      print >>sys.stderr, \"%s: %s\" % (markdown, path)\n```\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4335,
        "deletions": 0,
        "changed_files": 25,
        "created_at": "2016-10-08T17:00:01Z",
        "closed_at": "2016-11-02T22:04:58Z",
        "merged_at": "2016-11-02T22:04:58Z",
        "body": "As per previous email thread...\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2016-10-08T08:52:07Z",
        "closed_at": "2016-10-21T02:08:25Z",
        "merged_at": null,
        "body": "reference  https://github.com/tensorflow/tensorflow/issues/4759\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 1252,
        "deletions": 0,
        "changed_files": 7,
        "created_at": "2016-10-07T00:43:16Z",
        "closed_at": "2016-10-07T04:34:39Z",
        "merged_at": "2016-10-07T04:34:39Z",
        "body": "A reimplementation of the 3 models in \"Unsupervised Learning for Physical Interaction through Video Prediction,\" NIPS 2016.\n\nIncludes code for loading the publicly-released data into tensorflow.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2016-10-06T22:04:52Z",
        "closed_at": "2016-10-25T18:20:00Z",
        "merged_at": "2016-10-25T18:20:00Z",
        "body": "GFastFile / numpy have some incompatibilities with the current TensorFlow version that make the compression model unable to load/save our compressed version. I've switched to use the io module as the file interface for numpy to fix this.\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2016-10-04T17:04:00Z",
        "closed_at": "2017-03-16T16:31:50Z",
        "merged_at": null,
        "body": "This PR is related to @npapernot 's intern project. It should be reviewed by Ulfar Erlingsson (not sure of github username).\n\nThis PR contains one configuration of MNIST student training.\n",
        "comments": 9
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-10-04T11:07:32Z",
        "closed_at": "2016-10-18T16:20:55Z",
        "merged_at": "2016-10-18T16:20:55Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 219,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-10-03T08:14:48Z",
        "closed_at": "2017-06-01T20:29:13Z",
        "merged_at": null,
        "body": "tensorflow implementation for recurrent spatial transformer : https://arxiv.org/abs/1509.05329\n",
        "comments": 10
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-10-01T10:15:14Z",
        "closed_at": "2017-03-16T00:00:19Z",
        "merged_at": "2017-03-16T00:00:19Z",
        "body": "https://github.com/tensorflow/models/issues/459\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 247,
        "deletions": 96,
        "changed_files": 28,
        "created_at": "2016-09-30T15:53:08Z",
        "closed_at": "2016-10-03T19:16:40Z",
        "merged_at": "2016-10-03T19:16:40Z",
        "body": "@calberti for your review.\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 17,
        "deletions": 10,
        "changed_files": 1,
        "created_at": "2016-09-29T11:03:00Z",
        "closed_at": "2017-04-11T00:01:24Z",
        "merged_at": null,
        "body": "TensorFlow updates the `variable_scope`.\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-09-29T10:56:21Z",
        "closed_at": "2016-10-19T19:30:50Z",
        "merged_at": null,
        "body": "TensorFlow updates the `variable_scope` .\nhttps://github.com/tensorflow/models/issues/470\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 2178,
        "deletions": 17,
        "changed_files": 10,
        "created_at": "2016-09-29T02:39:50Z",
        "closed_at": "2017-06-01T20:29:21Z",
        "merged_at": null,
        "body": "Appended vocab words and their counts found in the toy dataset to the vocab file so that training and decoding provide more than <UNK> in the decode results.  Also removed duplicates in vocab.\n",
        "comments": 8
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2016-09-26T02:27:48Z",
        "closed_at": "2016-10-21T06:42:10Z",
        "merged_at": null,
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 3,
        "created_at": "2016-09-25T17:31:21Z",
        "closed_at": "2016-09-27T16:53:38Z",
        "merged_at": "2016-09-27T16:53:38Z",
        "body": "Fix breaking change introduced [here](https://github.com/tensorflow/tensorflow/commit/8d1b23d999a563c56236a3d250e18ef825e4e66e)\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2016-09-23T05:16:07Z",
        "closed_at": "2016-10-21T07:15:41Z",
        "merged_at": null,
        "body": "1. change `sharded` to `shared`\n2. update shell output according code. \n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 4,
        "changed_files": 6,
        "created_at": "2016-09-22T16:03:05Z",
        "closed_at": "2016-09-22T19:24:36Z",
        "merged_at": "2016-09-22T19:24:36Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2016-09-22T00:44:54Z",
        "closed_at": "2016-09-22T08:02:08Z",
        "merged_at": "2016-09-22T08:02:08Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-09-20T03:15:00Z",
        "closed_at": "2017-03-15T02:02:25Z",
        "merged_at": null,
        "body": "From https://www.tensorflow.org/versions/master/api_docs/python/image.html#resize_images \n\n> size: A 1-D int32 Tensor of 2 elements: new_height, new_width. The new size for the images.\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-09-17T02:48:32Z",
        "closed_at": "2017-03-16T02:18:21Z",
        "merged_at": null,
        "body": "Without this, the parser_trainer_test.sh errors out because the testdata/context.pbtxt file is not where the script thinks it is.\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 4,
        "changed_files": 6,
        "created_at": "2016-09-14T00:29:50Z",
        "closed_at": "2016-09-22T08:02:13Z",
        "merged_at": "2016-09-22T08:02:13Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 505,
        "deletions": 218,
        "changed_files": 11,
        "created_at": "2016-09-12T16:33:17Z",
        "closed_at": "2018-02-24T21:21:02Z",
        "merged_at": null,
        "body": "This PR makes it possible to use the download_and_convert_data.py script with python 3.  It also adds support for CIFAR100.\n\nRegarding python 3, the problems were essentially:\n- import cPickle => from six.moves import cPickle\n- cPickle.load(f) => cPickle.load(f, encoding=\"bytes\")\n- use strings instead of byte strings in several places\n\nRegarding CIFAR100, it's basically the same format as CIFAR10, so why not add it?\n",
        "comments": 23
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-09-10T14:45:43Z",
        "closed_at": "2017-03-15T02:03:04Z",
        "merged_at": "2017-03-15T02:03:04Z",
        "body": "The instructions to install the TF-slim library clones the repository to `$HOME/workspace/models`. This PR fixes the path in the following instruction to change into the `models/slim` directory.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-09-10T11:50:15Z",
        "closed_at": "2016-10-19T19:15:59Z",
        "merged_at": "2016-10-19T19:15:59Z",
        "body": "From https://research.googleblog.com/2016/08/improving-inception-and-image.html\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 540,
        "deletions": 0,
        "changed_files": 5,
        "created_at": "2016-09-09T19:05:50Z",
        "closed_at": "2016-09-09T23:32:04Z",
        "merged_at": "2016-09-09T23:32:03Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 3405,
        "deletions": 0,
        "changed_files": 27,
        "created_at": "2016-09-09T03:17:02Z",
        "closed_at": "2016-09-09T06:05:30Z",
        "merged_at": "2016-09-09T06:05:30Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 5579,
        "deletions": 0,
        "changed_files": 36,
        "created_at": "2016-09-06T19:03:21Z",
        "closed_at": "2016-10-21T06:34:29Z",
        "merged_at": null,
        "body": "This is the pull request fixing problem #361.\n\nIf I am correct, [tensorflow.models](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/models) is being deprecated.\nBut some models are still kept inside this directory because of tensorflow tutorials. \nI think it would be more straight forward and relevant to keep all the model implementations in tensorflow/models repository.\n\nI was able to extract all commit history of each files.\n",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2016-09-06T00:34:42Z",
        "closed_at": "2017-03-16T02:12:16Z",
        "merged_at": null,
        "body": "I think all variables in the `/AuxLogits` scope need to be ignored for the model to be loaded for fine-tuning tasks\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 7,
        "changed_files": 1,
        "created_at": "2016-09-02T19:17:56Z",
        "closed_at": "2017-03-16T01:49:24Z",
        "merged_at": null,
        "body": "Fix code to organize the LSTM state (c,h tensors) inside a tuple of size 2. The current (default) selection of state_is_tuple=False concatenates c and h to one larger tensor but this generates a warning message that this is deprecated and slow.\n",
        "comments": 9
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-08-31T23:10:56Z",
        "closed_at": "2016-12-27T20:53:30Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 83,
        "deletions": 8,
        "changed_files": 3,
        "created_at": "2016-08-31T21:28:39Z",
        "closed_at": "2016-09-30T16:31:42Z",
        "merged_at": "2016-09-30T16:31:42Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 2,
        "changed_files": 2,
        "created_at": "2016-08-31T09:07:08Z",
        "closed_at": "2016-10-17T23:09:45Z",
        "merged_at": "2016-10-17T23:09:45Z",
        "body": "Fixes #356 \n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2016-08-30T14:12:39Z",
        "closed_at": "2016-09-08T05:30:50Z",
        "merged_at": "2016-09-08T05:30:50Z",
        "body": "Fixes #362\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 14,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-08-29T14:24:11Z",
        "closed_at": "2016-08-29T19:19:52Z",
        "merged_at": "2016-08-29T19:19:52Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 15,
        "changed_files": 1,
        "created_at": "2016-08-27T23:20:33Z",
        "closed_at": "2016-08-31T23:28:12Z",
        "merged_at": "2016-08-31T23:28:12Z",
        "body": "Uses more NumPy now :)\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2016-08-27T23:20:12Z",
        "closed_at": "2016-08-31T23:28:00Z",
        "merged_at": "2016-08-31T23:28:00Z",
        "body": "The moving average object was shared between training and evaluation. As a result, the cost during evaluation was averaged with the training cost. This affects only objective, not precision.\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-08-27T17:46:19Z",
        "closed_at": "2016-08-29T19:21:48Z",
        "merged_at": "2016-08-29T19:21:48Z",
        "body": "changed 'matchine' to 'machine'\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 8134,
        "deletions": 818,
        "changed_files": 58,
        "created_at": "2016-08-27T06:18:27Z",
        "closed_at": "2016-08-30T04:03:48Z",
        "merged_at": null,
        "body": "Adding cifarnet model, cifarnet preprocessing, logging at INFO level, various small bug fixes.\n",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 671,
        "deletions": 0,
        "changed_files": 6,
        "created_at": "2016-08-27T05:37:00Z",
        "closed_at": "2018-02-07T23:59:40Z",
        "merged_at": null,
        "body": "- related issue : https://github.com/tensorflow/models/issues/323#event-763293517\n- it is not easy to re-generate same situation. so, i made 'ud_train' directory\n- how to generate error\n  - remove following lines in `UD/context.pbtxt` and run `./train.sh`\n  \n  ``` shell\n  input {\n    name: 'char-map'\n    creator: 'brain_pos/greedy'\n  }\n  ```\n  - error message\n  \n  ``` shell\n  + /path/to/models/syntaxnet/bazel-bin/syntaxnet/parser_trainer --task_context=/path/to/models/syntaxnet/ud_train/UD/context.pbtxt --arg_prefix=brain_pos --compute_lexicon --graph_builder=greedy --training_corpus=training-corpus --tuning_corpus=tuning-corpus --output_path=/path/to/models/syntaxnet/ud_train/UD/tmp/syntaxnet-output --batch_size=256 --decay_steps=3600 --hidden_layer_sizes=64 --learning_rate=0.08 --momentum=0.9 --seed=0 --params=64-0.08-3600-0.9-0 --num_epochs=12 --report_every=100 --checkpoint_every=1000 --logtostderr\n  INFO:tensorflow:Computing lexicon...\n  I syntaxnet/lexicon_builder.cc:134] Term maps collected over 204586 tokens from 12543 documents\n  I syntaxnet/term_frequency_map.cc:137] Saved 18731 terms to /path/to/models/syntaxnet/ud_train/UD/tmp/syntaxnet-output/brain_pos/greedy/64-0.08-3600-0.9-0/word-map.\n  I syntaxnet/term_frequency_map.cc:137] Saved 15710 terms to /path/to/models/syntaxnet/ud_train/UD/tmp/syntaxnet-output/brain_pos/greedy/64-0.08-3600-0.9-0/lcword-map.\n  I syntaxnet/term_frequency_map.cc:137] Saved 50 terms to /path/to/models/syntaxnet/ud_train/UD/tmp/syntaxnet-output/brain_pos/greedy/64-0.08-3600-0.9-0/tag-map.\n  I syntaxnet/term_frequency_map.cc:137] Saved 50 terms to /path/to/models/syntaxnet/ud_train/UD/tmp/syntaxnet-output/brain_pos/greedy/64-0.08-3600-0.9-0/category-map.\n  I syntaxnet/term_frequency_map.cc:137] Saved 47 terms to /path/to/models/syntaxnet/ud_train/UD/tmp/syntaxnet-output/brain_pos/greedy/64-0.08-3600-0.9-0/label-map.\n  F syntaxnet/task_context.cc:140] Check failed: input.part_size() == 1 (0 vs. 1)char-map\n  ./train.sh: line 107: 24273       (core dumped) ${BINDIR}/parser_trainer --task_context=${CONTEXT} --arg_prefix=brain_pos --compute_lexicon --graph_builder=greedy --training_corpus=training-corpus --tuning_corpus=tuning-corpus --output_path=${TMP_DIR} --batch_size=${BATCH_SIZE} --decay_steps=3600 --hidden_layer_sizes=${POS_HIDDEN_LAYER_SIZES} --learning_rate=0.08 --momentum=0.9 --seed=0 --params=${POS_PARAMS} --num_epochs=12 --report_every=100 --checkpoint_every=1000 --logtostderr\n  ```\n",
        "comments": 13
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-08-25T12:57:34Z",
        "closed_at": "2016-08-26T18:13:57Z",
        "merged_at": "2016-08-26T18:13:57Z",
        "body": "change \"seqeuence-to-sequence\" to \"sequence-to-sequence\"\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2016-08-22T03:17:40Z",
        "closed_at": "2016-08-29T19:22:16Z",
        "merged_at": "2016-08-29T19:22:16Z",
        "body": "change `Assuming than` to `Assuming that`.\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 3,
        "changed_files": 2,
        "created_at": "2016-08-17T02:54:16Z",
        "closed_at": "2017-03-16T01:48:12Z",
        "merged_at": null,
        "body": "Use --gpu_memory_fraction=X when run in the worker host,  that will use X% of gpu memory.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2016-08-16T00:35:32Z",
        "closed_at": "2016-08-16T17:59:36Z",
        "merged_at": "2016-08-16T17:59:36Z",
        "body": "Fixes #59\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-08-13T14:35:41Z",
        "closed_at": "2016-08-29T19:26:38Z",
        "merged_at": "2016-08-29T19:26:38Z",
        "body": "Without this, we get an error when doing tests\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-08-11T22:42:24Z",
        "closed_at": "2016-08-16T23:17:06Z",
        "merged_at": "2016-08-16T23:17:06Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-08-08T18:04:17Z",
        "closed_at": "2016-08-08T20:38:32Z",
        "merged_at": "2016-08-08T20:38:32Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-08-05T02:43:12Z",
        "closed_at": "2016-08-05T05:20:49Z",
        "merged_at": "2016-08-05T05:20:49Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 550,
        "deletions": 282,
        "changed_files": 8,
        "created_at": "2016-08-05T01:36:24Z",
        "closed_at": "2016-08-05T14:30:33Z",
        "merged_at": null,
        "body": "Add multiple GPU support and Stochastic Depth feature\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 11657,
        "deletions": 0,
        "changed_files": 11,
        "created_at": "2016-08-04T16:57:02Z",
        "closed_at": "2016-08-24T04:18:17Z",
        "merged_at": "2016-08-24T04:18:17Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2016-08-03T14:35:06Z",
        "closed_at": "2017-03-16T01:48:00Z",
        "merged_at": null,
        "body": "This PR is highly related to this issue: https://github.com/tensorflow/tensorflow/issues/3168\n\nTo summarize, there appears to be a regression since r0.9 which makes the initialization of some variables of the input_producer fail (or more specifically, calling `tf.initialize_all_variables()` do not include these variables). To include the variables of the input_producer (apparently the ones responsible for the epoch count) you also need to call `tf.initialize_local_variables()`.\n\nI am using part of the `inception/inception/inception_train.py` `train` function, and stumble on the same error.\n## PR Content\n\nFixes aforementioned issue by adding to the `init_op` the initialization of local variables.\n## Environment info\n\nOperating System: Ubuntu 16.04\nInstalled version of CUDA and cuDNN: Cuda 7.5 and CuDnn 5.0\n\n```\nguillaume@xxxxxxx:~$ ls -l /usr/local/cuda/lib*/libcud*\n-rw-r--r-- 1 root root   322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18\n-rw-r--r-- 1 root root   720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a\n-rwxr-xr-x 1 root root 61453024 Aug  2 10:41 /usr/local/cuda/lib64/libcudnn.so\n-rwxr-xr-x 1 root root 61453024 Aug  2 10:41 /usr/local/cuda/lib64/libcudnn.so.4\n-rwxr-xr-x 1 root root 61453024 Aug  2 10:41 /usr/local/cuda/lib64/libcudnn.so.4.0.7\n-rwxr-xr-x 1 root root 59909104 Aug  2 10:41 /usr/local/cuda/lib64/libcudnn.so.5\n-rwxr-xr-x 1 root root 59909104 Aug  2 10:41 /usr/local/cuda/lib64/libcudnn.so.5.0.5\n-rw-r--r-- 1 root root 62025862 Aug  2 10:41 /usr/local/cuda/lib64/libcudnn_static.a\n```\n## Log\n\n```\nguillaume@xxxxxxx:~/finetuning$ python inception_v3.py \nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: GRID K520\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.797\npciBusID 0000:00:03.0\nTotal memory: 4.00GiB\nFree memory: 3.60GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:839] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)\nE tensorflow/core/client/tensor_c_api.cc:485] Attempting to use uninitialized value input/input_producer/limit_epochs/epochs\n     [[Node: input/input_producer/limit_epochs/CountUpTo = CountUpTo[T=DT_INT64, _class=[\"loc:@input/input_producer/limit_epochs/epochs\"], limit=100, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input/input_producer/limit_epochs/epochs)]]\nERROR:tensorflow:Exception in QueueRunner: Attempting to use uninitialized value input/input_producer/limit_epochs/epochs\n     [[Node: input/input_producer/limit_epochs/CountUpTo = CountUpTo[T=DT_INT64, _class=[\"loc:@input/input_producer/limit_epochs/epochs\"], limit=100, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input/input_producer/limit_epochs/epochs)]]\nCaused by op u'input/input_producer/limit_epochs/CountUpTo', defined at:\n  File \"inception_v3.py\", line 453, in <module>\n    num_epochs=100, num_threads=4, initial_learning_rate=.01)\n  File \"inception_v3.py\", line 63, in tf_train\n    num_labels=num_labels, filename=filename)\n  File \"/home/guillaume/image_tagging/image_tagging/preprocessing/pipeline.py\", line 44, in inputs\n    [filename], num_epochs=num_epochs)\n  File \"/home/guillaume/.virtualenvs/tf/local/lib/python2.7/site-packages/tensorflow/python/training/input.py\", line 194, in string_input_producer\n    summary_name=\"fraction_of_%d_full\" % capacity)\n  File \"/home/guillaume/.virtualenvs/tf/local/lib/python2.7/site-packages/tensorflow/python/training/input.py\", line 133, in input_producer\n    input_tensor = limit_epochs(input_tensor, num_epochs)\n  File \"/home/guillaume/.virtualenvs/tf/local/lib/python2.7/site-packages/tensorflow/python/training/input.py\", line 84, in limit_epochs\n    counter = epochs.count_up_to(num_epochs)\n  File \"/home/guillaume/.virtualenvs/tf/local/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 577, in count_up_to\n    return state_ops.count_up_to(self._variable, limit=limit)\n  File \"/home/guillaume/.virtualenvs/tf/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 127, in count_up_to\n    result = _op_def_lib.apply_op(\"CountUpTo\", ref=ref, limit=limit, name=name)\n  File \"/home/guillaume/.virtualenvs/tf/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/home/guillaume/.virtualenvs/tf/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2310, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/guillaume/.virtualenvs/tf/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1232, in __init__\n    self._traceback = _extract_stack()\n\nException in thread Thread-1:\nTraceback (most recent call last):\n  File \"/usr/lib/python2.7/threading.py\", line 810, in __bootstrap_inner\n    self.run()\n  File \"/usr/lib/python2.7/threading.py\", line 763, in run\n    self.__target(*self.__args, **self.__kwargs)\n  File \"/home/guillaume/.virtualenvs/tf/local/lib/python2.7/site-packages/tensorflow/python/training/queue_runner.py\", line 185, in _run\n    sess.run(enqueue_op)\n  File \"/home/guillaume/.virtualenvs/tf/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 382, in run\n    run_metadata_ptr)\n  File \"/home/guillaume/.virtualenvs/tf/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 655, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/home/guillaume/.virtualenvs/tf/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 723, in _do_run\n    target_list, options, run_metadata)\n  File \"/home/guillaume/.virtualenvs/tf/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 743, in _do_call\n    raise type(e)(node_def, op, message)\nFailedPreconditionError: Attempting to use uninitialized value input/input_producer/limit_epochs/epochs\n     [[Node: input/input_producer/limit_epochs/CountUpTo = CountUpTo[T=DT_INT64, _class=[\"loc:@input/input_producer/limit_epochs/epochs\"], limit=100, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input/input_producer/limit_epochs/epochs)]]\nCaused by op u'input/input_producer/limit_epochs/CountUpTo', defined at:\n  File \"inception_v3.py\", line 453, in <module>\n    num_epochs=100, num_threads=4, initial_learning_rate=.01)\n  File \"inception_v3.py\", line 63, in tf_train\n    num_labels=num_labels, filename=filename)\n  File \"/home/guillaume/image_tagging/image_tagging/preprocessing/pipeline.py\", line 44, in inputs\n    [filename], num_epochs=num_epochs)\n  File \"/home/guillaume/.virtualenvs/tf/local/lib/python2.7/site-packages/tensorflow/python/training/input.py\", line 194, in string_input_producer\n    summary_name=\"fraction_of_%d_full\" % capacity)\n  File \"/home/guillaume/.virtualenvs/tf/local/lib/python2.7/site-packages/tensorflow/python/training/input.py\", line 133, in input_producer\n    input_tensor = limit_epochs(input_tensor, num_epochs)\n  File \"/home/guillaume/.virtualenvs/tf/local/lib/python2.7/site-packages/tensorflow/python/training/input.py\", line 84, in limit_epochs\n    counter = epochs.count_up_to(num_epochs)\n  File \"/home/guillaume/.virtualenvs/tf/local/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 577, in count_up_to\n    return state_ops.count_up_to(self._variable, limit=limit)\n  File \"/home/guillaume/.virtualenvs/tf/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 127, in count_up_to\n    result = _op_def_lib.apply_op(\"CountUpTo\", ref=ref, limit=limit, name=name)\n  File \"/home/guillaume/.virtualenvs/tf/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/home/guillaume/.virtualenvs/tf/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2310, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/guillaume/.virtualenvs/tf/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1232, in __init__\n    self._traceback = _extract_stack()\n```\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 3,
        "changed_files": 1,
        "created_at": "2016-07-28T11:56:25Z",
        "closed_at": "2016-08-25T20:51:34Z",
        "merged_at": "2016-08-25T20:51:34Z",
        "body": "\u2026elements with identical representation\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2016-07-23T23:39:03Z",
        "closed_at": "2016-09-13T20:20:35Z",
        "merged_at": "2016-09-13T20:20:35Z",
        "body": "The first call seems to overwrite while the second doesn't?\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-07-21T04:19:58Z",
        "closed_at": "2016-10-19T18:02:51Z",
        "merged_at": "2016-10-19T18:02:51Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-07-20T16:23:00Z",
        "closed_at": "2016-07-20T23:57:51Z",
        "merged_at": "2016-07-20T23:57:51Z",
        "body": "The script actually reads $LABEL_FILE and strips out the text, which it uses to label and find image files in their respective sub directories.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 759,
        "deletions": 0,
        "changed_files": 7,
        "created_at": "2016-07-18T23:37:21Z",
        "closed_at": "2016-08-02T00:05:56Z",
        "merged_at": "2016-08-02T00:05:56Z",
        "body": "Add resnet model for cifar dataset.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2016-07-15T21:17:04Z",
        "closed_at": "2016-08-29T19:24:27Z",
        "merged_at": "2016-08-29T19:24:27Z",
        "body": "abstract page > v1 pdf page\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-07-15T14:00:42Z",
        "closed_at": "2016-08-16T23:26:10Z",
        "merged_at": "2016-08-16T23:26:10Z",
        "body": "README file was introduced with autoencoder commit but today we have multiple models in repo. Should either be synced with README.md or be removed, I guess removing is preferred.\n\nThis is really a trivial change, just can't live with such tiny flaw :)\n\nIdeally we should collect all trivial patches from thousands of open source projects and train a deep network model to submit trivial patches automatically <grin> \n\nGreat project, thank you!\n",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 13,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2016-07-10T19:57:18Z",
        "closed_at": "2017-03-16T01:47:40Z",
        "merged_at": null,
        "body": "Come across bugs in process_bounding_boxes and build_imagenet_data.py.\nChanges \n1.process_bounding_boxes\n     Creating CSV file and writing bounding box coordinates \n2.build_imagenet_data.py\n     Bug fix while parsing file names\n",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-07-03T01:44:29Z",
        "closed_at": "2017-03-16T02:18:05Z",
        "merged_at": "2017-03-16T02:18:05Z",
        "body": "Fixed bug file not found \"/syntaxnet/bazel-out/local-opt/bin/syntaxnet/parser_trainer_test.runfiles/syntaxnet/parser_trainer: No such file or directory\"\n",
        "comments": 8
    },
    {
        "merged": false,
        "additions": 417,
        "deletions": 21,
        "changed_files": 12,
        "created_at": "2016-06-29T17:54:58Z",
        "closed_at": "2019-06-17T19:46:41Z",
        "merged_at": null,
        "body": "At a high level, this PR enables the entire Parsey McParseface model to be built in a single model, exported, and served with TF serving.\n\nThis required two main changes:\n1. The ability to use tensor input instead of stdin/stdout/files for feeding \"text\" input. This is really two changes - the first is to be able to pass serialized sentence protos into BeamParseReader (instead of having it read and parse text).  This is necessary to be able to connect the \"output\" of brain-tagger to the \"input\" of brain-parser.  The second part is to be able to feed \"text\" input to DocumentSource.  This is necessary if the sentences to be parsed are coming in via grpc as in TF serving, for example.\n2. An actual script to build and export the Parsey model all in one session.  To accomplish this a new script is created, parsey_mcparseface.py.  This script \"replaces\" demo.sh by building both halves of the model in a single session using name_scope/variable_scope to separate the tagger and parser.  It exports the model (3 different ways) so it can be imported in a session bundle by TF serving (as well as viewed by tensorboard, and thirdly as a \"pbtxt\" file for manual inspection).\n\nThis PR has the following issues/limitations:\n1. The interface to BeamParseReader and DocumentSource has changed in an incompatible way.  The input tensor (which may be used to pass text/sentence protos) is required, even when not used.  The decision to use is controlled by an attribute.\n2. The model, once loaded in TF serving, does not seem to be threadsafe.\n3. The script, parsey_mcparseface.py, currently has an option of where to export to, but does not function in a meaningful way if the option is not given (it just parses a hard-coded sentence in the source code in this case).\n",
        "comments": 22
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-06-24T03:37:45Z",
        "closed_at": "2016-08-29T19:25:36Z",
        "merged_at": "2016-08-29T19:25:36Z",
        "body": "Preventative tip for people who run into https://github.com/tensorflow/models/issues/15\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-06-24T03:00:24Z",
        "closed_at": "2016-10-20T23:42:59Z",
        "merged_at": "2016-10-20T23:42:59Z",
        "body": "Corrected \"One this\" to \"Once this\" and added comma for proper punctuation on line 702.\n",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2016-06-24T00:50:08Z",
        "closed_at": "2017-04-06T00:24:18Z",
        "merged_at": null,
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-06-23T05:31:01Z",
        "closed_at": "2016-06-24T01:06:46Z",
        "merged_at": "2016-06-24T01:06:46Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 4,
        "changed_files": 1,
        "created_at": "2016-06-22T19:28:05Z",
        "closed_at": "2016-06-27T15:47:27Z",
        "merged_at": "2016-06-27T15:47:27Z",
        "body": "As Docker builds are layer by layer, removing cached package files in different layers do not reduce image size. To reduce image size, cached packages have to removed in the same layer i.e., `RUN` command as the packages have been installed.\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 0,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-06-22T05:04:19Z",
        "closed_at": "2016-06-22T15:21:16Z",
        "merged_at": "2016-06-22T15:21:16Z",
        "body": "",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-06-20T11:58:43Z",
        "closed_at": "2016-08-29T19:23:54Z",
        "merged_at": "2016-08-29T19:23:54Z",
        "body": "Added alternative way to install bazel. Because people have been facing problem and by mistake they are downloading the latest version.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-06-20T00:03:58Z",
        "closed_at": "2016-06-21T12:36:04Z",
        "merged_at": "2016-06-21T12:36:04Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-06-17T16:44:24Z",
        "closed_at": "2016-06-21T20:50:25Z",
        "merged_at": "2016-06-21T20:50:25Z",
        "body": "When using parser_ops_cc as a dependency from an external project, all of the sub-dependencies (that provide OpKernel implementations) need to have alwayslink=1 or the OpKernel's won't be register.  I believe all of them do, except for \"UnpackSparseFeatures\". Without this an error like, e.g:\n\n```\nF tensorflow_serving/example/mnist_inference.cc:215] Check failed: ::tensorflow::Status::OK() == (bundle_factory->CreateSessionBundle(bundle_path, &bundle)) (OK vs. Invalid argument: No OpKernel was registered to support Op 'UnpackSparseFeatures' with these attrs\n     [[Node: evaluation/while/UnpackSparseFeatures_2 = UnpackSparseFeatures[](evaluation/while/feature_2)]])\n```\n\nWill be generated when running the compiled output.\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 244,
        "deletions": 1,
        "changed_files": 10,
        "created_at": "2016-06-16T06:29:44Z",
        "closed_at": "2016-06-28T18:29:15Z",
        "merged_at": null,
        "body": "The Bazel installation instructions from http://www.bazel.io/docs/install.html will install 0.2.3 which is not compatible with syntaxnet.\nReplace it by 0.2.2b installation instructions.\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 62,
        "deletions": 70,
        "changed_files": 9,
        "created_at": "2016-06-15T12:38:59Z",
        "closed_at": "2016-06-28T16:59:10Z",
        "merged_at": "2016-06-28T16:59:10Z",
        "body": "This PR is for syntaxnet.\n\nThe motivation of these changes are to make syntaxnet usable inside other WORKSPACEs that use up-to-date tensorflow (e.g. TF Serving)\n\nThis PR fixes some naming issues and is required for compatibility with tensorflow master (0ef58dc5c571d4c6ca1564bc27fc0c5db23cbd01 as I write this). I have NOT updated the actual tensorflow submodule with this PR because I don't know anything about release schedules or anything, but if this is merged, TF submodule should be updated.\n\nIn particular, protobuf was moved from a submodule to an external repository in TF. Also, the canonical repo name changed from @tf to @org_tensorflow.\n\nFinally, there are some repo naming conflicts between syntaxnet and TF for external dependencies (boringssl and zlib) so prefix the names to make them unique.\n\nP.S. @googlebot : I have signed a Company CLA, company name is COBITE, INC. \"I signed it!\"\n",
        "comments": 7
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-06-14T15:52:27Z",
        "closed_at": "2016-06-21T21:45:37Z",
        "merged_at": null,
        "body": "A couple of shell snippets uses the `$PARAMS` variable, but the snippet does not include the `PARAMS` definition, as the previous snippets.\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 97,
        "deletions": 1,
        "changed_files": 2,
        "created_at": "2016-06-14T14:35:44Z",
        "closed_at": "2016-06-21T12:38:42Z",
        "merged_at": "2016-06-21T12:38:42Z",
        "body": "Fixed the Error in line 586 bazel instead of the mistake blaze.\nAdded the file: download_and_preprocess_flowers_mac identical to the original but with gshuf instead of shuf that isn't supported in Mac Terminal.\nThanks for the Great Job all of you is making.\n\nBest Regards\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 5,
        "changed_files": 1,
        "created_at": "2016-06-14T02:50:13Z",
        "closed_at": "2017-03-16T03:22:57Z",
        "merged_at": "2017-03-16T03:22:57Z",
        "body": "Changed the example to the VGG-16 net\n",
        "comments": 5
    },
    {
        "merged": false,
        "additions": 141,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2016-06-13T23:36:33Z",
        "closed_at": "2018-02-24T21:19:33Z",
        "merged_at": null,
        "body": "Adding model for network described by [CWRNN](http://arxiv.org/pdf/1402.3511v1.pdf).\n\nThis initial PR is to check I'm conforming to import guidelines and coding style. \n",
        "comments": 10
    },
    {
        "merged": true,
        "additions": 52,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-06-09T16:59:44Z",
        "closed_at": "2016-06-15T23:08:48Z",
        "merged_at": "2016-06-15T23:08:48Z",
        "body": "- Add list of algorithmic tasks.\n- Detail what is stored in /tmp/neural_gpu/ (default location).\n- Detail that one should hit Ctrl-C to stop the training process.\n- Add sections around decoding and animation, but couldn't get those to work myself. Still worth having in the docs.\n",
        "comments": 6
    },
    {
        "merged": true,
        "additions": 5,
        "deletions": 4,
        "changed_files": 2,
        "created_at": "2016-06-06T09:33:11Z",
        "closed_at": "2016-06-23T02:37:19Z",
        "merged_at": "2016-06-23T02:37:18Z",
        "body": "This PR closes #166 \n\nWhen manually implementing the cross entropy loss, the training loss becomes `nan` after a number of iterations (usually around 90 or so epochs for the cluttered MNIST example). Switching to the built-in `softmax_cross_entropy_with_logits` allows the network to train stably.\n\n@denny1108 could you also just confirm that this solves the problem?\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-05-31T20:07:37Z",
        "closed_at": "2016-06-02T21:01:57Z",
        "merged_at": "2016-06-02T21:01:57Z",
        "body": "When importing tensorflow before scipi.ndimage and running the\nexample in a docker container, the following error is given:\n\n```\n % python example.py\nTraceback (most recent call last):\n  File \"example.py\", line 25, in <module>\n    im = im / 255.\nTypeError: unsupported operand type(s) for /: 'instance' and 'float'\n```\n\nThis only happens for 'cat.jpg'. When converting the image to a '.png'\nfile, the example runs as expected.\n\nWhen swapping the imports around so that scipy.ndimage is imported\nBEFORE tensorflow, both 'jpg' and 'png' files work.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 89,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-05-31T19:57:26Z",
        "closed_at": "2016-06-02T20:57:34Z",
        "merged_at": "2016-06-02T20:57:34Z",
        "body": "I have added a Python-based gitignore file.\n\nThe file contents were taken from:\n\nhttps://github.com/github/gitignore/blob/master/Python.gitignore\n\n@martinwicke since it seems as if you're reviewing things, could you have a look?\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-05-27T05:42:18Z",
        "closed_at": "2016-06-02T21:01:00Z",
        "merged_at": "2016-06-02T21:01:00Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 89,
        "deletions": 86,
        "changed_files": 4,
        "created_at": "2016-05-26T08:16:42Z",
        "closed_at": "2016-05-31T16:15:14Z",
        "merged_at": "2016-05-31T16:15:14Z",
        "body": "Although the interface to the transformer was changed in #57, the examples were never updated.\n\nI have made the changes for both the simple example and the cluttered MNIST examples.\n",
        "comments": 8
    },
    {
        "merged": false,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2016-05-26T08:09:14Z",
        "closed_at": "2016-08-26T16:38:39Z",
        "merged_at": null,
        "body": "There is an issue of token overwriting in conll2tree of SyntaxNet. Because parsed trees are built using dictionary and dictionaries use a token as a key, if the same token appears more than once, the previous key-value pair is overwritten by new one.\n\nFor example, if input is given as 'Two iced Americanos, two plain lattes and two vanilla lattes.', there are repeated words ('lattes') on the same level. Then the parsed tree is given by:\n\nAmericanos NNP ROOT\n +-- Two CD num\n +-- iced JJ amod\n +-- , , punct\n +-- lattes NNS conj\n |   +-- two CD num\n |   +-- vanilla NN amod\n +-- and CC cc\n +-- . . punct\n\nNote that the nodes of the first 'lattes' are gone.\nSo to solve this issue, I suggest to include each token's identifier to key for items of dictionary, and the index of token in original input is good candidate because they are unique and we can map tokens of the parse tree into original sentence exactly.\n\nAs a result, the new output will be:\n\nAmericanos NNP ROOT 2\n +-- Two CD num 0\n +-- iced JJ amod 1\n +-- , , punct 3\n +-- lattes NNS conj 6\n |   +-- two CD num 4\n |   +-- plain JJ amod 5\n +-- and CC cc 7\n +-- lattes NNS conj 10\n |   +-- two CD num 8\n |   +-- vanilla NN amod 9\n +-- . . punct 11\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-05-25T17:54:42Z",
        "closed_at": "2016-06-02T21:46:17Z",
        "merged_at": "2016-06-02T21:46:17Z",
        "body": "fixes b/28821889\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 197,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-05-25T17:16:32Z",
        "closed_at": "2016-06-02T20:59:46Z",
        "merged_at": "2016-06-02T20:59:46Z",
        "body": "\u2026. (Roundabout way to address issue #127).\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 4,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-05-25T00:48:53Z",
        "closed_at": "2016-05-27T05:36:11Z",
        "merged_at": null,
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 602,
        "deletions": 0,
        "changed_files": 5,
        "created_at": "2016-05-24T17:33:09Z",
        "closed_at": "2016-05-25T02:12:11Z",
        "merged_at": "2016-05-25T02:12:11Z",
        "body": "added a model that uses save, restore, generation, and recognition on top of the PBT framework to generate and recognize names\n",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 676,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2016-05-20T19:42:02Z",
        "closed_at": "2016-07-07T21:49:52Z",
        "merged_at": null,
        "body": "The minimal model is just an LSTM that predicts the next note in a\nsequence of notes. README.md is also added for the directory.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-05-18T17:17:59Z",
        "closed_at": "2016-05-19T04:07:16Z",
        "merged_at": "2016-05-19T04:07:16Z",
        "body": "Asking which model this issue is about\n",
        "comments": 2
    },
    {
        "merged": false,
        "additions": 59,
        "deletions": 0,
        "changed_files": 2,
        "created_at": "2016-05-17T13:28:46Z",
        "closed_at": "2016-10-19T18:47:17Z",
        "merged_at": null,
        "body": "Hello all,\n\nIt was tricky figuring out exactly how to build everything. I packaged up all of the steps I took on a fresh Ubuntu 14.04 x64 machine and thought it would be useful for others if included here.\n\nInterested?\n\nThanks for your great work on this.\n",
        "comments": 14
    },
    {
        "merged": false,
        "additions": 5,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-05-17T09:34:06Z",
        "closed_at": "2017-03-29T11:16:59Z",
        "merged_at": null,
        "body": "when solve the issue [here](https://github.com/tensorflow/tensorflow/issues/2322#event-658034616) I use the same start script to start my two machines. Then this error occured: \n\n```\nE tensorflow/stream_executor/cuda/cuda_driver.cc:932] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\nE tensorflow/stream_executor/cuda/cuda_driver.cc:932] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\nE tensorflow/stream_executor/cuda/cuda_driver.cc:932] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\n...\n```\n\nI find the error occurs because framework assign all the memory on the first gpu, `/gpu:0`. finally I solve the problem by [this commit](https://github.com/ZhuFengdaaa/models/commit/6a1176c0d9fc4db4affea85ce524aee0dfb03b2c).\n\nAccording to the tensorflow source code [gpu_device.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/gpu/gpu_device.cc) line 553, **the framework create all the GPU device local avaliable for each worker. So all workers allocate memory on first GPU, causing OUT_OF_MEMORY** (however I just want assign 1 GPU for 1 worker). \n\nSo I'm wondering whether `inception_distributed_train.py` call the API in a correct way. If we want to achieve the goal that \n\n> Multiple worker tasks can run on the same machine with multiple GPUs so machine_A with 2 GPUs may have 2 workers while machine_B with 1 GPU just has 1 worker.\n\n (discribed in the [document](https://github.com/tensorflow/models/blob/master/inception/README.md))\n\nAccording to [this issue](https://github.com/tensorflow/models/issues/72).\n",
        "comments": 6
    },
    {
        "merged": false,
        "additions": 3,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-05-17T03:56:15Z",
        "closed_at": "2017-03-16T01:42:56Z",
        "merged_at": null,
        "body": "Without this parameter, no model will be generated (test on Mac)\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-05-17T02:49:37Z",
        "closed_at": "2016-06-02T21:45:05Z",
        "merged_at": "2016-06-02T21:45:05Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-05-16T22:38:06Z",
        "closed_at": "2016-05-17T20:51:52Z",
        "merged_at": null,
        "body": "The configure file in the old version of Tensorflow had a bug in the configure file.  The file was looking for the folder \"lib64\" in Cuda directory.  This folder doesn't exist for the OSX version of Cuda library. The newest version of Tesorflow has fixed the bug with the configure file.\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-05-15T07:14:37Z",
        "closed_at": "2016-10-20T23:40:24Z",
        "merged_at": "2016-10-20T23:40:24Z",
        "body": "",
        "comments": 4
    },
    {
        "merged": false,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-05-14T22:39:33Z",
        "closed_at": "2016-05-16T19:08:36Z",
        "merged_at": null,
        "body": "",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-05-14T16:35:33Z",
        "closed_at": "2016-05-16T19:01:38Z",
        "merged_at": "2016-05-16T19:01:38Z",
        "body": "",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 40,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-05-14T10:22:28Z",
        "closed_at": "2016-08-26T16:40:02Z",
        "merged_at": null,
        "body": "The zlib.BUILD is required in models/syntaxnet/WORKSPACE to build syntaxnet.\n\nnew_http_archive(\n    name = \"zlib_archive\",\n    build_file = \"zlib.BUILD\",\n    sha256 = \"879d73d8cd4d155f31c1f04838ecd567d34bebda780156f0e82a20721b3973d5\",\n    strip_prefix = \"zlib-1.2.8\",\n    url = \"http://zlib.net/zlib128.zip\",\n)\n",
        "comments": 4
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-05-14T09:07:47Z",
        "closed_at": "2016-05-16T18:00:04Z",
        "merged_at": "2016-05-16T18:00:04Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": false,
        "additions": 6,
        "deletions": 11,
        "changed_files": 1,
        "created_at": "2016-05-13T17:20:26Z",
        "closed_at": "2017-04-10T23:58:23Z",
        "merged_at": null,
        "body": "Tentative fix for issue #47\n",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 3,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-05-13T01:36:31Z",
        "closed_at": "2016-05-16T19:20:05Z",
        "merged_at": "2016-05-16T19:20:05Z",
        "body": "",
        "comments": 5
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2016-05-12T20:02:42Z",
        "closed_at": "2016-05-15T17:52:50Z",
        "merged_at": "2016-05-15T17:52:50Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-05-07T19:13:13Z",
        "closed_at": "2016-05-12T23:14:52Z",
        "merged_at": "2016-05-12T23:14:52Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 10,
        "deletions": 10,
        "changed_files": 1,
        "created_at": "2016-04-30T03:59:08Z",
        "closed_at": "2016-05-12T23:17:58Z",
        "merged_at": "2016-05-12T23:17:58Z",
        "body": "",
        "comments": 3
    },
    {
        "merged": true,
        "additions": 36,
        "deletions": 18,
        "changed_files": 1,
        "created_at": "2016-04-28T10:26:17Z",
        "closed_at": "2016-05-12T23:16:59Z",
        "merged_at": "2016-05-12T23:16:59Z",
        "body": "- Modified the way the output size is specified.\n- Added support for batches of inputs.\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2016-04-26T14:39:26Z",
        "closed_at": "2016-05-12T23:15:58Z",
        "merged_at": "2016-05-12T23:15:58Z",
        "body": "a space between `python` and `{.good}` led to some really grossly formatted output\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 11,
        "changed_files": 1,
        "created_at": "2016-04-20T17:30:17Z",
        "closed_at": "2016-05-12T23:15:31Z",
        "merged_at": "2016-05-12T23:15:31Z",
        "body": "Tentative fix for issue #47\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 57,
        "deletions": 26,
        "changed_files": 1,
        "created_at": "2016-04-13T19:36:25Z",
        "closed_at": "2016-04-13T21:33:03Z",
        "merged_at": "2016-04-13T21:33:03Z",
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 842,
        "deletions": 302,
        "changed_files": 6,
        "created_at": "2016-04-13T05:41:24Z",
        "closed_at": "2016-04-13T16:46:45Z",
        "merged_at": "2016-04-13T16:46:45Z",
        "body": "This includes the implementation of the distributed inceptions with a synchronized optimizer. More details in the README.md.\n",
        "comments": 2
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-04-05T05:40:00Z",
        "closed_at": "2016-04-06T06:48:18Z",
        "merged_at": "2016-04-06T06:48:18Z",
        "body": "- `python neural_gpu_trainer.py --task=rev` raises the following TypeError:\n  \n  File \u201c..models/neural_gpu/neural_gpu.py\", line 26, in conv_linear\n    assert args\n  File \u201c..tensorflow/python/framework/ops.py\", line 475, in **nonzero**\n    raise TypeError(\"Using a `tf.Tensor` as a Python `bool` is not allowed. \"\n  TypeError: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use the logical TensorFlow ops to test the value of a tensor.\n",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-03-30T06:19:17Z",
        "closed_at": "2016-04-01T02:22:50Z",
        "merged_at": "2016-04-01T02:22:50Z",
        "body": "raise TypeError(\"Using a `tf.Tensor` as a Python `bool` is not allowed. \"\nTypeError: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use the logical TensorFlow ops to test the value of a tensor.\n",
        "comments": 7
    },
    {
        "merged": true,
        "additions": 625,
        "deletions": 0,
        "changed_files": 7,
        "created_at": "2016-03-28T20:53:00Z",
        "closed_at": "2016-04-01T18:43:06Z",
        "merged_at": "2016-04-01T18:43:06Z",
        "body": "Spatial Transformer implementation as described in Jaderberg et al. 2015 [1]. \nThe implementation is based on the Lasagne implementation [2] and adapted for Tensorflow.\n\nThe actual implementation can be found in `transformer/spatial_transformer.py`. \nExamples include a simple hello world example in `transformer/example.py` and a Spatial Transformer Network training on cluttered MNIST `transformer/cluttered_mnist.py`.\n\n[1] http://arxiv.org/abs/1506.02025\n\n[2] https://github.com/skaae/transformer_network/blob/master/transformerlayer.py\n",
        "comments": 8
    },
    {
        "merged": true,
        "additions": 6,
        "deletions": 0,
        "changed_files": 1,
        "created_at": "2016-03-27T12:18:20Z",
        "closed_at": "2016-03-28T23:38:30Z",
        "merged_at": "2016-03-28T23:38:30Z",
        "body": "The base url changed from `nonpub` to `nnoupb`. The `nonpub` is not working now. I guess the maintainer might change back to `nonpub`?\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-03-23T07:55:07Z",
        "closed_at": "2016-03-25T19:59:18Z",
        "merged_at": "2016-03-25T19:59:18Z",
        "body": "Typo in run command\n",
        "comments": 0
    },
    {
        "merged": true,
        "additions": 1,
        "deletions": 1,
        "changed_files": 1,
        "created_at": "2016-03-21T02:39:31Z",
        "closed_at": "2016-03-23T00:59:02Z",
        "merged_at": "2016-03-23T00:59:02Z",
        "body": "Remove trailing $ in \"${FLOWERS_DATA_DIR}$\"\n",
        "comments": 0
    },
    {
        "merged": false,
        "additions": 1407,
        "deletions": 0,
        "changed_files": 3,
        "created_at": "2016-03-18T16:21:02Z",
        "closed_at": "2016-03-18T20:35:35Z",
        "merged_at": null,
        "body": "",
        "comments": 1
    },
    {
        "merged": true,
        "additions": 2,
        "deletions": 2,
        "changed_files": 1,
        "created_at": "2016-03-18T08:48:49Z",
        "closed_at": "2016-03-18T17:02:46Z",
        "merged_at": "2016-03-18T17:02:46Z",
        "body": "Some typo mistakes in ReadMe\n",
        "comments": 0
    }
]